#!/usr/bin/env python3
"""æ£€æŸ¥ææ…ŒæŒ‡æ•°æ•°æ®è´¨é‡"""
import json
from datetime import datetime

def check_data_file(file_path):
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    print(f"\n{'='*60}")
    print(f"æ£€æŸ¥æ–‡ä»¶: {file_path}")
    print('='*60)
    
    with open(file_path, 'r') as f:
        lines = f.readlines()
    
    print(f"æ€»è®°å½•æ•°: {len(lines)}")
    
    # æ£€æŸ¥é”™è¯¯æ•°æ®
    errors = []
    valid_records = []
    
    for i, line in enumerate(lines, 1):
        try:
            data = json.loads(line.strip())
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['panic_index', 'beijing_time', 'liquidation_data']
            missing_fields = [f for f in required_fields if f not in data]
            
            if missing_fields:
                errors.append({
                    'line': i,
                    'error': f'ç¼ºå°‘å­—æ®µ: {missing_fields}',
                    'data': line[:100]
                })
                continue
            
            # æ£€æŸ¥panic_indexæ˜¯å¦åˆç†
            panic_index = data.get('panic_index', 0)
            if panic_index < 0 or panic_index > 100:
                errors.append({
                    'line': i,
                    'error': f'panic_indexå¼‚å¸¸: {panic_index}',
                    'time': data.get('beijing_time'),
                    'data': line[:100]
                })
                continue
            
            # æ£€æŸ¥æ—¶é—´æ ¼å¼
            try:
                datetime.strptime(data['beijing_time'], '%Y-%m-%d %H:%M:%S')
            except:
                errors.append({
                    'line': i,
                    'error': f'æ—¶é—´æ ¼å¼é”™è¯¯: {data.get("beijing_time")}',
                    'data': line[:100]
                })
                continue
            
            valid_records.append(data)
            
        except json.JSONDecodeError as e:
            errors.append({
                'line': i,
                'error': f'JSONè§£æé”™è¯¯: {e}',
                'data': line[:100]
            })
    
    print(f"âœ… æœ‰æ•ˆè®°å½•: {len(valid_records)}")
    print(f"âŒ é”™è¯¯è®°å½•: {len(errors)}")
    
    if errors:
        print(f"\nâš ï¸ å‘ç° {len(errors)} ä¸ªé”™è¯¯è®°å½•:")
        for err in errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"  è¡Œ{err['line']}: {err['error']}")
            if 'time' in err:
                print(f"    æ—¶é—´: {err['time']}")
    
    # ç»Ÿè®¡æ—¥æœŸåˆ†å¸ƒ
    if valid_records:
        dates = {}
        for record in valid_records:
            date = record['beijing_time'].split(' ')[0]
            dates[date] = dates.get(date, 0) + 1
        
        print(f"\nğŸ“… æ—¥æœŸåˆ†å¸ƒ:")
        for date in sorted(dates.keys()):
            print(f"  {date}: {dates[date]}æ¡")
    
    return valid_records, errors

# æ£€æŸ¥ä¸»æ–‡ä»¶
valid_records, errors = check_data_file('data/panic_jsonl/panic_wash_index.jsonl')

print(f"\n{'='*60}")
print("æ€»ç»“")
print('='*60)
print(f"âœ… æ€»æœ‰æ•ˆè®°å½•: {len(valid_records)}")
print(f"âŒ æ€»é”™è¯¯è®°å½•: {len(errors)}")

if len(errors) > 0:
    print(f"\nå»ºè®®: ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¸…ç†é”™è¯¯æ•°æ®")
    print(f"  python3 clean_panic_data.py")
