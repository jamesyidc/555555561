#!/usr/bin/env python3
"""
ç”Ÿæˆé¦–é¡µç³»ç»Ÿçš„æ¯æ—¥æ•°æ®è¯¦æƒ…æŠ¥å‘Š
"""
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict

def analyze_jsonl_files(directory):
    """åˆ†æJSONLæ–‡ä»¶çš„æ¯æ—¥æ•°æ®"""
    files = list(Path(directory).glob("*.jsonl"))
    if not files:
        return None
    
    daily_stats = {}
    total_records = 0
    
    for file in sorted(files):
        # æå–æ—¥æœŸ
        date = None
        filename = file.stem
        
        # å°è¯•ä»æ–‡ä»¶åæå–æ—¥æœŸ
        parts = filename.split('_')
        for part in parts:
            if len(part) == 10 and part.count('-') == 2:  # YYYY-MM-DD
                date = part
                break
            elif len(part) == 8 and part.isdigit():  # YYYYMMDD
                date = f"{part[:4]}-{part[4:6]}-{part[6:8]}"
                break
        
        # ç»Ÿè®¡è®°å½•æ•°
        try:
            with open(file, 'r', encoding='utf-8') as f:
                record_count = sum(1 for line in f if line.strip())
        except:
            record_count = 0
        
        file_size = file.stat().st_size / 1024  # KB
        
        if date:
            if date not in daily_stats:
                daily_stats[date] = {
                    'files': [],
                    'total_records': 0,
                    'total_size': 0
                }
            
            daily_stats[date]['files'].append(file.name)
            daily_stats[date]['total_records'] += record_count
            daily_stats[date]['total_size'] += file_size
        
        total_records += record_count
    
    return {
        'daily_stats': daily_stats,
        'total_files': len(files),
        'total_records': total_records,
        'date_range': f"{min(daily_stats.keys())} ~ {max(daily_stats.keys())}" if daily_stats else "N/A",
        'days_count': len(daily_stats)
    }

# æœ‰JSONLæ•°æ®çš„8ä¸ªç³»ç»Ÿ
SYSTEMS_WITH_DATA = {
    "SARè¶‹åŠ¿ç³»ç»Ÿ": {
        "dirs": ["sar_jsonl", "sar_slope_jsonl", "sar_1min", "sar_bias_stats"],
        "color": "ğŸŸ¢"
    },
    "æ”¯æ’‘å‹åŠ›(å¤§ç›˜)": {
        "dirs": ["support_resistance_jsonl", "support_resistance_daily"],
        "color": "ğŸ”µ"
    },
    "OKXå…¨ç”Ÿæ€": {
        "dirs": ["okx_trading_jsonl", "okx_trading_history", "okx_trading_logs", 
                "okx_angle_analysis", "okx_auto_strategy", "okx_tpsl_settings"],
        "color": "ğŸŸ¡"
    },
    "OKXæ—¥æ¶¨å¹…ç»Ÿè®¡æ—¥è®°": {
        "dirs": ["okx_day_change"],
        "color": "ğŸŸ "
    },
    "ææ…Œç›‘æ§æ´—ç›˜": {
        "dirs": ["panic_jsonl", "panic_daily"],
        "color": "ğŸ”´"
    },
    "11ä¿¡å·æ—¥çº¿æ€»": {
        "dirs": ["signal_stats"],
        "color": "ğŸŸ£"
    },
    "é€ƒé¡¶ä¿¡å·ç³»ç»Ÿ": {
        "dirs": ["escape_signal_jsonl"],
        "color": "ğŸŸ¤"
    },
    "ä»·æ ¼ä½ç½®é¢„è­¦ç³»ç»Ÿ": {
        "dirs": ["price_speed_jsonl", "price_speed_10m", "price_position"],
        "color": "âšª"
    }
}

def main():
    data_base = Path("/home/user/webapp/data")
    
    print("="*80)
    print("é¦–é¡µç³»ç»Ÿæ¯æ—¥æ•°æ®è¯¦æƒ…æŠ¥å‘Š")
    print(f"æ‰«ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    all_systems_stats = {}
    
    for system_name, info in SYSTEMS_WITH_DATA.items():
        print(f"\n{info['color']} {system_name}")
        print("-" * 80)
        
        system_total_files = 0
        system_total_records = 0
        system_total_days = set()
        system_daily_details = defaultdict(lambda: {'records': 0, 'files': [], 'size': 0})
        
        for dir_name in info['dirs']:
            dir_path = data_base / dir_name
            if not dir_path.exists():
                continue
            
            result = analyze_jsonl_files(dir_path)
            if not result:
                continue
            
            system_total_files += result['total_files']
            system_total_records += result['total_records']
            
            print(f"\n  ğŸ“ {dir_name}/")
            print(f"     â€¢ æ–‡ä»¶æ•°: {result['total_files']}")
            print(f"     â€¢ æ€»è®°å½•æ•°: {result['total_records']:,}")
            print(f"     â€¢ æ—¥æœŸèŒƒå›´: {result['date_range']}")
            print(f"     â€¢ æ•°æ®å¤©æ•°: {result['days_count']} å¤©")
            
            if result['daily_stats']:
                print(f"     â€¢ æ¯æ—¥è¯¦æƒ…:")
                for date in sorted(result['daily_stats'].keys()):
                    stats = result['daily_stats'][date]
                    system_total_days.add(date)
                    system_daily_details[date]['records'] += stats['total_records']
                    system_daily_details[date]['files'].extend(stats['files'])
                    system_daily_details[date]['size'] += stats['total_size']
                    
                    print(f"       - {date}: {stats['total_records']:,} æ¡è®°å½•, "
                          f"{stats['total_size']:.2f} KB, "
                          f"{len(stats['files'])} æ–‡ä»¶")
        
        # ç³»ç»Ÿæ€»è®¡
        print(f"\n  ğŸ“Š ç³»ç»Ÿæ±‡æ€»:")
        print(f"     â€¢ æ€»æ–‡ä»¶æ•°: {system_total_files}")
        print(f"     â€¢ æ€»è®°å½•æ•°: {system_total_records:,}")
        print(f"     â€¢ æ•°æ®å¤©æ•°: {len(system_total_days)} å¤©")
        
        if system_total_days:
            print(f"     â€¢ æ—¶é—´è·¨åº¦: {min(system_total_days)} ~ {max(system_total_days)}")
            
            # æ˜¾ç¤ºæ¯æ—¥æ±‡æ€»ï¼ˆå¦‚æœæœ‰å¤šä¸ªå­ç›®å½•ï¼‰
            if len(info['dirs']) > 1:
                print(f"\n  ğŸ“… æ¯æ—¥æ±‡æ€» (æ‰€æœ‰å­ç›®å½•åˆå¹¶):")
                for date in sorted(system_daily_details.keys()):
                    details = system_daily_details[date]
                    print(f"     {date}: {details['records']:,} æ¡è®°å½•, "
                          f"{details['size']:.2f} KB, "
                          f"{len(details['files'])} æ–‡ä»¶")
        
        all_systems_stats[system_name] = {
            'files': system_total_files,
            'records': system_total_records,
            'days': len(system_total_days),
            'date_range': f"{min(system_total_days)} ~ {max(system_total_days)}" if system_total_days else "N/A"
        }
    
    # æ€»ä½“ç»Ÿè®¡
    print("\n" + "="*80)
    print("æ€»ä½“ç»Ÿè®¡")
    print("="*80)
    
    total_files = sum(s['files'] for s in all_systems_stats.values())
    total_records = sum(s['records'] for s in all_systems_stats.values())
    
    print(f"\næœ‰JSONLæ•°æ®çš„ç³»ç»Ÿæ•°: {len(all_systems_stats)}")
    print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"æ€»è®°å½•æ•°: {total_records:,}")
    
    print(f"\nå„ç³»ç»Ÿæ•°æ®å¤©æ•°:")
    for system_name, stats in sorted(all_systems_stats.items(), 
                                     key=lambda x: x[1]['days'], 
                                     reverse=True):
        print(f"  â€¢ {system_name}: {stats['days']} å¤© ({stats['date_range']})")
    
    # æ— JSONLæ•°æ®çš„ç³»ç»Ÿè¯´æ˜
    print("\n" + "="*80)
    print("æ— JSONLæ•°æ®çš„ç³»ç»Ÿè¯´æ˜ (6ä¸ª)")
    print("="*80)
    
    no_data_systems = {
        "OKXåˆ©æ¶¦åˆ†æ": "åŸºäºOKXäº¤æ˜“æ•°æ®å®æ—¶è®¡ç®—åˆ©æ¶¦ï¼Œä¸ç‹¬ç«‹å­˜å‚¨JSONL",
        "æ•°æ®ç®¡ç†ä¸å¤‡ä»½": "çº¯Webç®¡ç†å·¥å…·ï¼Œç”¨äºç®¡ç†å…¶ä»–ç³»ç»Ÿçš„JSONLæ•°æ®",
        "é‡å¤§äº‹ä»¶ç›‘æ§": "èšåˆå¤šä¸ªç³»ç»Ÿçš„äº‹ä»¶æ•°æ®ï¼Œä¸ç‹¬ç«‹å­˜å‚¨JSONL",
        "æ•°æ®å¥åº·ç›‘æ§": "ç›‘æ§å…¶ä»–ç³»ç»Ÿçš„æ•°æ®å¥åº·çŠ¶æ€ï¼Œä¸ç‹¬ç«‹å­˜å‚¨JSONL",
        "ZTè¡Œé«˜è·Œç›˜é¢„è­¦ç³»ç»Ÿ": "å¯èƒ½å°šæœªå®ç°æ•°æ®é‡‡é›†åŠŸèƒ½",
        "æ”¯æ’‘å‹åŠ›ç³»ç»Ÿé…ç½®": "çº¯é…ç½®é¡µé¢ï¼Œç”¨äºè®¾ç½®ç³»ç»Ÿå‚æ•°"
    }
    
    for system, reason in no_data_systems.items():
        print(f"\nâšª {system}")
        print(f"   åŸå› : {reason}")

if __name__ == "__main__":
    main()
