#!/usr/bin/env python3
"""
æ•°æ®ç®¡ç†ç³»ç»Ÿ - ç»Ÿè®¡å’Œç®¡ç†æ‰€æœ‰JSONLæ•°æ®
æ‰«ædataç›®å½•ä¸‹çš„æ‰€æœ‰JSONLæ–‡ä»¶ï¼Œç»Ÿè®¡æ•°æ®é‡å’Œæ—¥æœŸèŒƒå›´
"""
import os
import json
from datetime import datetime
from collections import defaultdict
from pathlib import Path

class DataManager:
    def __init__(self, data_dir='data'):
        self.data_dir = Path(data_dir)
        self.stats = {}
        
    def scan_all_data(self):
        """æ‰«ææ‰€æœ‰JSONLæ–‡ä»¶å¹¶ç»Ÿè®¡"""
        print(f"ğŸ” å¼€å§‹æ‰«ææ•°æ®ç›®å½•: {self.data_dir}")
        
        # æŒ‰å­ç›®å½•åˆ†ç±»ç»Ÿè®¡
        dir_stats = defaultdict(lambda: {
            'files': [],
            'total_records': 0,
            'total_size': 0,
            'date_range': {'min': None, 'max': None}
        })
        
        # éå†æ‰€æœ‰JSONLæ–‡ä»¶
        for jsonl_file in self.data_dir.rglob('*.jsonl'):
            relative_path = jsonl_file.relative_to(self.data_dir)
            parent_dir = str(relative_path.parent) if relative_path.parent != Path('.') else 'root'
            
            # ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯
            file_info = self.analyze_file(jsonl_file)
            
            # æ·»åŠ åˆ°ç›®å½•ç»Ÿè®¡
            dir_stats[parent_dir]['files'].append({
                'name': jsonl_file.name,
                'path': str(relative_path),
                'records': file_info['records'],
                'size': file_info['size'],
                'size_mb': file_info['size_mb'],
                'dates': file_info['dates'],
                'modified': file_info['modified']
            })
            
            dir_stats[parent_dir]['total_records'] += file_info['records']
            dir_stats[parent_dir]['total_size'] += file_info['size']
            
            # æ›´æ–°æ—¥æœŸèŒƒå›´
            if file_info['dates']['min']:
                if not dir_stats[parent_dir]['date_range']['min'] or \
                   file_info['dates']['min'] < dir_stats[parent_dir]['date_range']['min']:
                    dir_stats[parent_dir]['date_range']['min'] = file_info['dates']['min']
                    
            if file_info['dates']['max']:
                if not dir_stats[parent_dir]['date_range']['max'] or \
                   file_info['dates']['max'] > dir_stats[parent_dir]['date_range']['max']:
                    dir_stats[parent_dir]['date_range']['max'] = file_info['dates']['max']
        
        self.stats = dict(dir_stats)
        return self.stats
    
    def analyze_file(self, file_path):
        """åˆ†æå•ä¸ªJSONLæ–‡ä»¶"""
        records = 0
        dates = {'min': None, 'max': None}
        
        try:
            # ç»Ÿè®¡è¡Œæ•°
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        records += 1
                        
                        # å°è¯•æå–æ—¥æœŸä¿¡æ¯
                        try:
                            data = json.loads(line)
                            date_str = self.extract_date(data)
                            if date_str:
                                if not dates['min'] or date_str < dates['min']:
                                    dates['min'] = date_str
                                if not dates['max'] or date_str > dates['max']:
                                    dates['max'] = date_str
                        except:
                            pass
            
            # æ–‡ä»¶å¤§å°
            size = os.path.getsize(file_path)
            size_mb = round(size / (1024 * 1024), 2)
            
            # ä¿®æ”¹æ—¶é—´
            modified = datetime.fromtimestamp(os.path.getmtime(file_path)).strftime('%Y-%m-%d %H:%M:%S')
            
            return {
                'records': records,
                'size': size,
                'size_mb': size_mb,
                'dates': dates,
                'modified': modified
            }
        except Exception as e:
            print(f"  âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return {
                'records': 0,
                'size': 0,
                'size_mb': 0,
                'dates': dates,
                'modified': 'unknown'
            }
    
    def extract_date(self, data):
        """ä»JSONæ•°æ®ä¸­æå–æ—¥æœŸ"""
        # å¸¸è§çš„æ—¥æœŸå­—æ®µ
        date_fields = ['date', 'time', 'timestamp', 'snapshot_time', 'created_at', 'updated_at']
        
        for field in date_fields:
            if field in data:
                value = data[field]
                if isinstance(value, str):
                    # æå–æ—¥æœŸéƒ¨åˆ† (YYYY-MM-DD)
                    if len(value) >= 10:
                        return value[:10]
        
        return None
    
    def print_summary(self):
        """æ‰“å°ç»Ÿè®¡æ‘˜è¦"""
        if not self.stats:
            print("âš ï¸ æ²¡æœ‰ç»Ÿè®¡æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ scan_all_data()")
            return
        
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡æ‘˜è¦")
        print("="*80)
        
        # æ€»ä½“ç»Ÿè®¡
        total_dirs = len(self.stats)
        total_files = sum(len(d['files']) for d in self.stats.values())
        total_records = sum(d['total_records'] for d in self.stats.values())
        total_size_mb = sum(d['total_size'] for d in self.stats.values()) / (1024 * 1024)
        
        print(f"\nğŸ“ æ€»ç›®å½•æ•°: {total_dirs}")
        print(f"ğŸ“„ æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"ğŸ“ æ€»è®°å½•æ•°: {total_records:,}")
        print(f"ğŸ’¾ æ€»å¤§å°: {total_size_mb:.2f} MB")
        
        # æŒ‰ç›®å½•ç»Ÿè®¡
        print("\n" + "-"*80)
        print("ğŸ“‚ å„ç³»ç»Ÿæ•°æ®ç»Ÿè®¡")
        print("-"*80)
        
        # æ’åºï¼šæŒ‰è®°å½•æ•°é™åº
        sorted_dirs = sorted(self.stats.items(), key=lambda x: x[1]['total_records'], reverse=True)
        
        for dir_name, info in sorted_dirs:
            print(f"\nğŸ“ {dir_name}")
            print(f"   æ–‡ä»¶æ•°: {len(info['files'])} ä¸ª")
            print(f"   è®°å½•æ•°: {info['total_records']:,} æ¡")
            print(f"   å¤§å°: {info['total_size'] / (1024 * 1024):.2f} MB")
            
            if info['date_range']['min'] and info['date_range']['max']:
                date_min = info['date_range']['min']
                date_max = info['date_range']['max']
                
                # è®¡ç®—å¤©æ•°
                try:
                    d1 = datetime.strptime(date_min, '%Y-%m-%d')
                    d2 = datetime.strptime(date_max, '%Y-%m-%d')
                    days = (d2 - d1).days + 1
                    print(f"   æ—¥æœŸèŒƒå›´: {date_min} è‡³ {date_max} ({days} å¤©)")
                except:
                    print(f"   æ—¥æœŸèŒƒå›´: {date_min} è‡³ {date_max}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†æ–‡ä»¶
            if len(info['files']) <= 5:
                for file_info in info['files']:
                    print(f"      â€¢ {file_info['name']}: {file_info['records']} æ¡è®°å½•")
            else:
                print(f"      â€¢ æœ€è¿‘çš„5ä¸ªæ–‡ä»¶:")
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
                sorted_files = sorted(info['files'], key=lambda x: x['modified'], reverse=True)
                for file_info in sorted_files[:5]:
                    print(f"        - {file_info['name']}: {file_info['records']} æ¡, {file_info['size_mb']} MB, ä¿®æ”¹äº {file_info['modified']}")
    
    def save_report(self, output_file='data_statistics.json'):
        """ä¿å­˜ç»Ÿè®¡æŠ¥å‘Šä¸ºJSON"""
        report = {
            'scan_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'total_directories': len(self.stats),
                'total_files': sum(len(d['files']) for d in self.stats.values()),
                'total_records': sum(d['total_records'] for d in self.stats.values()),
                'total_size_mb': sum(d['total_size'] for d in self.stats.values()) / (1024 * 1024)
            },
            'directories': self.stats
        }
        
        output_path = Path(output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        return output_path

if __name__ == '__main__':
    # è¿è¡Œæ•°æ®ç®¡ç†å™¨
    manager = DataManager(data_dir='data')
    
    print("ğŸš€ å¯åŠ¨æ•°æ®ç®¡ç†ç³»ç»Ÿ...")
    stats = manager.scan_all_data()
    
    # æ‰“å°æ‘˜è¦
    manager.print_summary()
    
    # ä¿å­˜æŠ¥å‘Š
    manager.save_report('data/data_statistics.json')
    
    print("\nâœ… æ•°æ®æ‰«æå®Œæˆï¼")
