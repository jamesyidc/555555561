#!/usr/bin/env python3
"""
é‡æ–°å¯¼å…¥levelç±»å‹çš„å†å²æ•°æ®
ä»æ¯ç§’çº§çš„å¸ç§è¯¦ç»†æ•°æ®èšåˆä¸ºæ¯åˆ†é’Ÿçº§çš„æ±‡æ€»æ•°æ®
"""

import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict
import pytz

# é…ç½®
DATA_DIR = Path("/home/user/webapp/data/support_resistance_daily")
DB_PATH = "/home/user/webapp/price_position_v2/config/data/db/price_position.db"
JSONL_OUTPUT_DIR = Path("/home/user/webapp/price_position_v2/data/timeline_jsonl")

# æ—¶åŒº
BJ_TZ = pytz.timezone('Asia/Shanghai')

def process_level_records(jsonl_file, target_date):
    """
    å¤„ç†levelç±»å‹è®°å½•ï¼Œèšåˆä¸ºæ¯åˆ†é’Ÿæ•°æ®
    
    Args:
        jsonl_file: åŸå§‹JSONLæ–‡ä»¶è·¯å¾„
        target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)
    
    Returns:
        list: æ¯åˆ†é’Ÿèšåˆåçš„æ•°æ®ç‚¹åˆ—è¡¨
    """
    print(f"ğŸ“‚ å¤„ç†æ–‡ä»¶: {jsonl_file}")
    
    # æŒ‰åˆ†é’Ÿåˆ†ç»„
    minute_groups = defaultdict(list)
    
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            
            try:
                record = json.loads(line)
                
                # åªå¤„ç†levelç±»å‹
                if record.get('type') != 'level':
                    continue
                
                # æå–dataå­—æ®µï¼ˆå¸ç§è¯¦ç»†æ•°æ®ï¼‰
                data = record.get('data', {})
                if not data:
                    continue
                
                # è·å–æ—¶é—´æˆ³ï¼ˆä»recordæˆ–dataä¸­ï¼‰
                record_time = data.get('record_time_beijing') or data.get('record_time') or record.get('timestamp')
                if not record_time:
                    continue
                
                # è§£ææ—¶é—´ï¼Œå‘ä¸‹å–æ•´åˆ°åˆ†é’Ÿ
                if 'T' in record_time:
                    dt = datetime.fromisoformat(record_time.replace('T', ' ').replace('Z', ''))
                else:
                    dt = datetime.strptime(record_time, '%Y-%m-%d %H:%M:%S')
                
                minute_key = dt.replace(second=0).strftime('%Y-%m-%d %H:%M:00')
                
                # æ·»åŠ åˆ°å¯¹åº”åˆ†é’Ÿç»„ï¼ˆå­˜å‚¨dataå­—æ®µï¼‰
                minute_groups[minute_key].append(data)
                
            except Exception as e:
                print(f"âš ï¸  è¡Œ {line_num} è§£æå¤±è´¥: {e}")
                continue
    
    print(f"âœ… å…±è¯»å– {sum(len(v) for v in minute_groups.values())} æ¡levelè®°å½•")
    print(f"âœ… èšåˆä¸º {len(minute_groups)} ä¸ªåˆ†é’Ÿçº§æ•°æ®ç‚¹")
    
    # èšåˆæ¯åˆ†é’Ÿçš„æ•°æ®
    minute_data = []
    
    for minute_time in sorted(minute_groups.keys()):
        records = minute_groups[minute_time]
        
        # ç»Ÿè®¡å„ç±»å¸ç§æ•°é‡
        support_48h_count = 0
        support_7d_count = 0
        pressure_48h_count = 0
        pressure_7d_count = 0
        
        support_48h_symbols = []
        support_7d_symbols = []
        pressure_48h_symbols = []
        pressure_7d_symbols = []
        
        for rec in records:
            symbol = rec.get('symbol', '')
            
            # æ”¯æ’‘çº¿1 (48å°æ—¶)
            dist_support_48h = rec.get('distance_to_support_1', 100)
            if dist_support_48h <= 5:
                support_48h_count += 1
                support_48h_symbols.append(symbol)
            
            # æ”¯æ’‘çº¿2 (7å¤©)
            dist_support_7d = rec.get('distance_to_support_2', 100)
            if dist_support_7d <= 5:
                support_7d_count += 1
                support_7d_symbols.append(symbol)
            
            # å‹åŠ›çº¿1 (48å°æ—¶)
            position_48h = rec.get('position_48h', 0)
            if position_48h >= 95:
                pressure_48h_count += 1
                pressure_48h_symbols.append(symbol)
            
            # å‹åŠ›çº¿2 (7å¤©)
            position_7d = rec.get('position_7d', 0)
            if position_7d >= 95:
                pressure_7d_count += 1
                pressure_7d_symbols.append(symbol)
        
        # åˆ¤å®šä¿¡å·ç±»å‹
        signal_type = 'none'
        signal_triggered = 0
        trigger_reason = ''
        
        # æŠ„åº•ä¿¡å·
        if (support_48h_count >= 1 and 
            support_7d_count >= 1 and 
            support_48h_count + support_7d_count >= 20):
            signal_type = 'buy'
            signal_triggered = 1
            trigger_reason = f'æ”¯æ’‘çº¿1={support_48h_count}, æ”¯æ’‘çº¿2={support_7d_count}, æ€»å’Œ={support_48h_count + support_7d_count}'
        
        # é€ƒé¡¶ä¿¡å·
        elif (pressure_48h_count >= 1 and 
              pressure_7d_count >= 1 and 
              pressure_48h_count + pressure_7d_count >= 8):
            signal_type = 'sell'
            signal_triggered = 1
            trigger_reason = f'å‹åŠ›çº¿1={pressure_48h_count}, å‹åŠ›çº¿2={pressure_7d_count}, æ€»å’Œ={pressure_48h_count + pressure_7d_count}'
        
        # æ„å»ºæ•°æ®ç‚¹
        data_point = {
            'snapshot_time': minute_time,
            'support_line_48h': support_48h_count,
            'support_line_7d': support_7d_count,
            'pressure_line_48h': pressure_48h_count,
            'pressure_line_7d': pressure_7d_count,
            'signal_type': signal_type,
            'signal_triggered': signal_triggered,
            'trigger_reason': trigger_reason,
            'detail_data': {
                'support_48h_symbols': support_48h_symbols,
                'support_7d_symbols': support_7d_symbols,
                'pressure_48h_symbols': pressure_48h_symbols,
                'pressure_7d_symbols': pressure_7d_symbols
            }
        }
        
        minute_data.append(data_point)
    
    return minute_data


def write_to_database(data_points, target_date):
    """
    å°†æ•°æ®ç‚¹å†™å…¥æ•°æ®åº“
    
    Args:
        data_points: æ•°æ®ç‚¹åˆ—è¡¨
        target_date: ç›®æ ‡æ—¥æœŸ
    """
    if not data_points:
        print(f"âš ï¸  {target_date}: æ— æ•°æ®ç‚¹ï¼Œè·³è¿‡")
        return
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # å…ˆåˆ é™¤è¯¥æ—¥æœŸçš„æ—§æ•°æ®
    cursor.execute("""
        DELETE FROM signal_timeline 
        WHERE date(snapshot_time) = ?
    """, (target_date,))
    
    deleted_count = cursor.rowcount
    print(f"ğŸ—‘ï¸  åˆ é™¤ {target_date} çš„æ—§æ•°æ®: {deleted_count} æ¡")
    
    # æ’å…¥æ–°æ•°æ®
    inserted_count = 0
    
    for point in data_points:
        try:
            cursor.execute("""
                INSERT INTO signal_timeline (
                    snapshot_time,
                    support_line_48h,
                    support_line_7d,
                    pressure_line_48h,
                    pressure_line_7d,
                    signal_type,
                    signal_triggered,
                    trigger_reason,
                    detail_data
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                point['snapshot_time'],
                point['support_line_48h'],
                point['support_line_7d'],
                point['pressure_line_48h'],
                point['pressure_line_7d'],
                point['signal_type'],
                point['signal_triggered'],
                point['trigger_reason'],
                json.dumps(point['detail_data'], ensure_ascii=False)
            ))
            inserted_count += 1
        except Exception as e:
            print(f"âš ï¸  æ’å…¥å¤±è´¥ {point['snapshot_time']}: {e}")
    
    conn.commit()
    conn.close()
    
    print(f"âœ… {target_date}: æ’å…¥ {inserted_count} æ¡æ–°æ•°æ®")


def write_to_jsonl(data_points, target_date):
    """
    å°†æ•°æ®ç‚¹å†™å…¥JSONLæ–‡ä»¶
    
    Args:
        data_points: æ•°æ®ç‚¹åˆ—è¡¨
        target_date: ç›®æ ‡æ—¥æœŸ
    """
    if not data_points:
        return
    
    JSONL_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    output_file = JSONL_OUTPUT_DIR / f"{target_date}.jsonl"
    
    # å¤‡ä»½ç°æœ‰æ–‡ä»¶
    if output_file.exists():
        backup_file = output_file.with_suffix('.jsonl.backup')
        output_file.rename(backup_file)
        print(f"ğŸ“¦ å¤‡ä»½æ—§æ–‡ä»¶: {backup_file}")
    
    # å†™å…¥æ–°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        for point in data_points:
            f.write(json.dumps(point, ensure_ascii=False) + '\n')
    
    print(f"ğŸ’¾ å†™å…¥JSONL: {output_file} ({len(data_points)} æ¡)")


def main():
    """
    ä¸»å‡½æ•°ï¼šå¤„ç†æ‰€æœ‰å†å²æ—¥æœŸ
    """
    print("=" * 80)
    print("ğŸš€ å¼€å§‹é‡æ–°å¯¼å…¥levelç±»å‹å†å²æ•°æ®")
    print("=" * 80)
    
    # è·å–æ‰€æœ‰JSONLæ–‡ä»¶
    jsonl_files = sorted(DATA_DIR.glob("support_resistance_*.jsonl"))
    
    print(f"\nğŸ“Š æ‰¾åˆ° {len(jsonl_files)} ä¸ªå†å²æ–‡ä»¶")
    
    total_files = 0
    total_points = 0
    
    for jsonl_file in jsonl_files:
        # ä»æ–‡ä»¶åæå–æ—¥æœŸ
        filename = jsonl_file.stem  # support_resistance_20260121
        date_str = filename.split('_')[-1]  # 20260121
        
        try:
            target_date = datetime.strptime(date_str, '%Y%m%d').strftime('%Y-%m-%d')
        except:
            print(f"âš ï¸  æ— æ³•è§£ææ—¥æœŸ: {filename}")
            continue
        
        print(f"\n" + "=" * 80)
        print(f"ğŸ“… å¤„ç†æ—¥æœŸ: {target_date}")
        print("=" * 80)
        
        # å¤„ç†levelè®°å½•
        data_points = process_level_records(jsonl_file, target_date)
        
        if not data_points:
            print(f"âš ï¸  {target_date}: æ— æœ‰æ•ˆæ•°æ®ç‚¹")
            continue
        
        # å†™å…¥æ•°æ®åº“
        write_to_database(data_points, target_date)
        
        # å†™å…¥JSONL
        write_to_jsonl(data_points, target_date)
        
        total_files += 1
        total_points += len(data_points)
        
        print(f"âœ… {target_date}: å®Œæˆ")
    
    print("\n" + "=" * 80)
    print("ğŸ‰ å…¨éƒ¨å¯¼å…¥å®Œæˆ!")
    print("=" * 80)
    print(f"ğŸ“Š å¤„ç†æ–‡ä»¶æ•°: {total_files}")
    print(f"ğŸ“Š æ€»æ•°æ®ç‚¹æ•°: {total_points}")
    print(f"ğŸ“Š å¹³å‡æ¯æ–‡ä»¶: {total_points // total_files if total_files > 0 else 0} ä¸ªæ•°æ®ç‚¹")
    print("=" * 80)


if __name__ == '__main__':
    main()
