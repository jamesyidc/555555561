#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OKXè¶‹åŠ¿è§’åº¦åˆ†æå™¨ V3 - å¢å¼ºç‰ˆ
æ£€æµ‹æ‰€æœ‰æ˜¾è‘—å³°å€¼ï¼Œä¸é™äºæ¯å°æ—¶ä¸€ä¸ª
"""

import json
import os
import math
from datetime import datetime, timedelta
from collections import defaultdict

# ä½¿ç”¨ç»å¯¹è·¯å¾„æŒ‡å‘ /home/user/webapp/data
BASE_DIR = '/home/user/webapp'
DATA_DIR = os.path.join(BASE_DIR, 'data')
COIN_TRACKER_DIR = os.path.join(DATA_DIR, 'coin_change_tracker')
OUTPUT_DIR = os.path.join(DATA_DIR, 'okx_angle_analysis')

# å›¾è¡¨å‚æ•°
CHART_WIDTH_PX = 800
CHART_HEIGHT_PX = 400
CHART_TIME_RANGE_MIN = 600
CHART_PRICE_RANGE_PCT = 100

# å³°å€¼æ£€æµ‹å‚æ•°
MIN_PEAK_VALUE = 5  # æœ€å°å³°å€¼ï¼ˆ%ï¼‰- é™ä½åˆ°5%ä»¥æ•è·æ›´å¤šå°å³°å€¼
MIN_PEAK_DISTANCE = 30  # æœ€å°å³°å€¼é—´è·ï¼ˆåˆ†é’Ÿï¼‰
MIN_VALLEY_TIME_GAP = 2  # Cç‚¹ä¸Aç‚¹çš„æœ€å°æ—¶é—´é—´éš”ï¼ˆåˆ†é’Ÿï¼‰

def load_trend_data(date_str):
    file_path = os.path.join(COIN_TRACKER_DIR, f'coin_change_{date_str}.jsonl')
    
    if not os.path.exists(file_path):
        print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return []
    
    data_points = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    item = json.loads(line)
                    # ä»beijing_timeæå–æ—¶é—´éƒ¨åˆ†ï¼ˆHH:MM:SSï¼‰
                    beijing_time = item.get('beijing_time', '')
                    time_part = beijing_time.split(' ')[1] if ' ' in beijing_time else '00:00:00'
                    
                    data_points.append({
                        'time': time_part,  # ä½¿ç”¨ä»beijing_timeæå–çš„æ—¶é—´
                        'cumulative_pct': float(item.get('total_change', 0)),
                        'timestamp': item.get('timestamp', '')
                    })
                except Exception as e:
                    continue
    
    data_points.sort(key=lambda x: x['time'])
    return data_points

def parse_time_to_minutes(time_str):
    try:
        h, m, s = map(int, time_str.split(':'))
        return h * 60 + m + s / 60.0
    except:
        return 0

def find_all_peaks(data_points):
    """æ‰¾åˆ°æ‰€æœ‰æ˜¾è‘—çš„å³°å€¼ï¼ˆæ­£å€¼å’Œè´Ÿå€¼ï¼‰"""
    positive_peaks = []  # æ­£å€¼å³°å€¼ï¼ˆå±€éƒ¨æœ€å¤§å€¼ï¼‰
    negative_peaks = []  # è´Ÿå€¼å³°å€¼ï¼ˆå±€éƒ¨æœ€å°å€¼ï¼‰
    
    # ä½¿ç”¨æ»‘åŠ¨çª—å£æ‰¾å±€éƒ¨æœ€å¤§å€¼å’Œæœ€å°å€¼
    window_size = 5  # å‰åå„5ä¸ªç‚¹
    
    for i in range(window_size, len(data_points) - window_size):
        current_value = data_points[i]['cumulative_pct']
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å±€éƒ¨æœ€å¤§å€¼ï¼ˆæ­£å³°å€¼ï¼‰
        is_max_peak = True
        for j in range(i - window_size, i + window_size + 1):
            if j != i and data_points[j]['cumulative_pct'] >= current_value:
                is_max_peak = False
                break
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å±€éƒ¨æœ€å°å€¼ï¼ˆè´Ÿå³°å€¼ï¼‰
        is_min_peak = True
        for j in range(i - window_size, i + window_size + 1):
            if j != i and data_points[j]['cumulative_pct'] <= current_value:
                is_min_peak = False
                break
        
        # æ£€æŸ¥æ­£å³°å€¼ï¼ˆ>=5%ï¼‰
        if is_max_peak and current_value >= MIN_PEAK_VALUE:
            if len(positive_peaks) == 0:
                positive_peaks.append(i)
            else:
                last_peak_time = parse_time_to_minutes(data_points[positive_peaks[-1]]['time'])
                current_time = parse_time_to_minutes(data_points[i]['time'])
                
                if current_time - last_peak_time >= MIN_PEAK_DISTANCE:
                    positive_peaks.append(i)
        
        # æ£€æŸ¥è´Ÿå³°å€¼ï¼ˆ<=-5%ï¼‰
        if is_min_peak and current_value <= -MIN_PEAK_VALUE:
            if len(negative_peaks) == 0:
                negative_peaks.append(i)
            else:
                last_peak_time = parse_time_to_minutes(data_points[negative_peaks[-1]]['time'])
                current_time = parse_time_to_minutes(data_points[i]['time'])
                
                if current_time - last_peak_time >= MIN_PEAK_DISTANCE:
                    negative_peaks.append(i)
    
    return positive_peaks, negative_peaks

def find_valley_after_peak(data_points, peak_idx):
    """åœ¨å³°å€¼åæ‰¾è°·åº•ï¼ˆCç‚¹ä¸Aç‚¹é—´éš”å¿…é¡»>=MIN_VALLEY_TIME_GAPåˆ†é’Ÿï¼‰"""
    if peak_idx >= len(data_points) - 1:
        return None
    
    valley_idx = None
    min_value = data_points[peak_idx]['cumulative_pct']
    peak_time = parse_time_to_minutes(data_points[peak_idx]['time'])
    
    for i in range(peak_idx + 1, len(data_points)):
        current = data_points[i]['cumulative_pct']
        current_time = parse_time_to_minutes(data_points[i]['time'])
        
        # æ£€æŸ¥æ—¶é—´é—´éš”æ˜¯å¦>=MIN_VALLEY_TIME_GAPåˆ†é’Ÿ
        time_diff = current_time - peak_time
        if time_diff < MIN_VALLEY_TIME_GAP:  # å°äºæœ€å°æ—¶é—´é—´éš”ï¼Œè·³è¿‡
            continue
        
        if current < min_value:
            min_value = current
            valley_idx = i
        elif valley_idx is not None and current > data_points[valley_idx]['cumulative_pct']:
            break
    
    return valley_idx

def find_recovery_after_trough(data_points, trough_idx):
    """åœ¨è°·åº•ï¼ˆè´Ÿå³°å€¼ï¼‰åæ‰¾å›å‡ç‚¹"""
    if trough_idx >= len(data_points) - 1:
        return None
    
    recovery_idx = None
    max_value = data_points[trough_idx]['cumulative_pct']
    trough_time = parse_time_to_minutes(data_points[trough_idx]['time'])
    
    for i in range(trough_idx + 1, len(data_points)):
        current = data_points[i]['cumulative_pct']
        current_time = parse_time_to_minutes(data_points[i]['time'])
        
        # æ£€æŸ¥æ—¶é—´é—´éš”æ˜¯å¦>=MIN_VALLEY_TIME_GAPåˆ†é’Ÿ
        time_diff = current_time - trough_time
        if time_diff < MIN_VALLEY_TIME_GAP:
            continue
        
        if current > max_value:
            max_value = current
            recovery_idx = i
        elif recovery_idx is not None and current < data_points[recovery_idx]['cumulative_pct']:
            break
    
    return recovery_idx

def find_price_match_before_peak(data_points, peak_idx, valley_price):
    """åœ¨å³°å€¼å‰æ‰¾ä»·æ ¼åŒ¹é…ç‚¹ï¼ˆC'ç‚¹ï¼‰"""
    if peak_idx == 0:
        return None
    
    best_idx = None
    min_diff = float('inf')
    
    for i in range(peak_idx):
        price = data_points[i]['cumulative_pct']
        diff = abs(price - valley_price)
        
        if diff < min_diff:
            min_diff = diff
            best_idx = i
    
    # æ”¾å®½ä»·æ ¼åŒ¹é…æ¡ä»¶ï¼šä»5%æé«˜åˆ°10%
    # å¯¹äºå°å³°å€¼ï¼Œè°·åº•ä»·æ ¼å¯èƒ½ä¸ä¹‹å‰çš„ä»·æ ¼å·®è·è¾ƒå¤§
    if min_diff > 10.0:
        return None
    
    return best_idx

def calculate_angle_visual(data_points, c_prime_idx, peak_idx):
    price_diff_pct = data_points[peak_idx]['cumulative_pct'] - data_points[c_prime_idx]['cumulative_pct']
    
    time_peak = parse_time_to_minutes(data_points[peak_idx]['time'])
    time_c_prime = parse_time_to_minutes(data_points[c_prime_idx]['time'])
    time_diff_min = time_peak - time_c_prime
    
    if time_diff_min <= 0:
        return None
    
    price_diff_px = (price_diff_pct / CHART_PRICE_RANGE_PCT) * CHART_HEIGHT_PX
    time_diff_px = (time_diff_min / CHART_TIME_RANGE_MIN) * CHART_WIDTH_PX
    
    angle_rad = math.atan(price_diff_px / time_diff_px)
    angle_deg = math.degrees(angle_rad)
    
    return {
        'angle': angle_deg,
        'type': 'acute' if angle_deg < 45 else 'obtuse',
        'vertical_distance_pct': price_diff_pct,
        'horizontal_distance_min': time_diff_min,
        'vertical_distance_px': price_diff_px,
        'horizontal_distance_px': time_diff_px,
        'c_prime_time': data_points[c_prime_idx]['time'],
        'c_prime_price': data_points[c_prime_idx]['cumulative_pct'],
        'peak_time': data_points[peak_idx]['time'],
        'peak_price': data_points[peak_idx]['cumulative_pct'],
        'valley_time': '',
        'valley_price': 0
    }

def calculate_negative_angle_visual(data_points, c_prime_idx, trough_idx):
    """è®¡ç®—è´Ÿè§’åº¦ï¼ˆä¸‹é™è¶‹åŠ¿çš„è§’åº¦ï¼‰"""
    price_diff_pct = data_points[c_prime_idx]['cumulative_pct'] - data_points[trough_idx]['cumulative_pct']
    
    time_trough = parse_time_to_minutes(data_points[trough_idx]['time'])
    time_c_prime = parse_time_to_minutes(data_points[c_prime_idx]['time'])
    time_diff_min = time_trough - time_c_prime
    
    if time_diff_min <= 0:
        return None
    
    price_diff_px = (price_diff_pct / CHART_PRICE_RANGE_PCT) * CHART_HEIGHT_PX
    time_diff_px = (time_diff_min / CHART_TIME_RANGE_MIN) * CHART_WIDTH_PX
    
    angle_rad = math.atan(price_diff_px / time_diff_px)
    angle_deg = math.degrees(angle_rad)
    
    return {
        'angle': angle_deg,
        'type': 'acute' if angle_deg < 45 else 'obtuse',
        'vertical_distance_pct': price_diff_pct,
        'horizontal_distance_min': time_diff_min,
        'vertical_distance_px': price_diff_px,
        'horizontal_distance_px': time_diff_px,
        'c_prime_time': data_points[c_prime_idx]['time'],
        'c_prime_price': data_points[c_prime_idx]['cumulative_pct'],
        'peak_time': data_points[trough_idx]['time'],
        'peak_price': data_points[trough_idx]['cumulative_pct'],
        'valley_time': '',
        'valley_price': 0
    }

def analyze_all_angles(data_points):
    """åˆ†ææ‰€æœ‰å³°å€¼çš„è§’åº¦ï¼Œæ¯å°æ—¶åªä¿ç•™æœ€é«˜/æœ€ä½çš„ä¸€ä¸ª"""
    positive_peaks, negative_peaks = find_all_peaks(data_points)
    
    print(f"ğŸ” æ‰¾åˆ° {len(positive_peaks)} ä¸ªæ­£å³°å€¼, {len(negative_peaks)} ä¸ªè´Ÿå³°å€¼")
    
    # åˆ†ææ­£å³°å€¼ï¼ˆå‘ä¸Šçš„è§’åº¦ï¼‰
    positive_angles = analyze_positive_peaks(data_points, positive_peaks)
    
    # åˆ†æè´Ÿå³°å€¼ï¼ˆå‘ä¸‹çš„è§’åº¦ï¼‰
    negative_angles = analyze_negative_peaks(data_points, negative_peaks)
    
    # åˆå¹¶æ‰€æœ‰è§’åº¦
    all_angles = positive_angles + negative_angles
    
    # æŒ‰æ—¶é—´æ’åº
    all_angles.sort(key=lambda x: x['peak_time'])
    
    print(f"ğŸ“Š æ€»å…±: {len(all_angles)} ä¸ªè§’åº¦ (æ­£:{len(positive_angles)}, è´Ÿ:{len(negative_angles)})")
    
    return all_angles

def analyze_positive_peaks(data_points, peak_indices):
    """åˆ†ææ­£å³°å€¼ï¼ˆå±€éƒ¨æœ€å¤§å€¼ï¼‰"""
    # æŒ‰å°æ—¶åˆ†ç»„å³°å€¼ï¼Œæ¯å°æ—¶åªä¿ç•™æœ€é«˜çš„
    peaks_by_hour = {}
    for peak_idx in peak_indices:
        peak_time = data_points[peak_idx]['time']
        hour = peak_time.split(':')[0]
        peak_value = data_points[peak_idx]['cumulative_pct']
        
        if hour not in peaks_by_hour or peak_value > data_points[peaks_by_hour[hour]]['cumulative_pct']:
            peaks_by_hour[hour] = peak_idx
    
    angles = []
    
    for hour in sorted(peaks_by_hour.keys()):
        peak_idx = peaks_by_hour[hour]
        valley_idx = find_valley_after_peak(data_points, peak_idx)
        
        if valley_idx is None:
            continue
        
        valley_price = data_points[valley_idx]['cumulative_pct']
        c_prime_idx = find_price_match_before_peak(data_points, peak_idx, valley_price)
        
        if c_prime_idx is None:
            continue
        
        angle_info = calculate_angle_visual(data_points, c_prime_idx, peak_idx)
        
        if angle_info is None:
            continue
        
        angle_info['valley_time'] = data_points[valley_idx]['time']
        angle_info['valley_price'] = valley_price
        angle_info['hour'] = hour
        angle_info['direction'] = 'up'  # æ ‡è®°ä¸ºå‘ä¸Šçš„è§’åº¦
        
        angles.append(angle_info)
    
    return angles

def analyze_negative_peaks(data_points, peak_indices):
    """åˆ†æè´Ÿå³°å€¼ï¼ˆå±€éƒ¨æœ€å°å€¼ï¼‰"""
    # æŒ‰å°æ—¶åˆ†ç»„å³°å€¼ï¼Œæ¯å°æ—¶åªä¿ç•™æœ€ä½çš„
    peaks_by_hour = {}
    for peak_idx in peak_indices:
        peak_time = data_points[peak_idx]['time']
        hour = peak_time.split(':')[0]
        peak_value = data_points[peak_idx]['cumulative_pct']
        
        if hour not in peaks_by_hour or peak_value < data_points[peaks_by_hour[hour]]['cumulative_pct']:
            peaks_by_hour[hour] = peak_idx
    
    angles = []
    
    for hour in sorted(peaks_by_hour.keys()):
        peak_idx = peaks_by_hour[hour]
        # å¯¹äºè´Ÿå³°å€¼ï¼Œæ‰¾å›å‡ç‚¹ï¼ˆå‘ä¸Šçš„è°·åº•å®é™…ä¸Šæ˜¯å‘ä¸Šå›å‡çš„ç‚¹ï¼‰
        recovery_idx = find_recovery_after_trough(data_points, peak_idx)
        
        if recovery_idx is None:
            continue
        
        recovery_price = data_points[recovery_idx]['cumulative_pct']
        c_prime_idx = find_price_match_before_peak(data_points, peak_idx, recovery_price)
        
        if c_prime_idx is None:
            continue
        
        # è®¡ç®—è´Ÿè§’åº¦ï¼ˆä»C'ç‚¹åˆ°è´Ÿå³°å€¼çš„ä¸‹é™è§’åº¦ï¼‰
        angle_info = calculate_negative_angle_visual(data_points, c_prime_idx, peak_idx)
        
        if angle_info is None:
            continue
        
        angle_info['valley_time'] = data_points[recovery_idx]['time']
        angle_info['valley_price'] = recovery_price
        angle_info['hour'] = hour
        angle_info['direction'] = 'down'  # æ ‡è®°ä¸ºå‘ä¸‹çš„è§’åº¦
        
        angles.append(angle_info)
    
    return angles

def save_angle_analysis(date_str, angles):
    output_file = os.path.join(OUTPUT_DIR, f'okx_angles_{date_str}.jsonl')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for angle_info in angles:
            record = {
                'date': date_str,
                'hour': angle_info.get('hour', '00'),
                **angle_info,
                'analyzed_at': datetime.now().isoformat()
            }
            f.write(json.dumps(record, ensure_ascii=False) + '\n')
    
    print(f"âœ… ä¿å­˜åˆ†æç»“æœ: {output_file}")
    return output_file

def analyze_date(date_str):
    print(f"\n{'='*70}")
    print(f"ğŸ“ åˆ†ææ—¥æœŸ: {date_str} (V3å¢å¼ºç‰ˆ)")
    print(f"{'='*70}")
    
    data_points = load_trend_data(date_str)
    
    if not data_points:
        print(f"âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
        return None
    
    print(f"ğŸ“Š åŠ è½½äº† {len(data_points)} ä¸ªæ•°æ®ç‚¹")
    
    angles = analyze_all_angles(data_points)
    
    if not angles:
        print(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è§’åº¦å½¢æ€")
        return None
    
    print(f"\nğŸ“ˆ æ‰¾åˆ° {len(angles)} ä¸ªè§’åº¦å½¢æ€:")
    print(f"{'='*70}")
    
    # åˆ†ç±»ç»Ÿè®¡
    up_acute = sum(1 for a in angles if a.get('direction') == 'up' and a['type'] == 'acute')
    up_obtuse = sum(1 for a in angles if a.get('direction') == 'up' and a['type'] == 'obtuse')
    down_acute = sum(1 for a in angles if a.get('direction') == 'down' and a['type'] == 'acute')
    down_obtuse = sum(1 for a in angles if a.get('direction') == 'down' and a['type'] == 'obtuse')
    
    print(f"â†—ï¸ ä¸Šå‡è§’åº¦: {up_acute + up_obtuse} ä¸ª (ğŸ”ºé”è§’:{up_acute}, ğŸ”»é’è§’:{up_obtuse})")
    print(f"â†˜ï¸ ä¸‹é™è§’åº¦: {down_acute + down_obtuse} ä¸ª (ğŸ”ºé”è§’:{down_acute}, ğŸ”»é’è§’:{down_obtuse})")
    print()
    
    for angle_info in angles:
        direction_icon = "â†—ï¸" if angle_info.get('direction') == 'up' else "â†˜ï¸"
        angle_type_cn = "ğŸ”º é”è§’" if angle_info['type'] == 'acute' else "ğŸ”» é’è§’"
        print(f"{direction_icon} {angle_type_cn} {angle_info['angle']:.2f}Â° - å³°å€¼: {angle_info['peak_time']} ({angle_info['peak_price']:.2f}%)")
    
    output_file = save_angle_analysis(date_str, angles)
    
    print(f"\n{'='*70}")
    print(f"âœ… åˆ†æå®Œæˆ")
    print(f"{'='*70}\n")
    
    return output_file

if __name__ == '__main__':
    import sys
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    if len(sys.argv) > 1:
        date_str = sys.argv[1]
        analyze_date(date_str)
    else:
        print("ç”¨æ³•: python3 okx_angle_analyzer_v3.py YYYYMMDD")
