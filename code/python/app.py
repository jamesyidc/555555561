#!/usr/bin/env python3
"""
åŠ å¯†è´§å¸æ•°æ®åˆ†æç³»ç»Ÿ - å®Œå…¨ä»¿ç…§å‚è€ƒé¡µé¢é£æ ¼
"""
import sys
# ç¡®ä¿source_codeç›®å½•åœ¨è·¯å¾„ä¸­
sys.path.insert(0, '/home/user/webapp/source_code')
# æ·»åŠ æ”¯æ’‘å‹åŠ›ç³»ç»Ÿv2.0è·¯å¾„
sys.path.insert(0, '/home/user/webapp/sr_v2')
# æ·»åŠ é€ƒé¡¶ä¿¡å·ç³»ç»Ÿv2.0è·¯å¾„
sys.path.insert(0, '/home/user/webapp/escape_v2')

from flask import Flask, render_template_string, render_template, request, jsonify, send_from_directory, send_file, make_response, redirect
from flask_compress import Compress
import sqlite3
from datetime import datetime, timedelta, timezone
import json
import pytz
import os
from functools import wraps
import time
import traceback
from pathlib import Path

# é¡¹ç›®æ ¹ç›®å½•å’Œæ•°æ®ç›®å½•
BASE_DIR = Path('/home/user/webapp')
DATA_DIR = BASE_DIR / 'data'

app = Flask(__name__, 
            template_folder='/home/user/webapp/templates',
            static_folder='/home/user/webapp/static',
            static_url_path='/static')
# å¯ç”¨gzipå‹ç¼© - å‡å°‘74KBåˆ°çº¦15-20KB
Compress(app)

# å¯¼å…¥JSONLç®¡ç†å™¨
from gdrive_jsonl_manager import GDriveJSONLManager
from query_jsonl_manager import QueryJSONLManager

gdrive_jsonl_manager = GDriveJSONLManager()
# ä½¿ç”¨GDriveæ•°æ®ç›®å½•ä½œä¸ºQueryæ•°æ®æº(åŒ…å«æœ€æ–°æ•°æ®)
query_jsonl_manager = QueryJSONLManager(data_dir='/home/user/webapp/data/gdrive_jsonl')

# å…¨å±€AnchorDailyReader(å¸¦ç¼“å­˜)
_global_anchor_reader = None

def get_anchor_reader():
    """è·å–å…¨å±€AnchorDailyReaderå®ä¾‹(å•ä¾‹æ¨¡å¼)"""
    global _global_anchor_reader
    if _global_anchor_reader is None:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from anchor_daily_reader import AnchorDailyReader
        _global_anchor_reader = AnchorDailyReader()
    return _global_anchor_reader

# OKXäº¤æ˜“æ—¥å¿—ç®¡ç†å™¨
class OKXTradingLogger:
    """OKXäº¤æ˜“æ—¥å¿—è®°å½•å™¨ - æ‰€æœ‰æ“ä½œè®°å½•åˆ°JSONLæ–‡ä»¶(åªå†™ä¸æ”¹)"""
    def __init__(self, log_dir='/home/user/webapp/data/okx_trading_logs'):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        
    def _get_log_file(self, date_str=None):
        """è·å–å½“å¤©çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
        if date_str is None:
            date_str = datetime.now(BEIJING_TZ).strftime('%Y%m%d')
        return os.path.join(self.log_dir, f'trading_log_{date_str}.jsonl')
    
    def log(self, action, account_id, details=None, result=None):
        """
        è®°å½•äº¤æ˜“æ“ä½œæ—¥å¿—
        
        å‚æ•°:
        - action: æ“ä½œç±»å‹(open_position, close_position, cancel_order, batch_open, batch_closeç­‰)
        - account_id: è´¦æˆ·ID
        - details: æ“ä½œè¯¦æƒ…(äº¤æ˜“å¯¹ã€æ–¹å‘ã€æ•°é‡ç­‰)
        - result: æ“ä½œç»“æœ(æˆåŠŸ/å¤±è´¥ã€é”™è¯¯ä¿¡æ¯ç­‰)
        """
        try:
            log_entry = {
                'timestamp': datetime.now(BEIJING_TZ).isoformat(),
                'timestamp_unix': int(time.time()),
                'action': action,
                'account_id': account_id,
                'details': details or {},
                'result': result or {}
            }
            
            log_file = self._get_log_file()
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
            
            print(f"[OKXæ—¥å¿—] {action} - {account_id} - {result.get('status', 'unknown')}")
            
        except Exception as e:
            print(f"[OKXæ—¥å¿—] è®°å½•å¤±è´¥: {str(e)}")
    
    def get_logs(self, date_str=None, limit=100):
        """
        è¯»å–æ—¥å¿—(ä¸ä¿®æ”¹)
        
        å‚æ•°:
        - date_str: æ—¥æœŸå­—ç¬¦ä¸²(YYYYMMDD),None=ä»Šå¤©
        - limit: è¿”å›æœ€è¿‘Næ¡
        """
        try:
            log_file = self._get_log_file(date_str)
            if not os.path.exists(log_file):
                return []
            
            logs = []
            with open(log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        logs.append(json.loads(line))
            
            # è¿”å›æœ€è¿‘çš„Næ¡
            return logs[-limit:] if limit else logs
            
        except Exception as e:
            print(f"[OKXæ—¥å¿—] è¯»å–å¤±è´¥: {str(e)}")
            return []

# åˆå§‹åŒ–äº¤æ˜“æ—¥å¿—è®°å½•å™¨
okx_trading_logger = OKXTradingLogger()

app.config['TEMPLATES_AUTO_RELOAD'] = True
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0
BEIJING_TZ = pytz.timezone('Asia/Shanghai')

# å¯¼å…¥äº¤æ˜“API Blueprint
from trading_api import trading_bp
app.register_blueprint(trading_bp)

# å¯¼å…¥SAR JSONL API
from sar_api_jsonl import get_sar_current_cycle

# å¯¼å…¥Extreme JSONL Manager
from extreme_jsonl_manager import ExtremeJSONLManager

# å¯¼å…¥Price Speedå’ŒV1V2 JSONL Manager
from price_speed_jsonl_manager import PriceSpeedJSONLManager
from v1v2_jsonl_manager import V1V2JSONLManager
from crypto_index_jsonl_manager import CryptoIndexJSONLManager

price_speed_manager = PriceSpeedJSONLManager()
v1v2_manager = V1V2JSONLManager(data_dir='/home/user/webapp/data/v1v2_jsonl')
crypto_index_manager = CryptoIndexJSONLManager()

# Kçº¿å›¾æœåŠ¡URLé…ç½®
CHART_BASE_URL = "https://5000-iz6uddj6rs3xe48ilsyqq-2e1b9533.sandbox.novita.ai"

# ============================================
# æœåŠ¡å™¨ç«¯ç¼“å­˜ç³»ç»Ÿ
# ============================================
class ServerCache:
    """æœåŠ¡å™¨ç«¯å†…å­˜ç¼“å­˜,å­˜å‚¨è®¡ç®—ç»“æœ"""
    def __init__(self):
        self.cache = {}
        self.timestamps = {}
        
    def get(self, key, max_age=60):
        """
        è·å–ç¼“å­˜æ•°æ®
        key: ç¼“å­˜é”®
        max_age: æœ€å¤§ç¼“å­˜æ—¶é—´(ç§’),é»˜è®¤60ç§’
        """
        if key not in self.cache:
            return None
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if time.time() - self.timestamps.get(key, 0) > max_age:
            # è¿‡æœŸ,åˆ é™¤ç¼“å­˜
            del self.cache[key]
            del self.timestamps[key]
            return None
        
        return self.cache[key]
    
    def set(self, key, value):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self.cache[key] = value
        self.timestamps[key] = time.time()
    
    def clear(self, key=None):
        """æ¸…é™¤ç¼“å­˜"""
        if key:
            if key in self.cache:
                del self.cache[key]
            if key in self.timestamps:
                del self.timestamps[key]
        else:
            self.cache.clear()
            self.timestamps.clear()
    
    def get_stats(self):
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_keys': len(self.cache),
            'keys': list(self.cache.keys())
        }

# åˆ›å»ºå…¨å±€ç¼“å­˜å®ä¾‹
server_cache = ServerCache()

def cached_response(max_age=60):
    """
    ç¼“å­˜è£…é¥°å™¨ - åœ¨æœåŠ¡å™¨ç«¯ç¼“å­˜APIå“åº”
    max_age: ç¼“å­˜æœ‰æ•ˆæœŸ(ç§’)
    """
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{f.__name__}:{':'.join(map(str, args))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = server_cache.get(cache_key, max_age=max_age)
            if cached_data is not None:
                # åˆ›å»ºå“åº”å‰¯æœ¬å¹¶æ·»åŠ ç¼“å­˜æ ‡è®°
                response_data = cached_data.copy()
                response_data['_from_server_cache'] = True
                response_data['_cache_age_seconds'] = int(time.time() - server_cache.timestamps.get(cache_key, 0))
                return jsonify(response_data)
            
            # æ‰§è¡ŒåŸå‡½æ•°è·å–ç»“æœ
            result = f(*args, **kwargs)
            
            # æå–å¹¶ç¼“å­˜JSONæ•°æ®
            if hasattr(result, 'json') and callable(result.json):
                try:
                    data = result.json
                    if isinstance(data, dict) and data.get('success'):
                        server_cache.set(cache_key, data)
                except:
                    pass
            
            return result
        
        return decorated_function
    return decorator

# ä¸»é¡µé¢HTML - å®Œå…¨ä»¿ç…§å‚è€ƒè®¾è®¡
MAIN_HTML = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>åŠ å¯†è´§å¸æ•°æ®å†å²å›çœ‹</title>
    <script src="https://cdn.jsdelivr.net/npm/echarts@5.4.3/dist/echarts.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', sans-serif;
            background: #1e2139;
            color: #fff;
            overflow-x: hidden;
        }
        
        .container {
            max-width: 100%;
            margin: 0 auto;
            padding: 0;
        }
        
        /* é¡¶éƒ¨å¯¼èˆªæ  */
        .top-nav {
            background: #2a2d47;
            padding: 12px 20px;
            display: flex;
            align-items: center;
            gap: 15px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.3);
            justify-content: space-between;
        }
        
        .nav-left {
            display: flex;
            align-items: center;
            gap: 15px;
        }
        
        .nav-right {
            display: flex;
            gap: 10px;
        }
        
        /* ç³»ç»Ÿå¯¼èˆªæ  */
        .systems-nav {
            background: linear-gradient(135deg, #2a2d47 0%, #3a3d5c 100%);
            padding: 15px 20px;
            border-bottom: 2px solid #3b7dff;
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
            align-items: center;
        }
        
        .systems-nav-title {
            font-size: 14px;
            font-weight: 600;
            color: #8b92b8;
            margin-right: 10px;
        }
        
        .system-link {
            background: rgba(59, 125, 255, 0.1);
            border: 1px solid rgba(59, 125, 255, 0.3);
            color: #00d4ff;
            padding: 8px 16px;
            border-radius: 6px;
            font-size: 13px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            text-decoration: none;
            display: inline-flex;
            align-items: center;
            gap: 6px;
        }
        
        .system-link:hover {
            background: rgba(59, 125, 255, 0.2);
            border-color: #3b7dff;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(59, 125, 255, 0.3);
        }
        
        .system-link.featured {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            color: #fff;
        }
        
        .system-link.featured:hover {
            background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
        }
        
        .home-btn {
            background: linear-gradient(135deg, #00d4ff 0%, #0099ff 100%);
            color: #fff;
            border: none;
            padding: 8px 20px;
            border-radius: 6px;
            font-size: 14px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 6px;
        }
        
        .home-btn:hover {
            background: linear-gradient(135deg, #0099ff 0%, #00d4ff 100%);
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 212, 255, 0.4);
        }
        
        .nav-brand {
            display: flex;
            align-items: center;
            gap: 8px;
            background: #3b7dff;
            padding: 6px 15px;
            border-radius: 6px;
            font-size: 14px;
            font-weight: 500;
        }
        
        .nav-title {
            font-size: 18px;
            font-weight: 500;
            color: #fff;
            margin-left: 10px;
        }
        
        /* æ§åˆ¶æ  */
        .control-bar {
            background: #2a2d47;
            padding: 15px 20px;
            display: flex;
            align-items: center;
            gap: 15px;
            flex-wrap: wrap;
            border-bottom: 1px solid #3a3d5c;
        }
        
        .control-group {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .control-label {
            color: #8b92b8;
            font-size: 13px;
        }
        
        .control-input {
            background: #1e2139;
            border: 1px solid #3a3d5c;
            color: #fff;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 13px;
            outline: none;
        }
        
        .control-input:focus {
            border-color: #3b7dff;
        }
        
        .control-btn {
            background: #3b7dff;
            border: none;
            color: white;
            padding: 7px 18px;
            border-radius: 4px;
            font-size: 13px;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .control-btn:hover {
            background: #2563eb;
        }
        
        .control-btn.secondary {
            background: #4a5178;
        }
        
        .control-btn.secondary:hover {
            background: #5a6188;
        }
        
        /* æ•°æ®ç»Ÿè®¡æ  */
        .stats-bar {
            background: #2a2d47;
            padding: 12px 20px;
            display: flex;
            gap: 25px;
            flex-wrap: wrap;
            border-bottom: 1px solid #3a3d5c;
            font-size: 13px;
        }
        
        .stat-item {
            display: flex;
            gap: 5px;
        }
        
        .stat-label {
            color: #8b92b8;
        }
        
        .stat-value {
            color: #fff;
            font-weight: 500;
            margin-left: 8px;
        }
        
        .stat-value.rise {
            color: #10b981;
        }
        
        .stat-value.fall {
            color: #ef4444;
        }
        
        /* æ¬¡çº§ç»Ÿè®¡æ  */
        .secondary-stats {
            background: #1e2139;
            padding: 10px 20px;
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
            font-size: 13px;
        }
        
        /* æ—¶é—´è½´å®¹å™¨ - ç«–ç›´å¸ƒå±€ */
        .timeline-container {
            background: #2a2d47;
            padding: 15px 20px;
            border-top: 1px solid #3a3d5c;
            max-height: 500px;  /* å¢åŠ é«˜åº¦ä»¥æ˜¾ç¤ºæ›´å¤šä¿¡æ¯ */
            overflow-y: auto;
        }
        
        .timeline-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            position: sticky;
            top: 0;
            background: #2a2d47;
            padding-bottom: 10px;
            border-bottom: 1px solid #3a3d5c;
        }
        
        .timeline-title {
            color: #8b92b8;
            font-size: 13px;
            font-weight: 500;
        }
        
        .timeline-info {
            color: #3b7dff;
            font-size: 12px;
        }
        
        /* ç«–ç›´æ—¶é—´è½´è½¨é“ */
        .timeline-track {
            position: relative;
            padding-left: 30px;
            margin-top: 10px;
        }
        
        /* ç«–ç›´çº¿ */
        .timeline-line {
            position: absolute;
            left: 15px;
            top: 0;
            bottom: 0;
            width: 2px;
            background: #3a3d5c;
        }
        
        /* ç«–ç›´æ’åˆ—çš„æ—¶é—´ç‚¹å®¹å™¨ */
        .timeline-points {
            display: flex;
            flex-direction: column;
            gap: 20px;  /* å¢åŠ é—´è·ä»¥å®¹çº³æ›´å¤šä¿¡æ¯ */
        }
        
        /* æ—¶é—´ç‚¹é¡¹ */
        .timeline-point {
            position: relative;
            display: flex;
            align-items: flex-start;  /* æ”¹ä¸ºé¡¶éƒ¨å¯¹é½,é€‚åº”å¤šè¡Œå†…å®¹ */
            cursor: pointer;
            padding: 10px 12px;  /* å¢åŠ padding */
            border-radius: 4px;
            transition: all 0.3s;
            min-height: 80px;  /* æœ€å°é«˜åº¦ç¡®ä¿æ˜¾ç¤ºå¤šè¡Œä¿¡æ¯ */
        }
        
        .timeline-point:hover {
            background: rgba(59, 125, 255, 0.1);
        }
        
        /* æ—¶é—´ç‚¹åœ†åœˆ */
        .timeline-point::before {
            content: '';
            position: absolute;
            left: -22px;
            width: 12px;
            height: 12px;
            background: #3b7dff;
            border: 2px solid #2a2d47;
            border-radius: 50%;
            transition: all 0.3s;
            z-index: 2;
        }
        
        .timeline-point:hover::before {
            width: 16px;
            height: 16px;
            left: -24px;
            background: #2563eb;
            box-shadow: 0 0 10px rgba(59, 125, 255, 0.5);
        }
        
        .timeline-point.active::before {
            background: #10b981;
            width: 16px;
            height: 16px;
            left: -24px;
            box-shadow: 0 0 8px rgba(16, 185, 129, 0.5);
        }
        
        /* æ—¶é—´æ ‡ç­¾ */
        .timeline-label {
            color: #8b92b8;
            font-size: 12px;
            display: flex;
            flex-direction: column;
            gap: 2px;
        }
        
        .timeline-point:hover .timeline-label {
            color: #fff;
        }
        
        .timeline-point.active .timeline-label {
            color: #10b981;
            font-weight: 500;
        }
        
        .timeline-label-time {
            font-size: 13px;
            font-weight: 500;
        }
        
        .timeline-label-stats {
            font-size: 11px;
            opacity: 0.85;
            line-height: 1.5;
            color: #a0aec0;
            max-width: 600px;  /* é™åˆ¶æœ€å¤§å®½åº¦ */
        }
        
        .timeline-label-stats div {
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        
        /* å›¾è¡¨åŒºåŸŸ */
        .chart-section {
            background: #2a2d47;
            margin: 0;
            padding: 20px;
        }
        
        .chart-title {
            color: #8b92b8;
            font-size: 14px;
            margin-bottom: 15px;
            text-align: center;
        }
        
        #mainChart {
            width: 100%;
            height: 450px;  /* å¢åŠ é«˜åº¦,è®©å›¾è¡¨æ›´æ¸…æ™° */
        }
        
        /* æ•°æ®åˆ—è¡¨æ ‡é¢˜ */
        .data-list-header {
            background: #2a2d47;
            padding: 12px 20px;
            color: #3b7dff;
            font-size: 14px;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        /* è¡¨æ ¼å®¹å™¨ */
        .table-container {
            background: #1e2139;
            overflow-x: auto;
        }
        
        /* æ•°æ®è¡¨æ ¼ */
        .data-table {
            width: 100%;
            border-collapse: collapse;
            font-size: 12px;
        }
        
        .data-table thead {
            background: #ef4444;
            position: sticky;
            top: 0;
            z-index: 10;
        }
        
        .data-table th {
            padding: 10px 8px;
            text-align: center;
            font-weight: 500;
            color: #fff;
            border-right: 1px solid #dc2626;
            white-space: nowrap;
        }
        
        .data-table tbody tr {
            border-bottom: 1px solid #2a2d47;
        }
        
        .data-table tbody tr:hover {
            background: #2a2d47;
        }
        
        .data-table td {
            padding: 8px 6px;
            text-align: center;
            border-right: 1px solid #2a2d47;
            white-space: nowrap;
        }
        
        /* æ“ä½œåˆ— */
        .action-btn {
            background: #ef4444;
            border: none;
            color: white;
            padding: 4px 10px;
            border-radius: 3px;
            font-size: 11px;
            cursor: pointer;
            font-weight: 500;
        }
        
        .action-btn:hover {
            background: #dc2626;
        }
        
        /* å¸ç§åç§° */
        .coin-symbol {
            font-weight: 600;
            color: #fff;
        }
        
        /* æ•°å€¼é¢œè‰² */
        .value-positive {
            color: #ef4444;
        }
        
        .value-negative {
            color: #10b981;
        }
        
        .value-neutral {
            color: #8b92b8;
        }
        
        /* çŠ¶æ€æ ‡ç­¾ */
        .status-tag {
            display: inline-block;
            padding: 2px 6px;
            border-radius: 3px;
            font-size: 11px;
        }
        
        .status-tag.rise {
            background: #dc2626;
            color: white;
        }
        
        .status-tag.fall {
            background: #10b981;
            color: white;
        }
        
        /* ä¼˜å…ˆçº§é¢œè‰² */
        .priority-1 { color: #ff0000; font-weight: bold; }
        .priority-2 { color: #ff6600; font-weight: bold; }
        .priority-3 { color: #ff9900; }
        .priority-4 { color: #ffcc00; }
        .priority-5 { color: #99cc00; }
        .priority-6 { color: #8b92b8; }
        
        /* åŠ è½½çŠ¶æ€ */
        .loading {
            text-align: center;
            padding: 40px;
            color: #8b92b8;
            font-size: 14px;
        }
        
        /* å“åº”å¼ */
        @media (max-width: 768px) {
            .control-bar {
                flex-direction: column;
                align-items: stretch;
            }
            
            .stats-bar {
                flex-direction: column;
                gap: 10px;
            }
            
            .data-table {
                font-size: 11px;
            }
            
            .data-table th,
            .data-table td {
                padding: 6px 4px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- é¡¶éƒ¨å¯¼èˆª -->
        <div class="top-nav">
            <div class="nav-left">
                <div class="nav-brand">
                    <span>ğŸ“Š</span> æ•°æ®å›çœ‹
                </div>
                <div class="nav-title">åŠ å¯†è´§å¸æ•°æ®å†å²å›çœ‹</div>
            </div>
            <div class="nav-right">
                <button class="home-btn" onclick="window.location.href='/'">
                    <span>ğŸ </span> è¿”å›é¦–é¡µ
                </button>
            </div>
        </div>
        
        <!-- ç³»ç»Ÿå¯¼èˆªæ  -->
        <div class="systems-nav">
            <div class="systems-nav-title">å¿«é€Ÿè®¿é—®:</div>
            <a href="/sar-slope" class="system-link featured">
                <span>ğŸ“ˆ</span> SARæ–œç‡ç³»ç»Ÿ
            </a>
            <a href="/kline-indicators" class="system-link">
                <span>ğŸ“Š</span> Kçº¿æŒ‡æ ‡ç³»ç»Ÿ
            </a>
            <a href="/support-resistance" class="system-link">
                <span>ğŸ“‰</span> æ”¯æ’‘é˜»åŠ›ç³»ç»Ÿ
            </a>
            <a href="/position-system" class="system-link">
                <span>ğŸ’¼</span> ä»“ä½ç³»ç»Ÿ
            </a>
            <a href="/gdrive-monitor-status" class="system-link">
                <span>â˜ï¸</span> Google Driveç›‘æ§
            </a>
            <a href="/crypto-index" class="system-link">
                <span>ğŸ“ˆ</span> æŒ‡æ•°ç³»ç»Ÿ
            </a>
            <a href="/coin-pool" class="system-link">
                <span>ğŸŠ</span> å¸æ± ç³»ç»Ÿ
            </a>
            <a href="/price-comparison" class="system-link">
                <span>ğŸ’±</span> æ¯”ä»·ç³»ç»Ÿ
            </a>
            <a href="/fund-monitor" class="system-link featured">
                <span>ğŸ’°</span> èµ„é‡‘ç›‘æ§ç³»ç»Ÿ
            </a>
        </div>
        
        <!-- æ§åˆ¶æ  -->
        <div class="control-bar">
            <div class="control-group">
                <span class="control-label">é€‰é¡¹æ—¥æœŸ:</span>
                <input type="date" id="queryDate" class="control-input">
            </div>
            
            <div class="control-group">
                <span class="control-label">æ—¶é—´é€‰æ‹©:</span>
                <input type="time" id="queryTime" class="control-input" value="00:00">
            </div>
            
            <div class="control-group">
                <span class="control-label">è‡³</span>
                <input type="time" id="endTime" class="control-input" value="23:59">
            </div>
            
            <button class="control-btn" onclick="queryData()">ğŸ” æŸ¥è¯¢</button>
            <button class="control-btn secondary" onclick="loadToday()">ğŸ“Š ä»Šå¤©</button>
            <button class="control-btn secondary" onclick="loadLatest()">ğŸ“¡ ç«‹å³åŠ è½½</button>
            <button class="control-btn secondary" onclick="batchImportData()" id="batchImportBtn">ğŸ“¥ æ‰¹é‡å¯¼å…¥ä»Šæ—¥æ•°æ®</button>
        </div>
        
        <!-- ä¸»è¦ç»Ÿè®¡æ  -->
        <div class="stats-bar">
            <div class="stat-item">
                <span class="stat-label">è¿ç®—æ—¶é—´:</span>
                <span class="stat-value" id="calcTime">2025-12-06 13:42:42</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ€¥æ¶¨:</span>
                <span class="stat-value rise" id="rushUp">1</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ€¥è·Œ:</span>
                <span class="stat-value fall" id="rushDown">22</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æœ¬è½®æ€¥æ¶¨:</span>
                <span class="stat-value" id="roundRushUp">1</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æœ¬è½®æ€¥è·Œ:</span>
                <span class="stat-value" id="roundRushDown">22</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">è®¡æ¬¡:</span>
                <span class="stat-value" id="countTimes">10</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">è®¡æ¬¡å¾—åˆ†:</span>
                <span class="stat-value" id="countScore">â˜†â˜†â˜†</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">çŠ¶æ€:</span>
                <span class="stat-value" id="status">éœ‡è¡æ— åº</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ¯”å€¼:</span>
                <span class="stat-value" id="ratio">10</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">å·®å€¼:</span>
                <span class="stat-value" id="diff">-21</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ¯”ä»·æœ€ä½:</span>
                <span class="stat-value" id="priceLowest">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ¯”ä»·åˆ›æ–°é«˜:</span>
                <span class="stat-value" id="priceNewhigh">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">24hæ¶¨â‰¥10%:</span>
                <span class="stat-value rise" id="rise24hCount">0</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">24hè·Œâ‰¤-10%:</span>
                <span class="stat-value fall" id="fall24hCount">0</span>
            </div>

        </div>
        
        <!-- æ¬¡çº§ç»Ÿè®¡æ  -->
        <div class="secondary-stats">
            <div class="stat-item">
                <span class="stat-label">å·²å›è°ƒå†å²: æ— </span>
            </div>
            <div class="stat-item">
                <span class="stat-label">å›è°ƒå¤©æ•°: 168 ç§’/0æ¬¡</span>
            </div>
            <div class="stat-item">
                <span class="stat-label">æ—¶é—´åé™: 2025-12-04 10:22:00 ~ 2025-12-04 18:32:00</span>
            </div>
        </div>
        
        <!-- å›¾è¡¨åŒºåŸŸ -->
        <div class="chart-section">
            <div class="chart-header" style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                <div class="chart-title">æ€¥æ¶¨/æ€¥è·Œå†å²è¶‹åŠ¿å›¾</div>
                <div class="chart-pagination" style="display: flex; gap: 10px; align-items: center;">
                    <span id="chartTimeRange" style="color: #8b92b8; font-size: 12px;"></span>
                    <button id="btnPrevPage" class="page-btn" style="padding: 5px 12px; background: #3a3d5c; color: #8b92b8; border: 1px solid #4a4d6c; border-radius: 4px; cursor: pointer;" disabled>
                        â—€ ä¸Šä¸€é¡µ
                    </button>
                    <span id="chartPageInfo" style="color: #8b92b8; font-size: 12px;">ç¬¬1é¡µ</span>
                    <button id="btnNextPage" class="page-btn" style="padding: 5px 12px; background: #3a3d5c; color: #8b92b8; border: 1px solid #4a4d6c; border-radius: 4px; cursor: pointer;" disabled>
                        ä¸‹ä¸€é¡µ â–¶
                    </button>
                </div>
            </div>
            <div id="mainChart"></div>
        </div>
        
        <!-- æ—¶é—´è½´ - æ”¾åœ¨å›¾è¡¨ä¸‹æ–¹ -->
        <div class="timeline-container">
            <div class="timeline-header">
                <span class="timeline-title">å†å²æ•°æ®æ—¶é—´è½´</span>
                <span class="timeline-info" id="timelineInfo">åŠ è½½ä¸­...</span>
            </div>
            <div class="timeline-track">
                <div class="timeline-line"></div>
                <div id="timelinePoints" class="timeline-points"></div>
            </div>
        </div>
        
        <!-- æ•°æ®åˆ—è¡¨æ ‡é¢˜ -->
        <div class="data-list-header">
            <span>ğŸ“‹</span> å¸åˆ—è¡¨
        </div>
        
        <!-- æ•°æ®è¡¨æ ¼ -->
        <div class="table-container">
            <table class="data-table">
                <thead>
                    <tr>
                        <th>ä¼˜å…ˆçº§</th>
                        <th>åºå·</th>
                        <th>å¸å</th>
                        <th>æ¶¨é€Ÿ</th>
                        <th>æ€¥æ¶¨</th>
                        <th>æ€¥è·Œ</th>
                        <th>æ›´æ–°æ—¶é—´</th>
                        <th>å†å²é«˜ç‚¹</th>
                        <th>é«˜ç‚¹æ—¶é—´</th>
                        <th>è·Œå¹…</th>
                        <th>24h%</th>
                        <th>æ’è¡Œ</th>
                        <th>å½“å‰ä»·æ ¼</th>
                        <th>æœ€é«˜å æ¯”</th>
                        <th>æœ€ä½å æ¯”</th>
                    </tr>
                </thead>
                <tbody id="dataTableBody">
                    <tr>
                        <td colspan="15" class="loading">æ­£åœ¨åŠ è½½æ•°æ®...</td>
                    </tr>
                </tbody>
            </table>
        </div>
    </div>

    <script>
        // åˆå§‹åŒ–å›¾è¡¨
        const chart = echarts.init(document.getElementById('mainChart'));
        
        // åˆå§‹åŒ–æ—¥æœŸ
        const today = new Date();
        document.getElementById('queryDate').valueAsDate = today;
        
        // å›¾è¡¨é…ç½®
        function updateChart(data) {
            const option = {
                backgroundColor: 'transparent',
                grid: {
                    left: '50px',
                    right: '50px',
                    bottom: '120px',  // å¢åŠ åº•éƒ¨ç©ºé—´ç»™æ—‹è½¬çš„æ¨ªè½´æ ‡ç­¾
                    top: '50px',
                    containLabel: true
                },
                tooltip: {
                    trigger: 'axis',  // æ”¹ä¸ºaxisè§¦å‘,æ˜¾ç¤ºåŒä¸€æ—¶é—´ç‚¹æ‰€æœ‰æ•°æ®
                    backgroundColor: 'rgba(0, 0, 0, 0.9)',
                    borderColor: '#3a3d5c',
                    borderWidth: 1,
                    textStyle: { color: '#fff', fontSize: 12 },
                    axisPointer: {
                        type: 'cross',
                        crossStyle: {
                            color: '#8b92b8'
                        }
                    },
                    formatter: function(params) {
                        if (!params || params.length === 0) return '';
                        const time = params[0].axisValue;
                        let html = `<div style="padding: 8px;">
                            <div style="font-weight: bold; margin-bottom: 8px; font-size: 13px; border-bottom: 1px solid #3a3d5c; padding-bottom: 5px;">${time}</div>`;
                        
                        params.forEach(item => {
                            html += `<div style="margin-top: 5px; display: flex; align-items: center; justify-content: space-between; gap: 15px;">
                                <span style="display: flex; align-items: center;">
                                    <span style="display: inline-block; width: 10px; height: 10px; border-radius: 50%; background-color: ${item.color}; margin-right: 8px;"></span>
                                    ${item.seriesName}
                                </span>
                                <span style="color: ${item.color}; font-weight: bold;">${item.value}</span>
                            </div>`;
                        });
                        
                        html += '</div>';
                        return html;
                    }
                },
                legend: {
                    data: ['æ€¥æ¶¨', 'æ€¥è·Œ', 'å·®å€¼(æ€¥æ¶¨-æ€¥è·Œ)', 'è®¡æ¬¡'],
                    top: 10,
                    left: 'center',
                    textStyle: { color: '#8b92b8', fontSize: 13 },
                    itemWidth: 30,
                    itemHeight: 14,
                    itemGap: 20
                },
                xAxis: {
                    type: 'category',
                    data: data.times || [],
                    axisLine: { 
                        lineStyle: { color: '#3a3d5c', width: 1 }
                    },
                    axisLabel: { 
                        color: '#8b92b8',
                        fontSize: 10,
                        rotate: 45,  // æ—‹è½¬45åº¦,é¿å…é‡å 
                        interval: 0,  // æ˜¾ç¤ºæ‰€æœ‰æ ‡ç­¾
                        margin: 12,
                        align: 'right',  // å³å¯¹é½
                        verticalAlign: 'middle'
                    },
                    axisTick: {
                        show: true,
                        lineStyle: { color: '#3a3d5c' }
                    },
                    splitLine: { 
                        show: true,  // æ˜¾ç¤ºåˆ†éš”çº¿
                        lineStyle: {
                            color: '#3a3d5c',
                            type: 'solid',  // å®çº¿
                            width: 1,
                            opacity: 0.3
                        }
                    }
                },
                yAxis: [
                    {
                        type: 'value',
                        name: 'æ•°é‡',
                        nameTextStyle: { 
                            color: '#8b92b8', 
                            fontSize: 12,
                            padding: [0, 0, 0, 10]
                        },
                        axisLine: { 
                            show: true,
                            lineStyle: { color: '#3a3d5c' } 
                        },
                        axisLabel: { 
                            color: '#8b92b8', 
                            fontSize: 11 
                        },
                        splitLine: { 
                            lineStyle: { 
                                color: '#3a3d5c', 
                                type: 'dashed',
                                opacity: 0.5
                            } 
                        }
                    },
                    {
                        type: 'value',
                        name: 'è®¡æ¬¡',
                        nameTextStyle: { 
                            color: '#3b7dff', 
                            fontSize: 12,
                            padding: [0, 10, 0, 0]
                        },
                        axisLine: { 
                            show: true,
                            lineStyle: { color: '#3a3d5c' } 
                        },
                        axisLabel: { 
                            color: '#3b7dff', 
                            fontSize: 11 
                        },
                        splitLine: { show: false }
                    }
                ],
                series: [
                    {
                        name: 'æ€¥æ¶¨',
                        type: 'line',
                        data: data.rush_up || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹,å½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#ef4444'
                        },
                        itemStyle: { 
                            color: '#ef4444',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        },
                        // æ·»åŠ æ—¥æœŸåˆ†éš”çº¿
                        markLine: {
                            silent: true,
                            symbol: 'none',
                            label: {
                                show: false
                            },
                            lineStyle: {
                                color: '#6366f1',
                                type: 'solid',
                                width: 2,
                                opacity: 0.6
                            },
                            data: (data.date_separators || []).map(sep => ({
                                xAxis: sep.index,
                                label: {
                                    show: true,
                                    position: 'insideEndTop',
                                    formatter: sep.date,
                                    color: '#6366f1',
                                    fontSize: 10,
                                    fontWeight: 'bold',
                                    backgroundColor: 'rgba(30, 31, 46, 0.8)',
                                    padding: [2, 6],
                                    borderRadius: 3
                                }
                            }))
                        }
                    },
                    {
                        name: 'æ€¥è·Œ',
                        type: 'line',
                        data: data.rush_down || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹,å½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#10b981'
                        },
                        itemStyle: { 
                            color: '#10b981',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    },
                    {
                        name: 'å·®å€¼(æ€¥æ¶¨-æ€¥è·Œ)',
                        type: 'line',
                        data: data.diff || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹,å½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#fbbf24'
                        },
                        itemStyle: { 
                            color: '#fbbf24',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    },
                    {
                        name: 'è®¡æ¬¡',
                        type: 'line',
                        yAxisIndex: 1,
                        data: data.count || [],
                        smooth: true,
                        connectNulls: true,  // è¿æ¥æ‰€æœ‰æ•°æ®ç‚¹,å½¢æˆè¿ç»­çº¿æ®µ
                        lineStyle: {
                            width: 3,
                            color: '#3b7dff'
                        },
                        itemStyle: { 
                            color: '#3b7dff',
                            borderColor: '#fff',
                            borderWidth: 2
                        },
                        symbolSize: 8,
                        emphasis: {
                            scale: true,
                            scaleSize: 12
                        }
                    }
                ]
            };
            
            chart.setOption(option);
        }
        
        // æŸ¥è¯¢æ•°æ®
        function queryData() {
            const date = document.getElementById('queryDate').value;
            const time = document.getElementById('queryTime').value;
            const datetime = date + ' ' + time;
            
            fetch('/api/query?time=' + encodeURIComponent(datetime))
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert('âŒ ' + data.error);
                        return;
                    }
                    updateUI(data);
                    loadChartData();  // åŠ è½½æ‰€æœ‰å†å²æ•°æ®è¶‹åŠ¿å›¾
                })
                .catch(error => {
                    alert('æŸ¥è¯¢å¤±è´¥: ' + error);
                });
        }
        
        // åŠ è½½ä»Šå¤©
        function loadToday() {
            const today = new Date();
            document.getElementById('queryDate').valueAsDate = today;
            queryData();
        }
        
        // åŠ è½½æœ€æ–°
        function loadLatest() {
            fetch('/api/latest')
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert('âŒ ' + data.error);
                        return;
                    }
                    updateUI(data);
                    loadChartData();  // åŠ è½½æ‰€æœ‰å†å²æ•°æ®è¶‹åŠ¿å›¾
                })
                .catch(error => {
                    alert('åŠ è½½å¤±è´¥: ' + error);
                });
        }
        
        // æ‰¹é‡å¯¼å…¥ä»Šæ—¥æ•°æ®
        function batchImportData() {
            const btn = document.getElementById('batchImportBtn');
            const originalText = btn.innerHTML;
            
            // ç¦ç”¨æŒ‰é’®å¹¶æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            btn.disabled = true;
            btn.innerHTML = 'â³ æ­£åœ¨æ‰¹é‡å¯¼å…¥...';
            btn.style.opacity = '0.6';
            btn.style.cursor = 'not-allowed';
            
            fetch('/api/query/batch-import', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                }
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    const stats = data.stats;
                    let message = `âœ… æ‰¹é‡å¯¼å…¥å®Œæˆï¼\n\n`;
                    message += `ğŸ“Š ç»Ÿè®¡ç»“æœ:\n`;
                    message += `   æ€»æ–‡ä»¶æ•°: ${stats.total}\n`;
                    message += `   âœ… æˆåŠŸå¯¼å…¥: ${stats.success}\n`;
                    message += `   â„¹ï¸  å·²å­˜åœ¨: ${stats.exists}\n`;
                    if (stats.invalid > 0) {
                        message += `   âš ï¸  æ— æ•ˆæ•°æ®: ${stats.invalid}\n`;
                    }
                    if (stats.error > 0) {
                        message += `   âŒ å¤±è´¥: ${stats.error}\n`;
                    }
                    
                    alert(message);
                    
                    // å¦‚æœæœ‰æ–°æ•°æ®å¯¼å…¥,åˆ™åˆ·æ–°é¡µé¢æ•°æ®
                    if (stats.success > 0) {
                        loadToday();
                    }
                } else {
                    alert('âŒ æ‰¹é‡å¯¼å…¥å¤±è´¥: ' + data.error);
                }
            })
            .catch(error => {
                alert('âŒ æ‰¹é‡å¯¼å…¥å¤±è´¥: ' + error);
            })
            .finally(() => {
                // æ¢å¤æŒ‰é’®çŠ¶æ€
                btn.disabled = false;
                btn.innerHTML = originalText;
                btn.style.opacity = '1';
                btn.style.cursor = 'pointer';
            });
        }
        
        // æ›´æ–°æ¬¡çº§ç»Ÿè®¡æ 
        function updateSecondaryStats() {
            fetch('/api/stats')
                .then(response => response.json())
                .then(data => {
                    if (!data.error) {
                        // æ›´æ–°æ¬¡çº§ç»Ÿè®¡æ å†…å®¹
                        const secondaryStats = document.querySelector('.secondary-stats');
                        if (secondaryStats) {
                            // è®¡ç®—æ•°æ®æ—¶é—´èŒƒå›´(ä»data_daysæ¨ç®—)
                            const today = new Date();
                            const startDate = new Date(today);
                            startDate.setDate(startDate.getDate() - (data.data_days - 1));
                            
                            const dateRangeStr = `${startDate.toISOString().split('T')[0]} ~ ${today.toISOString().split('T')[0]}`;
                            
                            secondaryStats.innerHTML = `
                                <div class="stat-item">
                                    <span class="stat-label">æ•°æ®æ—¶é—´èŒƒå›´: ${dateRangeStr}</span>
                                </div>
                                <div class="stat-item">
                                    <span class="stat-label">æ€»è®°å½•: ${data.total_records} æ¡</span>
                                </div>
                                <div class="stat-item">
                                    <span class="stat-label">ä»Šæ—¥æ•°æ®: ${data.today_records} æ¡ | æ•°æ®å¤©æ•°: ${data.data_days} å¤©</span>
                                </div>
                                <div class="stat-item">
                                    <span class="stat-label">æœ€åæ›´æ–°: ${data.last_update_time}</span>
                                </div>
                            `;
                        }
                    }
                })
                .catch(err => {
                    console.error('æ›´æ–°æ¬¡çº§ç»Ÿè®¡æ å¤±è´¥:', err);
                });
        }
        
        // åŠ è½½æ¶¨è·Œé€Ÿæ•°æ®
        function loadPriceSpeedData() {
            fetch('/api/price-speed/latest')
                .then(response => response.json())
                .then(response => {
                    if (response.success && response.data) {
                        const data = response.data;
                        
                        // ç»Ÿè®¡å„çº§åˆ«æ•°é‡
                        const upCount = data.filter(coin => 
                            coin.alert_level && coin.alert_level.includes('up') && coin.alert_level !== 'normal'
                        ).length;
                        
                        const downCount = data.filter(coin => 
                            coin.alert_level && coin.alert_level.includes('down') && coin.alert_level !== 'normal'
                        ).length;
                        
                        const normalCount = data.filter(coin => 
                            coin.alert_level === 'normal'
                        ).length;
                        
                        // æ›´æ–°UI (å·²ç§»é™¤æ€¥æ¶¨é€Ÿã€æ€¥è·Œé€Ÿã€æ­£å¸¸ç»Ÿè®¡)
                    }
                })
                .catch(err => {
                    console.error('åŠ è½½æ¶¨è·Œé€Ÿæ•°æ®å¤±è´¥:', err);
                    // å¦‚æœå¤±è´¥,æ˜¾ç¤ºé»˜è®¤å€¼ (å·²ç§»é™¤æ€¥æ¶¨é€Ÿã€æ€¥è·Œé€Ÿã€æ­£å¸¸ç»Ÿè®¡)
                });
        }
        
        // æ›´æ–°UI
        function updateUI(data) {
            document.getElementById('calcTime').textContent = data.snapshot_time;
            document.getElementById('rushUp').textContent = data.rush_up;
            document.getElementById('rushDown').textContent = data.rush_down;
            document.getElementById('roundRushUp').textContent = data.round_rush_up || data.rush_up;
            document.getElementById('roundRushDown').textContent = data.round_rush_down || data.rush_down;
            // ä½¿ç”¨é€æ˜æ ‡ç­¾çš„è®¡æ¬¡å€¼(ä»TXTæ–‡ä»¶æå–çš„)
            document.getElementById('countTimes').textContent = data.count_aggregate || data.count;
            document.getElementById('countScore').textContent = data.count_score_display || '---';
            document.getElementById('status').textContent = data.status;
            document.getElementById('ratio').textContent = data.ratio;
            document.getElementById('diff').textContent = data.diff;
            document.getElementById('priceLowest').textContent = data.price_lowest || 0;
            document.getElementById('priceNewhigh').textContent = data.price_newhigh || 0;
            document.getElementById('rise24hCount').textContent = data.rise_24h_count || 0;
            document.getElementById('fall24hCount').textContent = data.fall_24h_count || 0;
            
            // æ›´æ–°æ¬¡çº§ç»Ÿè®¡æ 
            updateSecondaryStats();
            
            // åŠ è½½æ¶¨è·Œé€Ÿæ•°æ®
            loadPriceSpeedData();
            
            // æ›´æ–°è¡¨æ ¼
            const tbody = document.getElementById('dataTableBody');
            if (data.coins && data.coins.length > 0) {
                let html = '';
                data.coins.forEach((coin, idx) => {
                    const speedClass = coin.speed > 0 ? 'value-positive' : (coin.speed < 0 ? 'value-negative' : 'value-neutral');
                    const change24Class = coin.change_24h > 0 ? 'value-positive' : (coin.change_24h < 0 ? 'value-negative' : 'value-neutral');
                    // priorityæ˜¯æ•°å­—1-6,priority_nameæ˜¯å­—ç¬¦ä¸²"ç­‰çº§1"-"ç­‰çº§6"
                    const priority = coin.priority || 999;
                    const priorityName = coin.priority_name || 'æœªçŸ¥';
                    const priorityClass = 'priority-' + priority;
                    
                    const rushUpTag = coin.rush_up > 0 ? '<span class="status-tag rise">' + coin.rush_up + '</span>' : coin.rush_up;
                    const rushDownTag = coin.rush_down > 0 ? '<span class="status-tag fall">' + coin.rush_down + '</span>' : coin.rush_down;
                    
                    html += '<tr>';
                    html += '<td class="' + priorityClass + '">' + priority + '</td>';
                    html += '<td>' + (idx + 1) + '</td>';
                    html += '<td class="coin-symbol">' + coin.symbol + '</td>';
                    html += '<td class="' + speedClass + '">' + coin.speed.toFixed(2) + '</td>';
                    html += '<td>' + rushUpTag + '</td>';
                    html += '<td>' + rushDownTag + '</td>';
                    html += '<td>' + coin.update_time + '</td>';
                    html += '<td>' + coin.high_price.toFixed(2) + '</td>';
                    html += '<td>' + coin.high_time + '</td>';
                    html += '<td class="value-negative">' + coin.decline.toFixed(2) + '</td>';
                    html += '<td class="' + change24Class + '">' + coin.change_24h.toFixed(2) + '</td>';
                    html += '<td>' + coin.rank + '</td>';
                    html += '<td>' + coin.current_price.toFixed(4) + '</td>';
                    html += '<td>' + (coin.max_ratio ? coin.max_ratio.toFixed(2) + '%' : 'N/A') + '</td>';
                    html += '<td>' + (coin.min_ratio ? coin.min_ratio.toFixed(2) + '%' : 'N/A') + '</td>';
                    html += '</tr>';
                });
                tbody.innerHTML = html;
            } else {
                tbody.innerHTML = '<tr><td colspan="15" class="loading">æš‚æ— æ•°æ®</td></tr>';
            }
        }
        
        // åŠ è½½å›¾è¡¨æ•°æ®
        // å½“å‰é¡µç (å…¨å±€å˜é‡)
        let currentPage = 0;
        
        function loadChartData(page = 0) {
            // åŠ è½½æŒ‡å®šé¡µçš„å†å²æ•°æ®ç‚¹(12å°æ—¶/é¡µ,æ˜¾ç¤ºæ‰€æœ‰æ•°æ®ç‚¹)
            currentPage = page;
            fetch(`/api/chart?page=${page}`)
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        console.error(data.error);
                        return;
                    }
                    updateChart(data);
                    
                    // æ›´æ–°åˆ†é¡µä¿¡æ¯
                    document.getElementById('chartPageInfo').textContent = 
                        `ç¬¬${page + 1}/${data.total_pages}é¡µ`;
                    document.getElementById('chartTimeRange').textContent = 
                        `${data.time_range.start} - ${data.time_range.end}`;
                    
                    // æ›´æ–°æŒ‰é’®çŠ¶æ€
                    document.getElementById('btnPrevPage').disabled = !data.has_prev;
                    document.getElementById('btnNextPage').disabled = !data.has_next;
                })
                .catch(error => {
                    console.error('å›¾è¡¨åŠ è½½å¤±è´¥:', error);
                });
        }
        
        // ç¿»é¡µæŒ‰é’®äº‹ä»¶
        document.addEventListener('DOMContentLoaded', function() {
            document.getElementById('btnPrevPage').addEventListener('click', function() {
                loadChartData(currentPage + 1);  // ä¸Šä¸€é¡µ(æ›´æ—©çš„æ•°æ®)
            });
            
            document.getElementById('btnNextPage').addEventListener('click', function() {
                loadChartData(currentPage - 1);  // ä¸‹ä¸€é¡µ(æ›´æ–°çš„æ•°æ®)
            });
        });
        
        // é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åŠ è½½æœ€æ–°æ•°æ®
        // åŠ è½½æ—¶é—´è½´æ•°æ® - ç«–ç›´å¸ƒå±€
        function loadTimeline() {
            fetch('/api/timeline')
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        document.getElementById('timelineInfo').textContent = data.error;
                        return;
                    }
                    
                    document.getElementById('timelineInfo').textContent = 
                        `å…± ${data.snapshots.length} ä¸ªæ•°æ®ç‚¹`;
                    
                    const pointsContainer = document.getElementById('timelinePoints');
                    pointsContainer.innerHTML = '';
                    
                    // æ—¶é—´ä»ä¸Šåˆ°ä¸‹:æœ€æ—©çš„åœ¨ä¸Šé¢,æœ€æ–°çš„åœ¨ä¸‹é¢
                    data.snapshots.forEach((snapshot, index) => {
                        const point = document.createElement('div');
                        point.className = 'timeline-point';
                        point.setAttribute('data-time', snapshot.snapshot_time);
                        
                        // æœ€åä¸€ä¸ª(æœ€æ–°çš„)æ ‡è®°ä¸ºæ¿€æ´»
                        if (index === data.snapshots.length - 1) {
                            point.classList.add('active');
                        }
                        
                        const label = document.createElement('div');
                        label.className = 'timeline-label';
                        
                        // æ—¶é—´æ˜¾ç¤º
                        const timeSpan = document.createElement('div');
                        timeSpan.className = 'timeline-label-time';
                        timeSpan.textContent = snapshot.snapshot_time;
                        
                        // ç»Ÿè®¡ä¿¡æ¯æ˜¾ç¤º - æ˜¾ç¤ºæ‰€æœ‰å…³é”®å­—æ®µ
                        const statsSpan = document.createElement('div');
                        statsSpan.className = 'timeline-label-stats';
                        
                        // ç¬¬ä¸€è¡Œ:æ€¥æ¶¨ã€æ€¥è·Œã€è®¡æ¬¡ã€å¾—åˆ†
                        const line1 = `æ€¥æ¶¨:${snapshot.rush_up} æ€¥è·Œ:${snapshot.rush_down} è®¡æ¬¡:${snapshot.count} ${snapshot.count_score_display || ''}`;
                        
                        // ç¬¬äºŒè¡Œ:çŠ¶æ€ã€æ¯”å€¼ã€å·®å€¼
                        const line2 = `çŠ¶æ€:${snapshot.status || ''} æ¯”å€¼:${snapshot.ratio || 0} å·®å€¼:${snapshot.diff}`;
                        
                        // ç¬¬ä¸‰è¡Œ:æœ¬è½®ã€æ¯”ä»·ã€24h
                        const line3 = `æœ¬è½®æ€¥æ¶¨:${snapshot.round_rush_up || 0} æœ¬è½®æ€¥è·Œ:${snapshot.round_rush_down || 0} 24hæ¶¨â‰¥10%:${snapshot.rise_24h_count || 0} 24hè·Œâ‰¤-10%:${snapshot.fall_24h_count || 0}`;
                        
                        statsSpan.innerHTML = `
                            <div style="margin-bottom: 2px;">${line1}</div>
                            <div style="margin-bottom: 2px;">${line2}</div>
                            <div>${line3}</div>
                        `;
                        
                        label.appendChild(timeSpan);
                        label.appendChild(statsSpan);
                        point.appendChild(label);
                        
                        point.onclick = function() {
                            // ç§»é™¤æ‰€æœ‰æ¿€æ´»çŠ¶æ€
                            document.querySelectorAll('.timeline-point').forEach(p => {
                                p.classList.remove('active');
                            });
                            // æ¿€æ´»å½“å‰ç‚¹
                            this.classList.add('active');
                            // åŠ è½½æ•°æ®
                            loadSnapshotData(snapshot.snapshot_time);
                        };
                        
                        pointsContainer.appendChild(point);
                    });
                })
                .catch(error => {
                    console.error('åŠ è½½æ—¶é—´è½´å¤±è´¥:', error);
                    document.getElementById('timelineInfo').textContent = 'åŠ è½½å¤±è´¥';
                });
        }
        
        // åŠ è½½æŒ‡å®šå¿«ç…§çš„æ•°æ®
        function loadSnapshotData(snapshotTime) {
            fetch('/api/query?time=' + encodeURIComponent(snapshotTime))
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        alert(data.error);
                        return;
                    }
                    updateUI(data);
                    updateChart(data);
                    
                    // æ›´æ–°æ—¶é—´è½´æ¿€æ´»çŠ¶æ€
                    document.querySelectorAll('.timeline-point').forEach(point => {
                        point.classList.remove('active');
                    });
                    event.target.classList.add('active');
                })
                .catch(error => console.error('åŠ è½½æ•°æ®å¤±è´¥:', error));
        }
        
        window.onload = function() {
            loadLatest();
            loadTimeline();
        };
        
        // å“åº”å¼è°ƒæ•´
        window.addEventListener('resize', function() {
            chart.resize();
        });
    </script>
</body>
</html>
"""

# APIè·¯ç”±ä¿æŒä¸å˜,ä½¿ç”¨ä¹‹å‰çš„ä»£ç 
@app.route('/')
def index():
    """é¦–é¡µ - åŠŸèƒ½å¯¼èˆª"""
    return render_template('index.html')

@app.route('/coin-change-tracker')
def coin_change_tracker_page():
    """27å¸æ¶¨è·Œå¹…è¿½è¸ªç³»ç»Ÿé¡µé¢"""
    response = make_response(render_template('coin_change_tracker.html'))
    # ç¦ç”¨ç¼“å­˜,ç¡®ä¿æ¯æ¬¡éƒ½è·å–æœ€æ–°é¡µé¢
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    return response

@app.route('/coin-change-tracker-v2')
def coin_change_tracker_v2_page():
    """27å¸æ¶¨è·Œå¹…è¿½è¸ªç³»ç»Ÿé¡µé¢ V2 - ç‹¬ç«‹æµ‹è¯•ç‰ˆæœ¬"""
    response = make_response(render_template('coin_change_tracker_v2.html'))
    # ç¦ç”¨ç¼“å­˜,ç¡®ä¿æ¯æ¬¡éƒ½è·å–æœ€æ–°é¡µé¢
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/test-chart')
def test_chart():
    """å›¾è¡¨æµ‹è¯•é¡µé¢"""
    return send_from_directory('.', 'test_chart.html')
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/query')
def query_page():
    """å†å²æ•°æ®æŸ¥è¯¢é¡µé¢"""
    response = make_response(render_template_string(MAIN_HTML))
    # ç¦ç”¨ç¼“å­˜,ç¡®ä¿æ¯æ¬¡éƒ½è·å–æœ€æ–°é¡µé¢
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/chart')
def chart_page():
    """è¶‹åŠ¿å›¾è¡¨é¡µé¢"""
    response = make_response(render_template_string(MAIN_HTML))
    # ç¦ç”¨ç¼“å­˜,ç¡®ä¿æ¯æ¬¡éƒ½è·å–æœ€æ–°é¡µé¢
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/query-test')
def query_test():
    """Queryé¡µé¢è¯Šæ–­å·¥å…·"""
    from flask import send_file
    return send_file('/home/user/webapp/query_test.html')

@app.route('/test-profit-chart')
def test_profit_chart():
    """Profit Chartè°ƒè¯•é¡µé¢"""
    from flask import send_file
    return send_file('/home/user/webapp/test_profit_chart.html')

@app.route('/simple-test')
def simple_test():
    """Simpleæµ‹è¯•é¡µé¢"""
    from flask import send_file
    return send_file('/home/user/webapp/simple_test.html')

@app.route('/timeline')
def timeline_page():
    """æ—¶é—´è½´é¡µé¢"""
    return render_template_string(MAIN_HTML)

@app.route('/status')
def status_page():
    """ç³»ç»ŸçŠ¶æ€é¡µé¢"""
    return render_template('status.html')

@app.route('/panic')
def panic_page():
    """ææ…Œæ¸…æ´—æŒ‡æ•°é¡µé¢"""
    response = make_response(render_template('panic_new.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/panic-v2')
def panic_v2_page():
    """ææ…Œæ¸…æ´—æŒ‡æ•°é¡µé¢ - V2ä¿®å¤ç‰ˆæœ¬(å…¨æ–°)"""
    response = make_response(render_template('panic_v2.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/panic-test')
def panic_test_page():
    """Panicæ•°æ®æµ‹è¯•éªŒè¯é¡µé¢"""
    response = make_response(render_template('panic_data_test.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/liquidation-monthly')
def liquidation_monthly_page():
    """1å°æ—¶çˆ†ä»“é‡‘é¢æœˆçº¿å›¾é¡µé¢"""
    response = make_response(render_template('liquidation_monthly.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/extreme-tracking')
def extreme_tracking_page():
    """æå€¼è¿½è¸ªç³»ç»Ÿé¡µé¢"""
    return render_template('extreme_tracking.html')

@app.route('/extreme-debug')
def extreme_debug_page():
    """æå€¼è¿½è¸ªè°ƒè¯•é¡µé¢"""
    return render_template('extreme_debug.html')

@app.route('/api/server-date')
def api_server_date():
    """è·å–æœåŠ¡å™¨å½“å‰æ—¥æœŸï¼ˆåŒ—äº¬æ—¶é—´ï¼‰"""
    from datetime import datetime
    import pytz
    
    # è·å–åŒ—äº¬æ—¶é—´
    beijing_tz = pytz.timezone('Asia/Shanghai')
    beijing_time = datetime.now(beijing_tz)
    
    return jsonify({
        'success': True,
        'date': beijing_time.strftime('%Y-%m-%d'),
        'datetime': beijing_time.strftime('%Y-%m-%d %H:%M:%S'),
        'timestamp': int(beijing_time.timestamp() * 1000)
    })

@app.route('/api/panic/latest')
def api_panic_latest():
    """ææ…Œæ¸…æ´—æŒ‡æ•°æœ€æ–°æ•°æ®API - ä»æŒ‰æ—¥æœŸåˆ†åŒºçš„JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from panic_daily_manager import PanicDailyManager
        
        manager = PanicDailyManager()
        latest = manager.get_latest_record()
        
        if latest:
            # PanicDailyManagerè¿”å›çš„æ˜¯å®Œæ•´è®°å½•,éœ€è¦æå–dataå­—æ®µ
            data = latest.get('data', {})
            panic_index_percentage = data.get('panic_index', 0)
            hour_24_people = data.get('hour_24_people', 0)
            total_position = data.get('total_position', 0)
            hour_1_amount_usd = data.get('hour_1_amount', 0)
            hour_24_amount_usd = data.get('hour_24_amount', 0)
            wash_index = data.get('wash_index', 0)
            
            # ä¿ç•™ææ…ŒæŒ‡æ•°çš„åŸå§‹ç²¾åº¦(ä¸å››èˆäº”å…¥)
            panic_index = panic_index_percentage
            
            # JSONLä¸­çš„æ•°æ®å·²ç»æ˜¯æ ‡å‡†å•ä½(é‡‡é›†å™¨å·²è½¬æ¢):
            # hour_1_amount: ä¸‡ç¾å…ƒ
            # hour_24_amount: ä¸‡ç¾å…ƒ(æ³¨æ„:ç°åœ¨ä¹Ÿæ˜¯ä¸‡ç¾å…ƒ,ä¸æ˜¯äº¿ç¾å…ƒ)
            # hour_24_people: ä¸‡äºº
            # total_position: äº¿ç¾å…ƒ
            # ç›´æ¥ä½¿ç”¨,åªéœ€å››èˆäº”å…¥åˆ°2ä½å°æ•°
            
            people_wan = round(hour_24_people, 2)
            position_yi = round(total_position, 2)
            hour_1_amount_wan = round(hour_1_amount_usd, 2)
            hour_24_amount_wan = round(hour_24_amount_usd, 2)  # ç°åœ¨æ˜¯ä¸‡ç¾å…ƒ
            
            # æ ¹æ®ææ…ŒæŒ‡æ•°ç¡®å®šç­‰çº§
            if panic_index_percentage < 5:
                panic_level = 'ä½ææ…Œ'
                level_color = 'green'
            elif panic_index_percentage < 10:
                panic_level = 'ä¸­åº¦ææ…Œ'
                level_color = 'yellow'
            else:
                panic_level = 'é«˜åº¦ææ…Œ'
                level_color = 'red'
            
            return jsonify({
                'success': True,
                'data': {
                    'record_time': data.get('record_time'),
                    'panic_index': panic_index,
                    'wash_index': wash_index,
                    'panic_level': panic_level,
                    'level_color': level_color,
                    'hour_24_people': people_wan,
                    'total_position': position_yi,
                    'hour_1_amount': hour_1_amount_wan,
                    'hour_24_amount': hour_24_amount_wan,  # ç°åœ¨æ˜¯ä¸‡ç¾å…ƒ
                    'market_zone': f'{people_wan}ä¸‡äºº/{position_yi}äº¿ç¾å…ƒ'
                }
            })
        else:
            return jsonify({'success': False, 'error': 'æš‚æ— æ•°æ®'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/liquidation-1h/history')
def api_liquidation_1h_history():
    """1å°æ—¶çˆ†ä»“é‡‘é¢å†å²æ•°æ®API
    
    å‚æ•°:
        limit: è¿”å›æœ€è¿‘Næ¡è®°å½•,é»˜è®¤1440(24å°æ—¶)
        start_time: å¼€å§‹æ—¶é—´(å¯é€‰,æ ¼å¼: YYYY-MM-DD HH:MM:SS)
        end_time: ç»“æŸæ—¶é—´(å¯é€‰,æ ¼å¼: YYYY-MM-DD HH:MM:SS)
    """
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from liquidation_1h_manager import Liquidation1HManager
        
        manager = Liquidation1HManager()
        
        # è·å–å‚æ•°
        limit = request.args.get('limit', type=int, default=1440)  # é»˜è®¤24å°æ—¶
        start_time = request.args.get('start_time')
        end_time = request.args.get('end_time')
        
        # è·å–æ•°æ®
        if start_time or end_time:
            data = manager.get_range(start_time=start_time, end_time=end_time, limit=limit)
        else:
            # è·å–æœ€æ–°Næ¡
            all_data = manager.get_range(limit=limit)
            data = all_data
        
        return jsonify({
            'success': True,
            'count': len(data),
            'data': data
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/liquidation-1h/latest')
def api_liquidation_1h_latest():
    """1å°æ—¶çˆ†ä»“é‡‘é¢æœ€æ–°æ•°æ®API"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from liquidation_1h_manager import Liquidation1HManager
        
        manager = Liquidation1HManager()
        data = manager.get_latest(limit=1)
        
        if data:
            return jsonify({
                'success': True,
                'data': data[0]
            })
        else:
            return jsonify({'success': False, 'error': 'æš‚æ— æ•°æ®'})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/stats')
def api_stats():
    """ç»Ÿè®¡æ•°æ®API - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        sys.path.insert(0, '/home/user/webapp')
        from gdrive_jsonl_manager import GDriveJSONLManager
        
        
        manager = GDriveJSONLManager()
        # ä½¿ç”¨GDriveJSONLManagerå¤„ç†èšåˆæ•°æ®
        
        # è·å–æ‰€æœ‰å¿«ç…§
        all_snapshots = manager.read_all_snapshots()
        all_aggregates = manager.load_all_aggregates()
        
        # æ€»è®°å½•æ•°
        total_records = len(all_snapshots)
        
        # ä»Šæ—¥è®°å½•æ•°
        today = datetime.now(BEIJING_TZ).date().strftime('%Y-%m-%d')
        today_records = len([s for s in all_snapshots if s.get('snapshot_date', '') == today])
        
        # æ•°æ®å¤©æ•°(ä»å¿«ç…§ä¸­ç»Ÿè®¡å”¯ä¸€æ—¥æœŸ)
        unique_dates = set(s.get('snapshot_date', '') for s in all_snapshots if s.get('snapshot_date'))
        data_days = len(unique_dates)
        
        # è·å–æœ€æ–°èšåˆæ•°æ®
        latest_aggregate = manager.get_latest_aggregate()
        
        # è·å–æœ€æ–°ä¸¤æ¡èšåˆè®°å½•ç”¨äºè®¡ç®—æœ¬è½®å·®å€¼
        if len(all_aggregates) >= 2:
            sorted_aggregates = sorted(all_aggregates, key=lambda x: x.get('snapshot_time', ''), reverse=True)
            latest_records = sorted_aggregates[:2]
        else:
            latest_records = all_aggregates
        
        last_update_time = '-'
        current_round_rush_up = 0
        current_round_rush_down = 0
        
        if latest_aggregate:
            # ä»æœ€æ–°èšåˆæ•°æ®è·å–æ—¶é—´
            time_str = latest_aggregate.get('snapshot_time', '')
            if time_str and ' ' in time_str:
                last_update_time = time_str.split(' ')[1][:5]  # æå– HH:MM
            
            # è®¡ç®—æœ¬è½®å·®å€¼(å¦‚æœæœ‰ä¸¤æ¡è®°å½•)
            if len(latest_records) >= 2:
                current_rush_up = latest_records[0].get('rush_up_total', 0)
                current_rush_down = latest_records[0].get('rush_down_total', 0)
                prev_rush_up = latest_records[1].get('rush_up_total', 0)
                prev_rush_down = latest_records[1].get('rush_down_total', 0)
                
                current_round_rush_up = current_rush_up - prev_rush_up
                current_round_rush_down = current_rush_down - prev_rush_down
        
        # è·å–ææ…Œæ¸…æ´—æŒ‡æ•°(ä»æŒ‰æ—¥æœŸåˆ†åŒºçš„JSONLè¯»å–)
        try:
            from panic_daily_manager import PanicDailyManager
            panic_manager = PanicDailyManager()
            panic_latest = panic_manager.get_latest_record()
        except:
            panic_latest = None
        
        panic_indicator = '-'
        panic_color = 'gray'
        panic_trend_rating = 0
        panic_market_zone = '-'
        panic_people_wan = 0
        panic_position_yi = 0
        
        if panic_latest:
            panic_indicator = panic_latest.get('panic_index', 0)
            panic_people_wan = round(panic_latest.get('hour_24_people', 0) / 10000, 2)
            panic_position_yi = round(panic_latest.get('total_position', 0) / 100000000, 2)
            
            # æ ¹æ®ææ…ŒæŒ‡æ•°è®¾ç½®é¢œè‰²
            if panic_indicator < 5:
                panic_color = 'ç»¿'  # ä½ææ…Œ(<5%)
            elif panic_indicator < 10:
                panic_color = 'é»„'  # ä¸­ææ…Œ(5-10%)
            else:
                panic_color = 'çº¢'  # é«˜ææ…Œ(>10%)
            
            # å¸‚åœºåŒºé—´æè¿°
            panic_market_zone = f"{panic_people_wan}ä¸‡äºº/{panic_position_yi}äº¿ç¾å…ƒ"
        
        return jsonify({
            'total_records': total_records,
            'today_records': today_records,
            'data_days': data_days,
            'last_update_time': last_update_time,
            'current_round_rush_up': current_round_rush_up,
            'current_round_rush_down': current_round_rush_down,
            'panic_indicator': panic_indicator,
            'panic_color': panic_color,
            'panic_trend_rating': panic_trend_rating,
            'panic_market_zone': panic_market_zone
        })
    except Exception as e:
        return jsonify({
            'total_records': 0,
            'today_records': 0,
            'data_days': 0,
            'last_update_time': '-',
            'current_round_rush_up': 0,
            'current_round_rush_down': 0,
            'panic_indicator': '-',
            'panic_color': 'gray',
            'panic_trend_rating': 0,
            'panic_market_zone': '-',
            'error': str(e)
        })

@app.route('/api/homepage/summary')
def api_homepage_summary():
    """é¦–é¡µèšåˆæ•°æ®API - ä¸€æ¬¡è¿”å›æ‰€æœ‰é¦–é¡µéœ€è¦çš„æ•°æ®"""
    try:
        result = {
            'success': True,
            'timestamp': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        }
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # 1. ç»Ÿè®¡æ æ•°æ®(æœ¬è½®æ€¥æ¶¨æ€¥è·Œå’Œææ…ŒæŒ‡æ•°)
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots")
        total_records = cursor.fetchone()[0]
        
        today = datetime.now(BEIJING_TZ).date().strftime('%Y-%m-%d')
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots WHERE snapshot_date = ?", (today,))
        today_records = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT snapshot_time, rush_up, rush_down
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 2
        """)
        latest_records = cursor.fetchall()
        
        last_update_time = '-'
        current_round_rush_up = 0
        current_round_rush_down = 0
        
        if latest_records and len(latest_records) >= 1:
            time_str = latest_records[0][0]
            if time_str and ' ' in time_str:
                last_update_time = time_str.split(' ')[1][:5]
            current_rush_up = latest_records[0][1]
            current_rush_down = latest_records[0][2]
            
            if len(latest_records) >= 2:
                prev_rush_up = latest_records[1][1]
                prev_rush_down = latest_records[1][2]
                current_round_rush_up = current_rush_up - prev_rush_up
                current_round_rush_down = current_rush_down - prev_rush_down
        
        cursor.execute("""
            SELECT panic_index, hour_24_people, total_position
            FROM panic_wash_index
            ORDER BY record_time DESC
            LIMIT 1
        """)
        panic_data = cursor.fetchone()
        
        panic_indicator = '-'
        panic_color = 'gray'
        panic_market_zone = '-'
        
        if panic_data:
            panic_indicator = panic_data[0]
            panic_people_wan = round(panic_data[1] / 10000, 2)
            panic_position_yi = round(panic_data[2] / 100000000, 2)
            
            if panic_indicator < 5:
                panic_color = 'ç»¿'
            elif panic_indicator < 10:
                panic_color = 'é»„'
            else:
                panic_color = 'çº¢'
            
            panic_market_zone = f"{panic_people_wan}ä¸‡äºº/{panic_position_yi}äº¿ç¾å…ƒ"
        
        result['stats'] = {
            'total_records': total_records,
            'today_records': today_records,
            'last_update_time': last_update_time,
            'current_round_rush_up': current_round_rush_up,
            'current_round_rush_down': current_round_rush_down,
            'panic_indicator': panic_indicator,
            'panic_color': panic_color,
            'panic_market_zone': panic_market_zone
        }
        
        # 2. æ¨¡å—ç»Ÿè®¡æ•°æ®
        cursor.execute("SELECT MIN(snapshot_date), MAX(snapshot_date) FROM crypto_snapshots")
        date_range = cursor.fetchone()
        data_days = 0
        if date_range and date_range[0] and date_range[1]:
            data_days = (datetime.strptime(date_range[1], '%Y-%m-%d') - 
                        datetime.strptime(date_range[0], '%Y-%m-%d')).days + 1
        
        cursor.execute("SELECT MAX(snapshot_time) FROM crypto_snapshots")
        last_snapshot = cursor.fetchone()
        last_update = last_snapshot[0] if last_snapshot else '-'
        
        result['modules_stats'] = {
            'query_module': {
                'total_records': total_records,
                'data_days': data_days,
                'last_update': last_update
            }
        }
        
        # 3. ä»·æ ¼çªç ´ç»Ÿè®¡(åˆ›æ–°é«˜/åˆ›æ–°ä½)
        cursor.execute("""
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE DATE(event_time) = ?
            GROUP BY event_type
        """, (today,))
        breakthrough_today = dict(cursor.fetchall())
        
        result['price_breakthrough'] = {
            'today': {
                'new_high': breakthrough_today.get('new_high', 0),
                'new_low': breakthrough_today.get('new_low', 0)
            }
        }
        
        # 4. V1V2æˆäº¤ç³»ç»Ÿæ•°æ®(ä»å®é™…APIè·å–æˆ–å ä½)
        # æš‚æ—¶ä½¿ç”¨å ä½æ•°æ®,åç»­å¯ä»¥è°ƒç”¨åŸæœ‰çš„v1v2 API
        result['v1v2_system'] = {
            'v1_count': 0,
            'v2_count': 0,
            'update_time': last_update
        }
        
        # 5. æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿæ•°æ®
        cursor.execute("""
            SELECT 
                symbol, 
                alert_scenario_1, alert_scenario_2, alert_scenario_3, alert_scenario_4,
                position_s2_r1, position_s1_r2, position_s1_r1
            FROM support_resistance_levels
            WHERE record_time = (SELECT MAX(record_time) FROM support_resistance_levels)
        """)
        sr_data = cursor.fetchall()
        
        scenario1_coins = []
        scenario2_coins = []
        scenario3_coins = []
        scenario4_coins = []
        
        for row in sr_data:
            symbol, s1, s2, s3, s4, pos_s2_r1, pos_s1_r2, pos_s1_r1 = row
            coin_symbol = symbol.replace('USDT', '')
            
            if s1:
                scenario1_coins.append({'symbol': coin_symbol, 'position': pos_s2_r1})
            if s2:
                scenario2_coins.append({'symbol': coin_symbol, 'position': pos_s1_r2})
            if s3:
                scenario3_coins.append({'symbol': coin_symbol, 'position': pos_s1_r2})
            if s4:
                scenario4_coins.append({'symbol': coin_symbol, 'position': pos_s1_r1})
        
        result['support_resistance'] = {
            'total_count': len(sr_data),
            'scenario1_coins': scenario1_coins,
            'scenario2_coins': scenario2_coins,
            'scenario3_coins': scenario3_coins,
            'scenario4_coins': scenario4_coins,
            'update_time': last_update
        }
        
        # 6. äº¤æ˜“ä¿¡å·ç³»ç»Ÿæ•°æ®
        # ç®€åŒ–ç‰ˆæœ¬,è¿”å›åŸºæœ¬è®¡æ•°
        result['trading_signals'] = {
            'buy_point_1_count': 0,
            'buy_point_2_count': 0,
            'total_coins': 27,
            'update_time': last_update
        }
        
        # 7. 1åˆ†é’Ÿæ¶¨è·Œé€Ÿæ•°æ®(å ä½,éœ€è¦å®é™…æ•°æ®æº)
        result['price_speed'] = {
            'up_count': 0,
            'down_count': 0,
            'update_time': last_update
        }
        
        # 8. ç›‘æ§çŠ¶æ€
        cursor.execute("""
            SELECT snapshot_time 
            FROM crypto_snapshots 
            ORDER BY snapshot_date DESC, snapshot_time DESC 
            LIMIT 1
        """)
        latest_snapshot_row = cursor.fetchone()
        latest_snapshot_time = latest_snapshot_row[0] if latest_snapshot_row else None
        
        need_collection = False
        minutes_since_last = None
        
        if latest_snapshot_time:
            latest_dt = datetime.strptime(latest_snapshot_time, '%Y-%m-%d %H:%M:%S')
            latest_dt = BEIJING_TZ.localize(latest_dt)
            now = datetime.now(BEIJING_TZ)
            minutes_since_last = (now - latest_dt).total_seconds() / 60
            
            if minutes_since_last > 15:
                need_collection = True
        
        result['monitor_status'] = {
            'need_collection': need_collection,
            'latest_snapshot': latest_snapshot_time,
            'minutes_since_last': round(minutes_since_last, 1) if minutes_since_last else None
        }
        
        # 9. Google Driveæ£€æµ‹å™¨çŠ¶æ€(å ä½)
        result['gdrive_detector'] = {
            'detector_running': False,
            'file_timestamp': None,
            'delay_minutes': None,
            'latest_file': None
        }
        
        conn.close()
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'timestamp': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })

@app.route('/api/query')
def api_query():
    """æŸ¥è¯¢API - ä½¿ç”¨GDrive JSONLæ•°æ®æº"""
    query_time = request.args.get('time', '')
    if not query_time:
        return jsonify({'error': 'è¯·æä¾›æŸ¥è¯¢æ—¶é—´'})
    
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        sys.path.insert(0, '/home/user/webapp')
        from gdrive_jsonl_manager import GDriveJSONLManager
        
        
        # ä½¿ç”¨GDrive JSONLç®¡ç†å™¨
        manager = GDriveJSONLManager()
        # ä½¿ç”¨GDriveJSONLManagerå¤„ç†èšåˆæ•°æ®
        
        # ä»æŸ¥è¯¢æ—¶é—´æå–æ—¥æœŸ,ç¡®å®šåº”è¯¥è¯»å–å“ªä¸ªåˆ†åŒºæ–‡ä»¶
        from datetime import datetime
        try:
            query_dt = datetime.strptime(query_time, '%Y-%m-%d %H:%M:%S')
            date_str = query_dt.strftime('%Y%m%d')
            
            # ä¼˜å…ˆè¯»å–å½“å¤©çš„åˆ†åŒºæ–‡ä»¶
            date_file = manager.get_date_file(date_str)
            
            coins = []
            if os.path.exists(date_file):
                # ä»åˆ†åŒºæ–‡ä»¶è¯»å–
                import json
                with open(date_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line:
                            record = json.loads(line)
                            if record.get('snapshot_time') == query_time:
                                coins.append(record)
            
            # å¦‚æœåˆ†åŒºæ–‡ä»¶ä¸­æ²¡æ‰¾åˆ°,å†ä»ä¸»æ–‡ä»¶æŸ¥æ‰¾
            if not coins:
                all_snapshots = manager.read_all_snapshots()
                coins = [s for s in all_snapshots if s.get('snapshot_time') == query_time]
        except Exception as e:
            print(f"æŸ¥è¯¢æ—¶é—´è§£æé”™è¯¯: {e}")
            # å›é€€åˆ°åŸæ¥çš„é€»è¾‘
            all_snapshots = manager.read_all_snapshots()
            coins = [s for s in all_snapshots if s.get('snapshot_time') == query_time]
        
        if not coins:
            return jsonify({'error': f'æœªæ‰¾åˆ° {query_time} çš„æ•°æ®'})
        
        # å°è¯•è·å–èšåˆæ•°æ®
        aggregate_data = manager.get_aggregate_by_time(query_time)
        
        if aggregate_data:
            # ä½¿ç”¨èšåˆæ•°æ®(ä¿®å¤å­—æ®µæ˜ å°„)
            rush_up = aggregate_data.get('rush_up_total', 0)
            rush_down = aggregate_data.get('rush_down_total', 0)
            diff = aggregate_data.get('diff', 0)  # ä¿®å¤: diff è€Œä¸æ˜¯ diff_total
            
            # ratioå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•°å­—,éœ€è¦å¤„ç†
            ratio_raw = aggregate_data.get('ratio', 0)
            if isinstance(ratio_raw, str) and ratio_raw.strip() == '':
                ratio = round(rush_up / rush_down, 1) if rush_down > 0 else 0
            else:
                ratio = float(ratio_raw) if ratio_raw else 0
            
            status = aggregate_data.get('status', '')
            # å¦‚æœstatusä¸ºç©º,æ ¹æ®diffè®¡ç®—
            if not status:
                if diff >= 5:
                    status = 'å¼ºåŠ¿ä¸Šæ¶¨'
                elif diff >= 2:
                    status = 'æ¸©å’Œä¸Šæ¶¨'
                elif diff <= -5:
                    status = 'å¼ºåŠ¿ä¸‹è·Œ'
                elif diff <= -2:
                    status = 'æ¸©å’Œä¸‹è·Œ'
                else:
                    status = 'éœ‡è¡æ— åº'
            
            count_aggregate = aggregate_data.get('count', 0)  # ä¿®å¤: count è€Œä¸æ˜¯ count_aggregate
            count_score_display = aggregate_data.get('count_score', '')  # ä¿®å¤: count_score è€Œä¸æ˜¯ count_score_display
            count_score_type = ''  # è¿™ä¸ªå­—æ®µåœ¨èšåˆæ•°æ®ä¸­ä¸å­˜åœ¨
            price_lowest = aggregate_data.get('price_lowest', 0)
            price_newhigh = aggregate_data.get('price_newhigh', 0)
        else:
            # å›é€€åˆ°ç´¯åŠ è®¡ç®—
            rush_up = sum(c.get('rush_up', 0) or 0 for c in coins)
            rush_down = sum(c.get('rush_down', 0) or 0 for c in coins)
            diff = rush_up - rush_down
            ratio = round(rush_up / rush_down, 1) if rush_down > 0 else 0
            count_aggregate = 0
            count_score_display = ''
            count_score_type = ''
            price_lowest = 0
            price_newhigh = 0
            
            if diff >= 5:
                status = 'å¼ºåŠ¿ä¸Šæ¶¨'
            elif diff >= 2:
                status = 'æ¸©å’Œä¸Šæ¶¨'
            elif diff <= -5:
                status = 'å¼ºåŠ¿ä¸‹è·Œ'
            elif diff <= -2:
                status = 'æ¸©å’Œä¸‹è·Œ'
            else:
                status = 'éœ‡è¡æ— åº'
        
        # æ ¼å¼åŒ–å¸ç§æ•°æ®
        formatted_coins = []
        for coin in coins:
            inst_id = coin.get('inst_id', '')
            formatted_coins.append({
                'inst_id': inst_id,
                'symbol': inst_id,  # æ·»åŠ symbolå­—æ®µ
                'rush_up': coin.get('rush_up', 0),
                'rush_down': coin.get('rush_down', 0),
                'last_price': coin.get('last_price', 0),
                'change_24h': coin.get('change_24h', 0),
                'vol_24h': coin.get('vol_24h', 0),
                'count': coin.get('count', 0),
                'status': coin.get('status', ''),
                'priority': coin.get('priority', 999),
                'priority_name': coin.get('priority_name', ''),
                'count_score_display': coin.get('count_score_display', ''),
                'max_ratio': coin.get('max_ratio', 0),
                'min_ratio': coin.get('min_ratio', 0),
                'snapshot_time': coin.get('snapshot_time', query_time)
            })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        formatted_coins.sort(key=lambda x: (x.get('priority', 999), x.get('inst_id', '')))
        
        # è¿”å›å®Œæ•´æ•°æ®
        return jsonify({
            'snapshot_time': query_time,
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'count': len(coins),
            'count_aggregate': count_aggregate,
            'ratio': ratio,
            'status': status,
            'round_rush_up': 0,
            'round_rush_down': 0,
            'price_lowest': price_lowest,
            'price_newhigh': price_newhigh,
            'count_score_display': count_score_display,
            'count_score_type': count_score_type,
            'rise_24h_count': 0,
            'fall_24h_count': 0,
            'data': formatted_coins,
            'total': len(coins)
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/count/am2')
def api_count_am2():
    """è·å–æ¯å¤©å‡Œæ™¨2ç‚¹ä¹‹åç¬¬ä¸€ä¸ªæ•°æ®ç‚¹çš„è®¡æ¬¡"""
    try:
        import sys
        from datetime import datetime, timedelta
        import pytz
        sys.path.insert(0, '/home/user/webapp/source_code')
        sys.path.insert(0, '/home/user/webapp')
        from gdrive_jsonl_manager import GDriveJSONLManager
        
        
        manager = GDriveJSONLManager()
        # ä½¿ç”¨GDriveJSONLManagerå¤„ç†èšåˆæ•°æ®
        
        # è·å–åŒ—äº¬æ—¶åŒº
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now_beijing = datetime.now(beijing_tz)
        
        # è®¡ç®—ä»Šå¤©å‡Œæ™¨2ç‚¹çš„æ—¶é—´
        today_2am = now_beijing.replace(hour=2, minute=0, second=0, microsecond=0)
        
        # å¦‚æœå½“å‰æ—¶é—´åœ¨å‡Œæ™¨2ç‚¹ä¹‹å‰,åˆ™è·å–æ˜¨å¤©å‡Œæ™¨2ç‚¹ä¹‹åçš„ç¬¬ä¸€ä¸ªæ•°æ®
        if now_beijing.hour < 2:
            target_2am = today_2am - timedelta(days=1)
        else:
            target_2am = today_2am
        
        # æŸ¥æ‰¾å‡Œæ™¨2ç‚¹ä¹‹åçš„ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹(æ—¶é—´èŒƒå›´:2:00 - 4:00)
        start_time = target_2am
        end_time = target_2am + timedelta(hours=2)
        
        all_snapshots = manager.read_all_snapshots()
        if all_snapshots:
            # ç­›é€‰å‡Œæ™¨2ç‚¹ä¹‹åçš„æ•°æ®
            filtered = []
            for snap in all_snapshots:
                snap_time_str = snap.get('snapshot_time', '')
                try:
                    snap_time = datetime.strptime(snap_time_str, '%Y-%m-%d %H:%M:%S')
                    snap_time = beijing_tz.localize(snap_time)
                    if start_time <= snap_time <= end_time:
                        filtered.append((snap_time, snap_time_str, snap))
                except:
                    continue
            
            if filtered:
                # æŒ‰æ—¶é—´å‡åºæ’åº,å–ç¬¬ä¸€ä¸ª(æœ€æ—©çš„)
                filtered.sort(key=lambda x: x[0])
                first_time_str = filtered[0][1]
                
                # è·å–è¯¥æ—¶é—´ç‚¹æ‰€æœ‰å¸ç§çš„å¿«ç…§
                same_time_snaps = [s for s in all_snapshots if s.get('snapshot_time') == first_time_str]
                
                # å°è¯•ä»èšåˆæ•°æ®è·å–
                aggregate_data = manager.get_aggregate_by_time(first_time_str)
                if aggregate_data:
                    count = aggregate_data.get('count', 0)  # ä½¿ç”¨é€æ˜æ ‡ç­¾_è®¡æ¬¡çš„å€¼
                    source = 'aggregate'
                else:
                    # æ²¡æœ‰èšåˆæ•°æ®,è¿”å›é»˜è®¤å€¼
                    count = 0
                    source = 'no_data'
                
                return jsonify({
                    'success': True,
                    'count': count,
                    'time': first_time_str,
                    'date': target_2am.strftime('%m-%d'),
                    'source': source
                })
        
        # æ²¡æœ‰æ‰¾åˆ°æ•°æ®
        return jsonify({
            'success': False,
            'count': 0,
            'time': '--',
            'date': target_2am.strftime('%m-%d'),
            'message': 'æš‚æ— æ•°æ®'
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/latest')
def api_latest():
    """è·å–æœ€æ–°æ•°æ®API - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        sys.path.insert(0, '/home/user/webapp')
        from gdrive_jsonl_manager import GDriveJSONLManager
        
        
        manager = GDriveJSONLManager()
        # ä½¿ç”¨GDriveJSONLManagerå¤„ç†èšåˆæ•°æ®
        
        # è·å–æœ€æ–°çš„èšåˆæ•°æ®
        aggregate_data = manager.get_latest_aggregate()
        
        # ä¼˜åŒ–:ä¼˜å…ˆè¯»å–ä»Šå¤©çš„åˆ†åŒºæ–‡ä»¶,å¦‚æœä¸å­˜åœ¨å†è¯»å–ä¸»æ–‡ä»¶
        import pytz
        beijing_tz = pytz.timezone('Asia/Shanghai')
        from datetime import datetime
        today = datetime.now(beijing_tz).strftime('%Y-%m-%d')
        
        all_snapshots = manager.read_snapshots_by_date(today)
        
        # å¦‚æœä»Šå¤©æ²¡æœ‰æ•°æ®,å›é€€åˆ°ä¸»æ–‡ä»¶
        if not all_snapshots:
            all_snapshots = manager.read_all_snapshots()
        
        if not all_snapshots and not aggregate_data:
            return jsonify({'error': 'æš‚æ— æ•°æ®'})
        
        # ç¡®å®šæ˜¾ç¤ºçš„æ—¶é—´(ä¼˜å…ˆä½¿ç”¨èšåˆæ•°æ®çš„æ—¶é—´)
        if aggregate_data:
            display_time = aggregate_data.get('snapshot_time', '')
        else:
            all_snapshots.sort(key=lambda x: x.get('snapshot_time', ''), reverse=True)
            display_time = all_snapshots[0].get('snapshot_time', '')
        
        # è·å–å¸ç§å¿«ç…§(ä½¿ç”¨æœ€æ–°çš„å¸ç§æ•°æ®æ—¶é—´)
        if all_snapshots:
            all_snapshots.sort(key=lambda x: x.get('snapshot_time', ''), reverse=True)
            latest_coin_time = all_snapshots[0].get('snapshot_time')
            same_time_snaps = [s for s in all_snapshots if s.get('snapshot_time') == latest_coin_time]
        else:
            same_time_snaps = []
            latest_coin_time = display_time
        
        # å°è¯•ä»èšåˆæ•°æ®æ–‡ä»¶è¯»å–é€æ˜æ ‡ç­¾æ•°æ®
        try:
            if aggregate_data:
                # ä½¿ç”¨é€æ˜æ ‡ç­¾çš„èšåˆæ•°æ®(ä¿®å¤å­—æ®µæ˜ å°„)
                rush_up_total = aggregate_data.get('rush_up_total', 0)
                rush_down_total = aggregate_data.get('rush_down_total', 0)
                diff = aggregate_data.get('diff', 0)  # ä¿®å¤: diff è€Œä¸æ˜¯ diff_total
                
                # ratioå¯èƒ½æ˜¯ç©ºå­—ç¬¦ä¸²,éœ€è¦å¤„ç†
                ratio_raw = aggregate_data.get('ratio', 0)
                if isinstance(ratio_raw, str) and ratio_raw.strip() == '':
                    ratio = round(rush_up_total / rush_down_total, 1) if rush_down_total > 0 else 0
                else:
                    ratio = float(ratio_raw) if ratio_raw else 0
                
                status = aggregate_data.get('status', '')
                # å¦‚æœstatusä¸ºç©º,æ ¹æ®diffè®¡ç®—
                if not status:
                    if diff >= 5:
                        status = 'å¼ºåŠ¿ä¸Šæ¶¨'
                    elif diff >= 2:
                        status = 'æ¸©å’Œä¸Šæ¶¨'
                    elif diff <= -5:
                        status = 'å¼ºåŠ¿ä¸‹è·Œ'
                    elif diff <= -2:
                        status = 'æ¸©å’Œä¸‹è·Œ'
                    else:
                        status = 'éœ‡è¡æ— åº'
                
                count_value = aggregate_data.get('count', 0)  # æ¥è‡ª"é€æ˜æ ‡ç­¾_è®¡æ¬¡"
                price_lowest = aggregate_data.get('price_lowest', 0)
                price_newhigh = aggregate_data.get('price_newhigh', 0)
                count_score_display = aggregate_data.get('count_score', '')  # ä¿®å¤: count_score è€Œä¸æ˜¯ count_score_display
                count_score_type = ''  # è¿™ä¸ªå­—æ®µåœ¨èšåˆæ•°æ®ä¸­ä¸å­˜åœ¨
                count_score_value = 0  # è¿™ä¸ªå­—æ®µåœ¨èšåˆæ•°æ®ä¸­ä¸å­˜åœ¨
                round_rush_up = aggregate_data.get('round_rush_up', 0)
                round_rush_down = aggregate_data.get('round_rush_down', 0)
            else:
                # å›é€€åˆ°ç´¯åŠ è®¡ç®—(å…¼å®¹æ—§æ•°æ®)
                rush_up_total = 0
                rush_down_total = 0
                for snap in same_time_snaps:
                    rush_up_total += snap.get('rush_up', 0) or 0
                    rush_down_total += snap.get('rush_down', 0) or 0
                diff = rush_up_total - rush_down_total
                ratio = round(rush_up_total / rush_down_total, 1) if rush_down_total > 0 else 0
                count_value = 0
                price_lowest = 0
                price_newhigh = 0
                count_score_display = ''
                count_score_type = ''
                count_score_value = 0
                round_rush_up = 0
                round_rush_down = 0
                
                # åˆ¤æ–­çŠ¶æ€
                if diff >= 5:
                    status = 'å¼ºåŠ¿ä¸Šæ¶¨'
                elif diff >= 2:
                    status = 'æ¸©å’Œä¸Šæ¶¨'
                elif diff <= -5:
                    status = 'å¼ºåŠ¿ä¸‹è·Œ'
                elif diff <= -2:
                    status = 'æ¸©å’Œä¸‹è·Œ'
                else:
                    status = 'éœ‡è¡æ— åº'
        except Exception as e:
            # å¦‚æœèšåˆæ•°æ®è¯»å–å¤±è´¥,ä½¿ç”¨ç´¯åŠ è®¡ç®—
            rush_up_total = 0
            rush_down_total = 0
            for snap in same_time_snaps:
                rush_up_total += snap.get('rush_up', 0) or 0
                rush_down_total += snap.get('rush_down', 0) or 0
            diff = rush_up_total - rush_down_total
            ratio = round(rush_up_total / rush_down_total, 1) if rush_down_total > 0 else 0
            count_value = 0
            price_lowest = 0
            price_newhigh = 0
            count_score_display = ''
            count_score_type = ''
            count_score_value = 0
            round_rush_up = 0
            round_rush_down = 0
            
            if diff >= 5:
                status = 'å¼ºåŠ¿ä¸Šæ¶¨'
            elif diff >= 2:
                status = 'æ¸©å’Œä¸Šæ¶¨'
            elif diff <= -5:
                status = 'å¼ºåŠ¿ä¸‹è·Œ'
            elif diff <= -2:
                status = 'æ¸©å’Œä¸‹è·Œ'
            else:
                status = 'éœ‡è¡æ— åº'
        
        # æ„å»ºå¸ç§æ•°æ®(æ·»åŠ ä¼˜å…ˆçº§å’Œè®¡æ¬¡å¾—åˆ†)
        coins = []
        for snap in same_time_snaps:
            inst_id = snap.get('inst_id', '')
            
            # å­—æ®µè¯´æ˜:
            # - speed: æ¶¨é€Ÿ (parts[2]) - æµ®ç‚¹æ•°
            # - rush_up: æ€¥æ¶¨æ¬¡æ•° (parts[3]) - æ•´æ•°  
            # - rush_down: æ€¥è·Œæ¬¡æ•° (parts[4]) - æ•´æ•°
            speed = snap.get('speed', 0) or 0
            rush_up = snap.get('rush_up', 0) or 0
            rush_down = snap.get('rush_down', 0) or 0
            
            # æ„å»ºå¸ç§æ•°æ®(æ ‡å‡†å­—æ®µ)
            coins.append({
                'symbol': inst_id,
                'change': snap.get('change_24h') or 0,
                'speed': speed,  # æ¶¨é€Ÿ (float)
                'rush_up': rush_up,  # æ€¥æ¶¨æ¬¡æ•° (int)
                'rush_down': rush_down,  # æ€¥è·Œæ¬¡æ•° (int)
                'update_time': snap.get('update_time') or latest_coin_time,
                'high_price': snap.get('high_price') or 0,
                'high_time': snap.get('high_time') or '',
                'decline': snap.get('drop_from_high') or 0,
                'change_24h': snap.get('change_24h') or 0,
                'rank': snap.get('ranking') or 0,
                'current_price': snap.get('current_price') or snap.get('last_price') or 0,
                'last_price': snap.get('last_price') or 0,
                'vol_24h': snap.get('vol_24h') or 0,
                'count': snap.get('count') or 0,
                'status': snap.get('status', ''),
                'priority': snap.get('priority', 999),
                'priority_name': snap.get('priority_name', ''),
                'count_score_display': snap.get('count_score_display', ''),
                'count_score_value': snap.get('count_score_value', 0),
                'count_score_type': snap.get('count_score_type', ''),
                'max_ratio': snap.get('max_ratio', 0),
                'min_ratio': snap.get('min_ratio', 0)
            })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº(ä¼˜å…ˆçº§å°çš„åœ¨å‰,ä¼˜å…ˆçº§ç›¸åŒæŒ‰symbolæ’åº)
        coins.sort(key=lambda x: (x.get('priority', 999), x.get('symbol', '')))
        
        return jsonify({
            'snapshot_time': display_time,
            'rush_up': rush_up_total,
            'rush_down': rush_down_total,
            'diff': diff,
            'count': count_value,  # æ¥è‡ª"é€æ˜æ ‡ç­¾_è®¡æ¬¡"
            'count_aggregate': count_value,  # æ·»åŠ è¿™ä¸ªå­—æ®µ,å‰ç«¯æœŸæœ›ä½¿ç”¨æ­¤å­—æ®µå
            'ratio': ratio,
            'status': status,
            'price_lowest': price_lowest,
            'price_newhigh': price_newhigh,
            'round_rush_up': round_rush_up,  # ä»èšåˆæ•°æ®è¯»å–
            'round_rush_down': round_rush_down,  # ä»èšåˆæ•°æ®è¯»å–
            'count_score_display': count_score_display,  # é€æ˜æ ‡ç­¾çš„è®¡æ¬¡å¾—åˆ†
            'count_score_type': count_score_type,
            'count_score_value': count_score_value,
            'rise_24h_count': 0,
            'fall_24h_count': 0,
            'coins': coins,
            'data_source': 'JSONL'
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/chart')
def api_chart():
    """å›¾è¡¨æ•°æ®API - ä¼˜åŒ–ç‰ˆ:åªè¯»å–ä»Šå¤©çš„æ•°æ®,å¤§å¹…æå‡æ€§èƒ½"""
    try:
        from datetime import datetime, timedelta
        import sys
        import pytz
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from gdrive_jsonl_manager import GDriveJSONLManager
        
        
        # è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', '0')  # é»˜è®¤ç¬¬0é¡µ(æœ€æ–°)
        page = int(page)
        
        # ä¼˜åŒ–:è¯»å–ä»Šå¤©çš„æ•°æ®,å¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°æœ€è¿‘7å¤©
        beijing_tz = pytz.timezone('Asia/Shanghai')
        today = datetime.now(beijing_tz)
        
        jsonl_manager = GDriveJSONLManager()
        all_snapshots = []
        target_date = None
        
        # å°è¯•è¯»å–æœ€è¿‘7å¤©çš„æ•°æ®
        for days_ago in range(8):
            check_date = (today - timedelta(days=days_ago)).strftime('%Y-%m-%d')
            all_snapshots = jsonl_manager.read_snapshots_by_date(check_date)
            if all_snapshots:
                target_date = check_date
                print(f"âœ… ä½¿ç”¨ {check_date} çš„æ•°æ®({len(all_snapshots)} æ¡å¿«ç…§)")
                break
        
        if not all_snapshots:
            return jsonify({'error': 'æœ€è¿‘7å¤©æš‚æ— æ•°æ®,è¯·æ£€æŸ¥æ•°æ®é‡‡é›†æœåŠ¡'})
        
        # è¯»å–èšåˆæ•°æ®(åŒ…å«æ­£ç¡®çš„è®¡æ¬¡)
        # ä½¿ç”¨GDriveJSONLManagerå¤„ç†èšåˆæ•°æ®
        
        # è¯»å–ç›®æ ‡æ—¥æœŸçš„èšåˆæ•°æ®
        import glob
        import os
        target_date_formatted = target_date.replace('-', '')
        agg_file = os.path.join('/home/user/webapp/data/gdrive_jsonl', f'crypto_aggregate_{target_date_formatted}.jsonl')
        
        all_aggregates = []
        if os.path.exists(agg_file):
            try:
                import json
                with open(agg_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            all_aggregates.append(json.loads(line))
            except Exception as e:
                print(f"âš ï¸ è¯»å–èšåˆæ•°æ®å¤±è´¥: {e}")
        
        # åˆ›å»ºèšåˆæ•°æ®çš„æ—¶é—´ç´¢å¼•
        aggregate_by_time = {}
        for agg in all_aggregates:
            time_key = agg.get('snapshot_time')
            if time_key:
                aggregate_by_time[time_key] = agg
        
        # æŒ‰æ—¶é—´åˆ†ç»„èšåˆ(ç›¸åŒæ—¶é—´çš„å¿«ç…§åˆå¹¶)
        time_groups = {}
        for snap in all_snapshots:
            time_key = snap.get('snapshot_time')
            if not time_key:
                continue
            
            if time_key not in time_groups:
                time_groups[time_key] = {
                    'snapshot_time': time_key,
                    'rush_up': 0,
                    'rush_down': 0,
                    'count': 0,
                    'diff': 0
                }
            
            # ç´¯åŠ æ€¥æ¶¨æ€¥è·Œæ•°æ®
            group = time_groups[time_key]
            group['rush_up'] += snap.get('rush_up', 0) or 0
            group['rush_down'] += snap.get('rush_down', 0) or 0
            
            # è®¡æ¬¡åº”è¯¥ä»èšåˆæ•°æ®è·å–,è€Œä¸æ˜¯ç´¯åŠ 
            if time_key in aggregate_by_time:
                group['count'] = aggregate_by_time[time_key].get('count', 0) or 0  # ä¿®å¤: count è€Œä¸æ˜¯ count_aggregate
        
        # è®¡ç®—diffå’Œè½¬æ¢ä¸ºåˆ—è¡¨
        all_points = []
        for time_key, data in sorted(time_groups.items()):
            try:
                dt = datetime.strptime(time_key, '%Y-%m-%d %H:%M:%S')
                data['diff'] = data['rush_up'] - data['rush_down']
                all_points.append({
                    'time': dt,
                    'formatted_time': dt.strftime('%m-%d | %H:%M'),
                    'rush_up': data['rush_up'],
                    'rush_down': data['rush_down'],
                    'diff': data['diff'],
                    'count': data['count']
                })
            except:
                continue
        
        if not all_points:
            return jsonify({'error': 'æ— æœ‰æ•ˆæ•°æ®'})
        
        # è®¡ç®—æ€»é¡µæ•°(æ¯é¡µ12å°æ—¶)
        earliest = all_points[0]['time']
        latest = all_points[-1]['time']
        total_hours = (latest - earliest).total_seconds() / 3600
        total_pages = max(1, int(total_hours / 12) + 1)
        
        # ç¡®ä¿pageåœ¨æœ‰æ•ˆèŒƒå›´å†…
        if page < 0:
            page = 0
        if page >= total_pages:
            page = total_pages - 1
        
        # è®¡ç®—å½“å‰é¡µçš„æ—¶é—´èŒƒå›´(ä»æœ€æ–°å¾€å‰æ¨)
        # page=0 æ˜¯æœ€æ–°çš„12å°æ—¶,page=1 æ˜¯ä¹‹å‰çš„12å°æ—¶,ä»¥æ­¤ç±»æ¨
        page_end_time = latest - timedelta(hours=12 * page)
        page_start_time = page_end_time - timedelta(hours=12)
        
        # ç­›é€‰å½“å‰é¡µçš„æ•°æ®ç‚¹
        page_points = [
            p for p in all_points 
            if page_start_time <= p['time'] <= page_end_time
        ]
        
        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ•°æ®,è¿”å›ç©ºæ•°ç»„
        if not page_points:
            return jsonify({
                'times': [],
                'rush_up': [],
                'rush_down': [],
                'diff': [],
                'count': [],
                'page': page,
                'total_pages': total_pages,
                'has_prev': page < total_pages - 1,
                'has_next': page > 0,
                'time_range': {
                    'start': page_start_time.strftime('%Y-%m-%d %H:%M'),
                    'end': page_end_time.strftime('%Y-%m-%d %H:%M')
                },
                'data_count': 0
            })
        
        # æå–æ•°æ®
        times = [p['formatted_time'] for p in page_points]
        rush_up = [p['rush_up'] for p in page_points]
        rush_down = [p['rush_down'] for p in page_points]
        diff = [p['diff'] for p in page_points]
        count = [p['count'] for p in page_points]
        
        # æ£€æµ‹æ—¥æœŸå˜åŒ–,æ ‡è®°åˆ†éš”çº¿ä½ç½®
        date_separators = []
        prev_date = None
        for idx, p in enumerate(page_points):
            current_date = p['time'].strftime('%Y-%m-%d')
            if prev_date is not None and current_date != prev_date:
                # æ—¥æœŸå˜åŒ–,è®°å½•åˆ†éš”çº¿ä½ç½®(åœ¨ä¸¤ä¸ªæ•°æ®ç‚¹ä¹‹é—´)
                date_separators.append({
                    'index': idx,  # æ–°æ—¥æœŸå¼€å§‹çš„ä½ç½®
                    'date': current_date,
                    'prev_date': prev_date
                })
            prev_date = current_date
        
        return jsonify({
            'times': times,
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'count': count,
            'date_separators': date_separators,  # æ–°å¢:æ—¥æœŸåˆ†éš”çº¿ä½ç½®
            'page': page,
            'total_pages': total_pages,
            'has_prev': page < total_pages - 1,  # æœ‰ä¸Šä¸€é¡µ(æ›´æ—©çš„æ•°æ®)
            'has_next': page > 0,  # æœ‰ä¸‹ä¸€é¡µ(æ›´æ–°çš„æ•°æ®)
            'time_range': {
                'start': page_start_time.strftime('%Y-%m-%d %H:%M'),
                'end': page_end_time.strftime('%Y-%m-%d %H:%M')
            },
            'data_count': len(page_points)
        })
    
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/api/timeline')
def api_timeline():
    """è·å–æ‰€æœ‰å†å²æ•°æ®ç‚¹API - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from gdrive_jsonl_manager import GDriveJSONLManager
        
        # ä»JSONLè¯»å–æ‰€æœ‰èšåˆæ•°æ®
        jsonl_manager = GDriveJSONLManager()
        all_snapshots = jsonl_manager.read_all_snapshots()
        
        # æŒ‰æ—¶é—´åˆ†ç»„èšåˆ
        time_groups = {}
        for snap in all_snapshots:
            time_key = snap.get('snapshot_time')
            if not time_key:
                continue
            
            if time_key not in time_groups:
                time_groups[time_key] = {
                    'snapshot_time': time_key,
                    'snapshot_date': snap.get('snapshot_date', time_key.split()[0] if time_key else ''),
                    'rush_up': 0,
                    'rush_down': 0,
                    'count': 0,
                    'count_score_display': '',
                    'count_score_type': '',
                    'status': '',
                    'price_lowest': 0,
                    'price_newhigh': 0
                }
            
            # ç´¯åŠ æ€¥æ¶¨æ€¥è·Œ
            group = time_groups[time_key]
            group['rush_up'] += snap.get('rush_up', 0) or 0
            group['rush_down'] += snap.get('rush_down', 0) or 0
            group['count'] = snap.get('count', 0) or 0
            group['count_score_display'] = snap.get('count_score_display', '') or ''
            group['count_score_type'] = snap.get('count_score_type', '') or ''
            group['status'] = snap.get('status', '') or ''
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶è®¡ç®—diffå’Œratio
        snapshots = []
        for time_key in sorted(time_groups.keys(), reverse=True):  # æ—¶é—´å€’åº
            group = time_groups[time_key]
            diff = group['rush_up'] - group['rush_down']
            ratio = round(group['rush_up'] / group['rush_down'], 1) if group['rush_down'] > 0 else 0
            
            snapshots.append({
                'snapshot_time': group['snapshot_time'],
                'snapshot_date': group['snapshot_date'],
                'rush_up': group['rush_up'],
                'rush_down': group['rush_down'],
                'diff': diff,
                'count': group['count'],
                'ratio': ratio,
                'status': group['status'],
                'round_rush_up': 0,  # æš‚ä¸è®¡ç®—
                'round_rush_down': 0,
                'price_lowest': group['price_lowest'],
                'price_newhigh': group['price_newhigh'],
                'count_score_display': group['count_score_display'],
                'count_score_type': group['count_score_type'],
                'rise_24h_count': 0,
                'fall_24h_count': 0
            })
        
        return jsonify({
            'snapshots': snapshots,
            'total': len(snapshots)
        })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)})

# ==================== äº¤æ˜“ä¿¡å·ç›‘æ§ API ====================

@app.route('/signals')
def signals_page():
    """äº¤æ˜“ä¿¡å·ç›‘æ§é¡µé¢"""
    return render_template('signals.html')

@app.route('/popup-demo')
def popup_demo():
    """å¼¹çª—æ•ˆæœæ¼”ç¤ºé¡µé¢"""
    with open('popup_demo.html', 'r', encoding='utf-8') as f:
        return f.read()

@app.route('/api/signals/stats')
def api_signals_stats():
    """è·å–ä¿¡å·ç»Ÿè®¡æ•°æ®"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°è®°å½•
        cursor.execute('''
            SELECT record_time, long_signals, short_signals, 
                   total_signals, long_ratio, short_ratio
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        latest = cursor.fetchone()
        
        # è·å–æ€»è®°å½•æ•°
        cursor.execute('SELECT COUNT(*) FROM trading_signals')
        total_records = cursor.fetchone()[0]
        
        conn.close()
        
        if latest:
            return jsonify({
                'success': True,
                'data': {
                    'latest_time': latest[0],
                    'latest_long': latest[1],
                    'latest_short': latest[2],
                    'latest_total': latest[3],
                    'long_ratio': latest[4],
                    'short_ratio': latest[5],
                    'total_records': total_records
                }
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/signals/chart')
def api_signals_chart():
    """è·å–å›¾è¡¨æ•°æ®(æ”¯æŒåˆ†é¡µå’Œæ—¶é—´èŒƒå›´)"""
    try:
        page = int(request.args.get('page', 0))
        time_range = request.args.get('range', '12h')
        
        # è®¡ç®—æ—¶é—´èŒƒå›´å¯¹åº”çš„æ•°æ®ç‚¹æ•°é‡(æ¯3åˆ†é’Ÿä¸€ä¸ªç‚¹)
        range_minutes = {
            '1h': 60,
            '6h': 360,
            '12h': 720,
            '24h': 1440
        }
        
        minutes = range_minutes.get(time_range, 720)
        points_per_page = minutes // 3  # æ¯3åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹
        offset = page * points_per_page
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æ€»è®°å½•æ•°
        cursor.execute('SELECT COUNT(*) FROM trading_signals')
        total = cursor.fetchone()[0]
        total_pages = (total + points_per_page - 1) // points_per_page
        
        # è·å–åˆ†é¡µæ•°æ®
        cursor.execute('''
            SELECT record_time, long_signals, short_signals, total_signals
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT ? OFFSET ?
        ''', (points_per_page, offset))
        
        rows = cursor.fetchall()
        conn.close()
        
        # åè½¬é¡ºåº,ä½¿æ—¶é—´ä»æ—©åˆ°æ™š
        rows.reverse()
        
        data = [{
            'time': row[0].split(' ')[1][:5],  # åªå–æ—¶åˆ†
            'long_signals': row[1],
            'short_signals': row[2],
            'total_signals': row[3]
        } for row in rows]
        
        return jsonify({
            'success': True,
            'data': data,
            'page': page,
            'total_pages': total_pages,
            'range': time_range
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/signals/history')
def api_signals_history():
    """è·å–å†å²è®°å½•åˆ—è¡¨"""
    try:
        limit = int(request.args.get('limit', 50))
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT record_time, long_signals, short_signals,
                   total_signals, long_ratio, short_ratio
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        data = [{
            'record_time': row[0],
            'long_signals': row[1],
            'short_signals': row[2],
            'total_signals': row[3],
            'long_ratio': row[4],
            'short_ratio': row[5]
        } for row in rows]
        
        return jsonify({
            'success': True,
            'data': data
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/liquidation/30days')
def api_liquidation_30days():
    """30æ—¥çˆ†ä»“æ•°æ®API - ä»panicæŒ‰æ—¥æœŸåˆ†åŒºçš„æ•°æ®èšåˆ"""
    try:
        import json as json_module
        from datetime import datetime, timedelta
        from collections import defaultdict
        import glob
        
        # è¯»å–panicæŒ‰æ—¥æœŸåˆ†åŒºçš„æ•°æ®ç›®å½•
        panic_dir = '/home/user/webapp/data/panic_daily'
        
        if not os.path.exists(panic_dir):
            return jsonify({
                'success': True,
                'data': [],
                'count': 0,
                'summary': {
                    'total_amount': 0,
                    'long_short_ratio': 1.0
                }
            })
        
        # è·å–æœ€è¿‘30å¤©çš„æ•°æ®
        now = datetime.now(BEIJING_TZ)
        thirty_days_ago = now - timedelta(days=30)
        
        # æŒ‰æ—¥æœŸèšåˆæ•°æ®(æ¯å¤©å–æœ€æ–°çš„hour_24_amount)
        daily_data = {}
        
        # éå†æ‰€æœ‰æ—¥æœŸæ–‡ä»¶
        pattern = os.path.join(panic_dir, 'panic_*.jsonl')
        for file_path in glob.glob(pattern):
            filename = os.path.basename(file_path)
            # æå–æ—¥æœŸ: panic_20260128.jsonl -> 20260128
            date_str_compact = filename.replace('panic_', '').replace('.jsonl', '')
            
            try:
                # è½¬æ¢æ—¥æœŸæ ¼å¼: 20260128 -> 2026-01-28
                date_obj = datetime.strptime(date_str_compact, '%Y%m%d')
                date_obj = BEIJING_TZ.localize(date_obj)
                
                # åªä¿ç•™æœ€è¿‘30å¤©çš„æ•°æ®
                if date_obj < thirty_days_ago:
                    continue
                
                date_str = date_obj.strftime('%Y-%m-%d')
                
                # è¯»å–è¯¥æ—¥æœŸæ–‡ä»¶çš„æœ€åä¸€æ¡è®°å½•(æœ€æ–°æ•°æ®)
                with open(file_path, 'r', encoding='utf-8') as f:
                    last_line = None
                    for line in f:
                        if line.strip():
                            last_line = line.strip()
                    
                    if last_line:
                        record = json_module.loads(last_line)
                        # æ–°æ ¼å¼:æ•°æ®åœ¨ data å­—æ®µä¸­
                        data_content = record.get('data', {})
                        hour_24_amount = data_content.get('hour_24_amount', 0)
                        record_time = data_content.get('record_time', '')
                        
                        daily_data[date_str] = {
                            'hour_24_amount': hour_24_amount,
                            'record_time': record_time
                        }
            
            except (ValueError, TypeError, json_module.JSONDecodeError) as e:
                continue
        
        # ç”Ÿæˆç»“æœ(æŒ‰æ—¥æœŸé™åº,æœ€æ–°çš„åœ¨å‰)
        result = []
        total_amount = 0
        
        for date_str in sorted(daily_data.keys(), reverse=True):
            data = daily_data[date_str]
            amount = data['hour_24_amount']
            total_amount += amount
            
            result.append({
                'date': date_str,
                'long_amount': round(amount * 0.5, 2),  # å‡è®¾å¤šç©ºæ¯”çº¦1:1
                'short_amount': round(amount * 0.5, 2),
                'total_amount': round(amount, 2),
                'updated_at': data['record_time'] or f'{date_str} 23:59:59'
            })
        
        return jsonify({
            'success': True,
            'data': result,
            'count': len(result),
            'summary': {
                'total_amount': round(total_amount, 2),
                'long_short_ratio': 1.0  # é»˜è®¤å¤šç©ºæ¯”ä¸º1:1
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–30å¤©æ•°æ®å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })


@app.route('/api/panic/hour1-curve')
def api_panic_hour1_curve():
    """è·å–1å°æ—¶çˆ†ä»“é‡‘é¢æ›²çº¿æ•°æ® (1åˆ†é’Ÿä¸€ä¸ªç‚¹) - ä»æŒ‰æ—¥æœŸåˆ†åŒºçš„JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/code/source_code')
        from panic_daily_manager import PanicDailyManager
        
        # è·å–å°æ—¶æ•°å‚æ•°,é»˜è®¤24å°æ—¶
        hours = int(request.args.get('hours', 24))
        limit = hours * 60  # æ¯åˆ†é’Ÿä¸€ä¸ªç‚¹
        
        # è®¡ç®—éœ€è¦æŸ¥æ‰¾å¤šå°‘å¤©(å‘ä¸Šå–æ•´,+1ä½œä¸ºç¼“å†²)
        days_back = (hours // 24) + 2
        
        manager = PanicDailyManager()
        # è·å–æœ€æ–°çš„limitæ¡è®°å½•(å·²ç»æŒ‰æ—¶é—´å€’åº)
        all_records = manager.get_latest_records(limit=limit, days_back=days_back)
        
        if not all_records:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # åè½¬é¡ºåº(æ—§â†’æ–°,ç”¨äºå›¾è¡¨ä»å·¦åˆ°å³æ˜¾ç¤º)
        records = list(reversed(all_records))  # ä»å€’åºå˜æˆé¡ºåº(æ—§åˆ°æ–°)
        
        # æå–éœ€è¦çš„å­—æ®µ
        curve_data = []
        for record in records:
            # æå–dataå­—æ®µ
            data = record.get('data', {})
            
            # è§£ærecord_timeä¸ºtimestamp
            from datetime import datetime
            import pytz
            record_time_str = data.get('record_time', '')
            try:
                # è§£æåŒ—äº¬æ—¶é—´
                beijing_tz = pytz.timezone('Asia/Shanghai')
                dt = datetime.strptime(record_time_str, '%Y-%m-%d %H:%M:%S')
                dt = beijing_tz.localize(dt)
                timestamp = int(dt.timestamp())
                datetime_str = dt.strftime('%Y-%m-%d %H:%M:%S')
            except:
                timestamp = 0
                datetime_str = record_time_str
            
            curve_data.append({
                'record_time': record_time_str,
                'datetime': datetime_str,
                'timestamp': timestamp,
                'hour_1_amount': round(data.get('hour_1_amount', 0), 2),  # å•ä½: ä¸‡ç¾å…ƒ
                'hour_24_amount': round(data.get('hour_24_amount', 0), 2),  # å•ä½: ä¸‡ç¾å…ƒ
                'hour_24_people': round(data.get('hour_24_people', 0), 2),  # å•ä½: ä¸‡äºº
                'total_position': round(data.get('total_position', 0), 2),  # å•ä½: äº¿ç¾å…ƒ
                'panic_index': round(data.get('panic_index', 0), 2),  # ææ…ŒæŒ‡æ•° = çˆ†ä»“äººæ•°/æŒä»“æ€»é‡
                'wash_index': round(data.get('wash_index', 0), 6)
            })
        
        return jsonify({
            'success': True,
            'data': curve_data,
            'count': len(curve_data),
            'hours': hours,
            'data_source': 'JSONL'
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/panic/history')
def api_panic_history():
    """ææ…Œæ¸…æ´—æŒ‡æ•°å†å²æ•°æ®API(æ”¯æŒæ—¶é—´æŸ¥è¯¢)- ä»æŒ‰æ—¥æœŸåˆ†åŒºçš„JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from panic_daily_manager import PanicDailyManager
        
        limit = int(request.args.get('limit', 50))
        query_time = request.args.get('time', None)
        
        # è¯»å–panicæ•°æ®æ–‡ä»¶
        panic_file = '/home/user/webapp/data/panic_jsonl/panic_wash_index.jsonl'
        all_records = []
        
        # ä»JSONLæ–‡ä»¶è¯»å–å†å²æ•°æ®
        try:
            with open(panic_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        record = json.loads(line.strip())
                        all_records.append(record)
                    except:
                        continue
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}'
            })
        
        # æŒ‰æ—¶é—´å€’åºæ’åº(å…¼å®¹æ–°æ—§æ ¼å¼)
        def get_time_key(x):
            return x.get('beijing_time', x.get('record_time', ''))
        
        all_records.sort(key=get_time_key, reverse=True)
        
        # é™åˆ¶è¿”å›æ•°é‡
        read_limit = limit * 2 if query_time else limit
        all_records = all_records[:read_limit]
        
        if not all_records:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— å†å²æ•°æ®'
            })
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®(å…¼å®¹æ–°æ—§æ•°æ®æ ¼å¼)
        def is_valid_record(r):
            panic_index = r.get('panic_index', 0)
            
            # åŸºæœ¬æ¡ä»¶:ææ…ŒæŒ‡æ•°å¿…é¡»å¤§äº0
            if panic_index <= 0:
                return False
            
            # å…¼å®¹æ–°æ—§æ ¼å¼
            # æ–°æ ¼å¼:liquidation_data.liquidation_24h
            # æ—§æ ¼å¼:hour_24_amount
            liq_data = r.get('liquidation_data', {})
            hour_24_amount = liq_data.get('liquidation_24h', r.get('hour_24_amount', 0))
            
            # åªè¦æœ‰24hçˆ†ä»“æ•°æ®å°±è®¤ä¸ºæ˜¯æœ‰æ•ˆè®°å½•
            if hour_24_amount <= 0:
                return False
                
            return True
        
        valid_records = [r for r in all_records if is_valid_record(r)]
        
        # å¦‚æœæŒ‡å®šäº†æ—¶é—´æŸ¥è¯¢
        if query_time:
            # æ‰¾åˆ°æŸ¥è¯¢æ—¶é—´å‰åçš„æ•°æ®
            half_limit = limit // 2
            before = []
            after = []
            
            for record in valid_records:
                record_time = record.get('beijing_time', record.get('record_time', ''))
                if record_time <= query_time:
                    before.append(record)
                    if len(before) >= half_limit:
                        break
            
            for record in reversed(valid_records):
                record_time = record.get('beijing_time', record.get('record_time', ''))
                if record_time > query_time:
                    after.append(record)
                    if len(after) >= half_limit:
                        break
            
            selected_records = before + list(reversed(after))
        else:
            # é»˜è®¤è¿”å›æœ€æ–°çš„Næ¡
            selected_records = valid_records[:limit]
        
        # JSONLæ•°æ®å·²ç»æ˜¯æ ‡å‡†å•ä½(é‡‡é›†å™¨å·²è½¬æ¢),ç›´æ¥ä½¿ç”¨
        # å…¼å®¹æ–°æ—§ä¸¤ç§æ ¼å¼
        def format_record(record):
            # æ–°æ ¼å¼:æœ‰beijing_timeå’Œliquidation_data
            # æ—§æ ¼å¼:æœ‰record_timeå’Œç›´æ¥å­—æ®µ
            liq_data = record.get('liquidation_data', {})
            
            return {
                'record_time': record.get('beijing_time', record.get('record_time', '')),
                'panic_index': record.get('panic_index', 0),
                'hour_24_people': round(liq_data.get('liquidation_count_24h', record.get('hour_24_people', 0)), 2),
                'total_position': round(liq_data.get('open_interest', record.get('total_position', 0)), 2),
                'hour_1_amount': round(liq_data.get('liquidation_1h', record.get('hour_1_amount', 0)), 2),
                'hour_24_amount': round(liq_data.get('liquidation_24h', record.get('hour_24_amount', 0)), 2)
            }
        
        data = [format_record(record) for record in selected_records]
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/api/panic/history-range')
def api_panic_history_range():
    """
    è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„ææ…ŒæŒ‡æ•°å†å²æ•°æ®
    
    å‚æ•°:
        start_date: å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)  
        limit: æ¯å¤©è¿”å›çš„æœ€å¤§è®°å½•æ•°(é»˜è®¤:å…¨éƒ¨)
    
    è¿”å›:
        {
            "success": true,
            "count": æ€»è®°å½•æ•°,
            "date_range": "2026-02-01 to 2026-02-10",
            "data": [
                {
                    "record_time": "2026-02-01 09:12:00",
                    "hour_1_amount": 674.87,
                    "hour_24_amount": 79361.15,
                    "hour_24_people": 23.54,
                    "total_position": 75.37,
                    "panic_index": 0.312
                },
                ...
            ]
        }
    """
    try:
        from datetime import datetime, timedelta
        from pathlib import Path
        
        # è·å–å‚æ•°
        start_date = request.args.get('start_date', '2026-02-01')
        end_date = request.args.get('end_date', '2026-02-10')
        limit_per_day = request.args.get('limit', type=int, default=None)
        
        # æ•°æ®ç›®å½•(æ”¯æŒä¸‰ä¸ªæ•°æ®æº)
        PANIC_DAILY_DIR = Path('/home/user/webapp/data/panic_daily')
        PANIC_V3_DIR = Path('/home/user/webapp/panic_v3/data')
        PANIC_JSONL_FILE = Path('/home/user/webapp/data/panic_jsonl/panic_wash_index.jsonl')
        
        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            start = datetime.strptime(start_date, '%Y-%m-%d')
            end = datetime.strptime(end_date, '%Y-%m-%d')
        except ValueError:
            return jsonify({
                'success': False,
                'error': 'æ—¥æœŸæ ¼å¼é”™è¯¯,åº”ä¸º YYYY-MM-DD'
            })
        
        # åŠ è½½æ•°æ®
        all_data = []
        current = start
        
        while current <= end:
            date_str = current.strftime('%Y%m%d')
            date_ymd = current.strftime('%Y-%m-%d')
            
            # å…ˆå°è¯•è¯»å–panic_dailyç›®å½•(æ—§æ•°æ®)
            file_path_daily = PANIC_DAILY_DIR / f"panic_{date_str}.jsonl"
            # å†å°è¯•è¯»å–panic_v3ç›®å½•(æ–°æ•°æ®)
            file_path_v3 = PANIC_V3_DIR / f"panic_{date_str}.jsonl"
            
            day_data = []
            
            # ä¼˜å…ˆè¯»å–æ—§æ ¼å¼æ•°æ®
            if file_path_daily.exists():
                with open(file_path_daily, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            record = json.loads(line.strip())
                            # æ—§æ ¼å¼:dataå­—æ®µåŒ…å«å®é™…æ•°æ®
                            day_data.append(('old', record))
                        except:
                            continue
            
            # è¯»å–æ–°æ ¼å¼æ•°æ®(panic_v3)
            if file_path_v3.exists():
                with open(file_path_v3, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            record = json.loads(line.strip())
                            # æ–°æ ¼å¼:ç›´æ¥æ˜¯æ•°æ®
                            day_data.append(('new', record))
                        except:
                            continue
            
            # æ€»æ˜¯å°è¯•ä»panic_wash_index.jsonlè¯»å–å½“å¤©æ•°æ®(æ›´æ–°é²œçš„æ•°æ®)
            if PANIC_JSONL_FILE.exists():
                with open(PANIC_JSONL_FILE, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            record = json.loads(line.strip())
                            # æ£€æŸ¥æ—¥æœŸæ˜¯å¦åŒ¹é…
                            beijing_time = record.get('beijing_time', '')
                            if beijing_time.startswith(date_ymd):
                                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¶é—´çš„è®°å½•,é¿å…é‡å¤
                                existing_times = {d[1].get('beijing_time') for d in day_data}
                                if beijing_time not in existing_times:
                                    day_data.append(('new', record))
                        except:
                            continue
            
            # å¦‚æœæŒ‡å®šäº†æ¯å¤©çš„é™åˆ¶,åªå–æœ€æ–°çš„Næ¡
            if limit_per_day and len(day_data) > limit_per_day:
                day_data = day_data[-limit_per_day:]
            
            all_data.extend(day_data)
            
            current += timedelta(days=1)
        
        # æ ¼å¼åŒ–æ•°æ®(å…¼å®¹æ–°æ—§æ ¼å¼)
        formatted_data = []
        for format_type, record in all_data:
            if format_type == 'old':
                # æ—§æ ¼å¼:dataå­—æ®µåŒ…å«å®é™…æ•°æ®
                data_field = record.get('data', {})
                formatted_data.append({
                    'record_time': data_field.get('record_time'),
                    'hour_1_amount': round(data_field.get('hour_1_amount', 0), 2),
                    'hour_24_amount': round(data_field.get('hour_24_amount', 0), 2),
                    'hour_24_people': round(data_field.get('hour_24_people', 0), 2),
                    'total_position': round(data_field.get('total_position', 0), 2),
                    'panic_index': round(data_field.get('panic_index', 0), 4)
                })
            else:
                # æ–°æ ¼å¼:å¯èƒ½æ˜¯panic_v3æ ¼å¼(å­—æ®µåœ¨é¡¶å±‚)æˆ–panic_washæ ¼å¼(liquidation_dataåµŒå¥—)
                liq_data = record.get('liquidation_data', {})
                # ä¼˜å…ˆä»liquidation_dataè¯»å–,å¦‚æœä¸å­˜åœ¨åˆ™ä»é¡¶å±‚è¯»å–
                formatted_data.append({
                    'record_time': record.get('beijing_time'),
                    'hour_1_amount': round(liq_data.get('liquidation_1h', record.get('liquidation_1h', 0)), 2),
                    'hour_24_amount': round(liq_data.get('liquidation_24h', record.get('liquidation_24h', 0)), 2),
                    'hour_24_people': round(liq_data.get('liquidation_count_24h', record.get('liquidation_count_24h', 0)), 2),
                    'total_position': round(liq_data.get('open_interest', record.get('open_interest', 0)), 2),
                    'panic_index': round(record.get('panic_index', 0), 4)
                })
        
        return jsonify({
            'success': True,
            'count': len(formatted_data),
            'date_range': f"{start_date} to {end_date}",
            'data': formatted_data
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/panic/30d-stats')
def get_panic_30d_stats():
    """è·å–30å¤©çˆ†ä»“ç»Ÿè®¡æ•°æ®"""
    try:
        from panic_daily_manager import PanicDailyManager
        from datetime import datetime, timedelta
        import pytz
        
        manager = PanicDailyManager()
        
        # è·å–å†å²æ•°æ®(æœ€å¤šå–30å¤©)
        history = manager.get_recent_records(days=30, limit=10000)
        
        if not history:
            return jsonify({
                'success': True,
                'data': {
                    'total_people': 0,
                    'total_amount': 0,
                    'days_count': 0,
                    'message': 'æš‚æ— å†å²æ•°æ®'
                }
            })
        
        # è®¡ç®—30å¤©å‰çš„æ—¶é—´
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz).replace(tzinfo=None)
        thirty_days_ago = now - timedelta(days=30)
        
        # ç­›é€‰30å¤©å†…çš„æ•°æ®
        recent_30d = [
            h for h in history 
            if datetime.strptime(h['record_time'], '%Y-%m-%d %H:%M:%S') >= thirty_days_ago
        ]
        
        if not recent_30d:
            return jsonify({
                'success': True,
                'data': {
                    'total_people': 0,
                    'total_amount': 0,
                    'days_count': 0,
                    'message': '30å¤©å†…æ— æ•°æ®'
                }
            })
        
        # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
        daily_stats = {}
        for record in recent_30d:
            date = record['record_time'].split(' ')[0]
            if date not in daily_stats:
                daily_stats[date] = {
                    'people': 0,
                    'amount': 0
                }
            
            # å–æ¯å¤©çš„æœ€å¤§å€¼(å› ä¸º24hæ•°æ®æ˜¯ç´¯è®¡çš„)
            people = record.get('hour_24_people', 0)
            amount = record.get('hour_24_amount_usd', 0)
            
            if people > daily_stats[date]['people']:
                daily_stats[date]['people'] = people
            if amount > daily_stats[date]['amount']:
                daily_stats[date]['amount'] = amount
        
        # è®¡ç®—æ€»å’Œ
        total_people = sum(day['people'] for day in daily_stats.values())
        total_amount = sum(day['amount'] for day in daily_stats.values())
        
        return jsonify({
            'success': True,
            'data': {
                'total_people': round(total_people / 10000, 2),  # è½¬ä¸ºä¸‡äºº
                'total_amount': round(total_amount / 100000000, 2),  # è½¬ä¸ºäº¿ç¾å…ƒ
                'days_count': len(daily_stats),
                'message': f'ç»Ÿè®¡äº†æœ€è¿‘{len(daily_stats)}å¤©çš„æ•°æ®'
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–30å¤©ç»Ÿè®¡å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })


# ============================================
# ææƒ§è´ªå©ªæŒ‡æ•° API
# ============================================

@app.route('/api/fear-greed/latest')
def api_fear_greed_latest():
    """ææƒ§è´ªå©ªæŒ‡æ•°æœ€æ–°æ•°æ®API"""
    try:
        from fear_greed_jsonl_manager import FearGreedJSONLManager
        manager = FearGreedJSONLManager()
        
        latest = manager.get_latest_record()
        if not latest:
            return jsonify({
                'success': False,
                'error': 'æš‚æ— æ•°æ®'
            })
        
        return jsonify({
            'success': True,
            'data': {
                'datetime': latest.get('datetime'),
                'value': latest.get('value'),
                'result': latest.get('result'),
                'source': latest.get('source', 'btc123.fans'),
                'updated_at': latest.get('updated_at')
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–ææƒ§è´ªå©ªæŒ‡æ•°å¤±è´¥: {str(e)}'
        })


@app.route('/api/fear-greed/history')
def api_fear_greed_history():
    """ææƒ§è´ªå©ªæŒ‡æ•°å†å²æ•°æ®API"""
    try:
        from fear_greed_jsonl_manager import FearGreedJSONLManager
        manager = FearGreedJSONLManager()
        
        # è·å–å‚æ•°
        limit = request.args.get('limit', 30, type=int)
        start_date = request.args.get('start_date', '')
        end_date = request.args.get('end_date', '')
        
        if start_date and end_date:
            # æŒ‰æ—¥æœŸèŒƒå›´æŸ¥è¯¢
            records = manager.get_records_by_date_range(start_date, end_date)
        else:
            # æŸ¥è¯¢æœ€è¿‘Næ¡
            records = manager.get_latest_n_records(limit)
        
        return jsonify({
            'success': True,
            'total': len(records),
            'data': records
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}'
        })


@app.route('/api/fear-greed/statistics')
def api_fear_greed_statistics():
    """ææƒ§è´ªå©ªæŒ‡æ•°ç»Ÿè®¡API"""
    try:
        from fear_greed_jsonl_manager import FearGreedJSONLManager
        manager = FearGreedJSONLManager()
        
        stats = manager.get_statistics()
        
        return jsonify({
            'success': True,
            'data': stats
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'
        })


@app.route('/api/modules/stats')
def api_modules_stats():
    """è·å–æ‰€æœ‰æ¨¡å—çš„ç»Ÿè®¡ä¿¡æ¯"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # 1. å†å²æ•°æ®æŸ¥è¯¢æ¨¡å—ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM crypto_snapshots")
        query_total = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT snapshot_date) FROM crypto_snapshots")
        query_days = cursor.fetchone()[0]
        
        cursor.execute("SELECT MAX(snapshot_time) FROM crypto_snapshots")
        query_last_time = cursor.fetchone()[0] or '-'
        if query_last_time != '-':
            # å¤„ç†æ—¶é—´æ ¼å¼:å¯èƒ½æ˜¯ "HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM:SS"
            if ' ' in query_last_time:
                query_last_time = query_last_time.split(' ')[1][:5]  # å–HH:MM
            else:
                query_last_time = query_last_time[:5]  # å·²ç»æ˜¯HH:MM:SS,å–HH:MM
        
        # 2. äº¤æ˜“ä¿¡å·ç›‘æ§æ¨¡å—ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM trading_signal_history")
        signal_total = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT DATE(created_at)) FROM trading_signal_history")
        signal_days = cursor.fetchone()[0]
        
        cursor.execute("SELECT MAX(created_at) FROM trading_signal_history")
        signal_last_time = cursor.fetchone()[0] or '-'
        if signal_last_time != '-':
            # å¤„ç†æ—¶é—´æ ¼å¼:å¯èƒ½æ˜¯ "HH:MM:SS" æˆ– "YYYY-MM-DD HH:MM:SS"
            if ' ' in signal_last_time:
                signal_last_time = signal_last_time.split(' ')[1][:5]  # å–HH:MM
            else:
                signal_last_time = signal_last_time[:5]  # å·²ç»æ˜¯HH:MM:SS,å–HH:MM
        
        # 3. ææ…Œæ¸…æ´—æŒ‡æ•°æ¨¡å—ç»Ÿè®¡(ä»æŒ‰æ—¥æœŸåˆ†åŒºçš„JSONLè¯»å–)
        try:
            from panic_daily_manager import PanicDailyManager
            panic_manager = PanicDailyManager()
            
            # è·å–æœ€è¿‘30å¤©çš„æ•°æ®
            panic_history = panic_manager.get_recent_records(days=30, limit=10000)
            
            if panic_history:
                panic_total = len(panic_history)
                
                # ç»Ÿè®¡å¤©æ•°
                dates = set()
                last_time = '-'
                for record in panic_history:
                    record_time = record.get('record_time', '')
                    if record_time:
                        dates.add(record_time.split(' ')[0])
                        last_time = record_time
                
                panic_days = len(dates)
                if last_time != '-' and ' ' in last_time:
                    panic_last_time = last_time.split(' ')[1][:5]  # å–HH:MM
                else:
                    panic_last_time = '-'
            else:
                panic_total = 0
                panic_days = 0
                panic_last_time = '-'
        except Exception as e:
            logging.error(f"è¯»å–ææ…ŒæŒ‡æ•°JSONLå¤±è´¥: {e}")
            panic_total = 0
            panic_days = 0
            panic_last_time = '-'
        
        
        conn.close()
        
        return jsonify({
            'success': True,
            'query_module': {
                'total_records': query_total,
                'data_days': query_days,
                'last_update': query_last_time
            },
            'signal_module': {
                'total_records': signal_total,
                'data_days': signal_days,
                'last_update': signal_last_time
            },
            'panic_module': {
                'total_records': panic_total,
                'data_days': panic_days,
                'last_update': panic_last_time
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/price-comparison')
def price_comparison_page():
    """æ¯”ä»·ç³»ç»Ÿé¡µé¢"""
    return render_template('price_comparison.html')

@app.route('/price-position')
def price_position_page():
    """ä»·æ ¼æŒä»“ç³»ç»Ÿé¡µé¢"""
    response = make_response(render_template('price_position_unified.html'))
    # ç¦ç”¨ç¼“å­˜ + æ·»åŠ æ—¶é—´æˆ³å¼ºåˆ¶åˆ·æ–°
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    response.headers['Last-Modified'] = datetime.now(timezone.utc).strftime('%a, %d %b %Y %H:%M:%S GMT')
    response.headers['ETag'] = str(int(time.time() * 1000))  # æ¯«ç§’æ—¶é—´æˆ³ä½œä¸º ETag
    return response

@app.route('/api/price-comparison/list')
def api_price_comparison_list():
    """è·å–æ¯”ä»·ç³»ç»Ÿæ‰€æœ‰å¸ç§æ•°æ® - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from price_comparison_jsonl_manager import PriceComparisonJSONLManager
        
        manager = PriceComparisonJSONLManager()
        data = manager.get_all_coins()
        
        return jsonify({
            'success': True,
            'data': data,
            'total': len(data),
            'data_source': 'JSONL'
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/update', methods=['POST'])
def api_price_comparison_update():
    """æ›´æ–°å¸ç§ä»·æ ¼å¹¶è¿›è¡Œæ¯”ä»·åˆ¤æ–­
    
    é€»è¾‘:
    - æ–°ä»·æ ¼ > æœ€é«˜ä»·: æ›´æ–°æœ€é«˜ä»·,æœ€é«˜è®¡æ¬¡æ¸…é›¶
    - æ–°ä»·æ ¼ < æœ€ä½ä»·: æ›´æ–°æœ€ä½ä»·,æœ€ä½è®¡æ¬¡æ¸…é›¶  
    - æœ€ä½ä»· <= æ–°ä»·æ ¼ <= æœ€é«˜ä»·: ä¸¤ä¸ªè®¡æ¬¡éƒ½+1
    """
    try:
        data = request.get_json()
        coin_name = data.get('coin_name')
        new_price = float(data.get('price'))
        
        if not coin_name or new_price is None:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦å‚æ•°: coin_name æˆ– price'
            })
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–å½“å‰å¸ç§çš„æœ€é«˜ä»·å’Œæœ€ä½ä»·
        cursor.execute('''
            SELECT highest_price, highest_count, lowest_price, lowest_count
            FROM price_baseline
            WHERE symbol = ?
        ''', (coin_name,))
        
        row = cursor.fetchone()
        if not row:
            conn.close()
            return jsonify({
                'success': False,
                'error': f'å¸ç§ {coin_name} ä¸å­˜åœ¨'
            })
        
        highest_price, highest_count, lowest_price, lowest_count = row
        old_highest_price = highest_price
        old_lowest_price = lowest_price
        
        # ä»·æ ¼æ¯”è¾ƒé€»è¾‘
        action = ''
        if new_price > highest_price:
            # æ–°ä»·æ ¼åˆ›æ–°é«˜
            old_highest_price = highest_price
            highest_price = new_price
            highest_count = 0
            action = 'new_high'
        elif new_price < lowest_price:
            # æ–°ä»·æ ¼åˆ›æ–°ä½
            old_lowest_price = lowest_price
            lowest_price = new_price
            lowest_count = 0
            action = 'new_low'
        else:
            # ä»·æ ¼åœ¨åŒºé—´å†…
            highest_count += 1
            lowest_count += 1
            action = 'in_range'
        
        # è®¡ç®—å æ¯”
        # æœ€é«˜ä»·å æ¯” = (å½“å‰ä»· / æœ€é«˜ä»·) Ã— 100
        highest_ratio = round((new_price / highest_price) * 100, 2) if highest_price > 0 else 0
        # æœ€ä½ä»·å æ¯” = (å½“å‰ä»· / æœ€ä½ä»·) Ã— 100
        lowest_ratio = round((new_price / lowest_price) * 100, 2) if lowest_price > 0 else 0
        
        # æ›´æ–°æ•°æ®åº“ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
        from datetime import datetime
        import pytz
        beijing_tz = pytz.timezone('Asia/Shanghai')
        beijing_time = datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            UPDATE price_baseline
            SET highest_price = ?,
                highest_count = ?,
                lowest_price = ?,
                lowest_count = ?,
                highest_ratio = ?,
                lowest_ratio = ?,
                last_update_time = ?
            WHERE symbol = ?
        ''', (highest_price, highest_count, lowest_price, lowest_count, 
              highest_ratio, lowest_ratio, beijing_time, coin_name))
        
        # å¦‚æœå‘ç”Ÿåˆ›æ–°é«˜æˆ–åˆ›æ–°ä½,è®°å½•äº‹ä»¶
        if action in ['new_high', 'new_low']:
            cursor.execute('''
                INSERT INTO price_breakthrough_events 
                (symbol, event_type, price, event_time)
                VALUES (?, ?, ?, ?)
            ''', (coin_name, action, new_price, beijing_time))
            
            # æ›´æ–°ç»Ÿè®¡è¡¨ç¼“å­˜(æ¸…é™¤ä»Šå¤©çš„ç¼“å­˜,ä¸‹æ¬¡æŸ¥è¯¢æ—¶ä¼šé‡æ–°è®¡ç®—)
            today_date = beijing_tz.localize(datetime.now()).strftime('%Y-%m-%d')
            cursor.execute('''
                DELETE FROM price_comparison_stats
                WHERE stat_date = ?
            ''', (today_date,))
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'action': action,
            'data': {
                'coin_name': coin_name,
                'new_price': new_price,
                'highest_price': highest_price,
                'highest_count': highest_count,
                'lowest_price': lowest_price,
                'lowest_count': lowest_count
            }
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/breakthrough-stats')
def api_breakthrough_stats():
    """è·å–åˆ›æ–°é«˜/ä½ç»Ÿè®¡ - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from price_comparison_jsonl_manager import PriceComparisonJSONLManager
        
        manager = PriceComparisonJSONLManager()
        stats = manager.get_breakthrough_stats()
        
        return jsonify({
            'success': True,
            'data': stats,
            'data_source': 'JSONL'
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/breakthrough-logs')
def api_breakthrough_logs():
    """è·å–åˆ›æ–°é«˜/ä½è¯¦ç»†æ—¥å¿— - ä»JSONLè¯»å–
    
    å‚æ•°:
    - limit: è¿”å›è®°å½•æ•°é‡,é»˜è®¤50
    - days: æŸ¥è¯¢æœ€è¿‘Nå¤©çš„è®°å½•,é»˜è®¤7å¤©
    - coin: ç­›é€‰ç‰¹å®šå¸ç§
    - type: ç­›é€‰ç±»å‹ (new_high/new_low)
    
    è¿”å›:
    - æ—¶é—´ã€å¸åã€äº‹ä»¶ç±»å‹(åˆ›æ–°é«˜/åˆ›æ–°ä½)ã€ä»·æ ¼ã€ä¹‹å‰æå€¼ä»·æ ¼
    """
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from price_comparison_jsonl_manager import PriceComparisonJSONLManager
        
        # è·å–å‚æ•°
        limit = request.args.get('limit', 50, type=int)
        days = request.args.get('days', 7, type=int)
        coin_filter = request.args.get('coin', None)
        type_filter = request.args.get('type', None)
        
        manager = PriceComparisonJSONLManager()
        logs = manager.get_breakthrough_events(
            limit=limit,
            days=days,
            coin_filter=coin_filter,
            type_filter=type_filter
        )
        
        return jsonify({
            'success': True,
            'data': logs,
            'count': len(logs),
            'filters': {
                'days': days,
                'coin': coin_filter,
                'type': type_filter,
                'limit': limit
            },
            'data_source': 'JSONL'
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/price-comparison/update-ratios')
def api_update_price_ratios():
    """æ‰¹é‡æ›´æ–°æ‰€æœ‰å¸ç§çš„ä»·æ ¼å æ¯”
    
    ä»æœ€æ–°å¿«ç…§æ•°æ®è·å–å½“å‰ä»·æ ¼,è®¡ç®—å¹¶æ›´æ–°å æ¯”:
    - æœ€é«˜ä»·å æ¯” = (å½“å‰ä»· / æœ€é«˜ä»·) Ã— 100%
    - æœ€ä½ä»·å æ¯” = (å½“å‰ä»· / æœ€ä½ä»·) Ã— 100%
    """
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°å¿«ç…§æ—¶é—´
        cursor.execute('SELECT MAX(snapshot_time) FROM crypto_coin_data')
        latest_time = cursor.fetchone()[0]
        
        if not latest_time:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰æ‰¾åˆ°å¿«ç…§æ•°æ®'
            })
        
        # è·å–æœ€æ–°å¿«ç…§çš„æ‰€æœ‰å¸ç§ä»·æ ¼
        cursor.execute('''
            SELECT symbol, current_price
            FROM crypto_coin_data
            WHERE snapshot_time = ?
        ''', (latest_time,))
        
        current_prices = {row[0]: row[1] for row in cursor.fetchall()}
        
        # è·å–æ‰€æœ‰å¸ç§çš„æœ€é«˜ä»·å’Œæœ€ä½ä»·
        cursor.execute('''
            SELECT symbol, highest_price, lowest_price
            FROM price_baseline
        ''')
        
        from datetime import datetime
        import pytz
        beijing_tz = pytz.timezone('Asia/Shanghai')
        current_time = datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        
        updated_count = 0
        update_details = []
        
        for row in cursor.fetchall():
            coin_name, highest_price, lowest_price = row
            
            # æŸ¥æ‰¾å½“å‰ä»·æ ¼
            current_price = current_prices.get(coin_name)
            
            if current_price is not None and current_price > 0:
                # è®¡ç®—å æ¯”
                highest_ratio = round((current_price / highest_price) * 100, 2) if highest_price > 0 else 0
                lowest_ratio = round((current_price / lowest_price) * 100, 2) if lowest_price > 0 else 0
                
                # æ›´æ–°æ•°æ®åº“
                cursor.execute('''
                    UPDATE price_baseline
                    SET highest_ratio = ?,
                        lowest_ratio = ?,
                        last_update_time = ?
                    WHERE symbol = ?
                ''', (highest_ratio, lowest_ratio, current_time, coin_name))
                
                updated_count += 1
                update_details.append({
                    'coin_name': coin_name,
                    'current_price': current_price,
                    'highest_ratio': highest_ratio,
                    'lowest_ratio': lowest_ratio
                })
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': f'æˆåŠŸæ›´æ–° {updated_count} ä¸ªå¸ç§çš„å æ¯”',
            'snapshot_time': latest_time,
            'updated_count': updated_count,
            'details': update_details[:10]  # åªè¿”å›å‰10ä¸ªä½œä¸ºç¤ºä¾‹
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/monitor/data-collection')
def api_monitor_data_collection():
    """ç›‘æ§æ•°æ®é‡‡é›†çŠ¶æ€"""
    try:
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # è·å–æœ€æ–°å¿«ç…§æ—¶é—´
        cursor.execute('SELECT MAX(snapshot_time) FROM crypto_snapshots')
        latest_snapshot = cursor.fetchone()[0]
        
        if not latest_snapshot:
            return jsonify({
                'success': False,
                'error': 'æ•°æ®åº“ä¸­æ²¡æœ‰ä»»ä½•å¿«ç…§æ•°æ®',
                'status': 'no_data'
            })
        
        # è®¡ç®—æ—¶é—´å·®
        latest_time = datetime.strptime(latest_snapshot, '%Y-%m-%d %H:%M:%S')
        latest_time = beijing_tz.localize(latest_time)
        time_diff_minutes = (now - latest_time).total_seconds() / 60
        
        # è·å–ä»Šå¤©çš„é‡‡é›†æ¬¡æ•°
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT COUNT(*) FROM crypto_snapshots 
            WHERE snapshot_time >= ?
        ''', (today_start_str,))
        today_count = cursor.fetchone()[0]
        
        conn.close()
        
        # åˆ¤æ–­çŠ¶æ€
        status = 'normal'
        message = 'æ•°æ®é‡‡é›†æ­£å¸¸'
        alert_level = 'success'
        
        if time_diff_minutes > 20:
            status = 'critical'
            message = f'ä¸¥é‡: å·²ç» {time_diff_minutes:.1f} åˆ†é’Ÿæ²¡æœ‰æ–°æ•°æ®'
            alert_level = 'danger'
        elif time_diff_minutes > 15:
            status = 'warning'
            message = f'è­¦å‘Š: å·²ç» {time_diff_minutes:.1f} åˆ†é’Ÿæ²¡æœ‰æ–°æ•°æ®'
            alert_level = 'warning'
        
        # è®¡ç®—é¢„æœŸé‡‡é›†æ¬¡æ•°(æ¯10åˆ†é’Ÿä¸€æ¬¡)
        expected_count = int((now.hour * 60 + now.minute) / 10)
        
        return jsonify({
            'success': True,
            'status': status,
            'message': message,
            'alert_level': alert_level,
            'data': {
                'current_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'latest_snapshot': latest_snapshot,
                'time_diff_minutes': round(time_diff_minutes, 1),
                'today_count': today_count,
                'expected_count': expected_count,
                'collection_rate': round((today_count / expected_count * 100) if expected_count > 0 else 0, 1)
            }
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/monitor')
def monitor_page():
    """æ•°æ®é‡‡é›†ç›‘æ§é¡µé¢(å¢å¼ºç‰ˆ)- æ”¯æŒæ‰§è¡Œæ—¥å¿—ã€å¼€å…³æ§åˆ¶ã€åˆ·æ–°é—´éš”"""
    return render_template('unified_monitor_enhanced.html')

@app.route('/monitor-old')
def monitor_page_old():
    """åŸå§‹ç›‘æ§é¡µé¢(æ—§ç‰ˆ)"""
    return render_template('monitor.html')

@app.route('/monitor-charts')
def monitor_charts_page():
    """ç›‘æ§ç³»ç»Ÿ - ä¸‰å¤§æ ¸å¿ƒå›¾è¡¨"""
    return render_template('monitor_charts.html')

@app.route('/star-system')
def star_system_page():
    """æ˜Ÿæ˜Ÿç³»ç»Ÿé¡µé¢"""
    return render_template('star_system.html')

@app.route('/api/star-system/data')
def api_star_system_data():
    """è·å–æ˜Ÿæ˜Ÿç³»ç»Ÿæ‰€æœ‰æŒ‡æ ‡æ•°æ®"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from star_system import calculate_star_system
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        beijing_tz = pytz.timezone('Asia/Shanghai')
        
        # è·å–æœ€æ–°å¿«ç…§æ•°æ®
        cursor.execute('''
            SELECT rush_up, rush_down, diff, count, snapshot_time
            FROM crypto_snapshots
            ORDER BY snapshot_date DESC, snapshot_time DESC
            LIMIT 1
        ''')
        snapshot = cursor.fetchone()
        
        if not snapshot:
            return jsonify({'success': False, 'error': 'æš‚æ— å¿«ç…§æ•°æ®'})
        
        rush_up, rush_down, diff, count, snapshot_time = snapshot
        
        # ç¡®ä¿æ•°å€¼ä¸ä¸ºNone
        rush_up = rush_up if rush_up is not None else 0
        rush_down = rush_down if rush_down is not None else 0
        diff = diff if diff is not None else 0
        count = count if count is not None else 0
        
        # è·å–å…¨ç½‘æŒä»“é‡(ä»ææ…Œæ¸…æ´—æŒ‡æ•°è¡¨)
        cursor.execute('''
            SELECT total_position
            FROM panic_wash_index
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        holdings_row = cursor.fetchone()
        holdings = holdings_row[0] if holdings_row and holdings_row[0] is not None else 10000000000  # é»˜è®¤100äº¿(å…ƒ)
        
        # è·å–åšå¤šåšç©ºä¿¡å·(ä»äº¤æ˜“ä¿¡å·è¡¨)
        cursor.execute('''
            SELECT long_signals, short_signals
            FROM trading_signals
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        signals_row = cursor.fetchone()
        long_signals = signals_row[0] if signals_row and signals_row[0] is not None else 0
        short_signals = signals_row[1] if signals_row and signals_row[1] is not None else 0
        
        # è·å–ä»Šæ—¥åˆ›æ–°é«˜æ–°ä½æ¬¡æ•°
        today_start = datetime.now(beijing_tz).replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT event_type, COUNT(*) 
            FROM price_breakthrough_events 
            WHERE event_time >= ?
            GROUP BY event_type
        ''', (today_start_str,))
        today_breakthrough = dict(cursor.fetchall())
        new_high_today = today_breakthrough.get('new_high', 0)
        new_low_today = today_breakthrough.get('new_low', 0)
        
        # è·å–å¸ç§ç»Ÿè®¡æ•°æ®(ä»æœ€æ–°å¿«ç…§çš„è¯¦ç»†æ•°æ®)
        cursor.execute('''
            SELECT symbol, rush_up, rush_down, priority_level
            FROM crypto_coin_data
            WHERE snapshot_time = ?
        ''', (snapshot_time,))
        coin_data = cursor.fetchall()
        
        # ç»Ÿè®¡ç‰¹æ®Šæƒ…å†µå¹¶è®°å½•å…·ä½“å¸ç§
        only_rush_up_coins = [c[0] for c in coin_data if c[1] > 0 and c[2] == 0]
        only_rush_up_count = len(only_rush_up_coins)
        
        rush_up_gt_down_coins = [c[0] for c in coin_data if c[1] > c[2]]
        rush_up_gt_down_count = len(rush_up_gt_down_coins)
        
        only_rush_down_coins = [c[0] for c in coin_data if c[1] == 0 and c[2] > 0]
        only_rush_down_count = len(only_rush_down_coins)
        
        rush_down_gt_up_coins = [c[0] for c in coin_data if c[2] > c[1]]
        rush_down_gt_up_count = len(rush_down_gt_up_coins)
        
        # ä¼˜å…ˆçº§â‰¥4 means ç­‰çº§1,2,3,4 (priority_level values: 'ç­‰çº§1', 'ç­‰çº§2', etc.)
        priority_high_coins = [c[0] for c in coin_data if c[3] in ['ç­‰çº§1', 'ç­‰çº§2', 'ç­‰çº§3', 'ç­‰çº§4']]
        priority_high_count = len(priority_high_coins)
        
        # ========== æ–°å¢åŠŸèƒ½3: ä½ç½®ç³»ç»Ÿå¹³å‡ä½ç½®(åœ¨conn.close()ä¹‹å‰æŸ¥è¯¢) ==========
        try:
            # è®¡ç®—48å°æ—¶å‰çš„åŒ—äº¬æ—¶é—´
            hours_ago_48 = datetime.now(beijing_tz) - timedelta(hours=48)
            hours_ago_48_str = hours_ago_48.strftime('%Y-%m-%d %H:%M:%S')
            
            cursor.execute("""
                SELECT 
                    AVG(position_4h) as avg_4h,
                    AVG(position_12h) as avg_12h,
                    AVG(position_24h) as avg_24h,
                    AVG(position_48h) as avg_48h
                FROM position_system
                WHERE record_time >= ?
            """, (hours_ago_48_str,))
            pos_row = cursor.fetchone()
            
            position_avg = {
                '4h': round(pos_row[0], 2) if pos_row and pos_row[0] else 0,
                '12h': round(pos_row[1], 2) if pos_row and pos_row[1] else 0,
                '24h': round(pos_row[2], 2) if pos_row and pos_row[2] else 0,
                '48h': round(pos_row[3], 2) if pos_row and pos_row[3] else 0
            }
        except Exception as e:
            position_avg = {'4h': 0, '12h': 0, '24h': 0, '48h': 0}
            print(f"ä½ç½®ç³»ç»Ÿå¹³å‡ä½ç½®æŸ¥è¯¢é”™è¯¯: {e}")
        
        # ========== æ–°å¢åŠŸèƒ½4: åˆ›æ–°é«˜/åˆ›æ–°ä½ç»Ÿè®¡(åœ¨conn.close()ä¹‹å‰æŸ¥è¯¢) ==========
        try:
            # å½“å¤©ç»Ÿè®¡(ä»Šå¤©0ç‚¹åˆ°ç°åœ¨)
            today_start = datetime.now(beijing_tz).replace(hour=0, minute=0, second=0, microsecond=0)
            today_start_str = today_start.strftime('%Y-%m-%d %H:%M:%S')
            
            # 3å¤©ç»Ÿè®¡
            three_days_ago = datetime.now(beijing_tz) - timedelta(days=3)
            three_days_ago_str = three_days_ago.strftime('%Y-%m-%d %H:%M:%S')
            
            # 7å¤©ç»Ÿè®¡
            seven_days_ago = datetime.now(beijing_tz) - timedelta(days=7)
            seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d %H:%M:%S')
            
            # æŸ¥è¯¢å½“å¤©åˆ›æ–°é«˜/åˆ›æ–°ä½
            cursor.execute("""
                SELECT 
                    SUM(CASE WHEN event_type = 'new_high' THEN 1 ELSE 0 END) as today_high,
                    SUM(CASE WHEN event_type = 'new_low' THEN 1 ELSE 0 END) as today_low
                FROM price_breakthrough_events
                WHERE event_time >= ?
            """, (today_start_str,))
            today_bt = cursor.fetchone()
            
            # æŸ¥è¯¢3å¤©åˆ›æ–°é«˜/åˆ›æ–°ä½
            cursor.execute("""
                SELECT 
                    SUM(CASE WHEN event_type = 'new_high' THEN 1 ELSE 0 END) as three_days_high,
                    SUM(CASE WHEN event_type = 'new_low' THEN 1 ELSE 0 END) as three_days_low
                FROM price_breakthrough_events
                WHERE event_time >= ?
            """, (three_days_ago_str,))
            three_days_bt = cursor.fetchone()
            
            # æŸ¥è¯¢7å¤©åˆ›æ–°é«˜/åˆ›æ–°ä½
            cursor.execute("""
                SELECT 
                    SUM(CASE WHEN event_type = 'new_high' THEN 1 ELSE 0 END) as seven_days_high,
                    SUM(CASE WHEN event_type = 'new_low' THEN 1 ELSE 0 END) as seven_days_low
                FROM price_breakthrough_events
                WHERE event_time >= ?
            """, (seven_days_ago_str,))
            seven_days_bt = cursor.fetchone()
            
            breakthrough_stats = {
                'today': {
                    'new_high': today_bt[0] if today_bt and today_bt[0] else 0,
                    'new_low': today_bt[1] if today_bt and today_bt[1] else 0
                },
                'three_days': {
                    'new_high': three_days_bt[0] if three_days_bt and three_days_bt[0] else 0,
                    'new_low': three_days_bt[1] if three_days_bt and three_days_bt[1] else 0
                },
                'seven_days': {
                    'new_high': seven_days_bt[0] if seven_days_bt and seven_days_bt[0] else 0,
                    'new_low': seven_days_bt[1] if seven_days_bt and seven_days_bt[1] else 0
                }
            }
        except Exception as e:
            breakthrough_stats = {
                'today': {'new_high': 0, 'new_low': 0},
                'three_days': {'new_high': 0, 'new_low': 0},
                'seven_days': {'new_high': 0, 'new_low': 0}
            }
            print(f"åˆ›æ–°é«˜/åˆ›æ–°ä½ç»Ÿè®¡æŸ¥è¯¢é”™è¯¯: {e}")
        
        conn.close()
        
        # å‡†å¤‡æ•°æ®ç»™æ˜Ÿæ˜Ÿç³»ç»Ÿè®¡ç®—
        data = {
            'rush_up': rush_up,
            'rush_down': rush_down,
            'diff': diff,
            'holdings': holdings,
            'long_signals': long_signals,
            'short_signals': short_signals,
            'only_rush_up_count': only_rush_up_count,
            'rush_up_gt_down_count': rush_up_gt_down_count,
            'priority_high_count': priority_high_count,
            'only_rush_down_count': only_rush_down_count,
            'rush_down_gt_up_count': rush_down_gt_up_count,
            'new_low_today': new_low_today,
            'new_high_today': new_high_today,
            'count': count,
            'snapshot_time': snapshot_time
        }
        
        # è®¡ç®—æ˜Ÿæ˜Ÿç³»ç»Ÿ
        results = calculate_star_system(data)
        
        # ä¿å­˜åˆ°å†å²è®°å½•è¡¨(æ¯æ¬¡è°ƒç”¨APIæ—¶ä¿å­˜)
        try:
            import json as json_lib
            cursor.execute('''
                INSERT INTO star_system_history 
                (timestamp, total_stars, solid_stars, hollow_stars, solid_percentage, hollow_percentage, raw_data)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                snapshot_time,
                results.get('total_stars', 0),
                results.get('solid_stars', 0),
                results.get('hollow_stars', 0),
                results.get('solid_percentage', 0),
                results.get('hollow_percentage', 0),
                json_lib.dumps(results, ensure_ascii=False)
            ))
            conn.commit()
        except Exception as save_err:
            print(f"ä¿å­˜å†å²æ•°æ®å¤±è´¥: {save_err}")
        
        # æ·»åŠ å¸ç§åˆ—è¡¨åˆ°ç»“æœä¸­
        coin_lists = {
            'only_rush_up_coins': only_rush_up_coins,
            'rush_up_gt_down_coins': rush_up_gt_down_coins,
            'priority_high_coins': priority_high_coins,
            'only_rush_down_coins': only_rush_down_coins,
            'rush_down_gt_up_coins': rush_down_gt_up_coins
        }
        
        # ========== æ–°å¢åŠŸèƒ½1: V1/V2å¸ç§ç»Ÿè®¡ ==========
        try:
            conn_v1v2 = sqlite3.connect('v1v2_data.db')
            cursor_v1v2 = conn_v1v2.cursor()
            
            coins_list = ['BTC', 'ETH', 'XRP', 'SOL', 'BNB', 'LTC', 'DOGE', 'SUI', 'TRX', 'TON', 
                         'ETC', 'BCH', 'HBAR', 'XLM', 'FIL', 'ADA', 'LINK', 'CRO', 'DOT', 'UNI',
                         'NEAR', 'APT', 'CFX', 'CRV', 'STX', 'LDO', 'TAO', 'AAVE']
            
            v1_coins_list = []
            v2_coins_list = []
            
            for coin in coins_list:
                try:
                    cursor_v1v2.execute(f"""
                        SELECT level FROM volume_{coin.lower()}
                        ORDER BY id DESC LIMIT 1
                    """)
                    row = cursor_v1v2.fetchone()
                    if row and row[0] == 'V1':
                        v1_coins_list.append(coin)
                    elif row and row[0] == 'V2':
                        v2_coins_list.append(coin)
                except:
                    pass
            
            conn_v1v2.close()
        except:
            v1_coins_list = []
            v2_coins_list = []
        
        # ========== æ–°å¢åŠŸèƒ½2: 1åˆ†é’Ÿæ¶¨è·Œé€Ÿé¢„è­¦ç»Ÿè®¡ ==========
        try:
            conn_ps = sqlite3.connect('price_speed_data.db')
            cursor_ps = conn_ps.cursor()
            
            # è·å–å„ç±»å‹é¢„è­¦çš„å¸ç§
            cursor_ps.execute("""
                SELECT alert_type, symbol
                FROM latest_price_speed
                WHERE alert_type != 'NORMAL'
            """)
            
            alert_coins = {
                'super_strong_up': [],
                'very_strong_up': [],
                'strong_up': [],
                'general_up': [],
                'super_strong_down': [],
                'very_strong_down': [],
                'strong_down': [],
                'general_down': []
            }
            
            for alert_type, symbol in cursor_ps.fetchall():
                if alert_type == 'SUPER_STRONG_UP':
                    alert_coins['super_strong_up'].append(symbol)
                elif alert_type == 'VERY_STRONG_UP':
                    alert_coins['very_strong_up'].append(symbol)
                elif alert_type == 'STRONG_UP':
                    alert_coins['strong_up'].append(symbol)
                elif alert_type == 'GENERAL_UP':
                    alert_coins['general_up'].append(symbol)
                elif alert_type == 'SUPER_STRONG_DOWN':
                    alert_coins['super_strong_down'].append(symbol)
                elif alert_type == 'VERY_STRONG_DOWN':
                    alert_coins['very_strong_down'].append(symbol)
                elif alert_type == 'STRONG_DOWN':
                    alert_coins['strong_down'].append(symbol)
                elif alert_type == 'GENERAL_DOWN':
                    alert_coins['general_down'].append(symbol)
            
            conn_ps.close()
        except:
            alert_coins = {
                'super_strong_up': [],
                'very_strong_up': [],
                'strong_up': [],
                'general_up': [],
                'super_strong_down': [],
                'very_strong_down': [],
                'strong_down': [],
                'general_down': []
            }
        
        return jsonify({
            'success': True,
            'data': results,
            'raw_data': data,
            'coin_lists': coin_lists,
            'update_time': snapshot_time,
            # æ–°å¢æ•°æ®
            'v1v2_data': {
                'v1_coins': v1_coins_list,
                'v1_count': len(v1_coins_list),
                'v2_coins': v2_coins_list,
                'v2_count': len(v2_coins_list)
            },
            'price_speed_alerts': {
                'up': {
                    'super_strong': {'count': len(alert_coins['super_strong_up']), 'coins': alert_coins['super_strong_up']},
                    'very_strong': {'count': len(alert_coins['very_strong_up']), 'coins': alert_coins['very_strong_up']},
                    'strong': {'count': len(alert_coins['strong_up']), 'coins': alert_coins['strong_up']},
                    'general': {'count': len(alert_coins['general_up']), 'coins': alert_coins['general_up']}
                },
                'down': {
                    'super_strong': {'count': len(alert_coins['super_strong_down']), 'coins': alert_coins['super_strong_down']},
                    'very_strong': {'count': len(alert_coins['very_strong_down']), 'coins': alert_coins['very_strong_down']},
                    'strong': {'count': len(alert_coins['strong_down']), 'coins': alert_coins['strong_down']},
                    'general': {'count': len(alert_coins['general_down']), 'coins': alert_coins['general_down']}
                }
            },
            'position_avg': position_avg,
            'breakthrough_stats': breakthrough_stats
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ==================== æ˜Ÿæ˜Ÿç³»ç»Ÿå†å²æ•°æ® API ====================
@app.route('/api/star-system/history')
def api_star_system_history():
    """è·å–æ˜Ÿæ˜Ÿç³»ç»Ÿå†å²æ•°æ®"""
    try:
        date = request.args.get('date')  # æ ¼å¼: YYYY-MM-DD
        limit = int(request.args.get('limit', 100))
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        if date:
            # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ•°æ®
            start_time = f"{date} 00:00:00"
            end_time = f"{date} 23:59:59"
            cursor.execute('''
                SELECT id, timestamp, total_stars, solid_stars, hollow_stars, 
                       solid_percentage, hollow_percentage, raw_data
                FROM star_system_history
                WHERE timestamp BETWEEN ? AND ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (start_time, end_time, limit))
        else:
            # æŸ¥è¯¢æœ€è¿‘çš„è®°å½•
            cursor.execute('''
                SELECT id, timestamp, total_stars, solid_stars, hollow_stars, 
                       solid_percentage, hollow_percentage, raw_data
                FROM star_system_history
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
        
        rows = cursor.fetchall()
        
        history_data = []
        for row in rows:
            try:
                import json as json_lib
                raw_data = json_lib.loads(row[7]) if row[7] else {}
            except:
                raw_data = {}
            
            history_data.append({
                'id': row[0],
                'timestamp': row[1],
                'total_stars': row[2],
                'solid_stars': row[3],
                'hollow_stars': row[4],
                'solid_percentage': row[5],
                'hollow_percentage': row[6],
                'details': raw_data
            })
        
        # è·å–å¯ç”¨æ—¥æœŸåˆ—è¡¨
        cursor.execute('''
            SELECT DISTINCT DATE(timestamp) as date
            FROM star_system_history
            ORDER BY date DESC
            LIMIT 30
        ''')
        available_dates = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': history_data,
            'available_dates': available_dates,
            'total_records': len(history_data)
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ==================== æ•°æ®é‡‡é›†ç›‘æ§ API ====================
@app.route('/api/monitor/status')
def api_monitor_status():
    """è·å–æ•°æ®é‡‡é›†ç›‘æ§çŠ¶æ€"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'status'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        status = json.loads(result.stdout)
        return jsonify({
            'success': True,
            'status': status
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/history')
def api_monitor_history():
    """è·å–é‡‡é›†å†å²"""
    import subprocess
    try:
        hours = request.args.get('hours', '2')
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'history', hours],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        history = json.loads(result.stdout)
        return jsonify({
            'success': True,
            'history': history
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/trigger', methods=['POST'])
def api_monitor_trigger():
    """æ‰‹åŠ¨è§¦å‘æ•°æ®é‡‡é›†"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'force'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        collection_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': result.returncode == 0,
            'result': collection_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/check', methods=['POST'])
def api_monitor_check():
    """æ£€æŸ¥å¹¶è‡ªåŠ¨æ¢å¤æ•°æ®é‡‡é›†"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'monitor_data_collection.py', 'check'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        check_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': True,
            'result': check_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ==================== å¤šæ¨¡å—ç›‘æ§ API ====================
@app.route('/api/monitor/all-modules')
def api_monitor_all_modules():
    """è·å–æ‰€æœ‰æ¨¡å—ç›‘æ§çŠ¶æ€"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'multi_module_monitor.py', 'status'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        # ä»stdoutæå–JSONéƒ¨åˆ†(è·³è¿‡å‰é¢çš„æ–‡æœ¬è¾“å‡º)
        output = result.stdout
        # æ‰¾åˆ°JSONå¼€å§‹çš„ä½ç½®
        json_start = output.find('{')
        if json_start >= 0:
            json_str = output[json_start:]
            statuses = json.loads(json_str)
            return jsonify({
                'success': True,
                'modules': statuses
            })
        else:
            return jsonify({
                'success': False,
                'error': 'No JSON output found'
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/check-all', methods=['POST'])
def api_monitor_check_all():
    """æ£€æŸ¥å¹¶è‡ªåŠ¨æ¢å¤æ‰€æœ‰æ¨¡å—"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'multi_module_monitor.py', 'check', '--silent'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶(å¤šä¸ªæ¨¡å—å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´)
        )
        check_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': True,
            'result': check_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/monitor/force-update/<module_key>', methods=['POST'])
def api_monitor_force_update(module_key):
    """å¼ºåˆ¶æ›´æ–°æŒ‡å®šæ¨¡å—"""
    import subprocess
    try:
        result = subprocess.run(
            ['python3', 'multi_module_monitor.py', 'force', module_key],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        update_result = json.loads(result.stdout) if result.stdout else {}
        return jsonify({
            'success': result.returncode == 0,
            'result': update_result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ==================== å¾—åˆ†ç³»ç»Ÿ API ====================
from score_calculator import ScoreCalculator

@app.route('/control-center')
def control_center_page():
    """æ·±åº¦å›¾å¾—åˆ†é¡µé¢(æ§åˆ¶ä¸­å¿ƒ)"""
    return render_template('control_center.html')

@app.route('/depth-score')
def depth_score_page():
    """æ·±åº¦å›¾å¾—åˆ†é¡µé¢"""
    return render_template('depth_score.html')

@app.route('/depth-chart')
def depth_chart_page():
    """æ·±åº¦å›¾å¯è§†åŒ–é¡µé¢"""
    return render_template('depth_chart.html')

@app.route('/score-overview')
def score_overview_page():
    """å¹³å‡åˆ†é¡µé¢"""
    return render_template('score_overview.html')

@app.route('/crypto-index')
def crypto_index_page():
    """OKEXåŠ å¯†æŒ‡æ•°é¡µé¢"""
    return render_template('crypto_index.html')

@app.route('/api/depth-scores')
def api_depth_scores():
    """è·å–æ·±åº¦å¾—åˆ†æ•°æ®"""
    try:
        timeframe = int(request.args.get('timeframe', 24))
        limit = int(request.args.get('limit', 50))
        
        calculator = ScoreCalculator()
        scores = calculator.calculate_all_coins_depth_scores(timeframe, limit)
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_score = sum(s['score'] for s in scores) / len(scores) if scores else 0
        
        return jsonify({
            'success': True,
            'data': {
                'scores': scores,
                'total_coins': len(scores),
                'average_score': round(avg_score, 2),
                'timeframe': f'{timeframe}h'
            }
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/depth-chart-data')
def api_depth_chart_data():
    """è·å–æ·±åº¦å›¾è¡¨æ•°æ®"""
    try:
        timeframe = int(request.args.get('timeframe', 24))
        top_n = int(request.args.get('top_n', 20))
        
        calculator = ScoreCalculator()
        chart_data = calculator.get_depth_chart_data(timeframe, top_n)
        
        return jsonify({
            'success': True,
            'data': chart_data
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/market-average-score')
def api_market_average_score():
    """è·å–å¸‚åœºå¹³å‡å¾—åˆ†"""
    try:
        timeframe = int(request.args.get('timeframe', 24))
        
        calculator = ScoreCalculator()
        market_score = calculator.calculate_average_market_score(timeframe)
        
        return jsonify({
            'success': True,
            'data': market_score
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okex-crypto-index')
def api_okex_crypto_index():
    """è·å–OKEXåŠ å¯†è´§å¸æŒ‡æ•°"""
    try:
        calculator = ScoreCalculator()
        index_data = calculator.calculate_okex_crypto_index()
        
        return jsonify({
            'success': True,
            'data': index_data
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ============================================================================
# OKEXåŠ å¯†æŒ‡æ•°é¡µé¢ä¸“ç”¨APIç«¯ç‚¹
# ============================================================================

@app.route('/api/index/start', methods=['POST'])
def api_index_start():
    """å¯åŠ¨æŒ‡æ•°ç›‘æ§"""
    return jsonify({
        'success': True,
        'message': 'æŒ‡æ•°ç›‘æ§å·²å¯åŠ¨'
    })

@app.route('/api/index/current')
def api_index_current():
    """è·å–å½“å‰æŒ‡æ•°å€¼ - ä»JSONLè¯»å–æœ€æ–°æ•°æ®(å«4/12/24/48å°æ—¶å¹³å‡ä½ç½®)"""
    try:
        # è·å–æœ€æ–°Kçº¿æ•°æ®
        latest = crypto_index_manager.get_latest()
        
        if not latest:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # æå–æ•°æ®
        timestamp = latest.get('timestamp', '')
        index_value = latest.get('index_value', 1000.0)
        open_price = latest.get('open_price', index_value)
        high_price = latest.get('high_price', index_value)
        low_price = latest.get('low_price', index_value)
        close_price = latest.get('close_price', index_value)
        
        # å¹³å‡ä½ç½®
        position_4h = latest.get('position_4h', 50.0)
        position_12h = latest.get('position_12h', 50.0)
        position_24h = latest.get('position_24h', 50.0)
        position_48h = latest.get('position_48h', 50.0)
        
        # è®¡ç®—æ¶¨è·Œ
        base_value = 1000.0
        change = close_price - base_value
        change_percent = (change / base_value) * 100
        
        return jsonify({
            'success': True,
            'data': {
                'value': round(close_price, 2),
                'base_value': base_value,
                'change': round(change, 2),
                'change_percent': round(change_percent, 2),
                'timestamp': timestamp,
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(close_price, 2),
                'position_4h': round(position_4h, 2),
                'position_12h': round(position_12h, 2),
                'position_24h': round(position_24h, 2),
                'position_48h': round(position_48h, 2),
                'data_source': 'CoinGecko API (JSONL)',
                'valid_components': 27
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/index/klines')
def api_index_klines():
    """è·å–Kçº¿å†å²æ•°æ®"""
    try:
        limit = int(request.args.get('limit', 100))
        
        # ä»JSONLè·å–Kçº¿æ•°æ®
        klines = crypto_index_manager.get_klines(limit=limit)
        
        if not klines:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— Kçº¿æ•°æ®'
            })
        
        return jsonify({
            'success': True,
            'count': len(klines),
            'data': klines
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/index/components')
def api_index_components():
    """è·å–æˆåˆ†è¯¦æƒ… - 27å¸ç§æƒé‡æ˜ç»†(ä»JSONLå’ŒCoinGecko)"""
    try:
        # å¸ç§æƒé‡é…ç½®
        COIN_WEIGHTS = {
            'bitcoin': 0.10,      # BTC 10%
            'ethereum': 0.07,     # ETH 7%
            'ripple': 0.0332,     # XRP 3.32%
            'binancecoin': 0.0332,  # BNB 3.32%
            'solana': 0.0332,     # SOL 3.32%
            'litecoin': 0.0332,   # LTC 3.32%
            'dogecoin': 0.0332,   # DOGE 3.32%
            'sui': 0.0332,        # SUI 3.32%
            'tron': 0.0332,       # TRX 3.32%
            'the-open-network': 0.0332,  # TON 3.32%
            'ethereum-classic': 0.0332,  # ETC 3.32%
            'bitcoin-cash': 0.0332,      # BCH 3.32%
            'hedera-hashgraph': 0.0332,  # HBAR 3.32%
            'stellar': 0.0332,    # XLM 3.32%
            'filecoin': 0.0332,   # FIL 3.32%
            'chainlink': 0.0332,  # LINK 3.32%
            'crypto-com-chain': 0.0332,  # CRO 3.32%
            'polkadot': 0.0332,   # DOT 3.32%
            'aave': 0.0332,       # AAVE 3.32%
            'uniswap': 0.0332,    # UNI 3.32%
            'near': 0.0332,       # NEAR 3.32%
            'aptos': 0.0332,      # APT 3.32%
            'conflux-token': 0.0332,     # CFX 3.32%
            'curve-dao-token': 0.0332,   # CRV 3.32%
            'stacks': 0.0332,     # STX 3.32%
            'lido-dao': 0.0332,   # LDO 3.32%
            'bittensor': 0.0332   # TAO 3.32%
        }
        
        # å¸ç§åç§°æ˜ å°„
        coin_name_map = {
            'bitcoin': 'BTC', 'ethereum': 'ETH', 'ripple': 'XRP',
            'binancecoin': 'BNB', 'solana': 'SOL', 'litecoin': 'LTC',
            'dogecoin': 'DOGE', 'sui': 'SUI', 'tron': 'TRX',
            'the-open-network': 'TON', 'ethereum-classic': 'ETC',
            'bitcoin-cash': 'BCH', 'hedera-hashgraph': 'HBAR',
            'stellar': 'XLM', 'filecoin': 'FIL', 'chainlink': 'LINK',
            'crypto-com-chain': 'CRO', 'polkadot': 'DOT', 'aave': 'AAVE',
            'uniswap': 'UNI', 'near': 'NEAR', 'aptos': 'APT',
            'conflux-token': 'CFX', 'curve-dao-token': 'CRV',
            'stacks': 'STX', 'lido-dao': 'LDO', 'bittensor': 'TAO'
        }
        
        # è·å–åŸºå‡†ä»·æ ¼(ä»JSONL)
        base_prices = crypto_index_manager.get_base_prices()
        
        # è·å–å½“å‰ä»·æ ¼(ä»CoinGecko)
        import requests
        current_prices = {}
        try:
            coin_ids = ','.join(COIN_WEIGHTS.keys())
            response = requests.get(
                'https://api.coingecko.com/api/v3/simple/price',
                params={'ids': coin_ids, 'vs_currencies': 'usd', 'precision': '8'},
                timeout=10
            )
            if response.status_code == 200:
                current_prices = response.json()
        except Exception as e:
            print(f"è·å–CoinGeckoä»·æ ¼å¤±è´¥: {e}")
        
        # æ„å»ºæˆåˆ†æ•°æ®
        components = []
        for coin_id, weight in COIN_WEIGHTS.items():
            symbol = coin_name_map.get(coin_id, coin_id.upper())
            base_price = base_prices.get(coin_id, 0)
            current_price = current_prices.get(coin_id, {}).get('usd', base_price)
            
            # è®¡ç®—æ¶¨è·Œå¹…
            if base_price > 0:
                price_change = ((current_price - base_price) / base_price * 100)
            else:
                price_change = 0
            
            # åŠ æƒè´¡çŒ®
            weighted_contribution = price_change * weight
            
            components.append({
                'symbol': symbol,
                'name': symbol,
                'coin_id': coin_id,
                'price': round(current_price, 8),
                'base_price': round(base_price, 8),
                'weight': weight,
                'weight_percent': f"{weight*100:.2f}%",
                'change_percent': round(price_change, 2),
                'weighted_contribution': round(weighted_contribution, 4)
            })
        
        # æŒ‰æƒé‡é™åºæ’åº
        components.sort(key=lambda x: x['weight'], reverse=True)
        
        return jsonify({
            'success': True,
            'total_coins': len(components),
            'data': components,
            'data_source': 'CoinGecko API + JSONL'
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–æˆåˆ†å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

@app.route('/test-refresh')
def test_refresh():
    """æµ‹è¯•åˆ·æ–°é¡µé¢ - ç”¨äºéªŒè¯ç¼“å­˜é—®é¢˜"""
    return render_template('test_refresh.html')

@app.route('/test-btc-eth')
def test_btc_eth():
    """æµ‹è¯•BTCå’ŒETHæ•°æ®æ˜¾ç¤º"""
    return render_template('test_btc_eth.html')

@app.route('/api/index/history')
def api_index_history():
    """è·å–å†å²æ•°æ® - ä»crypto_index JSONLè¯»å–Kçº¿å†å²æ•°æ®"""
    try:
        page = int(request.args.get('page', 1))  # å½“å‰é¡µ,é»˜è®¤ç¬¬1é¡µ
        page_size = 144  # æ¯é¡µ144æ¡(12å°æ—¶æ•°æ®,æ¯5åˆ†é’Ÿ1æ¡)
        
        # ä»crypto_index_managerè·å–Kçº¿æ•°æ®
        all_klines = crypto_index_manager.get_klines(limit=1000)  # è·å–æœ€è¿‘1000æ ¹Kçº¿
        
        if not all_klines:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— å†å²æ•°æ®'
            })
        
        # Kçº¿æ•°æ®å·²ç»æ˜¯æŒ‰æ—¶é—´å€’åºæ’åºçš„,éœ€è¦åè½¬ä¸ºæ­£åº(ä»æ—§åˆ°æ–°)
        all_klines.reverse()
        
        # è®¡ç®—åˆ†é¡µ
        total_records = len(all_klines)
        total_pages = max(1, (total_records + page_size - 1) // page_size)
        
        # ç¡®ä¿é¡µç æœ‰æ•ˆ
        if page < 1:
            page = 1
        if page > total_pages:
            page = total_pages
        
        # å€’åºåˆ†é¡µ:page=1æ˜¾ç¤ºæœ€æ–°æ•°æ®
        reverse_page = total_pages - page + 1
        start_idx = (reverse_page - 1) * page_size
        end_idx = min(start_idx + page_size, total_records)
        page_klines = all_klines[start_idx:end_idx]
        
        # è½¬æ¢ä¸ºå†å²æ•°æ®æ ¼å¼
        history = []
        base_value = 1000.00
        
        for kline in page_klines:
            close_price = kline.get('close_price', kline.get('index_value', base_value))
            change_percent = ((close_price - base_value) / base_value * 100)
            
            history.append({
                'time': kline.get('timestamp', ''),
                'value': round(close_price, 2),
                'close': round(close_price, 2),
                'change_percent': round(change_percent, 2),
                'open': round(kline.get('open_price', close_price), 2),
                'high': round(kline.get('high_price', close_price), 2),
                'low': round(kline.get('low_price', close_price), 2),
                'position_4h': kline.get('position_4h', 50.0),
                'position_12h': kline.get('position_12h', 50.0),
                'position_24h': kline.get('position_24h', 50.0),
                'position_48h': kline.get('position_48h', 50.0)
            })
        
        return jsonify({
            'success': True,
            'total': len(history),
            'total_records': total_records,
            'total_pages': total_pages,
            'current_page': page,
            'page_size': page_size,
            'interval': '5min',
            'data': history,
            'data_source': 'Crypto Index JSONL'
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}',
            'traceback': traceback.format_exc()
        })

# ==================== ä½ç½®ç³»ç»Ÿ API ====================

@app.route('/position-system')
def position_system():
    """ä½ç½®ç³»ç»Ÿé¡µé¢"""
    return render_template('position_system.html')

@app.route('/api/position/latest')
def api_position_latest():
    """è·å–æœ€æ–°ä½ç½®æ•°æ®"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„è®°å½•æ—¶é—´
        cursor.execute('SELECT MAX(record_time) FROM position_system')
        latest_time = cursor.fetchone()[0]
        
        if not latest_time:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # è·å–è¯¥æ—¶é—´çš„æ‰€æœ‰å¸ç§æ•°æ®
        cursor.execute('''
            SELECT symbol, current_price,
                   position_4h, position_12h, position_24h, position_48h,
                   high_4h, low_4h, high_12h, low_12h, high_24h, low_24h, high_48h, low_48h
            FROM position_system
            WHERE record_time = ?
            ORDER BY symbol
        ''', (latest_time,))
        
        rows = cursor.fetchall()
        
        # æ„é€ è¿”å›æ•°æ®
        data_list = []
        symbol_set = set()
        for row in rows:
            symbol_set.add(row[0])
            data_list.append({
                'symbol': row[0],
                'current_price': row[1],
                'position_4h': row[2],
                'position_12h': row[3],
                'position_24h': row[4],
                'position_48h': row[5],
                'high_4h': row[6],
                'low_4h': row[7],
                'high_12h': row[8],
                'low_12h': row[9],
                'high_24h': row[10],
                'low_24h': row[11],
                'high_48h': row[12],
                'low_48h': row[13]
            })
        
        # æ£€æŸ¥BTCå’ŒETHæ˜¯å¦å­˜åœ¨,å¦‚æœä¸å­˜åœ¨åˆ™ä»æœ€è¿‘è®°å½•ä¸­è¡¥å……
        missing_coins = []
        if 'BTC-USDT-SWAP' not in symbol_set:
            missing_coins.append('BTC-USDT-SWAP')
        if 'ETH-USDT-SWAP' not in symbol_set:
            missing_coins.append('ETH-USDT-SWAP')
        
        if missing_coins:
            for coin in missing_coins:
                cursor.execute('''
                    SELECT symbol, current_price,
                           position_4h, position_12h, position_24h, position_48h,
                           high_4h, low_4h, high_12h, low_12h, high_24h, low_24h, high_48h, low_48h
                    FROM position_system
                    WHERE symbol = ?
                    ORDER BY record_time DESC
                    LIMIT 1
                ''', (coin,))
                coin_row = cursor.fetchone()
                if coin_row:
                    data_list.append({
                        'symbol': coin_row[0],
                        'current_price': coin_row[1],
                        'position_4h': coin_row[2],
                        'position_12h': coin_row[3],
                        'position_24h': coin_row[4],
                        'position_48h': coin_row[5],
                        'high_4h': coin_row[6],
                        'low_4h': coin_row[7],
                        'high_12h': coin_row[8],
                        'low_12h': coin_row[9],
                        'high_24h': coin_row[10],
                        'low_24h': coin_row[11],
                        'high_48h': coin_row[12],
                        'low_48h': coin_row[13]
                    })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'record_time': latest_time,
            'total_count': len(data_list),
            'data': data_list
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ•°æ®å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/summary')
def api_position_summary():
    """è·å–ä½ç½®ç»Ÿè®¡æ‘˜è¦"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„è®°å½•æ—¶é—´
        cursor.execute('SELECT MAX(record_time) FROM position_system')
        latest_time = cursor.fetchone()[0]
        
        if not latest_time:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # ç»Ÿè®¡å„å‘¨æœŸçš„å¹³å‡ä½ç½®
        cursor.execute('''
            SELECT 
                AVG(position_4h) as avg_4h,
                AVG(position_12h) as avg_12h,
                AVG(position_24h) as avg_24h,
                AVG(position_48h) as avg_48h,
                COUNT(*) as total_count
            FROM position_system
            WHERE record_time = ?
        ''', (latest_time,))
        
        row = cursor.fetchone()
        
        # ç»Ÿè®¡å„åŒºé—´çš„å¸ç§æ•°é‡(ä»¥24hä¸ºä¾‹)
        cursor.execute('''
            SELECT 
                SUM(CASE WHEN position_24h >= 80 THEN 1 ELSE 0 END) as high_zone,
                SUM(CASE WHEN position_24h >= 50 AND position_24h < 80 THEN 1 ELSE 0 END) as mid_high_zone,
                SUM(CASE WHEN position_24h >= 20 AND position_24h < 50 THEN 1 ELSE 0 END) as mid_low_zone,
                SUM(CASE WHEN position_24h < 20 THEN 1 ELSE 0 END) as low_zone
            FROM position_system
            WHERE record_time = ?
        ''', (latest_time,))
        
        zone_counts = cursor.fetchone()
        
        # æ–°å¢:ç»Ÿè®¡å„å‘¨æœŸ>=95%çš„å¸ç§æ•°é‡
        cursor.execute('''
            SELECT 
                SUM(CASE WHEN position_4h >= 95 THEN 1 ELSE 0 END) as count_4h_ge95,
                SUM(CASE WHEN position_12h >= 95 THEN 1 ELSE 0 END) as count_12h_ge95,
                SUM(CASE WHEN position_24h >= 95 THEN 1 ELSE 0 END) as count_24h_ge95,
                SUM(CASE WHEN position_48h >= 95 THEN 1 ELSE 0 END) as count_48h_ge95
            FROM position_system
            WHERE record_time = ?
        ''', (latest_time,))
        
        ge95_counts = cursor.fetchone()
        conn.close()
        
        return jsonify({
            'success': True,
            'record_time': latest_time,
            'averages': {
                '4h': round(row[0], 2) if row[0] else 0,
                '12h': round(row[1], 2) if row[1] else 0,
                '24h': round(row[2], 2) if row[2] else 0,
                '48h': round(row[3], 2) if row[3] else 0
            },
            'total_count': row[4],
            'zone_distribution_24h': {
                'high': zone_counts[0] or 0,      # 80-100%
                'mid_high': zone_counts[1] or 0,  # 50-80%
                'mid_low': zone_counts[2] or 0,   # 20-50%
                'low': zone_counts[3] or 0        # 0-20%
            },
            'high_position_counts': {
                '4h': ge95_counts[0] or 0,   # 4å°æ—¶>=95%
                '12h': ge95_counts[1] or 0,  # 12å°æ—¶>=95%
                '24h': ge95_counts[2] or 0,  # 24å°æ—¶>=95%
                '48h': ge95_counts[3] or 0   # 48å°æ—¶>=95%
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/history/<symbol>')
def api_position_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²ä½ç½®æ•°æ®"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€è¿‘24å°æ—¶çš„æ•°æ®
        cursor.execute('''
            SELECT record_time, current_price,
                   position_4h, position_12h, position_24h, position_48h
            FROM position_system
            WHERE symbol = ?
            ORDER BY record_time DESC
            LIMIT 288
        ''', (symbol,))
        
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'time': row[0],
                'price': row[1],
                '4h': row[2],
                '12h': row[3],
                '24h': row[4],
                '48h': row[5]
            })
        
        history.reverse()  # æ—¶é—´æ­£åº
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'data': history
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/stats/latest')
def api_position_stats_latest():
    """è·å–æœ€æ–°çš„ä½ç½®ç»Ÿè®¡æ•°æ®(ä½äº1%çš„å¸ç§æ•°é‡)"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°çš„ç»Ÿè®¡æ•°æ®
        cursor.execute('''
            SELECT record_time, count_below_1_4h, count_below_1_12h, 
                   count_below_1_24h, count_below_1_48h, total_coins
            FROM position_system_stats
            ORDER BY record_time DESC
            LIMIT 1
        ''')
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— ç»Ÿè®¡æ•°æ®'
            })
        
        return jsonify({
            'success': True,
            'record_time': row[0],
            'stats': {
                '4h': {'below_1': row[1], 'total': row[5]},
                '12h': {'below_1': row[2], 'total': row[5]},
                '24h': {'below_1': row[3], 'total': row[5]},
                '48h': {'below_1': row[4], 'total': row[5]}
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}'
        })

@app.route('/api/position/stats/history')
def api_position_stats_history():
    """è·å–ç»Ÿè®¡æ•°æ®å†å²è®°å½•"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        limit = request.args.get('limit', default=100, type=int)
        start_time = request.args.get('start_time', default=None, type=str)
        end_time = request.args.get('end_time', default=None, type=str)
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = '''
            SELECT record_time, count_below_1_4h, count_below_1_12h, 
                   count_below_1_24h, count_below_1_48h, total_coins
            FROM position_system_stats
            WHERE 1=1
        '''
        params = []
        
        if start_time:
            query += ' AND record_time >= ?'
            params.append(start_time)
        
        if end_time:
            query += ' AND record_time <= ?'
            params.append(end_time)
        
        query += ' ORDER BY record_time DESC LIMIT ?'
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'time': row[0],
                '4h': {'below_1': row[1], 'total': row[5]},
                '12h': {'below_1': row[2], 'total': row[5]},
                '24h': {'below_1': row[3], 'total': row[5]},
                '48h': {'below_1': row[4], 'total': row[5]}
            })
        
        history.reverse()  # æ—¶é—´æ­£åº
        
        return jsonify({
            'success': True,
            'count': len(history),
            'data': history
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²ç»Ÿè®¡å¤±è´¥: {str(e)}'
        })

@app.route('/v1v2-volume')
def v1v2_volume():
    """V1V2æˆäº¤é‡ç³»ç»Ÿ - å·²åœç”¨,é‡å®šå‘åˆ°é¦–é¡µ"""
    return redirect('/', code=301)

@app.route('/v1v2-monitor')
def v1v2_monitor():
    """V1V2æˆäº¤é¢ç›‘æ§ - å·²åœç”¨,é‡å®šå‘åˆ°é¦–é¡µ"""
    return redirect('/', code=301)

@app.route('/api/v1v2/latest')
def api_v1v2_latest():
    """è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°V1V2æ•°æ® - ä½¿ç”¨JSONL"""
    try:
        # ä»JSONLè·å–æœ€æ–°æ•°æ®
        result = v1v2_manager.get_latest_all()
        
        # æŒ‰çº§åˆ«æ’åº: V1 > V2 > NONE
        level_order = {'V1': 0, 'V2': 1, 'NONE': 2}
        result.sort(key=lambda x: (level_order.get(x['level'], 3), -x.get('volume', 0)))
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = v1v2_manager.get_statistics()
        
        return jsonify({
            'success': True,
            'count': stats['total_count'],
            'data': result,
            'update_time': stats['update_time'],
            'total': stats['total_count'],
            'v1_count': stats['v1_count'],
            'v2_count': stats['v2_count']
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'data': [],
            'message': f'è·å–V1V2æ•°æ®å¤±è´¥: {str(e)}'
        })

@app.route('/v1v2-settings')
def v1v2_settings():
    """V1V2é˜ˆå€¼è®¾ç½® - å·²åœç”¨,é‡å®šå‘åˆ°é¦–é¡µ"""
    return redirect('/', code=301)

@app.route('/api/v1v2/settings', methods=['GET', 'POST'])
def api_v1v2_settings():
    """è·å–æˆ–æ›´æ–°V1V2é˜ˆå€¼è®¾ç½®"""
    import json
    import os
    
    SETTINGS_FILE = 'v1v2_settings.json'
    
    # é»˜è®¤é…ç½®
    DEFAULT_SETTINGS = {
        'BTC': {'v1': 200000, 'v2': 100000},
        'ETH': {'v1': 1300000, 'v2': 500000},
        'XRP': {'v1': 200000, 'v2': 87000},
        'SOL': {'v1': 351620, 'v2': 246380},
        'BNB': {'v1': 2388300, 'v2': 1737500},
        'LTC': {'v1': 50000, 'v2': 15000},
        'DOGE': {'v1': 150000, 'v2': 60000},
        'SUI': {'v1': 2000000, 'v2': 800000},
        'TRX': {'v1': 13280, 'v2': 6022},
        'TON': {'v1': 350000, 'v2': 200000},
        'ETC': {'v1': 12000, 'v2': 2000},
        'BCH': {'v1': 103500, 'v2': 50000},
        'HBAR': {'v1': 103500, 'v2': 40000},
        'XLM': {'v1': 103500, 'v2': 30000},
        'FIL': {'v1': 5003500, 'v2': 3700000},
        'ADA': {'v1': 67210, 'v2': 44230},
        'LINK': {'v1': 280000, 'v2': 200000},
        'CRO': {'v1': 100000, 'v2': 40000},
        'DOT': {'v1': 300000, 'v2': 250000},
        'UNI': {'v1': 140000, 'v2': 100000},
        'NEAR': {'v1': 100000, 'v2': 50000},
        'APT': {'v1': 300000, 'v2': 200000},
        'CFX': {'v1': 300000, 'v2': 250000},
        'CRV': {'v1': 1500000, 'v2': 1000000},
        'STX': {'v1': 50000, 'v2': 30000},
        'LDO': {'v1': 1000000, 'v2': 600000},
        'TAO': {'v1': 300000, 'v2': 180000}
    }
    
    if request.method == 'GET':
        # è¯»å–è®¾ç½®
        try:
            if os.path.exists(SETTINGS_FILE):
                with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
                    settings = json.load(f)
            else:
                settings = DEFAULT_SETTINGS
                # ä¿å­˜é»˜è®¤è®¾ç½®
                with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(settings, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'settings': settings
            })
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'è¯»å–è®¾ç½®å¤±è´¥: {str(e)}'
            })
    
    elif request.method == 'POST':
        # æ›´æ–°è®¾ç½®
        try:
            data = request.get_json()
            new_settings = data.get('settings', {})
            
            # éªŒè¯æ•°æ®
            for symbol, config in new_settings.items():
                if 'v1' not in config or 'v2' not in config:
                    return jsonify({
                        'success': False,
                        'message': f'å¸ç§ {symbol} é…ç½®ä¸å®Œæ•´'
                    })
                
                # ç¡®ä¿V1 > V2
                if config['v1'] <= config['v2']:
                    return jsonify({
                        'success': False,
                        'message': f'å¸ç§ {symbol}: V1é˜ˆå€¼å¿…é¡»å¤§äºV2é˜ˆå€¼'
                    })
            
            # ä¿å­˜è®¾ç½®
            with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
                json.dump(new_settings, f, indent=2, ensure_ascii=False)
            
            # è§¦å‘é‡‡é›†å™¨é‡æ–°åŠ è½½é…ç½®(é€šè¿‡åˆ›å»ºæ ‡è®°æ–‡ä»¶)
            with open('.v1v2_settings_updated', 'w') as f:
                f.write(str(int(time.time())))
            
            return jsonify({
                'success': True,
                'message': 'è®¾ç½®å·²ä¿å­˜,é‡‡é›†å™¨å°†åœ¨ä¸‹æ¬¡é‡‡é›†æ—¶ä½¿ç”¨æ–°é…ç½®'
            })
            
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'ä¿å­˜è®¾ç½®å¤±è´¥: {str(e)}'
            })

@app.route('/api/v1v2/statistics')
def api_v1v2_statistics():
    """è·å–V1V2ä¿¡å·ç»Ÿè®¡æ•°æ®(1h/3h/12h/1day/3day/7day)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('v1v2_data.db', timeout=30.0)
        conn.execute('PRAGMA journal_mode=WAL')
        conn.execute('PRAGMA busy_timeout=30000')
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰å¸ç§è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'volume_%'")
        tables = [row[0] for row in cursor.fetchall()]
        
        # å®šä¹‰æ—¶é—´èŒƒå›´
        now = datetime.now()
        time_ranges = {
            '1h': now - timedelta(hours=1),
            '3h': now - timedelta(hours=3),
            '12h': now - timedelta(hours=12),
            '1day': now - timedelta(days=1),
            '3day': now - timedelta(days=3),
            '7day': now - timedelta(days=7)
        }
        
        statistics = []
        
        for table_name in tables:
            symbol = table_name.replace('volume_', '').upper()
            
            try:
                coin_stats = {
                    'symbol': symbol,
                    '1h': {'v1': 0, 'v2': 0, 'total': 0},
                    '3h': {'v1': 0, 'v2': 0, 'total': 0},
                    '12h': {'v1': 0, 'v2': 0, 'total': 0},
                    '1day': {'v1': 0, 'v2': 0, 'total': 0},
                    '3day': {'v1': 0, 'v2': 0, 'total': 0},
                    '7day': {'v1': 0, 'v2': 0, 'total': 0}
                }
                
                # å¯¹æ¯ä¸ªæ—¶é—´èŒƒå›´è¿›è¡Œç»Ÿè®¡
                for period, start_time in time_ranges.items():
                    start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # ç»Ÿè®¡V1å’ŒV2çš„æ¬¡æ•°(åªç»Ÿè®¡V1å’ŒV2)
                    cursor.execute(f"""
                        SELECT level, COUNT(*) 
                        FROM {table_name} 
                        WHERE collect_time >= ? AND level IN ('V1', 'V2')
                        GROUP BY level
                    """, (start_time_str,))
                    
                    counts = dict(cursor.fetchall())
                    v1_count = counts.get('V1', 0)
                    v2_count = counts.get('V2', 0)
                    
                    coin_stats[period]['v1'] = v1_count
                    coin_stats[period]['v2'] = v2_count
                    coin_stats[period]['total'] = v1_count + v2_count
                
                statistics.append(coin_stats)
                
            except sqlite3.OperationalError:
                # è¡¨ä¸å­˜åœ¨æˆ–å‡ºé”™,è·³è¿‡
                continue
        
        conn.close()
        
        # æŒ‰7å¤©æ€»ä¿¡å·æ•°æ’åº
        statistics.sort(key=lambda x: x['7day']['total'], reverse=True)
        
        return jsonify({
            'success': True,
            'data': {
                'statistics': statistics,
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'total_coins': len(statistics)
            }
        })
        
    except Exception as e:
        import traceback
        print(f"âŒ V1V2ç»Ÿè®¡APIé”™è¯¯: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            'success': False,
            'message': f'è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}'
        }), 500

@app.route('/price-speed-monitor')
def price_speed_monitor():
    """1åˆ†é’Ÿæ¶¨è·Œé€Ÿç›‘æ§é¡µé¢"""
    return render_template('price_speed_monitor.html')

@app.route('/api/price-speed/latest')
def api_price_speed_latest():
    """è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°æ¶¨è·Œé€Ÿæ•°æ® - ä½¿ç”¨JSONL"""
    try:
        # ä»JSONLè·å–æœ€æ–°æ•°æ®
        data = price_speed_manager.get_latest_all()
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = price_speed_manager.get_statistics()
        
        return jsonify({
            'success': True,
            'count': len(data),
            'data': data,
            'update_time': stats['update_time']
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–æ¶¨è·Œé€Ÿæ•°æ®å¤±è´¥: {str(e)}',
            'data': []
        })

@app.route('/api/price-speed/history/<symbol>')
def api_price_speed_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²æ¶¨è·Œé€Ÿæ•°æ® - ä½¿ç”¨JSONL"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        limit = request.args.get('limit', 100, type=int)
        
        # ä»JSONLè·å–å†å²æ•°æ®
        data = price_speed_manager.get_history(symbol=symbol, limit=limit)
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'count': len(data),
            'data': data
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}',
            'data': []
        })

# ============================================================================
# Google Drive TXTæ£€æµ‹å™¨ API
# ============================================================================

@app.route('/gdrive-detector')
def gdrive_detector_page():
    """Google Driveæ£€æµ‹å™¨é¡µé¢"""
    return render_template('gdrive_detector.html')

@app.route('/test-gdrive-status')
def test_gdrive_status():
    """Google DriveçŠ¶æ€æµ‹è¯•é¡µé¢"""
    return render_template('test_gdrive_status.html')

@app.route('/gdrive-detector-fresh')
def gdrive_detector_fresh():
    """Google Driveæ£€æµ‹å™¨é¡µé¢(æ— ç¼“å­˜ç‰ˆæœ¬)"""
    import time
    return render_template('gdrive_detector_fresh.html', timestamp=int(time.time()))

@app.route('/opening-logic')
def opening_logic_page():
    """å¼€ä»“é€»è¾‘ç³»ç»Ÿé¡µé¢"""
    from flask import make_response
    response = make_response(render_template('opening_logic.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/opening-logic/suggestion')
def opening_logic_suggestion():
    """è·å–å¼€ä»“å»ºè®®API"""
    try:
        from opening_logic import get_opening_suggestion
        result = get_opening_suggestion()
        return jsonify({'success': True, 'data': result})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/gdrive-detector/status')
def gdrive_detector_status():
    """è·å–Google Driveæ£€æµ‹å™¨çŠ¶æ€"""
    try:
        import subprocess
        import re
        import requests
        from datetime import datetime
        import pytz
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # æ£€æŸ¥æ£€æµ‹å™¨è¿›ç¨‹æ˜¯å¦è¿è¡Œ
        # ç”±äºä½¿ç”¨é…ç½®æ–‡ä»¶å’Œæ‰‹åŠ¨æ›´æ–°,æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        detector_running = False
        try:
            import json
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # æ£€æŸ¥é…ç½®æ˜¯å¦æœ‰æ•ˆ:æœ‰folder_idã€æœ‰txt_filesã€æ—¥æœŸæ˜¯ä»Šå¤©
                today_str = now.strftime('%Y-%m-%d')
                if (config.get('folder_id') and 
                    config.get('txt_files') and 
                    len(config.get('txt_files', [])) > 0 and
                    config.get('current_date') == today_str):
                    detector_running = True
        except:
            detector_running = False
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–æœ€æ–°TXTæ–‡ä»¶åå’Œæ—¶é—´æˆ³
        file_timestamp = None
        delay_minutes = None
        
        try:
            import json
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
                # ä»æœ€æ–°TXTæ–‡ä»¶åè§£ææ—¶é—´æˆ³
                latest_txt = config.get('latest_txt')
                if latest_txt:
                    # æ–‡ä»¶åæ ¼å¼: 2026-02-03_1953.txt
                    # æå–æ—¥æœŸå’Œæ—¶é—´
                    match = re.search(r'(\d{4}-\d{2}-\d{2})_(\d{2})(\d{2})', latest_txt)
                    if match:
                        date_str = match.group(1)  # 2026-02-03
                        hour = match.group(2)       # 19
                        minute = match.group(3)     # 53
                        
                        # æ„å»ºæ—¶é—´æˆ³å­—ç¬¦ä¸²
                        file_timestamp = f"{date_str} {hour}:{minute}:00"
                        
                        # è®¡ç®—å»¶è¿Ÿ
                        try:
                            last_time = datetime.strptime(file_timestamp, '%Y-%m-%d %H:%M:%S')
                            last_time_beijing = beijing_tz.localize(last_time)
                            delay_seconds = (now - last_time_beijing).total_seconds()
                            delay_minutes = delay_seconds / 60
                        except Exception as e:
                            print(f"è®¡ç®—å»¶è¿Ÿå¤±è´¥: {e}")
                            pass
        except Exception as e:
            print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            pass
        
        # è¯»å–æ£€æŸ¥æ¬¡æ•°å’Œæœ€åæ£€æŸ¥æ—¶é—´
        check_count = 0
        last_check_time = None
        
        try:
            import json
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                
                # ä»é…ç½®æ–‡ä»¶è¯»å–æ£€æŸ¥æ¬¡æ•°(txt_countä½œä¸ºæ£€æŸ¥æ¬¡æ•°)
                check_count = config.get('txt_count', 0)
                
                # ä»last_updateè¯»å–æœ€åæ£€æŸ¥æ—¶é—´
                last_update = config.get('last_update')
                if last_update:
                    # last_updateæ ¼å¼: 2026-02-03T19:58:50.244976+08:00
                    # è½¬æ¢ä¸º: 2026-02-03 19:58:50
                    try:
                        from dateutil import parser
                        dt = parser.parse(last_update)
                        last_check_time = dt.strftime('%Y-%m-%d %H:%M:%S')
                    except:
                        # å¦‚æœdateutilä¸å¯ç”¨,å°è¯•ç®€å•è§£æ
                        try:
                            last_check_time = last_update.split('T')[0] + ' ' + last_update.split('T')[1].split('.')[0]
                        except:
                            pass
        except Exception as e:
            print(f"è¯»å–æ£€æŸ¥ä¿¡æ¯å¤±è´¥: {e}")
            pass
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–æ‰€æœ‰æ–‡ä»¶å¤¹ID
        root_folder_odd = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"  # é»˜è®¤å€¼
        root_folder_even = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"  # é»˜è®¤å€¼
        folder_id = None  # å­è´¦å·æ–‡ä»¶å¤¹ID(ä»Šæ—¥æ–‡ä»¶å¤¹)
        
        try:
            import json
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # è¯»å–å•æ•°/åŒæ•°çˆ¶æ–‡ä»¶å¤¹ID
                if 'root_folder_odd' in config:
                    root_folder_odd = config['root_folder_odd']
                if 'root_folder_even' in config:
                    root_folder_even = config['root_folder_even']
                # ğŸ†• è¯»å–å­è´¦å·æ–‡ä»¶å¤¹ID(ä»Šæ—¥æ–‡ä»¶å¤¹)
                if 'folder_id' in config:
                    folder_id = config['folder_id']
        except:
            pass
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰å­è´¦å·æ–‡ä»¶å¤¹ID,å°è¯•ä»æ—¥å¿—è¯»å–
        if not folder_id:
            try:
                with open('/home/user/webapp/gdrive_final_detector.log', 'r') as f:
                    lines = f.readlines()
                    for line in reversed(lines[-100:]):  # åªçœ‹æœ€è¿‘100è¡Œ
                        # æå–æ–‡ä»¶å¤¹ID(å­è´¦å·)
                        if 'ä»Šæ—¥æ–‡ä»¶å¤¹' in line or 'å­æ–‡ä»¶å¤¹' in line:
                            match = re.search(r'([A-Za-z0-9_-]{20,})', line)
                            if match and match.group(1) != root_folder_odd and match.group(1) != root_folder_even:
                                folder_id = match.group(1)
                                break
            except:
                pass
        
        return jsonify({
            'success': True,
            'data': {
                'detector_running': detector_running,
                'file_timestamp': file_timestamp,
                'delay_minutes': delay_minutes,
                'check_count': check_count,
                'last_check_time': last_check_time,
                'current_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'folder_id': folder_id,
                'root_folder_odd': root_folder_odd,
                'root_folder_even': root_folder_even,
                'today_date': now.strftime('%Yå¹´%mæœˆ%dæ—¥')
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'data': None
        })

@app.route('/api/gdrive-detector/txt-files')
def gdrive_detector_txt_files():
    """è·å–ä»Šå¤©çš„TXTæ–‡ä»¶åˆ—è¡¨(å¸¦ç¼“å­˜ä¼˜åŒ–)"""
    try:
        import requests
        import re
        from datetime import datetime
        import pytz
        import json
        import time
        
        # ç¼“å­˜æœºåˆ¶:5åˆ†é’Ÿå†…è¿”å›ç¼“å­˜æ•°æ®
        cache_file = '/tmp/gdrive_txt_files_cache.json'
        cache_duration = 300  # 5åˆ†é’Ÿ
        
        # å°è¯•è¯»å–ç¼“å­˜
        try:
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    cache_time = cache_data.get('timestamp', 0)
                    if time.time() - cache_time < cache_duration:
                        # è¿”å›ç¼“å­˜æ•°æ®
                        return jsonify(cache_data.get('data', {}))
        except:
            pass
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        today = datetime.now(beijing_tz).strftime('%Y-%m-%d')
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–ä»Šå¤©çš„æ–‡ä»¶å¤¹ID
        folder_id = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"  # é»˜è®¤å€¼
        try:
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('current_date') == today and 'folder_id' in config:
                    folder_id = config['folder_id']
        except:
            pass
        
        # ä¼˜å…ˆä»é…ç½®æ–‡ä»¶è¯»å–TXTæ–‡ä»¶åˆ—è¡¨
        txt_files = []
        try:
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                if config.get('current_date') == today and 'txt_files' in config:
                    txt_files = config.get('txt_files', [])
        except:
            pass
        
        # å¦‚æœé…ç½®ä¸­æ²¡æœ‰,å°è¯•ä»embeddedfolderviewè·å–
        if not txt_files:
            url = f"https://drive.google.com/embeddedfolderview?id={folder_id}"
            
            response = requests.get(url, timeout=10)
            content = response.text
            
            # æŸ¥æ‰¾æ‰€æœ‰TXTæ–‡ä»¶(æ”¯æŒä»»æ„æ ¼å¼)
            pattern = r'>([^<]+\.txt)<'
            matches = re.findall(pattern, content)
            txt_files = sorted(set(matches), reverse=True)  # å»é‡å¹¶æŒ‰æ—¶é—´é™åºæ’åº(æœ€æ–°çš„åœ¨å‰)
        
        result = {
            'success': True,
            'files': txt_files,
            'count': len(txt_files),
            'date': today,
            'folder_id': folder_id
        }
        
        # ä¿å­˜åˆ°ç¼“å­˜
        try:
            cache_content = {
                'timestamp': time.time(),
                'data': result
            }
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_content, f, ensure_ascii=False, indent=2)
        except:
            pass
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'files': [],
            'count': 0
        })

@app.route('/api/gdrive-detector/logs')
def gdrive_detector_logs():
    """è·å–æ£€æµ‹å™¨æ—¥å¿—"""
    try:
        lines = request.args.get('lines', 50, type=int)
        
        # å°è¯•å¤šä¸ªæ—¥å¿—æ–‡ä»¶
        log_files = [
            '/home/user/webapp/gdrive_final_detector.log',
            '/home/user/webapp/gdrive_txt_detector.log',
            '/home/user/webapp/gdrive_smart_detector.log'
        ]
        
        log_content = None
        total_lines = 0
        
        for log_file in log_files:
            try:
                with open(log_file, 'r') as f:
                    all_lines = f.readlines()
                    log_content = ''.join(all_lines[-lines:] if len(all_lines) > lines else all_lines)
                    total_lines = len(all_lines)
                    break
            except FileNotFoundError:
                continue
        
        if log_content is not None:
            return jsonify({
                'success': True,
                'logs': log_content,
                'total_lines': total_lines
            })
        else:
            return jsonify({
                'success': True,
                'logs': 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨',
                'total_lines': 0
            })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e),
            'logs': ''
        })

@app.route('/api/gdrive-detector/config', methods=['GET'])
def gdrive_detector_get_config():
    """è·å–Google Driveé…ç½®"""
    try:
        import json
        config_file = '/home/user/webapp/daily_folder_config.json'
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/gdrive-detector/config', methods=['POST'])
def gdrive_detector_update_config():
    """æ›´æ–°Google Driveé…ç½®(çˆ¶æ–‡ä»¶å¤¹å…±äº«é“¾æ¥)"""
    try:
        import json
        import re
        import requests
        from datetime import datetime
        import pytz
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        data = request.get_json()
        parent_folder_url = data.get('parent_folder_url', '')
        
        # ä»URLä¸­æå–æ–‡ä»¶å¤¹ID
        match = re.search(r'folders/([A-Za-z0-9_-]+)', parent_folder_url)
        if not match:
            return jsonify({
                'success': False,
                'message': 'æ— æ•ˆçš„Google Driveæ–‡ä»¶å¤¹é“¾æ¥'
            })
        
        parent_folder_id = match.group(1)
        
        # è·å–çˆ¶æ–‡ä»¶å¤¹å†…çš„ä»Šæ—¥æ–‡ä»¶å¤¹
        today_str = now.strftime('%Y-%m-%d')
        url = f"https://drive.google.com/embeddedfolderview?id={parent_folder_id}"
        response = requests.get(url, timeout=10)
        content = response.text
        
        # æŸ¥æ‰¾ä»Šæ—¥æ—¥æœŸæ–‡ä»¶å¤¹
        folder_pattern = rf'>{today_str}<'
        if today_str not in content:
            return jsonify({
                'success': False,
                'message': f'çˆ¶æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»Šæ—¥æ–‡ä»¶å¤¹: {today_str}'
            })
        
        # æå–ä»Šæ—¥æ–‡ä»¶å¤¹ID
        # æŸ¥æ‰¾åŒ…å«ä»Šæ—¥æ—¥æœŸçš„æ–‡ä»¶å¤¹é“¾æ¥
        folder_id_pattern = rf'"([A-Za-z0-9_-]{{20,}})"[^>]*>{today_str}<'
        folder_match = re.search(folder_id_pattern, content)
        
        if not folder_match:
            # å°è¯•å¦ä¸€ç§æ¨¡å¼
            folder_id_pattern = rf'https://drive\.google\.com/drive/folders/([A-Za-z0-9_-]+)[^>]*>{today_str}<'
            folder_match = re.search(folder_id_pattern, content)
        
        if not folder_match:
            return jsonify({
                'success': False,
                'message': f'æ— æ³•ä»çˆ¶æ–‡ä»¶å¤¹ä¸­æå–ä»Šæ—¥æ–‡ä»¶å¤¹ID: {today_str}'
            })
        
        today_folder_id = folder_match.group(1)
        
        # éªŒè¯ä»Šæ—¥æ–‡ä»¶å¤¹æ˜¯å¦åŒ…å«TXTæ–‡ä»¶
        txt_url = f"https://drive.google.com/embeddedfolderview?id={today_folder_id}"
        txt_response = requests.get(txt_url, timeout=10)
        txt_content = txt_response.text
        
        # æŸ¥æ‰¾TXTæ–‡ä»¶
        txt_pattern = rf'>{today_str}_(\d{{4}})\.txt<'
        txt_matches = re.findall(txt_pattern, txt_content)
        
        if not txt_matches:
            return jsonify({
                'success': False,
                'message': f'ä»Šæ—¥æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°TXTæ–‡ä»¶'
            })
        
        # è·å–æœ€æ–°çš„TXTæ–‡ä»¶
        latest_txt_time = sorted(txt_matches, reverse=True)[0]
        latest_txt = f"{today_str}_{latest_txt_time}.txt"
        
        # æ›´æ–°é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except:
            config = {}
        
        # åˆ¤æ–­ä»Šå¤©æ˜¯å•æ•°è¿˜æ˜¯åŒæ•°æ—¥æœŸ
        day_of_month = now.day
        is_odd_day = day_of_month % 2 == 1
        
        # æ›´æ–°é…ç½®
        config['parent_folder_url'] = parent_folder_url
        config['parent_folder_id'] = parent_folder_id
        config['current_date'] = today_str
        config['data_date'] = today_str
        config['folder_id'] = today_folder_id
        config['folder_name'] = today_str
        config['latest_txt'] = latest_txt
        config['txt_count'] = len(txt_matches)
        config['last_update'] = now.strftime('%Y-%m-%d %H:%M:%S')
        config['update_reason'] = 'é€šè¿‡é…ç½®é¡µé¢æ›´æ–°çˆ¶æ–‡ä»¶å¤¹'
        config['last_manual_update'] = now.strftime('%Y-%m-%d %H:%M:%S')
        
        # æ ¹æ®å•åŒæ•°æ›´æ–°å¯¹åº”çš„çˆ¶æ–‡ä»¶å¤¹ID
        if is_odd_day:
            config['root_folder_odd'] = parent_folder_id
        else:
            config['root_folder_even'] = parent_folder_id
        
        # ä¿å­˜é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': 'é…ç½®æ›´æ–°æˆåŠŸ',
            'data': {
                'parent_folder_id': parent_folder_id,
                'today_folder_id': today_folder_id,
                'today_date': today_str,
                'txt_count': len(txt_matches),
                'latest_txt': latest_txt,
                'is_odd_day': is_odd_day
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/gdrive-detector/trigger-update', methods=['POST'])
def gdrive_detector_trigger_update():
    """è§¦å‘æ‰‹åŠ¨æ›´æ–°æ£€æµ‹"""
    try:
        import subprocess
        import time
        
        # è¿è¡Œæ£€æµ‹è„šæœ¬ä¸€æ¬¡
        result = subprocess.run(
            ['python3', '/home/user/webapp/gdrive_final_detector.py'],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        return jsonify({
            'success': True,
            'message': 'æ£€æµ‹å·²æ‰§è¡Œ',
            'output': result.stdout[:500] if result.stdout else '',
            'error': result.stderr[:500] if result.stderr else ''
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'message': 'æ£€æµ‹è¶…æ—¶(30ç§’)'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/gdrive-config')
def gdrive_config_page():
    """Google Driveé…ç½®é¡µé¢"""
    return render_template('gdrive_config.html')

# ==================== ç»Ÿä¸€ç›‘æ§é¡µé¢ ====================
@app.route('/unified-monitor')
def unified_monitor():
    """ç»Ÿä¸€é‡‡é›†ç›‘æ§é¡µé¢"""
    return render_template('unified_monitor.html')

@app.route('/unified-monitor-enhanced')
def monitor_enhanced():
    """ç»Ÿä¸€é‡‡é›†ç›‘æ§é¡µé¢(å¢å¼ºç‰ˆ)- å¸¦æ‰§è¡Œæ—¥å¿—å’Œå¼€å…³æ§åˆ¶"""
    return render_template('unified_monitor_enhanced.html')

# ==================== ç»¼åˆé‡‡é›†å™¨ç›‘æ§ API ====================
@app.route('/api/collectors/status')
def api_collectors_status():
    """è·å–æ‰€æœ‰é‡‡é›†å™¨çš„è¿è¡ŒçŠ¶æ€"""
    try:
        import subprocess
        result = subprocess.run(
            ['python3', 'get_all_collectors_status.py'],
            cwd='/home/user/webapp',
            capture_output=True,
            text=True,
            timeout=10
        )
        status_list = json.loads(result.stdout)
        
        # ç»Ÿè®¡çŠ¶æ€
        total = len(status_list)
        normal = sum(1 for s in status_list if s['status'] == 'normal')
        warning = sum(1 for s in status_list if s['status'] == 'warning')
        error = sum(1 for s in status_list if s['status'] in ['error', 'stopped', 'no_data'])
        
        return jsonify({
            'success': True,
            'collectors': status_list,
            'summary': {
                'total': total,
                'normal': normal,
                'warning': warning,
                'error': error
            },
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/favicon.ico')
def favicon():
    """å¤„ç†faviconè¯·æ±‚,é¿å…404é”™è¯¯"""
    return '', 204  # è¿”å›æ— å†…å®¹çŠ¶æ€ç 

# ============================================================================
# å¸ç§é€‰æ‹©å’Œè¯„åˆ†ç³»ç»Ÿ
# ============================================================================

@app.route('/coin-pool')
def coin_pool_page():
    """å¸ç§æ± é¡µé¢ - ä»æ˜Ÿæ˜Ÿç³»ç»Ÿç­›é€‰çš„ä¼˜è´¨å¸ç§æ± """
    response = make_response(render_template('coin_pool.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

# ============================================================================
# æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ
# ============================================================================

@app.route('/support-resistance')
def support_resistance_page():
    """æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ - é‡å®šå‘åˆ°æ–°ç³»ç»Ÿ"""
    return redirect('/price-position', code=301)

@app.route('/test-support-api')
def test_support_api_page():
    """æ”¯æ’‘é˜»åŠ›APIæµ‹è¯•é¡µé¢"""
    response = make_response(render_template('test_support_api.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    return response

@app.route('/test-simple')
def test_simple():
    """æç®€æµ‹è¯•é¡µé¢ - æœ€å°åŒ–å›¾è¡¨æ˜¾ç¤ºæµ‹è¯•"""
    response = make_response(render_template('test_simple.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/test-inline')
def test_inline():
    """å†…è”æµ‹è¯•é¡µé¢ - å®Œå…¨ä¸ä¾èµ–CDN"""
    response = make_response(render_template('test_inline.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    response.headers.pop('ETag', None)
    response.headers.pop('Last-Modified', None)
    return response

@app.route('/clear-cache')
def clear_cache_redirect():
    """æ¸…é™¤ç¼“å­˜å¹¶è·³è½¬ - ç»ˆææ–¹æ¡ˆ"""
    response = make_response(render_template('clear_cache_redirect.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/force-refresh')
def force_refresh_page():
    """å¼ºåˆ¶åˆ·æ–°é¡µé¢ - æ¸…é™¤æ‰€æœ‰æµè§ˆå™¨ç¼“å­˜"""
    response = make_response(render_template('force_refresh.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/clear-cache-guide')
def clear_cache_guide():
    """æ¸…é™¤ç¼“å­˜å¼•å¯¼é¡µé¢"""
    import time
    response = make_response(render_template('clear_cache.html', timestamp=int(time.time())))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/escape-signal-history')
@app.route('/escape-signal-history-v2')  # v2è·¯ç”±,ç»•è¿‡CDNç¼“å­˜
def escape_signal_history_page():
    """é€ƒé¡¶ä¿¡å·ç³»ç»Ÿ - é‡å®šå‘åˆ°æ–°ç³»ç»Ÿ"""
    return redirect('/price-position', code=301)

# æ·»åŠ ç¼“å­˜æœºåˆ¶
_escape_signal_cache = {
    'data': None,
    'timestamp': 0,
    'ttl': 60  # ç¼“å­˜60ç§’
}

@app.route('/api/escape-signal-stats/keypoints')
def api_escape_signal_stats_keypoints():
    """è·å–é€ƒé¡¶ä¿¡å·å…³é”®ç‚¹æ•°æ®(ç”¨äºå›¾è¡¨å¿«é€Ÿæ¸²æŸ“)- åç«¯æ™ºèƒ½é‡‡æ · + ç¼“å­˜"""
    import time
    
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from escape_signal_jsonl_manager import EscapeSignalJSONLManager
        
        # ğŸ”¥ æ”¯æŒå¿«é€Ÿæ¨¡å¼:åªè¿”å›æœ€æ–°Nä¸ªç‚¹
        fast_mode = request.args.get('fast', type=str, default='false').lower() == 'true'
        fast_limit = request.args.get('limit', type=int, default=100)
        
        # æ£€æŸ¥ç¼“å­˜(åªæœ‰éå¿«é€Ÿæ¨¡å¼æ‰ä½¿ç”¨ç¼“å­˜)
        if not fast_mode:
            current_time = time.time()
            if (_escape_signal_cache['data'] is not None and 
                current_time - _escape_signal_cache['timestamp'] < _escape_signal_cache['ttl']):
                # ç¼“å­˜å‘½ä¸­,ç›´æ¥è¿”å›
                return jsonify(_escape_signal_cache['data'])
        
        manager = EscapeSignalJSONLManager()
        
        # è¯»å–æ‰€æœ‰è®°å½•
        all_records = manager.read_records(reverse=False)
        
        # è¿‡æ»¤å‡º1æœˆ3æ—¥ä¹‹åçš„æ•°æ®
        since_date = '2026-01-03 00:00:00'
        filtered_records = [r for r in all_records if r.get('stat_time', '') >= since_date]
        filtered_records = sorted(filtered_records, key=lambda x: x.get('stat_time', ''))
        
        if not filtered_records:
            return jsonify({'success': False, 'message': 'No data available'})
        
        # ğŸ”¥ å¿«é€Ÿæ¨¡å¼:åªè¿”å›æœ€æ–°Nä¸ªç‚¹
        if fast_mode:
            latest_records = filtered_records[-fast_limit:]
            result = {
                'success': True,
                'fast_mode': True,
                'keypoint_count': len(latest_records),
                'total_records': len(filtered_records),
                'data_range': f"{latest_records[0].get('stat_time', '')} ~ {latest_records[-1].get('stat_time', '')}",
                'keypoints': [
                    {
                        'stat_time': r.get('stat_time', ''),
                        'signal_24h_count': r.get('signal_24h_count', 0),
                        'signal_2h_count': r.get('signal_2h_count', 0),
                        'rise_strength_level': r.get('rise_strength_level', 0),
                        'decline_strength_level': r.get('decline_strength_level', 0),
                        'average_change': r.get('average_change', 0),
                        'total_change': r.get('total_change', 0),
                        'valid_coins': r.get('valid_coins', 0),
                        'total_coins': r.get('total_coins', 27)
                    }
                    for r in latest_records
                ],
                'max_signal_24h': max(r.get('signal_24h_count', 0) for r in latest_records)
            }
            # Flaskä¼šè‡ªåŠ¨å¤„ç†JSONå“åº”
            return jsonify(result)
        
        total_count = len(filtered_records)
        
        # æ™ºèƒ½å…³é”®ç‚¹é‡‡æ ·ç®—æ³•
        def extract_keypoints(data, target_points=2000):
            """æå–å…³é”®ç‚¹(åç«¯ç‰ˆæœ¬)"""
            if len(data) <= target_points:
                return list(range(len(data)))
            
            keypoints = set()
            
            # 1. è®¡ç®—P99.9é˜ˆå€¼
            signal24h_values = [d.get('signal_24h_count', 0) for d in data if d.get('signal_24h_count', 0) > 0]
            if not signal24h_values:
                return list(range(len(data)))
            
            sorted_signals = sorted(signal24h_values)
            p999_idx = int(len(sorted_signals) * 0.999)
            p999 = sorted_signals[p999_idx] if p999_idx < len(sorted_signals) else sorted_signals[-1]
            p95_idx = int(len(sorted_signals) * 0.95)
            p95 = sorted_signals[p95_idx] if p95_idx < len(sorted_signals) else sorted_signals[-1]
            
            # 2. æç«¯å³°å€¼(P99.9ä»¥ä¸Š)
            for i, d in enumerate(data):
                if d.get('signal_24h_count', 0) >= p999:
                    keypoints.add(i)
            
            # 3. å…¨å±€æå€¼
            max_val = max(d.get('signal_24h_count', 0) for d in data)
            min_vals = [d.get('signal_24h_count', 0) for d in data if d.get('signal_24h_count', 0) > 0]
            min_val = min(min_vals) if min_vals else 0
            
            for i, d in enumerate(data):
                val = d.get('signal_24h_count', 0)
                if val == max_val or (val == min_val and val > 0):
                    keypoints.add(i)
            
            # 4. å±€éƒ¨å³°å€¼(æ¯6å°æ—¶çª—å£ä¿ç•™1ä¸ªæ˜¾è‘—å³°å€¼)
            window_size = 360  # 6å°æ—¶
            for i in range(0, len(data), window_size):
                window_end = min(i + window_size, len(data))
                window_max = max(
                    (d.get('signal_24h_count', 0), idx) 
                    for idx, d in enumerate(data[i:window_end], start=i)
                )
                if window_max[0] >= p95:  # åªä¿ç•™è¶…è¿‡P95çš„å±€éƒ¨å³°å€¼
                    keypoints.add(window_max[1])
            
            # 5. é¦–å°¾ç‚¹
            keypoints.add(0)
            keypoints.add(len(data) - 1)
            
            # 6. å‡åŒ€å¡«å……åˆ°ç›®æ ‡ç‚¹æ•°
            current_count = len(keypoints)
            if current_count < target_points:
                needed = target_points - current_count
                step = max(1, len(data) // needed)
                for i in range(0, len(data), step):
                    if i not in keypoints:
                        keypoints.add(i)
                    if len(keypoints) >= target_points:
                        break
            
            return sorted(list(keypoints))
        
        # æå–å…³é”®ç‚¹ç´¢å¼•
        # æ”¯æŒlimitå‚æ•°æ§åˆ¶è¿”å›çš„å…³é”®ç‚¹æ•°é‡
        target_points = request.args.get('limit', type=int, default=2000)
        target_points = min(target_points, 2000)  # æœ€å¤š2000ä¸ª
        target_points = max(target_points, 50)    # æœ€å°‘50ä¸ª
        keypoint_indices = extract_keypoints(filtered_records, target_points=target_points)
        
        # æ„å»ºå…³é”®ç‚¹æ•°æ®(åŒ…å«ä»·æ ¼å­—æ®µ)
        keypoints_data = [
            {
                'stat_time': filtered_records[i].get('stat_time'),
                'signal_24h_count': filtered_records[i].get('signal_24h_count', 0),
                'signal_2h_count': filtered_records[i].get('signal_2h_count', 0),
                'decline_strength_level': filtered_records[i].get('decline_strength_level', 0),
                'rise_strength_level': filtered_records[i].get('rise_strength_level', 0),
                'average_change': filtered_records[i].get('average_change', 0),
                'total_change': filtered_records[i].get('total_change', 0),
                'valid_coins': filtered_records[i].get('valid_coins', 0),
                'total_coins': filtered_records[i].get('total_coins', 27)
            }
            for i in keypoint_indices
        ]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        max_signal_24h = max((r.get('signal_24h_count', 0) or 0) for r in filtered_records)
        max_signal_2h = max((r.get('signal_2h_count', 0) or 0) for r in filtered_records)
        
        result = {
            'success': True,
            'keypoints': keypoints_data,
            'total_records': total_count,
            'keypoint_count': len(keypoints_data),
            'compression_rate': f'{len(keypoints_data) / total_count * 100:.1f}%',
            'max_signal_24h': max_signal_24h,
            'max_signal_2h': max_signal_2h,
            'data_range': f'{filtered_records[0].get("stat_time")} ~ {filtered_records[-1].get("stat_time")}'
        }
        
        # æ›´æ–°ç¼“å­˜
        _escape_signal_cache['data'] = result
        _escape_signal_cache['timestamp'] = current_time
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/escape-signal-stats/incremental')
def api_escape_signal_stats_incremental():
    """å¢é‡æ›´æ–°API - åªè¿”å›æœ€æ–°çš„Næ¡æ•°æ®(é»˜è®¤10æ¡)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from escape_signal_jsonl_manager import EscapeSignalJSONLManager
        
        manager = EscapeSignalJSONLManager()
        
        # è·å–å‚æ•°
        limit = request.args.get('limit', type=int, default=10)  # é»˜è®¤åªè¿”å›æœ€æ–°10æ¡
        since_time = request.args.get('since', type=str, default=None)  # å¯é€‰:ä»æŸä¸ªæ—¶é—´ç‚¹ä¹‹åçš„æ•°æ®
        
        # è¯»å–æ‰€æœ‰è®°å½•(æ­£åº)
        all_records = manager.read_records(reverse=False)
        
        # è¿‡æ»¤å‡º1æœˆ3æ—¥ä¹‹åçš„æ•°æ®
        since_date = '2026-01-03 00:00:00'
        filtered_records = [r for r in all_records if r.get('stat_time', '') >= since_date]
        
        # å¦‚æœæŒ‡å®šäº†since_time,åªè¿”å›è¯¥æ—¶é—´ä¹‹åçš„æ•°æ®
        if since_time:
            filtered_records = [r for r in filtered_records if r.get('stat_time', '') > since_time]
        
        # æŒ‰æ—¶é—´å€’åºæ’åº,å–æœ€æ–°çš„limitæ¡
        filtered_records = sorted(filtered_records, key=lambda x: x.get('stat_time', ''), reverse=True)[:limit]
        
        # å†æŒ‰æ—¶é—´æ­£åºæ’åº(æ–¹ä¾¿å‰ç«¯è¿½åŠ )
        filtered_records = sorted(filtered_records, key=lambda x: x.get('stat_time', ''))
        
        if not filtered_records:
            return jsonify({
                'success': True,
                'data': [],
                'count': 0,
                'message': 'No new data'
            })
        
        # æ„å»ºè¿”å›æ•°æ®
        incremental_data = [
            {
                'stat_time': r.get('stat_time'),
                'signal_24h_count': r.get('signal_24h_count', 0),
                'signal_2h_count': r.get('signal_2h_count', 0),
                'decline_strength_level': r.get('decline_strength_level', 0),
                'rise_strength_level': r.get('rise_strength_level', 0)
            }
            for r in filtered_records
        ]
        
        return jsonify({
            'success': True,
            'data': incremental_data,
            'count': len(incremental_data),
            'latest_time': filtered_records[-1].get('stat_time') if filtered_records else None
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/escape-signal-stats')
def api_escape_signal_stats():
    """è·å–é€ƒé¡¶ä¿¡å·ç»Ÿè®¡æ•°æ®(ä»JSONLè¯»å–)- ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        from datetime import datetime, timedelta
        import numpy as np
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from escape_signal_jsonl_manager import EscapeSignalJSONLManager
        
        manager = EscapeSignalJSONLManager()
        
        # è·å–è¯·æ±‚å‚æ•°
        limit = request.args.get('limit', type=int, default=1000)  # é»˜è®¤é™åˆ¶1000æ¡
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats_info = manager.get_statistics()
        total_count = stats_info['total_records']
        
        # è¯»å–æ‰€æœ‰è®°å½•
        all_records = manager.read_records(reverse=False)  # æ­£åºè¯»å–æ‰€æœ‰æ•°æ®
        
        # è¿‡æ»¤å‡º1æœˆ3æ—¥ä¹‹åçš„æ•°æ®
        since_date = '2026-01-03 00:00:00'
        filtered_records = [r for r in all_records if r.get('stat_time', '') >= since_date]
        
        # å¦‚æœæŒ‡å®šäº†limit,åªå–æœ€è¿‘çš„limitæ¡
        if limit:
            filtered_records = sorted(filtered_records, key=lambda x: x.get('stat_time', ''), reverse=True)[:limit]
        else:
            # ä¸é™åˆ¶æ•°é‡,æŒ‰æ—¶é—´æ­£åºæ’åº
            filtered_records = sorted(filtered_records, key=lambda x: x.get('stat_time', ''))
        
        if not filtered_records:
            return jsonify({
                'success': False,
                'message': 'No data available'
            })
        
        # è®¡ç®—å†å²æœ€å¤§å€¼(åªåœ¨è¿™æ®µæ—¶é—´å†…)
        max_signal_24h = max((r.get('max_signal_24h', 0) or 0) for r in filtered_records)
        max_signal_2h = max((r.get('max_signal_2h', 0) or 0) for r in filtered_records)
        
        # è·å–æœ€è¿‘24å°æ—¶çš„æ•°æ®ç”¨äºè®¡ç®—æ ·æœ¬æ•°å’Œä¸­ä½æ•°
        time_24h_ago = (datetime.now() - timedelta(hours=24)).strftime('%Y-%m-%d %H:%M:%S')
        recent_24h_samples = [
            r.get('signal_24h_count', 0) 
            for r in filtered_records 
            if r.get('stat_time', '') >= time_24h_ago
        ]
        sample_24h_count = len(recent_24h_samples)
        median_24h = int(np.median(recent_24h_samples)) if recent_24h_samples else 0
        
        # å‡†å¤‡å›¾è¡¨æ•°æ®(å·²ç»æ˜¯1æœˆ3æ—¥ä¹‹åçš„äº†)
        recent_data = [
            {
                'stat_time': r.get('stat_time'),
                'signal_24h_count': r.get('signal_24h_count', 0),
                'signal_2h_count': r.get('signal_2h_count', 0),
                'decline_strength_level': r.get('decline_strength_level', 0),
                'rise_strength_level': r.get('rise_strength_level', 0)
            }
            for r in filtered_records
        ]
        
        # å·²ç»æŒ‰æ—¶é—´æ­£åºæ’åºäº†(å› ä¸ºreverseåå†reverse)
        
        # è·å–å®Œæ•´å†å²è®°å½•ç”¨äºè¡¨æ ¼(æœ€æ–°çš„åœ¨å‰)
        history_data = [
            {
                'stat_time': r.get('stat_time'),
                'signal_24h_count': r.get('signal_24h_count', 0),
                'signal_2h_count': r.get('signal_2h_count', 0),
                'decline_strength_level': r.get('decline_strength_level', 0),
                'rise_strength_level': r.get('rise_strength_level', 0)
            }
            for r in filtered_records
        ]
        # å§‹ç»ˆæŒ‰æ—¶é—´å€’åºæ’åˆ—(æœ€æ–°åœ¨å‰)
        history_data = sorted(history_data, key=lambda x: x.get('stat_time', ''), reverse=True)
        # å¦‚æœæœ‰limit,åªè¿”å›æœ€è¿‘çš„limitæ¡
        if limit and len(history_data) > limit:
            history_data = history_data[:limit]
        
        return jsonify({
            'success': True,
            'total_count': total_count,
            'max_signal_24h': max_signal_24h,
            'max_signal_2h': max_signal_2h,
            'sample_24h_count': sample_24h_count,
            'median_24h': median_24h,
            'recent_data': recent_data,
            'history_data': history_data,
            'data_source': 'JSONL (Full data since 2026-01-03)',
            'timezone': 'Beijing Time (UTC+8)',
            'data_range': f'{filtered_records[0].get("stat_time")} ~ {filtered_records[-1].get("stat_time")}'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/escape-signal-simple')
def escape_signal_simple_page():
    """é€ƒé¡¶ä¿¡å·ç®€æ´ç‰ˆé¡µé¢"""
    response = make_response(render_template('escape_signal_simple.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/escape-signal-simple')
def api_escape_signal_simple():
    """è·å–é€ƒé¡¶ä¿¡å·æ•°æ® - æç®€API"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from escape_signal_jsonl_manager import EscapeSignalJSONLManager
        
        manager = EscapeSignalJSONLManager()
        
        # è·å–limitå‚æ•°
        limit = request.args.get('limit', type=int, default=1000)
        
        # è¯»å–æœ€è¿‘çš„è®°å½•
        records = manager.read_records(limit=limit, reverse=True)  # å€’åº(æœ€æ–°åœ¨å‰)
        
        # è¿‡æ»¤1æœˆ3æ—¥ä¹‹åçš„æ•°æ®
        since_date = '2026-01-03 00:00:00'
        filtered_records = [r for r in records if r.get('stat_time', '') >= since_date]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        stats_info = manager.get_statistics()
        
        max_24h = max([r.get('signal_24h_count', 0) for r in filtered_records]) if filtered_records else 0
        max_2h = max([r.get('signal_2h_count', 0) for r in filtered_records]) if filtered_records else 0
        
        return jsonify({
            'success': True,
            'total_count': stats_info['total_records'],
            'records': filtered_records,
            'max_signal_24h': max_24h,
            'max_signal_2h': max_2h,
            'data_source': 'JSONL',
            'timezone': 'Beijing Time (UTC+8)'
        })
        
    except Exception as e:
        print(f"âŒ APIé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/escape-signal-stats/dates')
def get_escape_signal_dates():
    """è·å–é€ƒé¡¶ä¿¡å·å¯ç”¨çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from escape_signal_daily_reader import EscapeSignalDailyReader
        
        reader = EscapeSignalDailyReader()
        dates = reader.get_available_dates()
        
        return jsonify({
            'success': True,
            'dates': dates,
            'count': len(dates)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/escape-signal-stats/keypoints-monthly')
def get_escape_signal_keypoints_monthly():
    """è·å–é€ƒé¡¶ä¿¡å·å…³é”®ç‚¹æ•°æ®(ç”¨äºæœˆåº¦æ€»å›¾)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from escape_signal_daily_reader import EscapeSignalDailyReader
        
        reader = EscapeSignalDailyReader()
        keypoints = reader.get_keypoints()
        
        return jsonify({
            'success': True,
            'data': keypoints,
            'count': len(keypoints)
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/escape-signal-stats/by-date')
def get_escape_signal_by_date():
    """æŒ‰æ—¥æœŸè·å–é€ƒé¡¶ä¿¡å·æ•°æ®(ç”¨äºæ—¥çº¿å›¾)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from escape_signal_daily_reader import EscapeSignalDailyReader
        from datetime import datetime
        
        # è·å–æ—¥æœŸå‚æ•°(é»˜è®¤ä»Šå¤©)
        date = request.args.get('date', datetime.now().strftime("%Y-%m-%d"))
        
        reader = EscapeSignalDailyReader()
        data = reader.get_date_data(date)
        stats = reader.get_date_statistics(date)
        
        return jsonify({
            'success': True,
            'date': date,
            'data': data,
            'count': len(data),
            'statistics': stats
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/escape-signal-stats/summary')
def get_escape_signal_summary():
    """è·å–é€ƒé¡¶ä¿¡å·æ•°æ®æ€»è§ˆ"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from escape_signal_daily_reader import EscapeSignalDailyReader
        
        reader = EscapeSignalDailyReader()
        summary = reader.get_summary()
        
        return jsonify({
            'success': True,
            'summary': summary
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/trading-signals')
def trading_signals_page():
    """å†³ç­–-äº¤æ˜“ä¿¡å·ç³»ç»Ÿé¡µé¢"""
    response = make_response(render_template('trading_signals.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

def track_trading_signal(symbol, buy_point_type, suggested_position):
    """è·Ÿè¸ªäº¤æ˜“ä¿¡å·çš„é¦–æ¬¡è§¦å‘æ—¶é—´"""
    from datetime import datetime
    import pytz
    import sqlite3
    
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(beijing_tz)
    
    signal_key = f"{symbol}_{buy_point_type}"
    
    # ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®åº“è¿æ¥
    conn_track = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
    conn_track.row_factory = sqlite3.Row
    cursor_track = conn_track.cursor()
    
    try:
        # æ£€æŸ¥è¯¥ä¿¡å·æ˜¯å¦å·²å­˜åœ¨
        cursor_track.execute('''
            SELECT id, first_triggered_at, suggested_position 
            FROM trading_signal_history 
            WHERE signal_key = ? AND is_active = 1
        ''', (signal_key,))
        
        existing = cursor_track.fetchone()
        
        if existing:
            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
            cursor_track.execute('''
                UPDATE trading_signal_history 
                SET last_updated_at = ?, suggested_position = ?
                WHERE id = ?
            ''', (now.strftime('%Y-%m-%d %H:%M:%S'), suggested_position, existing['id']))
            conn_track.commit()
            return {
                'first_triggered_at': existing['first_triggered_at'],
                'initial_position': str(int(float(existing['suggested_position'].replace('%', '')) * 0.3)) + '%'
            }
        else:
            # æ’å…¥æ–°ä¿¡å·
            cursor_track.execute('''
                INSERT INTO trading_signal_history 
                (signal_key, symbol, buy_point_type, suggested_position, 
                 first_triggered_at, last_updated_at, is_active)
                VALUES (?, ?, ?, ?, ?, ?, 1)
            ''', (signal_key, symbol, buy_point_type, suggested_position,
                  now.strftime('%Y-%m-%d %H:%M:%S'), 
                  now.strftime('%Y-%m-%d %H:%M:%S')))
            conn_track.commit()
            return {
                'first_triggered_at': now.strftime('%Y-%m-%d %H:%M:%S'),
                'initial_position': str(int(float(suggested_position.replace('%', '')) * 0.3)) + '%'
            }
    finally:
        conn_track.close()

def check_no_new_low_5min(symbol):
    """æ£€æŸ¥åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½"""
    import sqlite3
    from datetime import datetime, timedelta
    
    conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€æ ¼å¼:FIL -> FIL-USDT-SWAP
        symbol_full = f"{symbol}-USDT-SWAP" if not symbol.endswith('-USDT-SWAP') else symbol
        symbol_short = symbol.replace('-USDT-SWAP', '')
        
        # è·å–æœ€è¿‘çš„åˆ›æ–°ä½äº‹ä»¶
        cursor.execute('''
            SELECT event_time, price
            FROM price_breakthrough_events
            WHERE symbol = ? AND event_type = 'new_low'
            ORDER BY event_time DESC
            LIMIT 1
        ''', (symbol_short,))
        
        last_new_low = cursor.fetchone()
        if not last_new_low:
            return False
        
        new_low_time = datetime.strptime(last_new_low[0], '%Y-%m-%d %H:%M:%S')
        new_low_price = last_new_low[1]
        
        # è·å–åˆ›æ–°ä½ä¹‹åçš„5ä¸ª5åˆ†é’ŸKçº¿
        cursor.execute('''
            SELECT low, timestamp
            FROM okex_kline_ohlc
            WHERE symbol = ?
              AND timeframe = '5m'
              AND datetime(timestamp/1000, 'unixepoch') > datetime(?)
            ORDER BY timestamp ASC
            LIMIT 5
        ''', (symbol_full, new_low_time.strftime('%Y-%m-%d %H:%M:%S')))
        
        klines_after = cursor.fetchall()
        
        # éœ€è¦æœ‰5æ ¹Kçº¿
        if len(klines_after) < 5:
            return False
        
        # æ£€æŸ¥è¿™5æ ¹Kçº¿æ˜¯å¦éƒ½æ²¡æœ‰åˆ›æ–°ä½
        for low, ts in klines_after:
            if low < new_low_price:
                return False
        
        return True
    finally:
        conn.close()

def get_1h_rsi(symbol):
    """è·å–1å°æ—¶RSI"""
    import sqlite3
    
    conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€æ ¼å¼
        symbol_full = f"{symbol}-USDT-SWAP" if not symbol.endswith('-USDT-SWAP') else symbol
        
        cursor.execute('''
            SELECT rsi_14
            FROM okex_technical_indicators
            WHERE symbol = ? AND timeframe IN ('1h', '1H')
            ORDER BY record_time DESC
            LIMIT 1
        ''', (symbol_full,))
        
        result = cursor.fetchone()
        return result[0] if result else None
    finally:
        conn.close()

def check_consecutive_oscillation_5min(symbol):
    """æ£€æŸ¥5åˆ†é’Ÿå‘¨æœŸè¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œåœ¨0%åˆ°+0.25%ä¹‹é—´(ä¸åŒ…æ‹¬è´Ÿæ¶¨è·Œ)"""
    import sqlite3
    
    conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # ç»Ÿä¸€æ ¼å¼
        symbol_full = f"{symbol}-USDT-SWAP" if not symbol.endswith('-USDT-SWAP') else symbol
        
        # è·å–æœ€è¿‘3æ ¹5åˆ†é’ŸKçº¿
        cursor.execute('''
            SELECT open, high, low, close
            FROM okex_kline_ohlc
            WHERE symbol = ?
              AND timeframe = '5m'
            ORDER BY timestamp DESC
            LIMIT 3
        ''', (symbol_full,))
        
        klines = cursor.fetchall()
        
        if len(klines) < 3:
            return False
        
        # æ£€æŸ¥æ¯æ ¹Kçº¿
        for open_price, high, low, close in klines:
            if open_price == 0:
                return False
            
            # éœ‡è¡å¹…åº¦ = (æœ€é«˜-æœ€ä½) / å¼€ç›˜ * 100
            oscillation = ((high - low) / open_price) * 100 if open_price > 0 else 999
            
            # æ¶¨è·Œå¹… = (æ”¶ç›˜-å¼€ç›˜) / å¼€ç›˜ * 100(ä¿ç•™æ­£è´Ÿ,ä¸å–ç»å¯¹å€¼)
            change = ((close - open_price) / open_price) * 100
            
            # ä»»ä½•ä¸€æ ¹ä¸æ»¡è¶³æ¡ä»¶å°±è¿”å›False
            # æ¶¨è·Œå¹…å¿…é¡»åœ¨ 0% åˆ° +0.25% ä¹‹é—´,éœ‡è¡å¹…åº¦ <= 0.50%
            if change < 0 or change > 0.25 or oscillation > 0.5:
                return False
        
        return True
    finally:
        conn.close()

def deactivate_missing_signals(active_signal_keys):
    """å°†ä¸å†æ»¡è¶³æ¡ä»¶çš„ä¿¡å·æ ‡è®°ä¸ºå¤±æ•ˆ"""
    from datetime import datetime
    import pytz
    import sqlite3
    
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(beijing_tz)
    
    conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
    cursor = conn.cursor()
    
    try:
        # è·å–æ‰€æœ‰å½“å‰æ´»è·ƒçš„ä¿¡å·
        cursor.execute('SELECT signal_key FROM trading_signal_history WHERE is_active = 1')
        all_active = [row[0] for row in cursor.fetchall()]
        
        # æ‰¾å‡ºä¸åœ¨å½“å‰ä¿¡å·åˆ—è¡¨ä¸­çš„ä¿¡å·(å³æ¡ä»¶ä¸å†æ»¡è¶³çš„ä¿¡å·)
        signals_to_deactivate = [sig for sig in all_active if sig not in active_signal_keys]
        
        # æ ‡è®°è¿™äº›ä¿¡å·ä¸ºå¤±æ•ˆ
        for signal_key in signals_to_deactivate:
            cursor.execute('''
                UPDATE trading_signal_history 
                SET is_active = 0, last_updated_at = ?
                WHERE signal_key = ? AND is_active = 1
            ''', (now.strftime('%Y-%m-%d %H:%M:%S'), signal_key))
        
        conn.commit()
        return len(signals_to_deactivate)
    finally:
        conn.close()

@app.route('/api/trading-signals/analyze')
def api_trading_signals_analyze():
    """åˆ†æäº¤æ˜“ä¿¡å· - åšå¤šä¹°ç‚¹1/2/3"""
    try:
        from datetime import datetime, timedelta
        import pytz
        from opening_logic import get_opening_suggestion
        
        # è¿æ¥crypto_dataæ•°æ®åº“(ç”¨äºå…¶ä»–ç³»ç»Ÿæ•°æ®)
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # 0. è·å–å¼€ä»“é€»è¾‘å»ºè®®(ç”¨äºä¹°ç‚¹3ä»“ä½è®¡ç®—)
        try:
            opening_logic_data = get_opening_suggestion()
            opening_position = opening_logic_data.get('position_info', {})
            opening_can_long = opening_logic_data.get('can_long', False)
            opening_position_percent = opening_position.get('position_percent', 0)
        except Exception as e:
            print(f"è·å–å¼€ä»“é€»è¾‘å¤±è´¥: {e}")
            opening_can_long = False
            opening_position_percent = 0
        
        # 1. è·å–æ”¯æ’‘å‹åŠ›çº¿æ•°æ®(ä»JSONL)
        import sys
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from support_resistance_api_adapter import SupportResistanceAPIAdapter
        
        adapter = SupportResistanceAPIAdapter()
        sr_result = adapter.get_all_symbols_latest()
        
        sr_data = {}
        if sr_result['success'] and sr_result['data']:
            for item in sr_result['data']:
                symbol = item.get('symbol', '')
                # è®¡ç®—è·ç¦»æ”¯æ’‘çº¿çš„è·ç¦»ç™¾åˆ†æ¯”
                current_price = item.get('current_price', 0)
                support_1 = item.get('support_line_1', 0)
                support_2 = item.get('support_line_2', 0)
                resistance_1 = item.get('resistance_line_1', 0)
                
                distance_to_support_1 = None
                distance_to_support_2 = None
                distance_to_resistance_1 = None
                position_s2_r1 = item.get('position_7d', 0)  # ä½¿ç”¨position_7dä½œä¸ºs2_r1ä½ç½®
                
                if support_1 and current_price:
                    distance_to_support_1 = ((current_price - support_1) / support_1) * 100
                if support_2 and current_price:
                    distance_to_support_2 = ((current_price - support_2) / support_2) * 100
                if resistance_1 and current_price:
                    distance_to_resistance_1 = ((resistance_1 - current_price) / current_price) * 100
                
                sr_data[symbol] = {
                    'symbol': symbol,
                    'current_price': current_price,
                    'support_line_1': support_1,
                    'support_line_2': support_2,
                    'resistance_line_1': resistance_1,
                    'distance_to_support_1': distance_to_support_1,
                    'distance_to_support_2': distance_to_support_2,
                    'distance_to_resistance_1': distance_to_resistance_1,
                    'position_s2_r1': position_s2_r1,
                    'record_time': item.get('record_time', '')
                }
        
        # 2. è·å–ä»·æ ¼çªç ´æ•°æ®(åˆ›æ–°ä½ç»Ÿè®¡ - æœ€è¿‘7å¤©)
        seven_days_ago = now - timedelta(days=7)
        cursor.execute('''
            SELECT symbol, COUNT(*) as count
            FROM price_breakthrough_events
            WHERE event_type = 'new_low'
              AND event_time >= ?
            GROUP BY symbol
        ''', (seven_days_ago.strftime('%Y-%m-%d %H:%M:%S'),))
        breakthrough_data = {row['symbol']: row['count'] for row in cursor.fetchall()}
        
        # 3. è·å–æœ€æ–°å¿«ç…§æ•°æ®(æ€¥æ¶¨æ€¥è·Œã€è®¡æ¬¡å¾—åˆ†)
        cursor.execute('''
            SELECT c.symbol, c.rush_up, c.rush_down, c.current_price,
                   s.count_score_display, s.count_score_type
            FROM crypto_coin_data c
            JOIN crypto_snapshots s ON c.snapshot_id = s.id
            WHERE c.id IN (
                SELECT MAX(id) 
                FROM crypto_coin_data 
                GROUP BY symbol
            )
        ''')
        coin_data = {row['symbol']: dict(row) for row in cursor.fetchall()}
        
        # 3.5 è·å–Kçº¿æŒ‡æ ‡æ•°æ® (5åˆ†é’ŸRSIã€SARä½ç½®ã€SARè±¡é™)
        cursor.execute('''
            SELECT symbol, rsi_14, sar_position, sar_quadrant, sar_count_label
            FROM okex_technical_indicators
            WHERE timeframe = '5m'
              AND (symbol, record_time) IN (
                SELECT symbol, MAX(record_time)
                FROM okex_technical_indicators
                WHERE timeframe = '5m'
                GROUP BY symbol
            )
        ''')
        kline_indicators = {}
        for row in cursor.fetchall():
            # ç»Ÿä¸€æ ¼å¼:FIL-USDT-SWAP -> FIL
            symbol_short = row['symbol'].replace('-USDT-SWAP', '')
            kline_indicators[symbol_short] = {
                'rsi_5m': row['rsi_14'],
                'sar_position': row['sar_position'],  # 'bullish' æˆ– 'bearish'
                'sar_quadrant': row['sar_quadrant'],  # 1-4è±¡é™
                'sar_count_label': row['sar_count_label']  # ä¾‹å¦‚ "å¤šå¤´12"
            }
        
        # 4. è·å–ä½ç½®ç³»ç»Ÿæ•°æ®(BTC/ETHçš„4h/12h/24h/48hå‘¨æœŸä½ç½®)
        cursor.execute('''
            SELECT symbol, position_4h, position_12h, position_24h, position_48h
            FROM position_system
            WHERE symbol IN ('BTC', 'ETH')
              AND id IN (
                SELECT MAX(id) 
                FROM position_system 
                GROUP BY symbol
            )
        ''')
        position_data = {}
        for row in cursor.fetchall():
            symbol = row['symbol']
            positions = [
                row['position_4h'], row['position_12h'], 
                row['position_24h'], row['position_48h']
            ]
            # ç»Ÿè®¡æœ‰å¤šå°‘ä¸ªå‘¨æœŸä½ç½® < 10%
            low_position_count = sum(1 for p in positions if p is not None and p < 10)
            position_data[symbol] = low_position_count
        
        conn.close()
        
        # æ£€æŸ¥BTCå’ŒETHæ˜¯å¦è‡³å°‘æœ‰5ä¸ªå‘¨æœŸ < 10%
        # ç”±äºåªæœ‰4ä¸ªå‘¨æœŸ,æˆ‘ä»¬æ”¹ä¸ºæ£€æŸ¥BTCå’ŒETHåŠ èµ·æ¥æ˜¯å¦æœ‰5ä¸ªä»¥ä¸Š
        btc_low = position_data.get('BTC', 0)
        eth_low = position_data.get('ETH', 0)
        total_low_positions = btc_low + eth_low
        condition6_pass = total_low_positions >= 5
        
        # 5. ç»Ÿè®¡æ¥è¿‘æ”¯æ’‘çº¿çš„å¸ç§æ•°é‡(ç”¨äºä¹°ç‚¹3æ¡ä»¶6)
        # æ¥è¿‘æ”¯æ’‘1:è·ç¦»æ”¯æ’‘çº¿1 <= æŸä¸ªé˜ˆå€¼(ä¾‹å¦‚10%)
        # æ¥è¿‘æ”¯æ’‘2:è·ç¦»æ”¯æ’‘çº¿2 <= æŸä¸ªé˜ˆå€¼(ä¾‹å¦‚10%)
        near_support_1_count = 0
        near_support_2_count = 0
        
        for symbol, sr in sr_data.items():
            dist_s1 = sr.get('distance_to_support_1')
            dist_s2 = sr.get('distance_to_support_2')
            
            # ç»Ÿè®¡æ¥è¿‘æ”¯æ’‘1çš„å¸ç§(è·ç¦» <= 10%)
            if dist_s1 is not None and dist_s1 <= 10:
                near_support_1_count += 1
            
            # ç»Ÿè®¡æ¥è¿‘æ”¯æ’‘2çš„å¸ç§(è·ç¦» <= 10%)
            if dist_s2 is not None and dist_s2 <= 10:
                near_support_2_count += 1
        
        # ä¹°ç‚¹3æ¡ä»¶6:æ¥è¿‘æ”¯æ’‘1çš„å¸ç§æ•° >= 8 æˆ– æ¥è¿‘æ”¯æ’‘2çš„å¸ç§æ•° >= 8
        condition6_support_system = near_support_1_count >= 8 or near_support_2_count >= 8
        
        # 6. åˆ†æä¿¡å·
        signals = []
        buy_point_1_count = 0
        buy_point_2_count = 0
        buy_point_3_count = 0
        
        for symbol, sr in sr_data.items():
            coin_name = symbol.replace('USDT', '')
            coin = coin_data.get(coin_name, {})
            kline = kline_indicators.get(coin_name, {})
            
            # è·å–åˆ›æ–°ä½æ¬¡æ•°
            new_lows = breakthrough_data.get(coin_name, 0)
            
            # è·å–è®¡æ¬¡å¾—åˆ†
            score_display = coin.get('count_score_display', '---')
            score_type = coin.get('count_score_type', 'ä¸­æ€§')
            
            # è·å–æ€¥æ¶¨æ€¥è·Œ
            rush_up = coin.get('rush_up', 0) or 0
            rush_down = coin.get('rush_down', 0) or 0
            rush_diff = rush_up - rush_down
            
            # è·å–Kçº¿æŒ‡æ ‡æ•°æ®
            rsi_5m = kline.get('rsi_5m')
            sar_position = kline.get('sar_position')  # 'bullish' / 'bearish'
            sar_quadrant = kline.get('sar_quadrant')  # 1-4
            sar_count_label = kline.get('sar_count_label', '')
            
            # è§£æç©ºå¤´/å¤šå¤´æ•°é‡(ä» "ç©ºå¤´20" æˆ– "å¤šå¤´12" ä¸­æå–æ•°å­—)
            sar_count = 0
            if sar_count_label:
                import re
                match = re.search(r'(\d+)', sar_count_label)
                if match:
                    sar_count = int(match.group(1))
            
            # é€šç”¨æ¡ä»¶åˆ¤æ–­
            condition1 = new_lows < 3  # åˆ›æ–°ä½ < 3 ã€ä¹°ç‚¹1/2/3é€‚ç”¨ã€‘
            condition2 = 'â˜…' in score_display or 'â­' in score_display  # è®¡æ¬¡å¾—åˆ†æ˜¯æ˜Ÿæ˜Ÿ ã€ä¹°ç‚¹1/2é€‚ç”¨ã€‘
            condition3 = rush_diff > 0  # æ€¥æ¶¨ - æ€¥è·Œ > 0 ã€ä¹°ç‚¹1/2é€‚ç”¨ã€‘
            condition4 = rsi_5m is not None and rsi_5m < 20  # 5åˆ†é’ŸRSI < 20 ã€ä¹°ç‚¹1é€‚ç”¨ã€‘(ä¿®æ”¹ä¸ºä½¿ç”¨5åˆ†é’ŸRSI)
            condition5 = rush_diff > -15  # æ€¥æ¶¨ - æ€¥è·Œ > -15 ã€ä¹°ç‚¹3é€‚ç”¨ã€‘
            condition6 = condition6_pass  # BTC/ETHè‡³å°‘5ä¸ªå‘¨æœŸ < 10% ã€ä¹°ç‚¹3é€‚ç”¨ã€‘
            
            # æ–°å¢æ¡ä»¶(åŸºäºKçº¿æŒ‡æ ‡)
            condition_sar_bearish = sar_position == 'bearish'  # ç©ºå¤´è¶‹åŠ¿
            condition_sar_count = sar_count > 20  # ç©ºå¤´æ•°é‡>20
            condition_sar_quadrant3 = sar_quadrant == 3  # SARç¬¬ä¸‰è±¡é™
            condition_rsi_low = rsi_5m is not None and rsi_5m < 30  # 5åˆ†é’ŸRSI<30 ã€ä¹°ç‚¹2é€‚ç”¨ã€‘
            
            # ä¹°ç‚¹3ä¸“ç”¨æ¡ä»¶æ£€æŸ¥
            condition_no_new_low_5m = check_no_new_low_5min(coin_name)  # åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½
            rsi_1h = get_1h_rsi(coin_name)  # è·å–1å°æ—¶RSI
            condition_rsi_1h_low = rsi_1h is not None and rsi_1h < 15  # 1å°æ—¶RSI<15
            condition_oscillation_3 = check_consecutive_oscillation_5min(coin_name)  # è¿ç»­3ä¸ªéœ‡è¡
            
            # è·å–è·ç¦»æ”¯æ’‘çº¿1çš„è·ç¦»(ç”¨äºä¹°ç‚¹1)
            distance = sr.get('distance_to_support_1')
            
            # åˆ¤æ–­å„ä¸ªä¹°ç‚¹
            buy_point_1 = False
            buy_point_2 = False
            buy_point_3 = False
            
            # ä¹°ç‚¹1: è¾¾åˆ°æ”¯æ’‘çº¿1 (è·ç¦» < 5%) + æ¡ä»¶1234
            if (distance is not None and distance <= 5 and 
                condition1 and condition2 and condition3 and condition4):
                buy_point_1 = True
                buy_point_1_count += 1
            
            # ä¹°ç‚¹2: å›è°ƒä¹°å…¥
            # æ¡ä»¶:æ¡ä»¶123 + ç©ºå¤´>20 + 5åˆ†é’ŸSARç¬¬ä¸‰è±¡é™ + 5åˆ†é’ŸRSI<30
            if (condition1 and condition2 and condition3 and 
                condition_sar_count and condition_sar_quadrant3 and condition_rsi_low):
                buy_point_2 = True
                buy_point_2_count += 1
            
            # ä¹°ç‚¹3: ç©ºè½¬å¤šä¹°å…¥(é‡æ–°å®šä¹‰æ¡ä»¶)
            # 6ä¸ªå¿…é¡»æ¡ä»¶:
            # 1. åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½
            # 2. 1å°æ—¶RSI < 15
            # 3. 5åˆ†é’Ÿå‘¨æœŸè¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œ<0.25%
            # 4. SARç©ºå¤´æ•°é‡ > 20
            # 5. 5åˆ†é’ŸSARåœ¨ç¬¬ä¸‰è±¡é™
            # 6. æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ:æ¥è¿‘æ”¯æ’‘1çš„å¸ç§æ•° >= 8 æˆ– æ¥è¿‘æ”¯æ’‘2çš„å¸ç§æ•° >= 8
            if (condition_no_new_low_5m and 
                condition_rsi_1h_low and 
                condition_oscillation_3 and 
                condition_sar_count and 
                condition_sar_quadrant3 and 
                condition6_support_system):  # ä½¿ç”¨å…¨å±€æ¡ä»¶
                buy_point_3 = True
                buy_point_3_count += 1
            
            # åªä¿ç•™æœ‰ä¿¡å·çš„å¸ç§
            if buy_point_1 or buy_point_2 or buy_point_3:
                # è¯¦ç»†çš„æ¡ä»¶åˆ¤æ–­ç»“æœ - ç”¨äºé€æ˜åŒ–æ˜¾ç¤º
                detailed_conditions = {
                    'buy_point_1_conditions': {
                        'distance_to_support': {'value': distance, 'threshold': 'â‰¤ 5%', 'pass': distance is not None and distance <= 5, 'desc': 'è·ç¦»æ”¯æ’‘çº¿1'},
                        'condition1': {'value': new_lows, 'threshold': '< 3', 'pass': condition1, 'desc': '7å¤©åˆ›æ–°ä½æ¬¡æ•°'},
                        'condition2': {'value': score_display, 'threshold': 'åŒ…å«â˜…æˆ–â­', 'pass': condition2, 'desc': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤º'},
                        'condition3': {'value': round(rush_diff, 2), 'threshold': '> 0', 'pass': condition3, 'desc': 'æ€¥æ¶¨-æ€¥è·Œ'},
                        'condition4': {'value': round(rsi_5m, 2) if rsi_5m else None, 'threshold': '< 20', 'pass': condition4, 'desc': '5åˆ†é’ŸRSI'}
                    },
                    'buy_point_2_conditions': {
                        'condition1': {'value': new_lows, 'threshold': '< 3', 'pass': condition1, 'desc': '7å¤©åˆ›æ–°ä½æ¬¡æ•°'},
                        'condition2': {'value': score_display, 'threshold': 'åŒ…å«â˜…æˆ–â­', 'pass': condition2, 'desc': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤º'},
                        'condition3': {'value': round(rush_diff, 2), 'threshold': '> 0', 'pass': condition3, 'desc': 'æ€¥æ¶¨-æ€¥è·Œ'},
                        'sar_count': {'value': sar_count, 'threshold': '> 20', 'pass': condition_sar_count, 'desc': 'SARç©ºå¤´æ•°é‡'},
                        'sar_quadrant': {'value': sar_quadrant, 'threshold': '= 3', 'pass': condition_sar_quadrant3, 'desc': 'SARç¬¬ä¸‰è±¡é™'},
                        'rsi_5m': {'value': round(rsi_5m, 2) if rsi_5m else None, 'threshold': '< 30', 'pass': condition_rsi_low, 'desc': '5åˆ†é’ŸRSI'}
                    },
                    'buy_point_3_conditions': {
                        'no_new_low_5m': {'value': 'æ˜¯' if condition_no_new_low_5m else 'å¦', 'threshold': 'æ˜¯', 'pass': condition_no_new_low_5m, 'desc': 'åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½'},
                        'rsi_1h': {'value': round(rsi_1h, 2) if rsi_1h else None, 'threshold': '< 15', 'pass': condition_rsi_1h_low, 'desc': '1å°æ—¶RSI'},
                        'oscillation_3': {'value': 'æ˜¯' if condition_oscillation_3 else 'å¦', 'threshold': 'æ˜¯', 'pass': condition_oscillation_3, 'desc': 'è¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œ<0.25%'},
                        'sar_count': {'value': sar_count, 'threshold': '> 20', 'pass': condition_sar_count, 'desc': 'SARç©ºå¤´æ•°é‡'},
                        'sar_quadrant': {'value': sar_quadrant, 'threshold': '= 3', 'pass': condition_sar_quadrant3, 'desc': '5åˆ†é’ŸSARç¬¬ä¸‰è±¡é™'},
                        'support_system': {'value': f'æ¥è¿‘æ”¯æ’‘1: {near_support_1_count}ä¸ª, æ¥è¿‘æ”¯æ’‘2: {near_support_2_count}ä¸ª', 'threshold': 'æ¥è¿‘æ”¯æ’‘1 â‰¥ 8ä¸ª æˆ– æ¥è¿‘æ”¯æ’‘2 â‰¥ 8ä¸ª', 'pass': condition6_support_system, 'desc': 'æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ'}
                    }
                }
                
                # ç¡®å®šä¹°ç‚¹ç±»å‹å’Œå»ºè®®ä»“ä½
                buy_point_type = None
                suggested_position = None
                position_calculation_note = None
                buy_times = None  # åˆ†æ‰¹ä¹°å…¥æ¬¡æ•°
                
                if buy_point_1:
                    buy_point_type = 'buy_point_1'
                    suggested_position = '30%'
                    buy_times = 3  # ä¹°ç‚¹1åˆ†3æ¬¡ä¹°å…¥
                    position_calculation_note = 'ä¹°ç‚¹1å›ºå®šä»“ä½,åˆ†3æ¬¡ä¹°å…¥'
                    
                elif buy_point_3:
                    buy_point_type = 'buy_point_3'
                    buy_times = 2  # ä¹°ç‚¹3åˆ†2æ¬¡ä¹°å…¥
                    # ä¹°ç‚¹3ç‰¹æ®Šä»“ä½é€»è¾‘
                    if opening_can_long and opening_position_percent > 0:
                        # æƒ…å†µ2:å¼€ä»“é€»è¾‘å…è®¸å¼€ä»“
                        # ä¹°ç‚¹3ä»“ä½ = å¼€ä»“é€»è¾‘å»ºè®® + 20%,æœ€é«˜70%
                        bp3_position = min(opening_position_percent + 20, 70)
                        suggested_position = f'{int(bp3_position)}%'
                        position_calculation_note = f'å¼€ä»“é€»è¾‘{int(opening_position_percent)}% + ä¹°ç‚¹3åŠ æˆ20% = {int(bp3_position)}% (ä¸Šé™70%),åˆ†2æ¬¡ä¹°å…¥'
                    else:
                        # æƒ…å†µ1:å¼€ä»“é€»è¾‘ä¸å…è®¸å¼€ä»“
                        # ä¹°ç‚¹3å¯é¢å¤–å¼€20%
                        suggested_position = '20%'
                        position_calculation_note = 'å¼€ä»“é€»è¾‘ä¸å…è®¸,ä¹°ç‚¹3å¯é¢å¤–å¼€20%,åˆ†2æ¬¡ä¹°å…¥'
                        
                elif buy_point_2:
                    buy_point_type = 'buy_point_2'
                    suggested_position = '20%'
                    buy_times = 2  # ä¹°ç‚¹2åˆ†2æ¬¡ä¹°å…¥
                    position_calculation_note = 'ä¹°ç‚¹2å›ºå®šä»“ä½,åˆ†2æ¬¡ä¹°å…¥'
                
                # è·Ÿè¸ªä¿¡å·å†å²,è·å–é¦–æ¬¡è§¦å‘æ—¶é—´å’Œé¦–æ¬¡å¼€ä»“å»ºè®®
                tracking_info = track_trading_signal(coin_name, buy_point_type, suggested_position)
                
                signals.append({
                    'symbol': coin_name,
                    'current_price': sr.get('current_price', 0),
                    'support_line_1': sr.get('support_line_1'),
                    'distance_to_support_1': distance,
                    'buy_point_1': buy_point_1,
                    'buy_point_2': buy_point_2,
                    'buy_point_3': buy_point_3,
                    'suggested_position': suggested_position,
                    'buy_times': buy_times,  # æ–°å¢:åˆ†æ‰¹ä¹°å…¥æ¬¡æ•°
                    'position_calculation_note': position_calculation_note,  # æ–°å¢:ä»“ä½è®¡ç®—è¯´æ˜
                    'opening_logic_position': f'{int(opening_position_percent)}%' if opening_can_long else 'ä¸å…è®¸',  # æ–°å¢:å¼€ä»“é€»è¾‘å»ºè®®
                    'first_triggered_at': tracking_info['first_triggered_at'],  # æ–°å¢:é¦–æ¬¡è§¦å‘æ—¶é—´
                    'initial_position': tracking_info['initial_position'],  # æ–°å¢:é¦–æ¬¡å¼€ä»“å»ºè®®(æ€»ä»“ä½çš„30%)
                    'conditions': {
                        'condition1_pass': condition1,
                        'condition2_pass': condition2,
                        'condition3_pass': condition3,
                        'new_lows': new_lows,
                        'score_display': score_display,
                        'rush_diff': round(rush_diff, 2)
                    },
                    'kline_indicators': {
                        'rsi_5m': round(rsi_5m, 2) if rsi_5m else None,
                        'sar_position': sar_position,
                        'sar_quadrant': sar_quadrant,
                        'sar_count': sar_count,
                        'sar_count_label': sar_count_label
                    },
                    'detailed_conditions': detailed_conditions  # æ–°å¢:è¯¦ç»†æ¡ä»¶åˆ¤æ–­ç»“æœ
                })
        
        # æŒ‰ä¹°ç‚¹1 > ä¹°ç‚¹3 > ä¹°ç‚¹2 ä¼˜å…ˆçº§æ’åº,åŒä¼˜å…ˆçº§æŒ‰è·æ”¯æ’‘çº¿è·ç¦»æ’åº
        def sort_key(x):
            priority = 0
            if x['buy_point_1']:
                priority = 3
            elif x['buy_point_3']:
                priority = 2
            elif x['buy_point_2']:
                priority = 1
            distance = x['distance_to_support_1'] if x['distance_to_support_1'] is not None else 999
            return (-priority, distance)
        
        signals.sort(key=sort_key)
        
        # æ”¶é›†å½“å‰æ‰€æœ‰æ´»è·ƒä¿¡å·çš„signal_key
        active_signal_keys = []
        for signal in signals:
            coin_name = signal['symbol']
            if signal['buy_point_1']:
                active_signal_keys.append(f"{coin_name}_buy_point_1")
            elif signal['buy_point_3']:
                active_signal_keys.append(f"{coin_name}_buy_point_3")
            elif signal['buy_point_2']:
                active_signal_keys.append(f"{coin_name}_buy_point_2")
        
        # å°†ä¸å†æ»¡è¶³æ¡ä»¶çš„ä¿¡å·æ ‡è®°ä¸ºå¤±æ•ˆ
        deactivated_count = deactivate_missing_signals(active_signal_keys)
        
        # ä¹°ç‚¹è§„åˆ™è¯´æ˜ - é€æ˜åŒ–å±•ç¤º
        buy_point_rules = {
            'buy_point_1': {
                'name': 'ä¹°ç‚¹1 - æ”¯æ’‘çº¿ä¹°å…¥',
                'suggested_position': '30%',
                'buy_times': 3,  # åˆ†3æ¬¡ä¹°å…¥
                'conditions': [
                    {'id': 'è·ç¦»æ”¯æ’‘çº¿', 'rule': 'è·ç¦»æ”¯æ’‘çº¿1 â‰¤ 5%', 'priority': 'high'},
                    {'id': 'åˆ›æ–°ä½', 'rule': '7å¤©åˆ›æ–°ä½æ¬¡æ•° < 3', 'priority': 'high'},
                    {'id': 'è®¡æ¬¡å¾—åˆ†', 'rule': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤ºåŒ…å«â˜…æˆ–â­', 'priority': 'medium'},
                    {'id': 'æ€¥æ¶¨æ€¥è·Œ', 'rule': 'æ€¥æ¶¨ - æ€¥è·Œ > 0', 'priority': 'medium'},
                    {'id': 'RSI 5m', 'rule': '5åˆ†é’ŸRSI < 20', 'priority': 'high'}
                ],
                'description': 'ä»·æ ¼æ¥è¿‘æ”¯æ’‘çº¿æ—¶çš„ä¹°å…¥æœºä¼š,é£é™©è¾ƒä½,å»ºè®®åˆ†3æ¬¡ä¹°å…¥'
            },
            'buy_point_2': {
                'name': 'ä¹°ç‚¹2 - å›è°ƒä¹°å…¥',
                'suggested_position': '20%',
                'buy_times': 2,  # åˆ†2æ¬¡ä¹°å…¥
                'conditions': [
                    {'id': 'åˆ›æ–°ä½', 'rule': '7å¤©åˆ›æ–°ä½æ¬¡æ•° < 3', 'priority': 'high'},
                    {'id': 'è®¡æ¬¡å¾—åˆ†', 'rule': 'è®¡æ¬¡å¾—åˆ†æ˜¾ç¤ºåŒ…å«â˜…æˆ–â­', 'priority': 'medium'},
                    {'id': 'æ€¥æ¶¨æ€¥è·Œ', 'rule': 'æ€¥æ¶¨ - æ€¥è·Œ > 0', 'priority': 'medium'},
                    {'id': 'SARç©ºå¤´æ•°', 'rule': 'SARç©ºå¤´æ•°é‡ > 20', 'priority': 'high'},
                    {'id': 'SARè±¡é™', 'rule': 'SARåœ¨ç¬¬ä¸‰è±¡é™', 'priority': 'high'},
                    {'id': 'RSI 5m', 'rule': '5åˆ†é’ŸRSI < 30', 'priority': 'high'}
                ],
                'description': 'å¸‚åœºå›è°ƒæ—¶çš„ä¹°å…¥æœºä¼š,éœ€è¦æŠ€æœ¯æŒ‡æ ‡ç¡®è®¤,å»ºè®®åˆ†2æ¬¡ä¹°å…¥'
            },
            'buy_point_3': {
                'name': 'ä¹°ç‚¹3 - ç©ºè½¬å¤šä¹°å…¥',
                'suggested_position': 'æœ€å¤š20% (å¦‚æ— å¼€ä»“é€»è¾‘å»ºè®®)',
                'buy_times': 2,  # åˆ†2æ¬¡ä¹°å…¥
                'conditions': [
                    {'id': '5åˆ†é’Ÿä¸åˆ›æ–°ä½', 'rule': 'åˆ›æ–°ä½åè¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½', 'priority': 'high'},
                    {'id': '1h RSI', 'rule': '1å°æ—¶RSI < 15', 'priority': 'high'},
                    {'id': 'è¿ç»­éœ‡è¡', 'rule': '5åˆ†é’Ÿå‘¨æœŸè¿ç»­3ä¸ªéœ‡è¡â‰¤0.5% ä¸”æ¶¨è·Œ<0.25%', 'priority': 'high'},
                    {'id': 'SARç©ºå¤´æ•°', 'rule': 'SARç©ºå¤´æŒç»­æ•°é‡ > 20', 'priority': 'high'},
                    {'id': 'SARè±¡é™', 'rule': '5åˆ†é’ŸSARåœ¨ç¬¬ä¸‰è±¡é™', 'priority': 'high'},
                    {'id': 'æ”¯æ’‘å‹åŠ›çº¿', 'rule': 'æ¥è¿‘æ”¯æ’‘1çš„å¸ç§æ•° â‰¥ 8ä¸ª æˆ– æ¥è¿‘æ”¯æ’‘2çš„å¸ç§æ•° â‰¥ 8ä¸ª', 'priority': 'high'}
                ],
                'description': 'æåº¦è¶…å–åçš„ç©ºè½¬å¤šä¹°å…¥æœºä¼š,ä¸¥æ ¼æ¡ä»¶ç­›é€‰(éœ€å¸‚åœºæ•´ä½“æ¥è¿‘æ”¯æ’‘çº¿),å»ºè®®åˆ†2æ¬¡ä¹°å…¥'
            }
        }
        
        return jsonify({
            'success': True,
            'data': {
                'signals': signals,
                'buy_point_1_count': buy_point_1_count,
                'buy_point_2_count': buy_point_2_count,
                'buy_point_3_count': buy_point_3_count,
                'total_coins': len(sr_data),
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S'),
                'buy_point_rules': buy_point_rules,  # æ–°å¢:ä¹°ç‚¹è§„åˆ™è¯´æ˜
                'opening_logic_info': {  # æ–°å¢:å¼€ä»“é€»è¾‘ä¿¡æ¯
                    'can_long': opening_can_long,
                    'position_percent': opening_position_percent,
                    'suggestion': f'{int(opening_position_percent)}%' if opening_can_long else 'ä¸å…è®¸å¼€ä»“'
                },
                'notes': {
                    'buy_point_1': 'âœ… æ”¯æ’‘çº¿ä¹°å…¥ (è·ç¦»<5%) + åˆ›æ–°ä½<3 + è®¡æ¬¡å¾—åˆ†â­/â˜… + æ€¥æ¶¨>æ€¥è·Œ + 5åˆ†é’ŸRSI<20 - å·²æ›´æ–°ä½¿ç”¨5åˆ†é’ŸRSI',
                    'buy_point_2': 'âœ… å›è°ƒä¹°å…¥ (æ¡ä»¶1-3 + ç©ºå¤´>20 + 5åˆ†é’ŸSARç¬¬ä¸‰è±¡é™ + 5åˆ†é’ŸRSI<30) - å·²é›†æˆKçº¿æŒ‡æ ‡',
                    'buy_point_3': 'âœ… ç©ºè½¬å¤šä¹°å…¥ (5ä¸ª5åˆ†é’Ÿä¸åˆ›æ–°ä½ + 1h RSI<15 + è¿ç»­3ä¸ªéœ‡è¡ + SARç©ºå¤´>20 + SARç¬¬3è±¡é™) - ä¸¥æ ¼æ¡ä»¶',
                    'buy_point_3_position': 'ğŸ“Š ä¹°ç‚¹3ä»“ä½è§„åˆ™:è‹¥å¼€ä»“é€»è¾‘å…è®¸,åˆ™ä¸º å¼€ä»“é€»è¾‘ä»“ä½+20% (ä¸Šé™70%)ï¼›è‹¥å¼€ä»“é€»è¾‘ä¸å…è®¸,åˆ™é¢å¤–å¼€20%',
                    'data_integration': 'âœ… å·²é›†æˆkline-indicatorsæ•°æ®:5åˆ†é’ŸRSIã€SARä½ç½®ã€SARè±¡é™ã€SARè®¡æ•°',
                    'data_limitation': 'âš ï¸ ä»éœ€è¡¥å……:è¿ç»­5ä¸ª5åˆ†é’ŸKçº¿ä¸åˆ›æ–°ä½ã€è¿ç»­3ä¸ªéœ‡è¡æ¡ä»¶'
                }
            }
        })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/trading-signals/buy-points')
def api_trading_signals_buy_points():
    """è·å–å½“å‰æ‰€æœ‰ä¹°ç‚¹ä¿¡å·(ç®€åŒ–ç‰ˆAPI)"""
    try:
        import sqlite3
        from datetime import datetime
        import pytz
        
        # è°ƒç”¨ç°æœ‰çš„åˆ†æå‡½æ•°
        response = api_trading_signals_analyze()
        
        # å¦‚æœè¿”å›çš„æ˜¯Responseå¯¹è±¡,è·å–å…¶JSONæ•°æ®
        if hasattr(response, 'get_json'):
            data = response.get_json()
        else:
            import json
            data = json.loads(response[0])
        
        if not data.get('success'):
            return jsonify({
                'success': False,
                'message': 'è·å–ä¹°ç‚¹æ•°æ®å¤±è´¥',
                'error': data.get('error', 'Unknown error')
            }), 500
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # æå–ä¹°ç‚¹ä¿¡å·
        signals_data = data.get('data', {})
        buy_signals = signals_data.get('signals', [])
        
        # æŒ‰ä¹°ç‚¹ç±»å‹åˆ†ç»„
        buy_point_1 = [s for s in buy_signals if s.get('buy_point') == 1]
        buy_point_2 = [s for s in buy_signals if s.get('buy_point') == 2]
        buy_point_3 = [s for s in buy_signals if s.get('buy_point') == 3]
        
        # ç®€åŒ–ä¿¡å·æ•°æ®
        def simplify_signal(signal):
            return {
                'symbol': signal.get('symbol'),
                'buy_point': signal.get('buy_point'),
                'current_price': signal.get('current_price'),
                'suggested_position': signal.get('suggested_position'),
                'buy_times': signal.get('buy_times'),
                'distance_to_support': signal.get('distance_to_support_1'),
                'conditions_met': signal.get('conditions_met'),
                'score_display': signal.get('score_display'),
                'sar_position': signal.get('sar_position'),
                'rsi_5m': signal.get('rsi_5m'),
                'rsi_1h': signal.get('rsi_1h'),
                'recommended': signal.get('recommended', False)
            }
        
        result = {
            'success': True,
            'timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'total_signals': len(buy_signals),
                'buy_point_1_count': len(buy_point_1),
                'buy_point_2_count': len(buy_point_2),
                'buy_point_3_count': len(buy_point_3)
            },
            'buy_points': {
                'buy_point_1': [simplify_signal(s) for s in buy_point_1],
                'buy_point_2': [simplify_signal(s) for s in buy_point_2],
                'buy_point_3': [simplify_signal(s) for s in buy_point_3]
            },
            'all_signals': [simplify_signal(s) for s in buy_signals],
            'rules': signals_data.get('buy_point_rules', {})
        }
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        print(f"è·å–ä¹°ç‚¹ä¿¡å·å¤±è´¥: {e}")
        traceback.print_exc()
        return jsonify({
            'success': False,
            'message': 'è·å–ä¹°ç‚¹ä¿¡å·å¤±è´¥',
            'error': str(e)
        }), 500

@app.route('/api/trading-signals/history')
def api_trading_signals_history():
    """è·å–å†å²ä¿¡å·(å·²å¤±æ•ˆçš„ä¿¡å·)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        import pytz
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # è·å–æœ€è¿‘7å¤©å†…å¤±æ•ˆçš„ä¿¡å·
        seven_days_ago = now - timedelta(days=7)
        
        cursor.execute('''
            SELECT signal_key, symbol, buy_point_type, suggested_position,
                   first_triggered_at, last_updated_at
            FROM trading_signal_history
            WHERE is_active = 0
              AND last_updated_at >= ?
            ORDER BY last_updated_at DESC
            LIMIT 50
        ''', (seven_days_ago.strftime('%Y-%m-%d %H:%M:%S'),))
        
        history_signals = []
        for row in cursor.fetchall():
            # è®¡ç®—ä¿¡å·æŒç»­æ—¶é—´
            first_time = datetime.strptime(row['first_triggered_at'], '%Y-%m-%d %H:%M:%S')
            last_time = datetime.strptime(row['last_updated_at'], '%Y-%m-%d %H:%M:%S')
            duration_minutes = int((last_time - first_time).total_seconds() / 60)
            
            buy_point_name = {
                'buy_point_1': 'ä¹°ç‚¹1',
                'buy_point_2': 'ä¹°ç‚¹2',
                'buy_point_3': 'ä¹°ç‚¹3'
            }.get(row['buy_point_type'], 'æœªçŸ¥')
            
            history_signals.append({
                'symbol': row['symbol'],
                'buy_point_type': buy_point_name,
                'suggested_position': row['suggested_position'],
                'initial_position': str(int(float(row['suggested_position'].replace('%', '')) * 0.3)) + '%',
                'first_triggered_at': row['first_triggered_at'],
                'last_updated_at': row['last_updated_at'],
                'duration_minutes': duration_minutes
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'history_signals': history_signals,
                'total_count': len(history_signals),
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S')
            }
        })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/support-resistance/latest')
def api_support_resistance_latest():
    """è·å–æœ€æ–°çš„æ”¯æ’‘å‹åŠ›çº¿æ•°æ®(ä»æŒ‰æ—¥æœŸå­˜å‚¨çš„JSONL)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from support_resistance_daily_manager import SupportResistanceDailyManager
        
        manager = SupportResistanceDailyManager()
        
        # å°è¯•è·å–ä»Šå¤©çš„æ•°æ®
        latest_levels = manager.get_latest_levels()
        
        # å¦‚æœä»Šå¤©æ²¡æœ‰æ•°æ®,å°è¯•æœ€è¿‘7å¤©çš„æ•°æ®
        if not latest_levels:
            print("âš ï¸ ä»Šå¤©æ²¡æœ‰æ•°æ®,å°è¯•æœ€è¿‘7å¤©...")
            from datetime import datetime, timedelta
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            for days_ago in range(1, 8):
                past_date = (datetime.now(beijing_tz) - timedelta(days=days_ago)).strftime('%Y%m%d')
                latest_levels = manager.get_latest_levels(date_str=past_date)
                if latest_levels:
                    print(f"âœ… ä½¿ç”¨ {days_ago} å¤©å‰çš„æ•°æ® ({past_date})")
                    break
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®,fallbackåˆ°ç›´æ¥è¯»å–JSONL
        if not latest_levels:
            print("âš ï¸ æŒ‰æ—¥æœŸæ•°æ®ä¸ºç©º,fallbackåˆ°JSONLæ–‡ä»¶")
            return api_support_resistance_latest_from_jsonl()
        
        # è·å–æœ€æ–°æ—¶é—´(ç”¨äºæ˜¾ç¤º"æœ€åæ›´æ–°")
        update_time = None
        for level in latest_levels:
            data = level.get('data', level)  # æå–dataå­—æ®µ
            time_str = data.get('record_time_beijing') or data.get('record_time')
            if time_str:
                update_time = time_str
                break
        
        # æ ¼å¼åŒ–æ•°æ®
        coins_data = []
        scenario_1_coins = []
        scenario_2_coins = []
        
        for level in latest_levels:
            # æå–dataå­—æ®µ(æ–°JSONLæ ¼å¼)
            data = level.get('data', level)  # å…¼å®¹æ–°æ—§æ ¼å¼
            
            symbol = data.get('symbol', '')
            
            # è½¬æ¢ä¸º OKX æ ¼å¼(BTCUSDT -> BTC-USDT-SWAP)
            if symbol.endswith('USDT'):
                okx_symbol = f"{symbol[:-4]}-USDT-SWAP"
            else:
                okx_symbol = symbol
            
            current_price = data.get('current_price', 0)
            support_1 = data.get('support_line_1', 0)
            support_2 = data.get('support_line_2', 0)
            resistance_1 = data.get('resistance_line_1', 0)
            resistance_2 = data.get('resistance_line_2', 0)
            position_7d = data.get('position_7d', 0)
            position_48h = data.get('position_48h', 0)
            
            # åˆ¤æ–­å‘Šè­¦åœºæ™¯
            alert_7d_low = data.get('alert_7d_low', 0) or (1 if position_7d <= 10 else 0)
            alert_7d_high = data.get('alert_7d_high', 0) or (1 if position_7d >= 90 else 0)
            alert_48h_low = data.get('alert_48h_low', 0) or (1 if position_48h <= 10 else 0)
            alert_48h_high = data.get('alert_48h_high', 0) or (1 if position_48h >= 90 else 0)
            
            coin_info = {
                'symbol': okx_symbol,
                'current_price': current_price,
                # å‰ç«¯æœŸæœ›çš„å­—æ®µå
                'support_line_1': support_1,
                'support_line_2': support_2,
                'resistance_line_1': resistance_1,
                'resistance_line_2': resistance_2,
                # å¤©æ•°å’Œå°æ—¶æ•°
                'support_1_days': data.get('support_1_days', 0),
                'support_2_hours': data.get('support_2_hours', 0),
                'resistance_1_days': data.get('resistance_1_days', 0),
                'resistance_2_hours': data.get('resistance_2_hours', 0),
                # ä½ç½®å­—æ®µ
                'position_7d': position_7d,
                'position_48h': position_48h,
                # å‘åå…¼å®¹å­—æ®µ
                'support_1': support_1,
                'support_2': support_2,
                'resistance_1': resistance_1,
                'resistance_2': resistance_2,
                'position_s2_r1': position_7d,
                'position_s1_r2': position_48h,
                'position_s1_r2_upper': position_48h,
                'position_s1_r1': position_7d,
                # å‘Šè­¦å­—æ®µ(æ—§æ ¼å¼,ç”¨äºscenarioç»Ÿè®¡)
                'alert_scenario_1': alert_7d_low,
                'alert_scenario_2': alert_7d_high,
                'alert_scenario_3': alert_48h_low,
                'alert_scenario_4': alert_48h_high,
                # å‘Šè­¦å­—æ®µ(æ–°æ ¼å¼,ç”¨äºå‰ç«¯ç»Ÿè®¡å¡ç‰‡)
                'alert_7d_low': bool(alert_7d_low),
                'alert_7d_high': bool(alert_7d_high),
                'alert_48h_low': bool(alert_48h_low),
                'alert_48h_high': bool(alert_48h_high)
            }
            
            coins_data.append(coin_info)
            
            # æ·»åŠ åˆ°åœºæ™¯åˆ—è¡¨
            if alert_7d_low:
                scenario_1_coins.append(coin_info)
            if alert_7d_high:
                scenario_2_coins.append(coin_info)
        
        # é¢„è®¡ç®—4ç§å‘Šè­¦åœºæ™¯(æœåŠ¡å™¨ç«¯å®Œæˆç­›é€‰,é¿å…å‰ç«¯è®¡ç®—)
        scenario_1_list = []  # 7dä½ç½®<=10% (ä½ä½æ”¯æ’‘)
        scenario_2_list = []  # 7dä½ç½®>=90% (é«˜ä½å‹åŠ›)
        scenario_3_list = []  # 48hä½ç½®<=10% (çŸ­æœŸæ”¯æ’‘)
        scenario_4_list = []  # 48hä½ç½®>=90% (çŸ­æœŸå‹åŠ›)
        
        for coin in coins_data:
            if coin.get('alert_scenario_1'):
                scenario_1_list.append({
                    'symbol': coin['symbol'],
                    'position': coin.get('position_s2_r1', 0)
                })
            if coin.get('alert_scenario_2'):
                scenario_2_list.append({
                    'symbol': coin['symbol'],
                    'position': coin.get('position_s1_r2', 0)
                })
            if coin.get('alert_scenario_3'):
                scenario_3_list.append({
                    'symbol': coin['symbol'],
                    'position': coin.get('position_s1_r2', 0)
                })
            if coin.get('alert_scenario_4'):
                scenario_4_list.append({
                    'symbol': coin['symbol'],
                    'position': coin.get('position_s1_r1', 0)
                })
        
        return jsonify({
            'success': True,
            'update_time': update_time or 'æœªçŸ¥',
            'coins': len(coins_data),
            'data': coins_data,
            'scenario_1_coins': len(scenario_1_coins),
            'scenario_2_coins': len(scenario_2_coins),
            'data_source': 'Daily JSONL (æŒ‰æ—¥æœŸå­˜å‚¨)',
            'timezone': 'Beijing Time (UTC+8)',
            # æ–°å¢:é¢„è®¡ç®—çš„å‘Šè­¦åœºæ™¯è¯¦æƒ…(é¿å…å‰ç«¯filterè®¡ç®—)
            'alerts_summary': {
                'scenario_1': {
                    'count': len(scenario_1_list),
                    'description': '7å¤©ä½ç½®<=10% (ä½ä½æ”¯æ’‘)',
                    'coins': scenario_1_list
                },
                'scenario_2': {
                    'count': len(scenario_2_list),
                    'description': '7å¤©ä½ç½®>=90% (é«˜ä½å‹åŠ›)',
                    'coins': scenario_2_list
                },
                'scenario_3': {
                    'count': len(scenario_3_list),
                    'description': '48å°æ—¶ä½ç½®<=10% (çŸ­æœŸæ”¯æ’‘)',
                    'coins': scenario_3_list
                },
                'scenario_4': {
                    'count': len(scenario_4_list),
                    'description': '48å°æ—¶ä½ç½®>=90% (çŸ­æœŸå‹åŠ›)',
                    'coins': scenario_4_list
                }
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/support-resistance/snapshots')
def api_support_resistance_snapshots():
    """è·å–å¿«ç…§æ•°æ®(ä» JSONL)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from support_resistance_api_adapter import SupportResistanceAPIAdapter
        
        adapter = SupportResistanceAPIAdapter()
        
        # è·å–æŸ¥è¯¢å‚æ•°
        all_data = request.args.get('all', 'false').lower() == 'true'
        date_filter = request.args.get('date', None)
        limit = int(request.args.get('limit', 100))
        
        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸ,ç›´æ¥è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰æ•°æ®
        if date_filter:
            result = adapter.get_snapshots(date=date_filter, limit=None)
        else:
            # è·å–å¿«ç…§æ•°æ®
            # all=trueæ—¶è¿”å›æ‰€æœ‰å†å²æ•°æ®(ä»2025-12-25å¼€å§‹çš„å®Œæ•´æ•°æ®,çº¦30000æ¡)
            result = adapter.get_snapshots(limit=None if all_data else limit)
        
        if not result['success']:
            return jsonify(result)
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/support-resistance/signals-computed')
def api_support_resistance_signals_computed():
    """
    è·å–å·²è®¡ç®—å¥½çš„ä¿¡å·æ•°æ®(åç«¯è®¡ç®—,å‰ç«¯ç›´æ¥å±•ç¤º)
    åŒ…å«:ä¿¡å·æ ‡è®°ç‚¹ã€24å°æ—¶ä¿¡å·åˆ—è¡¨ã€ç»Ÿè®¡æ•°æ®ç­‰
    """
    try:
        from datetime import datetime, timedelta
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from support_resistance_api_adapter import SupportResistanceAPIAdapter
        
        adapter = SupportResistanceAPIAdapter()
        
        # è·å–æ‰€æœ‰å¿«ç…§æ•°æ®
        result = adapter.get_snapshots(limit=None)
        
        if not result['success']:
            return jsonify(result)
        
        data = result['data']
        
        if not data:
            return jsonify({
                'success': False,
                'message': 'No snapshot data available'
            })
        
        # è®¡ç®—ä¿¡å·æ ‡è®°ç‚¹
        signal_mark_points = []
        buy_signals = []  # æŠ„åº•ä¿¡å·åˆ—è¡¨
        sell_signals = []  # é€ƒé¡¶ä¿¡å·åˆ—è¡¨
        
        for index, d in enumerate(data):
            scenario1 = d.get('scenario_1_count', 0) or 0
            scenario2 = d.get('scenario_2_count', 0) or 0
            scenario3 = d.get('scenario_3_count', 0) or 0
            scenario4 = d.get('scenario_4_count', 0) or 0
            
            support_total = scenario1 + scenario2
            resistance_total = scenario3 + scenario4
            snapshot_time = d.get('snapshot_time', '')
            
            # æŠ„åº•ä¿¡å·:æƒ…å†µ1 â‰¥ 8 ä¸” æƒ…å†µ2 â‰¥ 8
            if scenario1 >= 8 and scenario2 >= 8:
                signal_mark_points.append({
                    'type': 'buy',
                    'name': 'æŠ„åº•',
                    'index': index,
                    'time': snapshot_time,
                    'count': support_total,
                    'scenario1': scenario1,
                    'scenario2': scenario2,
                    'y_value': max(scenario1, scenario2)
                })
                buy_signals.append({
                    'time': snapshot_time,
                    'count': support_total,
                    'scenario1': scenario1,
                    'scenario2': scenario2
                })
            
            # é€ƒé¡¶ä¿¡å·:å‹åŠ›çº¿å¸ç§ â‰¥ 8
            if resistance_total >= 8:
                signal_mark_points.append({
                    'type': 'sell',
                    'name': 'é€ƒé¡¶',
                    'index': index,
                    'time': snapshot_time,
                    'count': resistance_total,
                    'scenario3': scenario3,
                    'scenario4': scenario4,
                    'y_value': max(scenario3, scenario4)
                })
                sell_signals.append({
                    'time': snapshot_time,
                    'count': resistance_total,
                    'scenario3': scenario3,
                    'scenario4': scenario4
                })
        
        # è®¡ç®—24å°æ—¶å†…çš„ä¿¡å·(ä½¿ç”¨åŒ—äº¬æ—¶é—´)
        import pytz
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        time_24h_ago = (now - timedelta(hours=24)).strftime('%Y-%m-%d %H:%M:%S')
        time_2h_ago = (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        buy_signals_24h = [s for s in buy_signals if s['time'] >= time_24h_ago]
        sell_signals_24h = [s for s in sell_signals if s['time'] >= time_24h_ago]
        sell_signals_2h = [s for s in sell_signals if s['time'] >= time_2h_ago]
        
        # ç»Ÿè®¡æ•°æ®
        stats = {
            'total_signals': len(signal_mark_points),
            'buy_signals_total': len(buy_signals),
            'sell_signals_total': len(sell_signals),
            'buy_signals_count': len(buy_signals),  # å‰ç«¯æœŸæœ›çš„å­—æ®µå
            'sell_signals_count': len(sell_signals),  # å‰ç«¯æœŸæœ›çš„å­—æ®µå
            'buy_signals_24h': len(buy_signals_24h),
            'sell_signals_24h': len(sell_signals_24h),
            'sell_signals_2h': len(sell_signals_2h),
            'latest_buy_signal': buy_signals[-1] if buy_signals else None,
            'latest_sell_signal': sell_signals[-1] if sell_signals else None
        }
        
        return jsonify({
            'success': True,
            'data': data,  # æ·»åŠ å®Œæ•´çš„å¿«ç…§æ•°æ®
            'signal_mark_points': signal_mark_points,
            'buy_signals_24h': buy_signals_24h,
            'sell_signals_24h': sell_signals_24h,
            'sell_signals_2h': sell_signals_2h,
            'stats': stats,
            'data_count': len(data),
            'time_range': {
                'start': data[0].get('snapshot_time') if data else None,
                'end': data[-1].get('snapshot_time') if data else None
            },
            'computed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'data_source': 'JSONL',
            'timezone': 'Beijing Time (UTC+8)'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/api/support-resistance/chart-data')
def api_support_resistance_chart_data():
    """è·å–å›¾è¡¨æ•°æ®(åç«¯è®¡ç®—å¥½çš„)"""
    try:
        from support_resistance_api_adapter import SupportResistanceAPIAdapter
        from datetime import datetime
        
        # è·å–æŸ¥è¯¢å‚æ•°
        all_data = request.args.get('all', 'false').lower() == 'true'
        date_filter = request.args.get('date', None)
        page = int(request.args.get('page', 1))
        items_per_page = int(request.args.get('items_per_page', 40))
        
        # ä»JSONLè·å–æ•°æ®
        adapter = SupportResistanceAPIAdapter()
        
        if all_data:
            # è·å–æ‰€æœ‰å†å²æ•°æ®
            result = adapter.get_snapshots(limit=None)
            data = result.get('data', []) if isinstance(result, dict) else []
            # åè½¬æ•°æ®,ä½¿æ—¶é—´ä»æ—©åˆ°æ™šæ’åˆ—
            data = list(reversed(data))
        elif date_filter:
            # æŒ‰æ—¥æœŸè¿‡æ»¤
            result = adapter.get_snapshots(limit=None)
            all_data_list = result.get('data', []) if isinstance(result, dict) else []
            data = [d for d in all_data_list if d.get('snapshot_time', '').startswith(date_filter)]
            # åè½¬æ•°æ®,ä½¿æ—¶é—´ä»æ—©åˆ°æ™šæ’åˆ—
            data = list(reversed(data))
        else:
            # è·å–æœ€è¿‘çš„æ•°æ®ç”¨äºåˆ†é¡µ
            result = adapter.get_snapshots(limit=None)
            data = result.get('data', []) if isinstance(result, dict) else []
            # åè½¬æ•°æ®,ä½¿æ—¶é—´ä»æ—©åˆ°æ™šæ’åˆ—
            data = list(reversed(data))
        
        if not data:
            return jsonify({
                'success': True,
                'chart_data': {
                    'categories': [],
                    'scenario_1': [],
                    'scenario_2': [],
                    'scenario_3': [],
                    'scenario_4': []
                },
                'signal_points': {
                    'buy_signals': [],
                    'sell_signals': []
                },
                'pagination': {
                    'current_page': 1,
                    'total_pages': 0,
                    'total_records': 0
                }
            })
        
        # åç«¯è®¡ç®—å›¾è¡¨æ•°æ®
        categories = []
        scenario_1_data = []
        scenario_2_data = []
        scenario_3_data = []
        scenario_4_data = []
        buy_signals = []
        sell_signals = []
        
        # å¦‚æœæ˜¯åˆ†é¡µæ¨¡å¼,è®¡ç®—å½“å‰é¡µçš„æ•°æ®èŒƒå›´
        start_idx = 0
        end_idx = len(data)
        if not all_data and not date_filter:
            total_pages = (len(data) + items_per_page - 1) // items_per_page
            start_idx = (page - 1) * items_per_page
            end_idx = min(start_idx + items_per_page, len(data))
            page_data = data[start_idx:end_idx]
        else:
            page_data = data
            total_pages = 1
        
        # å¤„ç†æ•°æ®
        for idx, snapshot in enumerate(page_data):
            snapshot_time = snapshot.get('snapshot_time', '')
            # æå–æ—¶é—´æ ‡ç­¾ (MM-DD HH:MM)
            if snapshot_time:
                try:
                    dt = datetime.strptime(snapshot_time, '%Y-%m-%d %H:%M:%S')
                    time_label = dt.strftime('%m-%d %H:%M')
                except:
                    time_label = snapshot_time[-14:]  # å–æœ€å14ä¸ªå­—ç¬¦
            else:
                time_label = f'Point {idx}'
            
            categories.append(time_label)
            
            # å››ç§åœºæ™¯çš„è®¡æ•°
            s1 = snapshot.get('scenario_1_count', 0)
            s2 = snapshot.get('scenario_2_count', 0)
            s3 = snapshot.get('scenario_3_count', 0)
            s4 = snapshot.get('scenario_4_count', 0)
            
            scenario_1_data.append(s1)
            scenario_2_data.append(s2)
            scenario_3_data.append(s3)
            scenario_4_data.append(s4)
            
            # ä¿¡å·æ£€æµ‹
            # æŠ„åº•ä¿¡å·:scenario_1 >= 8 ä¸” scenario_2 >= 8
            if s1 >= 8 and s2 >= 8:
                buy_signals.append({
                    'index': idx,
                    'time': snapshot_time,
                    'time_label': time_label,
                    'scenario_1': s1,
                    'scenario_2': s2,
                    'type': 'buy'
                })
            
            # é€ƒé¡¶ä¿¡å·:scenario_3 + scenario_4 >= 8
            resistance_total = s3 + s4
            if resistance_total >= 8:
                sell_signals.append({
                    'index': idx,
                    'time': snapshot_time,
                    'time_label': time_label,
                    'scenario_3': s3,
                    'scenario_4': s4,
                    'total': resistance_total,
                    'type': 'sell'
                })
        
        return jsonify({
            'success': True,
            'chart_data': {
                'categories': categories,
                'scenario_1': scenario_1_data,
                'scenario_2': scenario_2_data,
                'scenario_3': scenario_3_data,
                'scenario_4': scenario_4_data
            },
            'signal_points': {
                'buy_signals': buy_signals,
                'sell_signals': sell_signals
            },
            'pagination': {
                'current_page': page,
                'total_pages': total_pages,
                'total_records': len(data),
                'items_per_page': items_per_page,
                'start_index': start_idx if not all_data and not date_filter else 0,
                'end_index': end_idx if not all_data and not date_filter else len(data)
            },
            'stats': {
                'buy_signals_count': len(buy_signals),
                'sell_signals_count': len(sell_signals)
            },
            'data_source': 'JSONL',
            'timezone': 'Beijing Time (UTC+8)',
            'computed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/api/support-resistance/latest-signal')
def api_support_resistance_latest_signal():
    """è·å–æœ€æ–°å¿«ç…§æ•°æ®å¹¶æ£€æµ‹æ˜¯å¦è§¦å‘ä¿¡å·(ä»æŒ‰æ—¥æœŸå­˜å‚¨çš„JSONL)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from support_resistance_api_adapter import SupportResistanceAPIAdapter
        
        adapter = SupportResistanceAPIAdapter()
        
        # ä»APIé€‚é…å™¨è·å–æœ€æ–°å¿«ç…§
        result = adapter.get_snapshots(limit=1)
        
        if not result['success'] or not result['data']:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— å¿«ç…§æ•°æ®'
            })
        
        row = result['data'][0]
        
        scenario_1 = row.get('scenario_1_count', 0) or 0
        scenario_2 = row.get('scenario_2_count', 0) or 0
        scenario_3 = row.get('scenario_3_count', 0) or 0
        scenario_4 = row.get('scenario_4_count', 0) or 0
        
        # æ£€æµ‹ä¿¡å·
        # æŠ„åº•ä¿¡å·:æƒ…å†µ1 >= 8 AND æƒ…å†µ2 >= 8(ä¸¤ä¸ªæ¡ä»¶éƒ½è¦æ»¡è¶³)
        buy_signal = scenario_1 >= 8 and scenario_2 >= 8
        
        # é€ƒé¡¶ä¿¡å·:(æƒ…å†µ3 + æƒ…å†µ4) >= 8(æ€»å’Œæ»¡è¶³å³å¯)
        sell_signal = (scenario_3 + scenario_4) >= 8
        
        result_data = {
            'success': True,
            'snapshot_time': row.get('snapshot_time'),
            'snapshot_date': row.get('snapshot_date'),
            'scenario_1_count': scenario_1,
            'scenario_2_count': scenario_2,
            'scenario_3_count': scenario_3,
            'scenario_4_count': scenario_4,
            'scenario_1_coins': row.get('scenario_1_coins', []),
            'scenario_2_coins': row.get('scenario_2_coins', []),
            'scenario_3_coins': row.get('scenario_3_coins', []),
            'scenario_4_coins': row.get('scenario_4_coins', []),
            'total_coins': row.get('total_coins', 27),
            'signals': {
                'buy': buy_signal,
                'sell': sell_signal,
                'buy_count': scenario_1 + scenario_2 if buy_signal else 0,
                'sell_count': scenario_3 + scenario_4 if sell_signal else 0
            },
            'data_source': 'JSONL (æŒ‰æ—¥æœŸå­˜å‚¨)',
            'timezone': 'Beijing Time (UTC+8)'
        }
        
        return jsonify(result_data)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/support-resistance/dates')
def api_support_resistance_dates():
    """è·å–æœ‰å¿«ç…§æ•°æ®çš„æ‰€æœ‰æ—¥æœŸåˆ—è¡¨(ä»æŒ‰æ—¥æœŸå­˜å‚¨çš„JSONL)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from support_resistance_daily_manager import SupportResistanceDailyManager
        
        manager = SupportResistanceDailyManager()
        
        # è·å–æ‰€æœ‰å¯ç”¨æ—¥æœŸ
        available_dates = manager.get_available_dates()
        
        # è½¬æ¢æ ¼å¼:YYYYMMDD -> YYYY-MM-DD
        formatted_dates = []
        for date_str in reversed(available_dates):  # å€’åº,æœ€æ–°çš„åœ¨å‰
            if len(date_str) == 8:
                formatted_dates.append(f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}")
            else:
                formatted_dates.append(date_str)
        
        return jsonify({
            'success': True,
            'dates': formatted_dates,
            'count': len(formatted_dates),
            'data_source': 'JSONL (æŒ‰æ—¥æœŸå­˜å‚¨)'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/support-resistance/escape-max-stats')
def api_support_resistance_escape_max_stats():
    """è·å–é€ƒé¡¶å¿«ç…§æ•°çš„å†å²æœ€å¤§å€¼ç»Ÿè®¡(ä»æŒ‰æ—¥æœŸå­˜å‚¨çš„JSONL)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        sys.path.insert(0, '/home/user/webapp/source_code')
        from support_resistance_api_adapter import SupportResistanceAPIAdapter
        from datetime import datetime, timedelta
        
        adapter = SupportResistanceAPIAdapter()
        
        # è®¡ç®—24å°æ—¶å‰çš„æ—¶é—´
        now = datetime.now()
        time_24h_ago = now - timedelta(hours=24)
        time_2h_ago = now - timedelta(hours=2)
        
        # è·å–æœ€è¿‘2å¤©çš„æ‰€æœ‰å¿«ç…§(ç¡®ä¿è¦†ç›–24å°æ—¶)
        today = now.strftime('%Y-%m-%d')
        yesterday = (now - timedelta(days=1)).strftime('%Y-%m-%d')
        
        # è·å–ä»Šæ—¥å’Œæ˜¨æ—¥çš„å¿«ç…§
        snapshots_today = adapter.get_snapshots(date=today, limit=None)
        snapshots_yesterday = adapter.get_snapshots(date=yesterday, limit=None)
        
        all_snapshots = []
        if snapshots_today['success'] and snapshots_today['data']:
            all_snapshots.extend(snapshots_today['data'])
        if snapshots_yesterday['success'] and snapshots_yesterday['data']:
            all_snapshots.extend(snapshots_yesterday['data'])
        
        # ç­›é€‰24å°æ—¶å†…å’Œ2å°æ—¶å†…çš„å¿«ç…§
        rows_24h = []
        rows_2h = []
        
        for snapshot in all_snapshots:
            snapshot_time_str = snapshot.get('snapshot_time', '')
            if not snapshot_time_str:
                continue
                
            try:
                snapshot_time = datetime.strptime(snapshot_time_str, '%Y-%m-%d %H:%M:%S')
            except:
                continue
            
            scenario_3 = snapshot.get('scenario_3_count', 0) or 0
            scenario_4 = snapshot.get('scenario_4_count', 0) or 0
            escape_count = scenario_3 + scenario_4
            
            if snapshot_time >= time_24h_ago:
                rows_24h.append(escape_count)
                
                if snapshot_time >= time_2h_ago:
                    rows_2h.append(escape_count)
        
        # è®¡ç®—24å°æ—¶å†…çš„é€ƒé¡¶å¿«ç…§æ•°å’Œæœ€å¤§çš„é€ƒé¡¶ä¿¡å·æ•°
        escape_snapshot_count_24h = sum(1 for count in rows_24h if count >= 5)
        max_escape_count_24h = max(rows_24h, default=0)
        
        # è®¡ç®—2å°æ—¶å†…çš„é€ƒé¡¶å¿«ç…§æ•°å’Œæœ€å¤§çš„é€ƒé¡¶ä¿¡å·æ•°
        escape_snapshot_count_2h = sum(1 for count in rows_2h if count >= 5)
        max_escape_count_2h = max(rows_2h, default=0)
        
        return jsonify({
            'success': True,
            'stats_24h': {
                'escape_snapshot_count': escape_snapshot_count_24h,  # é€ƒé¡¶å¿«ç…§æ•°
                'max_escape_count': max_escape_count_24h  # æœ€å¤§çš„é€ƒé¡¶ä¿¡å·æ•°(S3+S4)
            },
            'stats_2h': {
                'escape_snapshot_count': escape_snapshot_count_2h,
                'max_escape_count': max_escape_count_2h
            },
            'data_source': 'JSONL (æŒ‰æ—¥æœŸå­˜å‚¨)',
            'timezone': 'Beijing Time (UTC+8)'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'message': str(e),
            'traceback': traceback.format_exc()
        })

# =====================================================
# æ”¯æ’‘å‹åŠ›çº¿å…¨å±€è¶‹åŠ¿ API
# =====================================================

@app.route('/api/support-resistance/trend')
def api_support_resistance_trend():
    """è·å–å…¨å±€è¶‹åŠ¿æ•°æ®(æ”¯æŒåˆ†å±‚åŠ è½½:å…¨å±€15åˆ†é’Ÿé‡‡æ ·,æ”¾å¤§å1åˆ†é’Ÿå®Œæ•´æ•°æ®)"""
    try:
        import os
        import json
        from datetime import datetime, timedelta
        
        # è·å–å‚æ•°
        days = request.args.get('days', 30, type=int)  # é»˜è®¤30å¤©
        month = request.args.get('month', None)  # å¯é€‰:æŒ‡å®šæœˆä»½ YYYYMM
        sample = request.args.get('sample', 15, type=int)  # é‡‡æ ·é—´éš”(åˆ†é’Ÿ),é»˜è®¤15åˆ†é’Ÿ
        start_time = request.args.get('start', None)  # å¯é€‰:å¼€å§‹æ—¶é—´(æ”¾å¤§æŸ¥çœ‹æ—¶ä½¿ç”¨)
        end_time = request.args.get('end', None)  # å¯é€‰:ç»“æŸæ—¶é—´(æ”¾å¤§æŸ¥çœ‹æ—¶ä½¿ç”¨)
        
        trend_dir = '/home/user/webapp/data/support_resistance_trend'
        
        if month:
            # æŒ‡å®šæœˆä»½
            trend_file = os.path.join(trend_dir, f'support_resistance_trend_{month}.jsonl')
            files_to_read = [trend_file] if os.path.exists(trend_file) else []
        else:
            # è¯»å–æœ€è¿‘Nå¤©çš„æ•°æ®(å¯èƒ½è·¨æœˆ)
            now = datetime.now()
            months_to_check = set()
            for i in range(days + 1):
                date = now - timedelta(days=i)
                months_to_check.add(date.strftime('%Y%m'))
            
            files_to_read = []
            for m in sorted(months_to_check):
                trend_file = os.path.join(trend_dir, f'support_resistance_trend_{m}.jsonl')
                if os.path.exists(trend_file):
                    files_to_read.append(trend_file)
        
        # è¯»å–æ•°æ®
        trend_data = []
        cutoff_time = datetime.now() - timedelta(days=days) if not month else None
        
        # æ—¶é—´èŒƒå›´è¿‡æ»¤(æ”¾å¤§æŸ¥çœ‹æ—¶ä½¿ç”¨)
        filter_start = datetime.fromisoformat(start_time.replace('+08:00', '')) if start_time else None
        filter_end = datetime.fromisoformat(end_time.replace('+08:00', '')) if end_time else None
        
        for file_path in files_to_read:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            point = json.loads(line)
                            
                            # æ—¶é—´è¿‡æ»¤
                            point_time = datetime.fromisoformat(point['timestamp'].replace('+08:00', ''))
                            
                            # è¿‡æ»¤å¤©æ•°èŒƒå›´
                            if cutoff_time and point_time < cutoff_time:
                                continue
                            
                            # è¿‡æ»¤æ”¾å¤§æ—¶é—´èŒƒå›´
                            if filter_start and point_time < filter_start:
                                continue
                            if filter_end and point_time > filter_end:
                                continue
                            
                            trend_data.append(point)
                        except:
                            continue
        
        # æŒ‰æ—¶é—´æ’åº
        trend_data.sort(key=lambda x: x['timestamp'])
        
        # æ•°æ®é‡‡æ ·(å…¨å±€è§†å›¾æ—¶é™é‡‡æ ·,æ”¾å¤§åè¿”å›å®Œæ•´æ•°æ®)
        sampled_data = trend_data
        actual_interval = '1 minute'
        
        if sample > 1 and not (start_time and end_time):
            # å…¨å±€è§†å›¾:è¿›è¡Œé‡‡æ ·(æ¯Nåˆ†é’Ÿå–ä¸€ä¸ªç‚¹)
            sampled_data = []
            for i, point in enumerate(trend_data):
                try:
                    point_time = datetime.fromisoformat(point['timestamp'].replace('+08:00', ''))
                    # æ¯Nåˆ†é’Ÿå–ä¸€ä¸ªç‚¹:åˆ†é’Ÿæ•°èƒ½è¢«Næ•´é™¤
                    if point_time.minute % sample == 0:
                        sampled_data.append(point)
                except:
                    continue
            actual_interval = f'{sample} minutes'
        else:
            # æ”¾å¤§è§†å›¾æˆ–sample=1:è¿”å›å®Œæ•´æ•°æ®
            actual_interval = '1 minute'
        
        return jsonify({
            'success': True,
            'data': sampled_data,
            'count': len(sampled_data),
            'total_count': len(trend_data),
            'days': days,
            'sample': sample,
            'data_source': 'JSONL Trend Data',
            'interval': actual_interval,
            'description': f'é‡‡é›†é¢‘ç‡1åˆ†é’Ÿ,è¿”å›é—´éš”{actual_interval}',
            'is_sampled': len(sampled_data) < len(trend_data),
            'zoom_range': {
                'start': start_time,
                'end': end_time
            } if (start_time and end_time) else None
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# =====================================================
# OKEx Kçº¿æŒ‡æ ‡ç³»ç»Ÿ APIè·¯ç”±
# =====================================================

@app.route('/kline-indicators')
def kline_indicators_page():
    """Kçº¿æŒ‡æ ‡ç³»ç»Ÿç›‘æ§é¡µé¢"""
    return render_template('kline_indicators.html')

@app.route('/api/kline-indicators/latest')
def api_kline_indicators_latest():
    """
    è·å–æœ€æ–°çš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    
    å‚æ•°:
        - symbol: å¸ç§(å¯é€‰,å¦‚BTC-USDT-SWAP)
        - timeframe: æ—¶é—´å‘¨æœŸ(å¯é€‰,5mæˆ–1h)
    """
    try:
        symbol = request.args.get('symbol')
        timeframe = request.args.get('timeframe')
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []
        
        if symbol:
            conditions.append('symbol = ?')
            params.append(symbol)
        if timeframe:
            conditions.append('timeframe = ?')
            params.append(timeframe)
        
        # æ„å»ºWHEREå­å¥
        if conditions:
            where_clause = f"WHERE {' AND '.join(conditions)} AND"
        else:
            where_clause = "WHERE"
        
        # è·å–æ¯ä¸ªå¸ç§+æ—¶é—´å‘¨æœŸçš„æœ€æ–°æ•°æ®
        cursor.execute(f'''
            SELECT 
                symbol, timeframe, current_price, rsi_14, 
                sar, sar_position, sar_quadrant, sar_count_label,
                bb_upper, bb_middle, bb_lower, record_time
            FROM okex_technical_indicators
            {where_clause} id IN (
                SELECT MAX(id)
                FROM okex_technical_indicators
                GROUP BY symbol, timeframe
            )
            ORDER BY symbol, timeframe
        ''', params)
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            data.append({
                'symbol': row['symbol'],
                'timeframe': row['timeframe'],
                'current_price': row['current_price'],
                'rsi_14': row['rsi_14'],
                'sar': row['sar'],
                'sar_position': row['sar_position'],
                'sar_quadrant': row['sar_quadrant'],
                'sar_count_label': row['sar_count_label'],
                'bb_upper': row['bb_upper'],
                'bb_middle': row['bb_middle'],
                'bb_lower': row['bb_lower'],
                'record_time': row['record_time']
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data),
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/kline-indicators/collector-status')
def api_kline_indicators_status():
    """è·å–é‡‡é›†å™¨è¿è¡ŒçŠ¶æ€"""
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°é‡‡é›†æ—¶é—´
        cursor.execute('''
            SELECT MAX(record_time) as last_collection
            FROM okex_technical_indicators
        ''')
        row = cursor.fetchone()
        last_collection = row['last_collection'] if row else None
        
        # ç»Ÿè®¡æ•°æ®é‡
        cursor.execute('SELECT COUNT(*) as count_indicators FROM okex_technical_indicators')
        count_indicators = cursor.fetchone()['count_indicators']
        
        # ç»Ÿè®¡ä¸åŒæ—¶é—´å‘¨æœŸçš„æ•°é‡
        cursor.execute('''
            SELECT 
                SUM(CASE WHEN timeframe = '5m' THEN 1 ELSE 0 END) as count_5m,
                SUM(CASE WHEN timeframe = '1H' THEN 1 ELSE 0 END) as count_1h
            FROM okex_technical_indicators
        ''')
        row = cursor.fetchone()
        count_5m = row['count_5m'] or 0
        count_1h = row['count_1h'] or 0
        
        conn.close()
        
        # è®¡ç®—çŠ¶æ€(æ•°æ®åº“å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´)
        if last_collection:
            # æ•°æ®åº“ä¸­çš„æ—¶é—´æ˜¯åŒ—äº¬æ—¶é—´,éœ€è¦ä¸åŒ—äº¬æ—¶é—´æ¯”è¾ƒ
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            last_time = datetime.strptime(last_collection, '%Y-%m-%d %H:%M:%S')
            now_beijing = datetime.now(beijing_tz).replace(tzinfo=None)
            delta_minutes = (now_beijing - last_time).total_seconds() / 60
            status = 'running' if delta_minutes < 10 else 'stopped'
        else:
            status = 'not_started'
            delta_minutes = None
        
        return jsonify({
            'success': True,
            'status': status,
            'last_collection_time': last_collection,
            'minutes_since_last': round(delta_minutes, 1) if delta_minutes else None,
            'data_counts': {
                'kline_5m': count_5m,
                'kline_1h': count_1h,
                'indicators': count_indicators
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def cleanup_expired_signals():
    """
    æ¸…ç†2å°æ—¶ä¹‹å‰çš„è¿‡æœŸä¿¡å·
    å°† is_valid è®¾ç½®ä¸º 0
    """
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=5.0)
        cursor = conn.cursor()
        
        from datetime import datetime, timedelta
        cutoff_time = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # æ¸…ç†ä¹°ç‚¹4è¿‡æœŸä¿¡å·
        cursor.execute('''
            UPDATE buy_point_4_signals
            SET is_valid = 0
            WHERE is_valid = 1 AND confirm_time < ?
        ''', (cutoff_time,))
        buy_point_4_cleaned = cursor.rowcount
        
        # æ¸…ç†å–ç‚¹1è¿‡æœŸä¿¡å·
        cursor.execute('''
            UPDATE sell_point_1_signals
            SET is_valid = 0
            WHERE is_valid = 1 AND mark_time < ?
        ''', (cutoff_time,))
        sell_point_1_cleaned = cursor.rowcount
        
        conn.commit()
        conn.close()
        
        return {
            'buy_point_4_cleaned': buy_point_4_cleaned,
            'sell_point_1_cleaned': sell_point_1_cleaned
        }
    except Exception as e:
        return {'error': str(e)}

@app.route('/api/kline-indicators/signals')
def api_kline_indicators_signals():
    """
    è¿”å›Kçº¿æŒ‡æ ‡ä¿¡å·(2å°æ—¶æ—¶é—´çª—å£)
    æ•°æ®å®Œå…¨ä»æ•°æ®åº“è¯»å–,ä¸è¿›è¡Œå®æ—¶æ£€æµ‹
    - ä¹°ç‚¹4: ä» buy_point_4_signals è¡¨è¯»å–(RSI < 20)
    - å–ç‚¹1: ä» sell_point_1_signals è¡¨è¯»å–(RSI >= 60)
    """
    try:
        conn = sqlite3.connect('crypto_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        from datetime import datetime, timedelta
        now = datetime.now()
        cutoff_time = (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # åˆå§‹åŒ–ä¿¡å·å®¹å™¨
        signals = {
            'buy_point_4': [],      # ä¹°ç‚¹4(ä»æ•°æ®åº“è¯»å–)
            'sell_point_1': []      # å–ç‚¹1(ä»æ•°æ®åº“è¯»å–)
        }
        
        # 1. è¯»å–ä¹°ç‚¹4ä¿¡å·(ä¸æŸ¥è¯¢å½“å‰ä»·æ ¼,ä½¿ç”¨ä¿¡å·æ—¶çš„ä»·æ ¼)
        cursor.execute('''
            SELECT symbol, low_price, low_time, confirm_time, 
                   signal_generated_at, confirm_rsi
            FROM buy_point_4_signals
            WHERE is_valid = 1 
              AND confirm_rsi IS NOT NULL 
              AND confirm_rsi < 20
              AND confirm_time >= ?
            ORDER BY confirm_time DESC
            LIMIT 100
        ''', (cutoff_time,))
        
        for row in cursor.fetchall():
            signals['buy_point_4'].append({
                'symbol': row[0],
                'price': row[1],
                'low_7d': row[1],
                'low_time': row[2],
                'confirm_time': row[3],
                'signal_generated_at': row[4],
                'confirm_rsi': row[5],
                'current_price': row[1],  # ä½¿ç”¨ç¡®è®¤æ—¶çš„ä»·æ ¼
                'distance': 0.0  # ä¿¡å·æ—¶åˆ»è·ç¦»ä¸º0
            })
        
        # 2. è¯»å–å–ç‚¹1ä¿¡å·(ä¸æŸ¥è¯¢å½“å‰ä»·æ ¼)
        cursor.execute('''
            SELECT symbol, high_price, high_time, mark_price, 
                   mark_time, mark_rsi, signal_generated_at
            FROM sell_point_1_signals
            WHERE is_valid = 1 
              AND mark_rsi IS NOT NULL 
              AND mark_rsi >= 60
              AND mark_time >= ?
            ORDER BY mark_time DESC
            LIMIT 100
        ''', (cutoff_time,))
        
        for row in cursor.fetchall():
            signals['sell_point_1'].append({
                'symbol': row[0],
                'high_price': row[1],
                'high_time': row[2],
                'mark_price': row[3],
                'mark_time': row[4],
                'mark_rsi': row[5],
                'signal_generated_at': row[6],
                'current_price': row[3],  # ä½¿ç”¨æ ‡è®°æ—¶çš„ä»·æ ¼
                'distance': 0.0  # ä¿¡å·æ—¶åˆ»è·ç¦»ä¸º0
            })
        
        conn.close()
        
        # ç»Ÿè®¡ä¿¡å·æ•°é‡
        signal_counts = {k: len(v) for k, v in signals.items()}
        
        # å¼‚æ­¥æ¸…ç†è¿‡æœŸä¿¡å·(ä¸é˜»å¡å“åº”)
        import threading
        threading.Thread(target=cleanup_expired_signals, daemon=True).start()
        
        return jsonify({
            'success': True,
            'data': {
                'signals': signals,
                'counts': signal_counts,
                'update_time': now.strftime('%Y-%m-%d %H:%M:%S')
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/kline-indicators-tv/latest')
def api_kline_indicators_tv_latest():
    """
    è·å–TradingViewç›´æ¥è·å–çš„Kçº¿æŒ‡æ ‡æ•°æ®(ä¸è®¡ç®—)
    æ”¯æŒå‚æ•°: symbol, timeframe
    æ•°æ®æº: TradingView (OKXäº¤æ˜“æ‰€)
    """
    try:
        symbol = request.args.get('symbol')
        timeframe = request.args.get('timeframe')
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []
        
        if symbol:
            conditions.append('symbol = ?')
            params.append(symbol)
        if timeframe:
            conditions.append('timeframe = ?')
            params.append(timeframe)
        
        # æ„å»ºWHEREå­å¥
        if conditions:
            where_clause = f"WHERE {' AND '.join(conditions)}"
        else:
            where_clause = ""
        
        # è·å–æ¯ä¸ªå¸ç§+æ—¶é—´å‘¨æœŸçš„æœ€æ–°æ•°æ®
        query = f'''
            SELECT 
                symbol, timeframe, current_price, rsi_14, 
                sar, bb_upper, bb_middle, bb_lower,
                ema_10, ema_20, recommendation,
                buy_signals, sell_signals, neutral_signals,
                record_time
            FROM okex_tv_indicators
            {where_clause}
            ORDER BY symbol, timeframe
        '''
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            # Calculate SAR position
            sar_position = None
            if row['sar'] and row['current_price']:
                sar_position = 'bullish' if row['current_price'] > row['sar'] else 'bearish'
            
            # Calculate BB middle if not provided
            bb_middle = row['bb_middle']
            if not bb_middle and row['bb_upper'] and row['bb_lower']:
                bb_middle = (row['bb_upper'] + row['bb_lower']) / 2
            
            data.append({
                'symbol': row['symbol'],
                'timeframe': row['timeframe'],
                'current_price': row['current_price'],
                'rsi_14': row['rsi_14'],
                'sar': row['sar'],
                'sar_position': sar_position,
                'bb_upper': row['bb_upper'],
                'bb_middle': bb_middle,
                'bb_lower': row['bb_lower'],
                'ema_10': row['ema_10'],
                'ema_20': row['ema_20'],
                'recommendation': row['recommendation'],
                'buy_signals': row['buy_signals'],
                'sell_signals': row['sell_signals'],
                'neutral_signals': row['neutral_signals'],
                'record_time': row['record_time'],
                'data_source': 'TradingView (ç›´æ¥è·å–, ä¸è®¡ç®—)'
            })
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data),
            'data_source': 'TradingView API (OKX Exchange)',
            'note': 'æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å‡ç›´æ¥ä»TradingViewè·å–,ä¸è¿›è¡Œæœ¬åœ°è®¡ç®—',
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/kline-indicators-tv/collector-status')
def api_kline_indicators_tv_status():
    """è·å–TradingViewæŒ‡æ ‡é‡‡é›†å™¨è¿è¡ŒçŠ¶æ€"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute('''
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='okex_tv_collector_status'
        ''')
        
        if not cursor.fetchone():
            conn.close()
            return jsonify({
                'success': True,
                'status': 'not_initialized',
                'message': 'TradingView collector not initialized yet'
            })
        
        # è·å–é‡‡é›†çŠ¶æ€
        cursor.execute('''
            SELECT last_collect_time, total_indicators_count, status
            FROM okex_tv_collector_status
            WHERE id = 1
        ''')
        
        row = cursor.fetchone()
        
        # ç»Ÿè®¡æ•°æ®é‡
        cursor.execute('SELECT COUNT(*) FROM okex_tv_indicators')
        count_indicators = cursor.fetchone()[0]
        
        conn.close()
        
        status = row['status'] if row else 'stopped'
        last_collection = row['last_collect_time'] if row else None
        
        return jsonify({
            'success': True,
            'status': status,
            'last_collection_time': last_collection,
            'total_indicators': count_indicators,
            'data_source': 'TradingView (ç›´æ¥è·å–)',
            'note': 'RSI, SAR, å¸ƒæ—å¸¦å‡ç›´æ¥ä»TradingViewè·å–,ä¸è®¡ç®—'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== å¸ç§è¯¦æƒ…é¡µé¢ ====================

@app.route('/symbol/<symbol>')
def symbol_detail(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ - è‡ªåŠ¨é‡å®šå‘åˆ°v6ä»¥é¿å¼€æµè§ˆå™¨ç¼“å­˜"""
    from flask import redirect, url_for
    return redirect(url_for('symbol_detail_v6', symbol=symbol), code=302)

@app.route('/api/symbol/<symbol>/kline')
def api_symbol_kline(symbol):
    """è·å–å¸ç§Kçº¿æ•°æ®(10å¤©)- ä½¿ç”¨okex_technical_indicatorsè¡¨"""
    try:
        timeframe = request.args.get('timeframe', '5m')  # 5m æˆ– 1H
        
        # å°†symbolè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        if not symbol.endswith('-USDT-SWAP'):
            symbol = f"{symbol}-USDT-SWAP"
        
        # è½¬æ¢timeframeæ ¼å¼: 5m -> 5m, 1h -> 1H (æ•°æ®åº“ä¸­ä½¿ç”¨å¤§å†™H)
        db_timeframe = timeframe.upper() if timeframe == '1h' else timeframe
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ ¹æ®æ—¶é—´å‘¨æœŸè®¾ç½®limit
        if timeframe == '5m':
            # 10å¤©çš„5åˆ†é’ŸKçº¿ = 10 * 24 * 12 = 2880æ ¹
            limit = 2880
        else:  # 1h
            # 10å¤©çš„1å°æ—¶Kçº¿ = 10 * 24 = 240æ ¹
            limit = 240
        
        # ä»okex_kline_ohlcè¡¨è·å–çœŸå®çš„OHLC Kçº¿æ•°æ®
        # å…ˆæŒ‰æ—¶é—´é™åºå–æœ€æ–°çš„Næ¡,ç„¶ååè½¬ä¸ºå‡åº
        cursor.execute('''
            SELECT timestamp, open, high, low, close, volume
            FROM (
                SELECT timestamp, open, high, low, close, volume
                FROM okex_kline_ohlc
                WHERE symbol = ? AND timeframe = ?
                ORDER BY timestamp DESC
                LIMIT ?
            )
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe, limit))
        
        rows = cursor.fetchall()
        
        # å¦‚æœOHLCè¡¨æ²¡æœ‰æ•°æ®,å›é€€åˆ°indicators_historyè¡¨
        if not rows:
            cursor.execute('''
                SELECT timestamp, current_price
                FROM (
                    SELECT timestamp, current_price
                    FROM okex_indicators_history
                    WHERE symbol = ? AND timeframe = ?
                    ORDER BY timestamp DESC
                    LIMIT ?
                )
                ORDER BY timestamp ASC
            ''', (symbol, db_timeframe, limit))
            
            rows_indicators = cursor.fetchall()
            kline_data = []
            
            for i, row in enumerate(rows_indicators):
                timestamp = int(row[0]) if row[0] else 0
                close_price = float(row[1]) if row[1] else 0
                
                # æ¨¡æ‹ŸOHLC
                open_price = close_price * (1 + 0.001 * (i % 3 - 1))
                high_price = close_price * 1.002
                low_price = close_price * 0.998
                volume = close_price * 10
                
                kline_data.append({
                    'timestamp': timestamp,
                    'data': [open_price, high_price, low_price, close_price],  # æ ‡å‡†Kçº¿æ ¼å¼: OHLC
                    'volume': volume
                })
        else:
            # ä½¿ç”¨çœŸå®OHLCæ•°æ®
            kline_data = []
            for row in rows:
                timestamp = int(row[0]) if row[0] else 0
                open_price = float(row[1]) if row[1] else 0
                high_price = float(row[2]) if row[2] else 0
                low_price = float(row[3]) if row[3] else 0
                close_price = float(row[4]) if row[4] else 0
                volume = float(row[5]) if row[5] else 0
                
                kline_data.append({
                    'timestamp': timestamp,
                    'data': [open_price, high_price, low_price, close_price],  # æ ‡å‡†Kçº¿æ ¼å¼: OHLC
                    'volume': volume
                })
        
        # æŸ¥è¯¢æŠ€æœ¯æ ‡è®°æ•°æ®(çª„å¹…éœ‡è¡ã€é«˜ä½ç‚¹ã€SARã€RSIã€å¸ƒæ—å¸¦ç­‰)
        cursor.execute('''
            SELECT timestamp, is_narrow_range, change_percent, range_percent, consecutive_count,
                   is_7d_high, is_7d_low, is_48h_high, is_48h_low,
                   rsi_14, sar, sar_position, sar_quadrant, sar_count_label,
                   bb_upper, bb_middle, bb_lower, is_buy_point_4
            FROM kline_technical_markers
            WHERE symbol = ? AND timeframe = ?
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe))
        
        marker_rows = cursor.fetchall()
        markers_dict = {}
        for marker_row in marker_rows:
            ts = int(marker_row[0]) if marker_row[0] else 0
            markers_dict[ts] = {
                'is_narrow_range': bool(marker_row[1]),
                'change_percent': float(marker_row[2]) if marker_row[2] else 0,
                'range_percent': float(marker_row[3]) if marker_row[3] else 0,
                'consecutive_count': int(marker_row[4]) if marker_row[4] else 0,
                'is_7d_high': bool(marker_row[5]),
                'is_7d_low': bool(marker_row[6]),
                'is_48h_high': bool(marker_row[7]),
                'is_48h_low': bool(marker_row[8]),
                'rsi_14': float(marker_row[9]) if marker_row[9] else None,
                'sar': float(marker_row[10]) if marker_row[10] else None,
                'sar_position': marker_row[11],
                'sar_quadrant': int(marker_row[12]) if marker_row[12] else None,
                'sar_count_label': marker_row[13],
                'bb_upper': float(marker_row[14]) if marker_row[14] else None,
                'bb_middle': float(marker_row[15]) if marker_row[15] else None,
                'bb_lower': float(marker_row[16]) if marker_row[16] else None,
                'is_buy_point_4': bool(marker_row[17])
            }
        
        # å°†æ ‡è®°æ•°æ®åˆå¹¶åˆ°Kçº¿æ•°æ®ä¸­
        for item in kline_data:
            ts = item['timestamp']
            if ts in markers_dict:
                item['markers'] = markers_dict[ts]
        
        conn.close()
        
        # åˆ›å»ºå“åº”å¯¹è±¡å¹¶æ·»åŠ ç¼“å­˜å¤´
        response = jsonify({
            'success': True,
            'symbol': symbol,
            'timeframe': timeframe,
            'data': kline_data,
            'count': len(kline_data)
        })
        
        # æ·»åŠ HTTPç¼“å­˜å¤´(ç¼“å­˜60ç§’,å› ä¸ºæ•°æ®æ¯60ç§’æ›´æ–°ä¸€æ¬¡)
        response.headers['Cache-Control'] = 'public, max-age=60'
        response.headers['Vary'] = 'Accept-Encoding'
        
        return response
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/symbol/<symbol>/indicators')
def api_symbol_indicators(symbol):
    """è·å–å¸ç§æŠ€æœ¯æŒ‡æ ‡æ•°æ® - ä½¿ç”¨okex_technical_indicatorsè¡¨"""
    try:
        timeframe = request.args.get('timeframe', '5m')
        
        # å°†symbolè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        if not symbol.endswith('-USDT-SWAP'):
            symbol = f"{symbol}-USDT-SWAP"
        
        # è½¬æ¢timeframeæ ¼å¼: 5m -> 5m, 1h -> 1H
        db_timeframe = timeframe.upper() if timeframe == '1h' else timeframe
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è®¾ç½®limit
        limit = 2880 if timeframe == '5m' else 240
        
        # ä»okex_indicators_historyè¡¨è·å–å†å²æŒ‡æ ‡æ•°æ®
        cursor.execute('''
            SELECT created_at, current_price, rsi_14, sar, sar_position, sar_count_label,
                   bb_upper, bb_middle, bb_lower, timestamp
            FROM okex_indicators_history
            WHERE symbol = ? AND timeframe = ?
            ORDER BY timestamp ASC
            LIMIT ?
        ''', (symbol, db_timeframe, limit))
        
        rows = cursor.fetchall()
        
        indicators = []
        for row in rows:
            # ä½¿ç”¨æ•°æ®åº“ä¸­çš„timestampå­—æ®µ(æ¯«ç§’)
            timestamp = int(row[9]) if row[9] else 0
            
            indicators.append({
                'timestamp': timestamp,
                'price': float(row[1]) if row[1] else None,
                'rsi': float(row[2]) if row[2] else None,
                'sar': float(row[3]) if row[3] else None,
                'sar_position': row[4],
                'sar_label': row[5],
                'bb_upper': float(row[6]) if row[6] else None,
                'bb_middle': float(row[7]) if row[7] else None,
                'bb_lower': float(row[8]) if row[8] else None,
                'time_str': row[0]  # ä¿ç•™æ—¶é—´å­—ç¬¦ä¸²ç”¨äºè°ƒè¯•
            })
        
        conn.close()
        
        # åˆ›å»ºå“åº”å¯¹è±¡å¹¶æ·»åŠ ç¼“å­˜å¤´
        response = jsonify({
            'success': True,
            'symbol': symbol,
            'timeframe': timeframe,
            'data': indicators,
            'count': len(indicators)
        })
        
        # æ·»åŠ HTTPç¼“å­˜å¤´(ç¼“å­˜60ç§’,å› ä¸ºæ•°æ®æ¯60ç§’æ›´æ–°ä¸€æ¬¡)
        response.headers['Cache-Control'] = 'public, max-age=60'
        response.headers['Vary'] = 'Accept-Encoding'
        
        return response
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/signals/recent')
def api_signals_recent():
    """è·å–æœ€è¿‘2å°æ—¶å†…çš„äº¤æ˜“ä¿¡å·,æŒ‰ç±»å‹åˆ†ç±»"""
    try:
        from datetime import datetime, timedelta
        import json
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è®¡ç®—2å°æ—¶å‰çš„æ—¶é—´
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # è·å–2å°æ—¶å†…çš„ä¿¡å·
        cursor.execute('''
            SELECT record_time, long_signals, short_signals, 
                   today_new_high, today_new_low, raw_data
            FROM trading_signals
            WHERE record_time >= ?
            ORDER BY record_time DESC
        ''', (two_hours_ago,))
        
        rows = cursor.fetchall()
        conn.close()
        
        # åˆ†ç±»ç»Ÿè®¡
        signals_by_type = {
            'long': [],  # åšå¤šä¿¡å·
            'short': [],  # åšç©ºä¿¡å·
            'new_high': [],  # æ–°é«˜ä¿¡å·
            'new_low': []  # æ–°ä½ä¿¡å·
        }
        
        for row in rows:
            record_time = row[0]
            long_count = row[1] or 0
            short_count = row[2] or 0
            new_high = row[3] or 0
            new_low = row[4] or 0
            raw_data = json.loads(row[5]) if row[5] else {}
            
            if long_count > 0:
                signals_by_type['long'].append({
                    'time': record_time,
                    'count': long_count,
                    'detail': raw_data.get('breakdown', {})
                })
            
            if short_count > 0:
                signals_by_type['short'].append({
                    'time': record_time,
                    'count': short_count,
                    'detail': raw_data.get('breakdown', {})
                })
            
            if new_high > 0:
                signals_by_type['new_high'].append({
                    'time': record_time,
                    'count': new_high
                })
            
            if new_low > 0:
                signals_by_type['new_low'].append({
                    'time': record_time,
                    'count': new_low
                })
        
        # è®¡ç®—æ±‡æ€»
        summary = {
            'long_total': sum(s['count'] for s in signals_by_type['long']),
            'short_total': sum(s['count'] for s in signals_by_type['short']),
            'new_high_total': sum(s['count'] for s in signals_by_type['new_high']),
            'new_low_total': sum(s['count'] for s in signals_by_type['new_low']),
            'time_range': two_hours_ago
        }
        
        return jsonify({
            'success': True,
            'signals': signals_by_type,
            'summary': summary
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/symbol/<symbol>/extremes')
def api_symbol_extremes(symbol):
    """è·å–å¸ç§çš„48å°æ—¶å’Œ7å¤©é«˜ä½ç‚¹"""
    try:
        from datetime import datetime, timedelta
        
        timeframe = request.args.get('timeframe', '5m')
        
        # å°†symbolè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        if not symbol.endswith('-USDT-SWAP'):
            symbol = f"{symbol}-USDT-SWAP"
        
        # è½¬æ¢timeframeæ ¼å¼
        db_timeframe = timeframe.upper() if timeframe == '1h' else timeframe
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è®¡ç®—æ—¶é—´èŒƒå›´(æ¯«ç§’æ—¶é—´æˆ³)
        now_ms = int(datetime.now().timestamp() * 1000)
        hours_48_ago_ms = int((datetime.now() - timedelta(hours=48)).timestamp() * 1000)
        days_7_ago_ms = int((datetime.now() - timedelta(days=7)).timestamp() * 1000)
        
        # è·å–48å°æ—¶å†…çš„é«˜ä½ç‚¹
        cursor.execute('''
            SELECT timestamp, open, high, low, close
            FROM okex_kline_ohlc
            WHERE symbol = ? AND timeframe = ? AND timestamp >= ?
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe, hours_48_ago_ms))
        
        rows_48h = cursor.fetchall()
        
        # è·å–7å¤©å†…çš„é«˜ä½ç‚¹
        cursor.execute('''
            SELECT timestamp, open, high, low, close
            FROM okex_kline_ohlc
            WHERE symbol = ? AND timeframe = ? AND timestamp >= ?
            ORDER BY timestamp ASC
        ''', (symbol, db_timeframe, days_7_ago_ms))
        
        rows_7d = cursor.fetchall()
        conn.close()
        
        # è®¡ç®—48å°æ—¶é«˜ä½ç‚¹
        extremes_48h = {'high': None, 'low': None, 'high_time': None, 'low_time': None}
        if rows_48h:
            max_price = max(row[2] for row in rows_48h)  # high
            min_price = min(row[3] for row in rows_48h)  # low
            
            for row in rows_48h:
                if row[2] == max_price:
                    extremes_48h['high'] = max_price
                    extremes_48h['high_time'] = row[0]
                if row[3] == min_price:
                    extremes_48h['low'] = min_price
                    extremes_48h['low_time'] = row[0]
        
        # è®¡ç®—7å¤©é«˜ä½ç‚¹
        extremes_7d = {'high': None, 'low': None, 'high_time': None, 'low_time': None}
        if rows_7d:
            max_price = max(row[2] for row in rows_7d)  # high
            min_price = min(row[3] for row in rows_7d)  # low
            
            for row in rows_7d:
                if row[2] == max_price:
                    extremes_7d['high'] = max_price
                    extremes_7d['high_time'] = row[0]
                if row[3] == min_price:
                    extremes_7d['low'] = min_price
                    extremes_7d['low_time'] = row[0]
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'timeframe': timeframe,
            'extremes_48h': extremes_48h,
            'extremes_7d': extremes_7d
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ==================== æ–°ç‰ˆæœ¬è·¯ç”± - å¼ºåˆ¶åˆ·æ–° ====================

@app.route('/symbol/<symbol>/v6')
def symbol_detail_v6(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ v6.0 - å…¨æ–°è·¯ç”±é¿å¼€ç¼“å­˜"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('symbol_detail_v6.html', symbol=symbol, cache_buster=cache_buster))
    
    # ç¦ç”¨HTMLé¡µé¢ç¼“å­˜,ç¡®ä¿æ¯æ¬¡éƒ½åŠ è½½æœ€æ–°ä»£ç 
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

@app.route('/symbol/<symbol>/v7')
def symbol_detail_v7(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ v7.0 - å…¨æ–°è·¯ç”±é¿å¼€ç¼“å­˜,ç®€åŒ–è°ƒè¯•"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('symbol_detail_v7.html', symbol=symbol, cache_buster=cache_buster))
    
    # ç¦ç”¨HTMLé¡µé¢ç¼“å­˜,ç¡®ä¿æ¯æ¬¡éƒ½åŠ è½½æœ€æ–°ä»£ç 
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

@app.route('/symbol/<symbol>/v8')
def symbol_detail_v8(symbol):
    """å¸ç§è¯¦æƒ…é¡µé¢ v8.0 - å½»åº•é¿å¼€æ‰€æœ‰æµè§ˆå™¨ç¼“å­˜"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('symbol_detail_v8.html', symbol=symbol, cache_buster=cache_buster))
    
    # æœ€å¼ºç¼“å­˜ç¦ç”¨ç­–ç•¥
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    response.headers['X-Content-Type-Options'] = 'nosniff'
    
    return response

@app.route('/kline/<symbol>')
def kline_chart(symbol):
    """å…¨æ–°çš„Kçº¿å›¾è·¯ç”± - å®Œå…¨ç‹¬ç«‹çš„åœ°å€"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('kline_chart.html', symbol=symbol, cache_buster=cache_buster))
    
    # å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    response.headers['X-Content-Type-Options'] = 'nosniff'
    
    return response

@app.route('/test-xlm-data')
def test_xlm_data():
    """XLMæ•°æ®è¯Šæ–­æµ‹è¯•é¡µ"""
    return render_template('test_xlm_data.html')

@app.route('/chart/<symbol>')
def chart_new(symbol):
    """å…¨æ–°Kçº¿å›¾ - ä»é›¶å¼€å§‹,ç®€å•æ¸…æ™°"""
    from datetime import datetime
    from flask import make_response
    
    cache_buster = datetime.now().strftime('%Y%m%d%H%M%S')
    response = make_response(render_template('chart_new.html', symbol=symbol, cache_buster=cache_buster))
    
    # å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    
    return response

# ==================== Google Drive ç›‘æ§çŠ¶æ€ API ====================

@app.route('/gdrive-monitor-status')
def gdrive_monitor_status_page():
    """Google Drive ç›‘æ§çŠ¶æ€é¡µé¢ - 11åˆ†é’Ÿè¶…æ—¶ä¿é™©æœºåˆ¶å¯è§†åŒ–"""
    return render_template('gdrive_monitor_status.html')

@app.route('/api/gdrive-monitor/status')
def api_gdrive_monitor_status():
    """è·å– Google Drive ç›‘æ§çŠ¶æ€çš„å®æ—¶æ•°æ®"""
    import os
    import json
    from datetime import datetime
    import pytz
    import re
    import requests
    from bs4 import BeautifulSoup
    
    try:
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        config = {}
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        # ğŸ†• æ‰«æ Google Drive ä¸­çš„å®é™…æ–‡ä»¶
        gdrive_dates = {}
        gdrive_scan_error = None
        try:
            ROOT_FOLDER_ID = "1jFGGlGP5KEVhAxpCNxFIYEFI5-cDOBjM"
            url = f"https://drive.google.com/embeddedfolderview?id={ROOT_FOLDER_ID}"
            response = requests.get(url, timeout=5)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            all_links = soup.find_all('a', href=True)
            pattern = re.compile(r'(\d{4}-\d{2}-\d{2})_(\d{4})\.txt')
            
            for link in all_links:
                text = link.get_text(strip=True)
                match = pattern.match(text)
                if match:
                    date = match.group(1)
                    if date not in gdrive_dates:
                        gdrive_dates[date] = 0
                    gdrive_dates[date] += 1
        except Exception as e:
            gdrive_scan_error = str(e)
        
        # è¯»å–æ—¥å¿—æ–‡ä»¶è·å–æœ€æ–°çŠ¶æ€
        log_file = '/home/user/webapp/gdrive_final_detector.log'
        latest_file = None
        latest_file_time = None
        check_count = 0
        last_file_found_time = None
        recovery_count = 0
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
                # åˆ†ææ—¥å¿—
                for line in reversed(lines[-500:]):  # åªçœ‹æœ€è¿‘500è¡Œ
                    # æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
                    if 'æœ€æ–°æ–‡ä»¶å =' in line and not latest_file:
                        match = re.search(r'æœ€æ–°æ–‡ä»¶å = (.+\.txt)', line)
                        if match:
                            latest_file = match.group(1)
                            # æå–æ—¶é—´æˆ³
                            time_match = re.search(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                            if time_match:
                                latest_file_time = time_match.group(1)
                    
                    # æŸ¥æ‰¾æ£€æŸ¥æ¬¡æ•°
                    if 'æ£€æŸ¥ #' in line:
                        match = re.search(r'æ£€æŸ¥ #(\d+)', line)
                        if match:
                            check_count = max(check_count, int(match.group(1)))
                    
                    # æŸ¥æ‰¾æ¢å¤è§¦å‘
                    if 'è§¦å‘11åˆ†é’Ÿè¶…æ—¶æ¢å¤æœºåˆ¶' in line:
                        recovery_count += 1
                    
                    # æŸ¥æ‰¾æœ€åæ‰¾åˆ°æ–‡ä»¶çš„æ—¶é—´
                    if 'æ‰¾åˆ°' in line and 'TXTæ–‡ä»¶' in line and not last_file_found_time:
                        match = re.search(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', line)
                        if match:
                            last_file_found_time = match.group(1)
        
        # è®¡ç®—è·ä¸Šæ¬¡æ‰¾åˆ°æ–‡ä»¶çš„æ—¶é—´
        time_since_last_file = 0
        if last_file_found_time:
            try:
                last_time = datetime.strptime(last_file_found_time, '%Y-%m-%d %H:%M:%S')
                last_time = beijing_tz.localize(last_time)
                time_since_last_file = (now - last_time).total_seconds()
            except:
                pass
        
        # è·å–æ•°æ®åº“è®°å½•æ•°
        db_records = 0
        try:
            import sqlite3
            conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM crypto_snapshots WHERE snapshot_date = ?", (now.strftime('%Y-%m-%d'),))
            db_records = cursor.fetchone()[0]
            conn.close()
        except:
            pass
        
        # è®¡ç®—ç³»ç»Ÿè¿è¡Œæ—¶é•¿ (ä»æœ€æ—©çš„æ—¥å¿—æ—¶é—´æˆ³å¼€å§‹)
        uptime_seconds = 0
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                first_line = f.readline()
                match = re.search(r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]', first_line)
                if match:
                    start_time = datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S')
                    start_time = beijing_tz.localize(start_time)
                    uptime_seconds = (now - start_time).total_seconds()
        
        # ğŸ†• åˆ¤æ–­æ•°æ®æºçŠ¶æ€
        today_str = now.strftime('%Y-%m-%d')
        data_source_status = 'unknown'
        data_source_message = ''
        
        if gdrive_dates:
            latest_gdrive_date = max(gdrive_dates.keys())
            if latest_gdrive_date == today_str:
                data_source_status = 'active'
                data_source_message = f'âœ… æ•°æ®æºæ­£å¸¸,ä»Šå¤©æœ‰ {gdrive_dates[today_str]} ä¸ªæ–‡ä»¶'
            else:
                days_old = (datetime.strptime(today_str, '%Y-%m-%d') - datetime.strptime(latest_gdrive_date, '%Y-%m-%d')).days
                data_source_status = 'stale'
                data_source_message = f'âš ï¸  æ•°æ®æºå·²åœæ›´ {days_old} å¤©,æœ€æ–°æ•°æ®:{latest_gdrive_date}'
        elif gdrive_scan_error:
            data_source_status = 'error'
            data_source_message = f'âŒ æ— æ³•è®¿é—® Google Drive: {gdrive_scan_error}'
        else:
            data_source_status = 'empty'
            data_source_message = 'âŒ Google Drive ä¸­æ²¡æœ‰ä»»ä½•æ•°æ®æ–‡ä»¶'
        
        return jsonify({
            'success': True,
            'time_since_last_file': time_since_last_file,
            'current_folder_id': config.get('folder_id', 'N/A'),
            'folder_date': config.get('current_date', '--'),
            'latest_file': latest_file or '--',
            'file_time': latest_file_time or '--',
            'gdrive_dates': gdrive_dates,  # ğŸ†• Google Drive ä¸­çš„æ—¥æœŸåˆ†å¸ƒ
            'data_source_status': data_source_status,  # ğŸ†• æ•°æ®æºçŠ¶æ€
            'data_source_message': data_source_message,  # ğŸ†• æ•°æ®æºçŠ¶æ€æ¶ˆæ¯
            'today_date': today_str,  # ğŸ†• å½“å‰æ—¥æœŸ
            'root_folder_odd': config.get('root_folder_odd', 'N/A'),  # ğŸ†• å•æ•°æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹
            'root_folder_even': config.get('root_folder_even', 'N/A'),  # ğŸ†• åŒæ•°æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹
            'recovery_count': recovery_count,
            'check_count': check_count,
            'files_found': check_count,  # ç®€åŒ–å¤„ç†
            'db_records': db_records,
            'last_update': now.strftime('%H:%M:%S'),
            'uptime_seconds': uptime_seconds,
            'current_time': now.strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== æ¯æ—¥00:10ä»»åŠ¡çŠ¶æ€ API ====================

@app.route('/daily-tasks-status')
def daily_tasks_status_page():
    """æ¯æ—¥00:10ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€é¡µé¢"""
    return render_template('daily_tasks_status.html')

@app.route('/api/daily-tasks/status')
def api_daily_tasks_status():
    """è·å–æ¯æ—¥00:10ä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€"""
    import os
    import json
    from datetime import datetime
    import pytz
    
    try:
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        today_str = now.strftime('%Y-%m-%d')
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        config = {}
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        # çˆ¶æ–‡ä»¶å¤¹æ›´æ–°ä»»åŠ¡çŠ¶æ€
        parent_folder_update = {
            'status': config.get('auto_update_status', 'pending'),
            'last_update': config.get('last_auto_update', '--'),
            'parent_folder_id': config.get('root_folder_odd') or config.get('root_folder_even', '--'),
            'child_folder_id': config.get('folder_id', '--'),
            'url': config.get('parent_folder_url', '--')
        }
        
        # æ¸…ç†ä»»åŠ¡çŠ¶æ€
        cleanup = {
            'last_cleanup': config.get('last_cleanup', None),
            'cleanup_reason': config.get('cleanup_reason', '--'),
            'root_folder_odd': config.get('root_folder_odd'),
            'root_folder_even': config.get('root_folder_even')
        }
        
        return jsonify({
            'success': True,
            'today_date': today_str,
            'parent_folder_update': parent_folder_update,
            'cleanup': cleanup
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/daily-tasks/logs')
def api_daily_tasks_logs():
    """è·å–æ¯æ—¥ä»»åŠ¡çš„æ‰§è¡Œæ—¥å¿—"""
    import os
    
    try:
        log_file = '/home/user/webapp/parent_folder_update.log'
        logs = []
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # åªè¿”å›æœ€è¿‘100è¡Œ
                logs = [line.rstrip() for line in lines[-100:]]
        
        return jsonify({
            'success': True,
            'logs': logs
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ==================== æ–‡ä»¶å¤¹æ›´æ–°ç›‘æ§ API ====================

@app.route('/folder-update-monitor')
def folder_update_monitor():
    """æ–‡ä»¶å¤¹æ›´æ–°ç›‘æ§é¡µé¢"""
    return render_template('folder_update_monitor.html')

@app.route('/api/folder-update-status')
def api_folder_update_status():
    """è·å–æ–‡ä»¶å¤¹æ›´æ–°çŠ¶æ€"""
    import os
    import json
    
    try:
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        today_str = now.strftime('%Y-%m-%d')
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_file = '/home/user/webapp/daily_folder_config.json'
        config = {}
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        
        config_date = config.get('current_date', 'unknown')
        need_update = config_date != today_str
        
        return jsonify({
            'success': True,
            'data': {
                'config_date': config_date,
                'today_date': today_str,
                'folder_id': config.get('folder_id', 'N/A'),
                'latest_txt': config.get('latest_txt', 'N/A'),
                'txt_count': config.get('txt_count', 0),
                'last_updated': config.get('last_updated', 'N/A'),
                'need_update': need_update,
                'message': 'é…ç½®æ—¥æœŸä¸ä»Šå¤©ä¸åŒ¹é…' if need_update else 'é…ç½®æ­£å¸¸'
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

@app.route('/api/trigger-folder-update', methods=['POST'])
def api_trigger_folder_update():
    """è§¦å‘æ–‡ä»¶å¤¹æ›´æ–°"""
    import subprocess
    import os
    
    try:
        script_path = '/home/user/webapp/auto_update_today_folder.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'message': 'æ›´æ–°è„šæœ¬ä¸å­˜åœ¨'
            }), 404
        
        # æ‰§è¡Œæ›´æ–°è„šæœ¬
        result = subprocess.run(
            ['python3', script_path],
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode == 0:
            # è¯»å–æ›´æ–°åçš„é…ç½®
            config_file = '/home/user/webapp/daily_folder_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            return jsonify({
                'success': True,
                'data': {
                    'folder_id': config.get('folder_id'),
                    'date': config.get('current_date'),
                    'latest_txt': config.get('latest_txt'),
                    'txt_count': config.get('txt_count', 0)
                },
                'message': 'æ›´æ–°æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': f'æ›´æ–°å¤±è´¥: {result.stderr}'
            }), 500
            
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'message': 'æ›´æ–°è¶…æ—¶(60ç§’)'
        }), 500
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

@app.route('/api/list-recent-folders')
def api_list_recent_folders():
    """åˆ—å‡ºæœ€è¿‘çš„æ–‡ä»¶å¤¹"""
    import requests
    from bs4 import BeautifulSoup
    import re
    
    try:
        parent_folder_id = "1j8YV6KysUCmgcmASFOxztWWIE1Vq-kYV"
        url = f"https://drive.google.com/embeddedfolderview?id={parent_folder_id}"
        
        response = requests.get(url, timeout=15)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        folders = []
        all_links = soup.find_all('a', href=True)
        
        for link in all_links:
            href = link.get('href', '')
            text = link.get_text(strip=True)
            
            if '/folders/' in href:
                match = re.search(r'/folders/([a-zA-Z0-9_-]+)', href)
                if match:
                    folder_id = match.group(1)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸæ–‡ä»¶å¤¹
                    if re.search(r'\d{4}-\d{2}-\d{2}', text):
                        folders.append({
                            'name': text,
                            'id': folder_id
                        })
        
        # æ’åº(æœ€æ–°çš„åœ¨å‰)
        folders.sort(key=lambda x: x['name'], reverse=True)
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        today = datetime.now(beijing_tz).strftime('%Y-%m-%d')
        
        return jsonify({
            'success': True,
            'data': {
                'folders': folders[:10],  # åªè¿”å›æœ€è¿‘10ä¸ª
                'today': today
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

@app.route('/api/get-update-log')
def api_get_update_log():
    """è·å–æ›´æ–°æ—¥å¿—"""
    import os
    
    try:
        log_file = '/home/user/webapp/auto_update_folder.log'
        log_content = ''
        
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                # åªè¿”å›æœ€è¿‘200è¡Œ
                log_content = ''.join(lines[-200:])
        
        return jsonify({
            'success': True,
            'data': {
                'log': log_content or 'æš‚æ— æ—¥å¿—'
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        }), 500

# æ—§çš„telegram-dashboardè·¯ç”±å·²åºŸå¼ƒ,ä½¿ç”¨ä¸‹æ–¹æ–°ç‰ˆæœ¬
# @app.route('/telegram-dashboard')
# def telegram_dashboard():
#     """Telegramä¿¡å·æ¨é€ç³»ç»Ÿç›‘æ§é¢æ¿"""
#     import time
#     cache_buster = int(time.time())
#     return render_template('telegram_dashboard.html', cache_buster=cache_buster)

@app.route('/api/telegram/send-message', methods=['POST'])
def telegram_send_message():
    """å‘é€Telegramæ¶ˆæ¯"""
    try:
        import requests
        import json
        import os
        
        # è·å–è¯·æ±‚æ•°æ®
        data = request.get_json()
        message = data.get('message', '')
        
        if not message:
            return jsonify({
                'success': False,
                'error': 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º'
            })
        
        # è¯»å–Telegramé…ç½®
        config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'configs', 'telegram_config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            tg_config = json.load(f)
        
        bot_token = tg_config.get('bot_token')
        chat_id = tg_config.get('chat_id')
        
        if not bot_token or not chat_id:
            return jsonify({
                'success': False,
                'error': 'Telegramé…ç½®ä¸å®Œæ•´'
            })
        
        # å‘é€æ¶ˆæ¯
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        payload = {
            'chat_id': chat_id,
            'text': message,
            'parse_mode': 'HTML',
            'disable_web_page_preview': True
        }
        
        response = requests.post(url, json=payload, timeout=10)
        result = response.json()
        
        if result.get('ok'):
            return jsonify({
                'success': True,
                'message_id': result.get('result', {}).get('message_id')
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('description', 'å‘é€å¤±è´¥')
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/telegram/status')
def telegram_status():
    """è·å–Telegramç›‘æ§ç³»ç»ŸçŠ¶æ€"""
    try:
        import subprocess
        import os
        
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿è¡Œ(æ£€æŸ¥telegram_signal_system.pyè€Œä¸æ˜¯tg_signal_monitor.py)
        result = subprocess.run(
            ['pgrep', '-f', 'telegram_signal_system.py'],
            capture_output=True,
            text=True
        )
        
        is_running = bool(result.stdout.strip())
        pid = result.stdout.strip() if is_running else None
        
        # è·å–æ•°æ®åº“ç»Ÿè®¡
        db_stats = {}
        signal_counts = {}  # åˆå§‹åŒ–ä¸ºç©ºå­—å…¸
        db_path = '/home/user/webapp/databases/tg_signals.db'
        if os.path.exists(db_path):
            conn = sqlite3.connect(db_path, timeout=5.0)
            cursor = conn.cursor()
            
            # è·å–æ€»å‘é€æ•°
            cursor.execute("SELECT COUNT(*) FROM signal_history")
            total_sent = cursor.fetchone()[0]
            
            # è·å–æœ€è¿‘1å°æ—¶å‘é€æ•°
            cursor.execute("""
                SELECT COUNT(*) FROM signal_history 
                WHERE sent_time >= datetime('now', '-1 hour', 'localtime')
            """)
            sent_1h = cursor.fetchone()[0]
            
            # è·å–ä»Šå¤©å‘é€æ•°
            cursor.execute("""
                SELECT COUNT(*) FROM signal_history 
                WHERE date(sent_time) = date('now', 'localtime')
            """)
            sent_today = cursor.fetchone()[0]
            
            # è·å–å„ç±»ä¿¡å·ç»Ÿè®¡
            cursor.execute("""
                SELECT signal_type, COUNT(*) as count
                FROM signal_history
                GROUP BY signal_type
            """)
            signal_counts = dict(cursor.fetchall())
            
            # è·å–æœ€æ–°å‘é€æ—¶é—´
            cursor.execute("""
                SELECT sent_time FROM signal_history 
                ORDER BY created_at DESC LIMIT 1
            """)
            last_sent = cursor.fetchone()
            last_sent_time = last_sent[0] if last_sent else None
            
            conn.close()
            
            db_stats = {
                'total_sent': total_sent,
                'sent_1h': sent_1h,
                'sent_today': sent_today,
                'signal_counts': signal_counts,
                'last_sent_time': last_sent_time
            }
        
        # è¿”å›æ‰å¹³åŒ–çš„æ•°æ®ç»“æ„,ç¬¦åˆå‰ç«¯æœŸå¾…çš„æ ¼å¼
        return jsonify({
            'success': True,
            'is_running': is_running,
            'pid': pid,
            'status': 'è¿è¡Œä¸­' if is_running else 'æœªè¿è¡Œ',
            'total_sent': db_stats.get('total_sent', 0),
            'sent_1h': db_stats.get('sent_1h', 0),
            'sent_today': db_stats.get('sent_today', 0),
            'last_sent_time': db_stats.get('last_sent_time'),
            'last_update': db_stats.get('last_sent_time', 'æœªçŸ¥'),
            'signal_counts': signal_counts,
            'last_messages': [],  # å‰ç«¯éœ€è¦çš„å­—æ®µ
            # åŒæ—¶ä¿ç•™åµŒå¥—æ ¼å¼ä»¥å…¼å®¹å…¶ä»–å¯èƒ½çš„è°ƒç”¨
            'data': {
                'is_running': is_running,
                'pid': pid,
                'database_stats': db_stats
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/telegram/history')
def telegram_history():
    """è·å–Telegramä¿¡å·å‘é€å†å²"""
    try:
        import os
        
        if not os.path.exists('tg_signals.db'):
            return jsonify({
                'success': False,
                'error': 'æ•°æ®åº“ä¸å­˜åœ¨'
            }), 404
        
        # è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', 1, type=int)
        limit = request.args.get('limit', 50, type=int)
        signal_type = request.args.get('type', '')
        
        conn = sqlite3.connect('tg_signals.db', timeout=5.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        where_clause = ""
        params = []
        if signal_type:
            where_clause = "WHERE signal_type = ?"
            params.append(signal_type)
        
        # è·å–æ€»æ•°
        cursor.execute(f"SELECT COUNT(*) FROM signal_history {where_clause}", params)
        total = cursor.fetchone()[0]
        
        # è·å–åˆ†é¡µæ•°æ®
        offset = (page - 1) * limit
        cursor.execute(f"""
            SELECT id, signal_type, symbol, signal_name, signal_data, sent_time, created_at
            FROM signal_history
            {where_clause}
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        """, params + [limit, offset])
        
        records = []
        for row in cursor.fetchall():
            records.append({
                'id': row['id'],
                'signal_type': row['signal_type'],
                'symbol': row['symbol'],
                'signal_name': row['signal_name'],
                'signal_data': row['signal_data'],
                'sent_time': row['sent_time'],
                'created_at': row['created_at']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'records': records,
                'total': total,
                'page': page,
                'limit': limit,
                'pages': (total + limit - 1) // limit
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/coins/realtime-status')
def api_coins_realtime_status():
    """
    è·å–æ‰€æœ‰å¸ç§çš„å®æ—¶çŠ¶æ€
    åŒ…æ‹¬:å½“å‰ä»·æ ¼(æ¥è‡ªæœ€æ–°Kçº¿)ã€7å¤©é«˜ä½ç‚¹ã€æ¶¨è·Œå¹…ã€äº¤æ˜“ä¿¡å·åŠå‘ç”Ÿæ—¶é—´
    """
    try:
        import pytz
        conn = sqlite3.connect('crypto_data.db', timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        
        # å®šä¹‰27ä¸ªå¸ç§
        symbols = [
            'AAVE', 'APT', 'BCH', 'BNB', 'BTC', 'CRV', 'DOGE', 'DOT', 'ETC', 'ETH', 'FIL',
            'HBAR', 'LDO', 'LINK', 'LTC', 'NEAR', 'SOL', 'SUI', 'TAO', 'TON', 'TRX',
            'XLM', 'XRP', 'CFX', 'CRO', 'STX', 'UNI'
        ]
        
        results = []
        
        for symbol_short in symbols:
            symbol = f"{symbol_short}-USDT-SWAP"
            
            # 1. è·å–æœ€æ–°Kçº¿æ•°æ®(å½“å‰ä»·æ ¼)
            cursor.execute('''
                SELECT timestamp, close, open
                FROM okex_kline_ohlc
                WHERE symbol = ? AND timeframe = '5m'
                ORDER BY timestamp DESC
                LIMIT 1
            ''', (symbol,))
            latest_kline = cursor.fetchone()
            
            if not latest_kline:
                continue
            
            current_price = latest_kline['close']
            open_price = latest_kline['open']
            latest_time = datetime.fromtimestamp(latest_kline['timestamp'] / 1000, tz=beijing_tz)
            
            # è®¡ç®—æ¶¨è·Œå¹…
            change_pct = ((current_price - open_price) / open_price * 100) if open_price > 0 else 0
            
            # 2. è·å–7å¤©é«˜ä½ç‚¹
            cursor.execute('''
                SELECT MAX(high) as high_7d, MIN(low) as low_7d
                FROM okex_kline_ohlc
                WHERE symbol = ? AND timeframe = '5m'
                AND timestamp >= ?
            ''', (symbol, int((datetime.now() - timedelta(days=7)).timestamp() * 1000)))
            extremes = cursor.fetchone()
            
            high_7d = extremes['high_7d'] if extremes and extremes['high_7d'] else current_price
            low_7d = extremes['low_7d'] if extremes and extremes['low_7d'] else current_price
            
            # 3. æ£€æŸ¥æœ€è¿‘2å°æ—¶çš„äº¤æ˜“ä¿¡å·
            two_hours_ago = datetime.now(beijing_tz) - timedelta(hours=2)
            
            cursor.execute('''
                SELECT record_time, long_signals, short_signals, today_new_high, today_new_low
                FROM trading_signals
                WHERE record_time >= ?
                ORDER BY record_time DESC
                LIMIT 1
            ''', (two_hours_ago.strftime('%Y-%m-%d %H:%M:%S'),))
            signal_row = cursor.fetchone()
            
            signal_type = None
            signal_time = None
            
            if signal_row:
                signal_time_dt = datetime.strptime(signal_row['record_time'], '%Y-%m-%d %H:%M:%S')
                signal_time_dt = beijing_tz.localize(signal_time_dt)
                signal_time = signal_time_dt.strftime('%m-%d %H:%M')
                
                # åˆ¤æ–­ä¿¡å·ç±»å‹
                if signal_row['long_signals'] > 0 or signal_row['today_new_low'] > 0:
                    signal_type = 'buy'
                elif signal_row['short_signals'] > 0 or signal_row['today_new_high'] > 0:
                    signal_type = 'sell'
            
            results.append({
                'symbol': symbol_short,
                'current_price': current_price,
                'high_7d': high_7d,
                'low_7d': low_7d,
                'change_pct': change_pct,
                'signal_type': signal_type,  # 'buy' or 'sell' or None
                'signal_time': signal_time,  # Kçº¿æ—¶é—´,æ ¼å¼:'MM-DD HH:MM'
                'latest_update': latest_time.strftime('%Y-%m-%d %H:%M:%S')
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': results,
            'count': len(results),
            'timestamp': datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/sell-point-1/save', methods=['POST'])
def api_sell_point_1_save():
    """
    ä¿å­˜å–ç‚¹1ä¿¡å·åˆ°æ•°æ®åº“
    
    è¯·æ±‚ä½“æ ¼å¼:
    {
        "symbol": "BTC",
        "high_price": 90000.0,
        "high_time": "2025-12-15 14:30:00",
        "high_index": 1000,
        "mark_price": 89500.0,
        "mark_time": "2025-12-15 15:00:00",
        "mark_index": 1006,
        "mark_rsi": 65.5
    }
    """
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['symbol', 'high_price', 'high_time', 'high_index', 
                          'mark_price', 'mark_time', 'mark_index', 'mark_rsi']
        for field in required_fields:
            if field not in data:
                return jsonify({
                    'success': False,
                    'error': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}'
                }), 400
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ä¿¡å·(é¿å…é‡å¤æ’å…¥)
        cursor.execute('''
            SELECT id FROM sell_point_1_signals
            WHERE symbol = ? AND mark_time = ? AND is_valid = 1
        ''', (data['symbol'], data['mark_time']))
        
        existing = cursor.fetchone()
        if existing:
            conn.close()
            return jsonify({
                'success': True,
                'message': 'ä¿¡å·å·²å­˜åœ¨',
                'signal_id': existing[0]
            })
        
        # æ’å…¥æ–°ä¿¡å·
        now = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('''
            INSERT INTO sell_point_1_signals (
                symbol, high_price, high_time, high_index,
                mark_price, mark_time, mark_index, mark_rsi,
                signal_generated_at, is_valid
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, 1)
        ''', (
            data['symbol'],
            data['high_price'],
            data['high_time'],
            data['high_index'],
            data['mark_price'],
            data['mark_time'],
            data['mark_index'],
            data['mark_rsi'],
            now
        ))
        
        signal_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': 'å–ç‚¹1ä¿¡å·ä¿å­˜æˆåŠŸ',
            'signal_id': signal_id
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/sell-point-1/latest')
def api_sell_point_1_latest():
    """
    è·å–æœ€æ–°çš„å–ç‚¹1ä¿¡å·
    
    å‚æ•°:
        - symbol: å¸ç§(å¯é€‰,å¦‚BTC)
        - hours: æ—¶é—´èŒƒå›´(å¯é€‰,é»˜è®¤24å°æ—¶)
    """
    try:
        symbol = request.args.get('symbol')
        hours = int(request.args.get('hours', 24))
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢
        beijing_tz = pytz.timezone('Asia/Shanghai')
        cutoff_time = (datetime.now(beijing_tz) - timedelta(hours=hours)).strftime('%Y-%m-%d %H:%M:%S')
        
        if symbol:
            cursor.execute('''
                SELECT * FROM sell_point_1_signals
                WHERE symbol = ? AND mark_time >= ? AND is_valid = 1
                ORDER BY mark_time DESC
            ''', (symbol, cutoff_time))
        else:
            cursor.execute('''
                SELECT * FROM sell_point_1_signals
                WHERE mark_time >= ? AND is_valid = 1
                ORDER BY mark_time DESC
            ''', (cutoff_time,))
        
        rows = cursor.fetchall()
        conn.close()
        
        signals = []
        for row in rows:
            signals.append({
                'id': row['id'],
                'symbol': row['symbol'],
                'high_price': row['high_price'],
                'high_time': row['high_time'],
                'high_index': row['high_index'],
                'mark_price': row['mark_price'],
                'mark_time': row['mark_time'],
                'mark_index': row['mark_index'],
                'mark_rsi': row['mark_rsi'],
                'signal_generated_at': row['signal_generated_at'],
                'created_at': row['created_at']
            })
        
        return jsonify({
            'success': True,
            'data': signals,
            'count': len(signals),
            'timestamp': datetime.now(beijing_tz).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/telegram-dashboard')
def telegram_dashboard():
    """Telegramä¿¡å·æ¨é€ç³»ç»Ÿä»ªè¡¨æ¿"""
    return render_template('telegram_signal_dashboard.html')

@app.route('/cache-help')
def cache_help():
    """ç¼“å­˜æ¸…é™¤å¸®åŠ©é¡µé¢"""
    return render_template('cache_clear_guide.html')

@app.route('/api/telegram/signals/support-resistance')
def api_telegram_support_resistance():
    """è·å–æ”¯æ’‘å‹åŠ›çº¿ä¿¡å·(2å°æ—¶å†…)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        # è·å–2å°æ—¶å†…çš„ä¿¡å·
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT signal_type, symbol, price, signal_time, sent_at
            FROM support_resistance_signals
            WHERE sent_at >= ?
            ORDER BY sent_at DESC
        ''', (two_hours_ago,))
        
        signals = []
        for row in cursor.fetchall():
            signals.append({
                'signal_type': row[0],
                'symbol': row[1],
                'price': row[2],
                'signal_time': row[3],
                'sent_at': row[4]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'signals': signals,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/signals/count-alerts')
def api_telegram_count_alerts():
    """è·å–è®¡æ¬¡é¢„è­¦(2å°æ—¶å†…)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT record_time, count_value, threshold, full_data, sent_at
            FROM count_alerts
            WHERE sent_at >= ?
            ORDER BY sent_at DESC
        ''', (two_hours_ago,))
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'record_time': row[0],
                'count_value': row[1],
                'threshold': row[2],
                'full_data': row[3],
                'sent_at': row[4]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'alerts': alerts,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/signals/trading')
def api_telegram_trading():
    """è·å–äº¤æ˜“ä¿¡å·(2å°æ—¶å†…)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        two_hours_ago = (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        cursor.execute('''
            SELECT signal_type, symbol, price, signal_time, rsi, sent_at
            FROM trading_signals
            WHERE sent_at >= ?
            ORDER BY sent_at DESC
        ''', (two_hours_ago,))
        
        signals = []
        for row in cursor.fetchall():
            signals.append({
                'signal_type': row[0],
                'symbol': row[1],
                'price': row[2],
                'signal_time': row[3],
                'rsi': row[4],
                'sent_at': row[5]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'signals': signals,
            'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/signals/stats')
def api_telegram_stats():
    """è·å–å‘é€ç»Ÿè®¡"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect('telegram_signals.db')
        cursor = conn.cursor()
        
        # æ€»å‘é€æ•°
        cursor.execute('SELECT COUNT(*) FROM support_resistance_signals')
        support_count = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM count_alerts')
        alert_count = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM trading_signals')
        trade_count = cursor.fetchone()[0]
        total = support_count + alert_count + trade_count
        
        # æœ€è¿‘1å°æ—¶
        one_hour_ago = (datetime.now() - timedelta(hours=1)).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute('SELECT COUNT(*) FROM support_resistance_signals WHERE sent_at >= ?', (one_hour_ago,))
        support_1h = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM count_alerts WHERE sent_at >= ?', (one_hour_ago,))
        alert_1h = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM trading_signals WHERE sent_at >= ?', (one_hour_ago,))
        trade_1h = cursor.fetchone()[0]
        last_hour = support_1h + alert_1h + trade_1h
        
        # ä»Šæ—¥å‘é€
        today_start = datetime.now().strftime('%Y-%m-%d 00:00:00')
        cursor.execute('SELECT COUNT(*) FROM support_resistance_signals WHERE sent_at >= ?', (today_start,))
        support_today = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM count_alerts WHERE sent_at >= ?', (today_start,))
        alert_today = cursor.fetchone()[0]
        cursor.execute('SELECT COUNT(*) FROM trading_signals WHERE sent_at >= ?', (today_start,))
        trade_today = cursor.fetchone()[0]
        today = support_today + alert_today + trade_today
        
        # æœ€åæ¨é€æ—¶é—´
        cursor.execute('''
            SELECT MAX(sent_at) FROM (
                SELECT sent_at FROM support_resistance_signals
                UNION ALL
                SELECT sent_at FROM count_alerts
                UNION ALL
                SELECT sent_at FROM trading_signals
            )
        ''')
        last_time = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'total': total,
            'last_hour': last_hour,
            'today': today,
            'last_time': last_time
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/system/status')
def api_telegram_system_status():
    """è·å–Telegramæ¨é€ç³»ç»ŸçŠ¶æ€"""
    try:
        import subprocess
        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿è¡Œ
        result = subprocess.run(['pgrep', '-f', 'telegram_signal_system.py'], 
                               capture_output=True, text=True)
        is_running = bool(result.stdout.strip())
        pid = result.stdout.strip() if is_running else None
        
        return jsonify({
            'success': True,
            'running': is_running,
            'pid': pid,
            'message': 'ç³»ç»Ÿè¿è¡Œä¸­' if is_running else 'ç³»ç»Ÿæœªè¿è¡Œ'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/start', methods=['POST'])
def api_telegram_start():
    """å¯åŠ¨Telegramæ¨é€ç³»ç»Ÿ"""
    try:
        import subprocess
        result = subprocess.run(['./start_telegram_signal_system.sh'], 
                               capture_output=True, text=True, cwd='/home/user/webapp')
        return jsonify({
            'success': True,
            'message': 'ç³»ç»Ÿå·²å¯åŠ¨',
            'output': result.stdout
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/telegram/stop', methods=['POST'])
def api_telegram_stop():
    """åœæ­¢Telegramæ¨é€ç³»ç»Ÿ"""
    try:
        import subprocess
        result = subprocess.run(['./stop_telegram_signal_system.sh'], 
                               capture_output=True, text=True, cwd='/home/user/webapp')
        return jsonify({
            'success': True,
            'message': 'ç³»ç»Ÿå·²åœæ­¢',
            'output': result.stdout
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/query/latest')
def api_query_latest():
    """è·å–æœ€æ–°æŸ¥è¯¢æ•°æ®API(ç”¨äºè®¡æ¬¡é¢„è­¦)- ä½¿ç”¨JSONLæ•°æ®æº"""
    try:
        # ä½¿ç”¨gdrive_jsonl_managerè·å–æœ€æ–°èšåˆæ•°æ®
        manager = gdrive_jsonl_manager
        snapshot = manager.get_latest_aggregate()
        
        if not snapshot:
            return jsonify({'success': False, 'error': 'æš‚æ— æ•°æ®'})
        
        return jsonify({
            'success': True,
            'data': {
                'è¿ç®—æ—¶é—´': snapshot.get('snapshot_time'),
                'æ€¥æ¶¨': snapshot.get('rush_up_total', 0),  # GDriveä½¿ç”¨rush_up_total
                'æ€¥è·Œ': snapshot.get('rush_down_total', 0),  # GDriveä½¿ç”¨rush_down_total
                'å·®å€¼': snapshot.get('diff', 0),
                'è®¡æ¬¡': snapshot.get('count', 0),
                'æ¯”å€¼': snapshot.get('ratio', 0),
                'çŠ¶æ€': snapshot.get('status', ''),
                'æœ¬è½®æ€¥æ¶¨': snapshot.get('round_rush_up', 0),
                'æœ¬è½®æ€¥è·Œ': snapshot.get('round_rush_down', 0),
                'æ¯”ä»·æœ€ä½': snapshot.get('price_lowest', 0),
                'æ¯”ä»·åˆ›æ–°é«˜': snapshot.get('price_newhigh', 0),
                'è®¡æ¬¡å¾—åˆ†': snapshot.get('count_score_display', ''),
                '24hæ¶¨â‰¥10%': snapshot.get('rise_24h_count', 0),
                '24hè·Œâ‰¤-10%': snapshot.get('fall_24h_count', 0)
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/support-resistance/export', methods=['POST'])
def api_support_resistance_export():
    """å¯¼å‡ºæ”¯æ’‘é˜»åŠ›ä½æ•°æ®"""
    try:
        import subprocess
        import os
        
        script_path = '/home/user/webapp/export_support_resistance_data.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'å¯¼å‡ºè„šæœ¬ä¸å­˜åœ¨'
            })
        
        # æ‰§è¡Œå¯¼å‡ºè„šæœ¬
        result = subprocess.run(
            ['python3', script_path],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode != 0:
            return jsonify({
                'success': False,
                'error': 'å¯¼å‡ºå¤±è´¥',
                'output': result.stderr
            })
        
        # ä»è¾“å‡ºä¸­æå–å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        export_file = None
        for line in result.stdout.split('\n'):
            if 'å¯¼å‡ºæ–‡ä»¶:' in line:
                export_file = line.split('å¯¼å‡ºæ–‡ä»¶:')[-1].strip()
                break
        
        if not export_file or not os.path.exists(export_file):
            return jsonify({
                'success': False,
                'error': 'æ‰¾ä¸åˆ°å¯¼å‡ºæ–‡ä»¶'
            })
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(export_file)
        file_size_mb = file_size / (1024 * 1024)
        filename = os.path.basename(export_file)
        
        return jsonify({
            'success': True,
            'message': 'å¯¼å‡ºæˆåŠŸ',
            'file_path': export_file,
            'filename': filename,
            'file_size': file_size,
            'file_size_mb': round(file_size_mb, 2),
            'download_url': f'/api/support-resistance/download/{filename}'
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'error': 'å¯¼å‡ºè¶…æ—¶'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/support-resistance/download/<filename>')
def api_support_resistance_download(filename):
    """ä¸‹è½½å¯¼å‡ºçš„æ•°æ®æ–‡ä»¶"""
    try:
        export_dir = '/home/user/webapp/exports'
        file_path = os.path.join(export_dir, filename)
        
        if not os.path.exists(file_path):
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        return send_from_directory(export_dir, filename, as_attachment=True)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/support-resistance/import', methods=['POST'])
def api_support_resistance_import():
    """å¯¼å…¥æ”¯æ’‘é˜»åŠ›ä½æ•°æ®"""
    try:
        import subprocess
        import os
        from werkzeug.utils import secure_filename
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¼ çš„æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': 'æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶'
            })
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': 'æ–‡ä»¶åä¸ºç©º'
            })
        
        # æ£€æŸ¥æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®
        clear_existing = request.form.get('clear_existing', 'false').lower() == 'true'
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        filename = secure_filename(file.filename)
        upload_dir = '/home/user/webapp/uploads'
        os.makedirs(upload_dir, exist_ok=True)
        
        file_path = os.path.join(upload_dir, filename)
        file.save(file_path)
        
        # æ‰§è¡Œå¯¼å…¥è„šæœ¬
        script_path = '/home/user/webapp/import_support_resistance_data.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'å¯¼å…¥è„šæœ¬ä¸å­˜åœ¨'
            })
        
        # æ„å»ºå‘½ä»¤
        cmd = ['python3', script_path, file_path]
        if clear_existing:
            cmd.append('--clear')
        
        # æ‰§è¡Œå¯¼å…¥
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300
        )
        
        # åˆ é™¤ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
        try:
            os.remove(file_path)
        except:
            pass
        
        if result.returncode != 0:
            return jsonify({
                'success': False,
                'error': 'å¯¼å…¥å¤±è´¥',
                'output': result.stderr or result.stdout
            })
        
        # ä»è¾“å‡ºä¸­æå–ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'tables': 0,
            'records': 0
        }
        
        for line in result.stdout.split('\n'):
            if 'è¡¨æ•°é‡:' in line:
                try:
                    stats['tables'] = int(line.split(':')[-1].strip())
                except:
                    pass
            elif 'æ€»è®°å½•æ•°:' in line:
                try:
                    stats['records'] = int(line.split(':')[-1].strip().replace(',', ''))
                except:
                    pass
        
        return jsonify({
            'success': True,
            'message': 'å¯¼å…¥æˆåŠŸ',
            'stats': stats,
            'output': result.stdout
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'error': 'å¯¼å…¥è¶…æ—¶'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/support-resistance/latest-from-jsonl')
def api_support_resistance_latest_from_jsonl():
    """ç›´æ¥ä»JSONLæ–‡ä»¶è·å–æœ€æ–°æ”¯æ’‘é˜»åŠ›æ•°æ®(fallbackæ–¹æ¡ˆ)"""
    try:
        import json
        from collections import defaultdict
        
        levels_file = '/home/user/webapp/data/support_resistance_jsonl/support_resistance_levels.jsonl'
        
        if not os.path.exists(levels_file):
            return jsonify({
                'success': False,
                'message': 'Data file not found'
            })
        
        # è¯»å–æœ€å1MBè·å–æœ€æ–°æ•°æ®
        latest_by_symbol = {}
        with open(levels_file, 'r', encoding='utf-8') as f:
            # ä»æ–‡ä»¶æœ«å°¾è¯»å–
            f.seek(0, 2)  # ç§»åˆ°æ–‡ä»¶æœ«å°¾
            file_size = f.tell()
            # è¯»å–æœ€å1MBæ•°æ®
            read_size = min(1024 * 1024, file_size)
            f.seek(max(0, file_size - read_size))
            # è·³è¿‡ç¬¬ä¸€è¡Œ(å¯èƒ½ä¸å®Œæ•´)
            if file_size > read_size:
                f.readline()
            
            for line in f:
                try:
                    data = json.loads(line.strip())
                    symbol = data.get('symbol', '')
                    if symbol:
                        # ä¿ç•™æ¯ä¸ªå¸ç§çš„æœ€æ–°è®°å½•
                        record_time = data.get('record_time', '')
                        if symbol not in latest_by_symbol or record_time > latest_by_symbol[symbol].get('record_time', ''):
                            latest_by_symbol[symbol] = data
                except:
                    continue
        
        if not latest_by_symbol:
            return jsonify({
                'success': False,
                'message': 'No data available'
            })
        
        # æ ¼å¼åŒ–è¾“å‡º,åŒ¹é…å‰ç«¯æœŸæœ›çš„å­—æ®µ
        coins_data = []
        for symbol, data in latest_by_symbol.items():
            # è½¬æ¢ä¸º OKX æ ¼å¼(BTCUSDT -> BTC-USDT-SWAP)
            if symbol.endswith('USDT'):
                okx_symbol = f"{symbol[:-4]}-USDT-SWAP"
            else:
                okx_symbol = symbol
            
            coins_data.append({
                'symbol': okx_symbol,
                'current_price': data.get('current_price', 0),
                'support_line_1': data.get('support_line_1', 0),
                'support_line_2': data.get('support_line_2', 0),
                'resistance_line_1': data.get('resistance_line_1', 0),
                'resistance_line_2': data.get('resistance_line_2', 0),
                'position_7d': data.get('position_7d', 0),
                'position_48h': data.get('position_48h', 0),
                'status': data.get('current_price_status', ''),
                'record_time': data.get('record_time', ''),
                'record_time_beijing': data.get('record_time_beijing', data.get('record_time', ''))
            })
        
        # æŒ‰symbolæ’åº
        coins_data.sort(key=lambda x: x['symbol'])
        
        return jsonify({
            'success': True,
            'data': coins_data,
            'coins': len(coins_data),
            'data_source': 'JSONL (ç›´æ¥è¯»å–)',
            'update_time': coins_data[0]['record_time_beijing'] if coins_data else ''
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e),
            'message': 'Failed to read data'
        })

@app.route('/api/query/batch-import', methods=['POST'])
def api_query_batch_import():
    """æ‰¹é‡å¯¼å…¥å½“å¤©æ‰€æœ‰TXTæ–‡ä»¶æ•°æ®"""
    try:
        import subprocess
        import os
        
        # æ‰§è¡Œæ‰¹é‡å¯¼å…¥è„šæœ¬
        script_path = '/home/user/webapp/batch_import_daily_txt.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': 'æ‰¹é‡å¯¼å…¥è„šæœ¬ä¸å­˜åœ¨'
            })
        
        # ä½¿ç”¨subprocessè¿è¡Œè„šæœ¬
        result = subprocess.run(
            ['python3', script_path],
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        # è§£æè¾“å‡ºç»“æœ
        output_lines = result.stdout.split('\n')
        
        # æå–ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'total': 0,
            'success': 0,
            'exists': 0,
            'invalid': 0,
            'error': 0
        }
        
        for line in output_lines:
            if 'æ€»æ–‡ä»¶æ•°:' in line:
                stats['total'] = int(line.split(':')[-1].strip())
            elif 'æˆåŠŸå¯¼å…¥:' in line:
                stats['success'] = int(line.split(':')[-1].strip())
            elif 'å·²å­˜åœ¨:' in line:
                stats['exists'] = int(line.split(':')[-1].strip())
            elif 'æ— æ•ˆæ•°æ®:' in line:
                stats['invalid'] = int(line.split(':')[-1].strip())
            elif 'å¤±è´¥:' in line and 'âŒ' in line:
                stats['error'] = int(line.split(':')[-1].strip())
        
        return jsonify({
            'success': True,
            'message': 'æ‰¹é‡å¯¼å…¥å®Œæˆ',
            'stats': stats,
            'output': result.stdout
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({
            'success': False,
            'error': 'æ‰¹é‡å¯¼å…¥è¶…æ—¶(è¶…è¿‡5åˆ†é’Ÿ)'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/chart-config')
def chart_config():
    """è·å–Kçº¿å›¾é…ç½®URL"""
    return jsonify({
        'success': True,
        'chart_base_url': CHART_BASE_URL,
        'example': f"{CHART_BASE_URL}/chart/BTC"
    })

@app.route('/gdrive-config')
def gdrive_config():
    """Google Driveé…ç½®ç®¡ç†é¡µé¢"""
    return render_template('gdrive_config.html')

@app.route('/api/gdrive-config/get')
def gdrive_config_get():
    """è·å–å½“å‰Google Driveé…ç½®"""
    try:
        import json
        config_file = '/home/user/webapp/daily_folder_config.json'
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/gdrive-config/update', methods=['POST'])
def gdrive_config_update():
    """æ›´æ–°Google Driveæ–‡ä»¶å¤¹é…ç½®"""
    try:
        import json
        from datetime import datetime
        
        data = request.get_json()
        parent_folder_url = data.get('parent_folder_url', '')
        
        if not parent_folder_url:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›Google Driveæ–‡ä»¶å¤¹é“¾æ¥'
            }), 400
        
        # æå–æ–‡ä»¶å¤¹ID
        import re
        folder_id_match = re.search(r'/folders/([a-zA-Z0-9_-]+)', parent_folder_url)
        if not folder_id_match:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•ä»é“¾æ¥ä¸­æå–æ–‡ä»¶å¤¹ID,è¯·æ£€æŸ¥é“¾æ¥æ ¼å¼'
            }), 400
        
        root_folder_id = folder_id_match.group(1)
        
        # è¯»å–ç°æœ‰é…ç½®
        config_file = '/home/user/webapp/daily_folder_config.json'
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except:
            config = {}
        
        # æ›´æ–°é…ç½®
        beijing_time = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        today = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d')
        
        # æ ¹æ®æ—¥æœŸåˆ¤æ–­æ˜¯å•æ•°è¿˜æ˜¯åŒæ•°
        day_of_month = datetime.now(BEIJING_TZ).day
        is_odd_day = day_of_month % 2 == 1
        
        if is_odd_day:
            config['root_folder_odd'] = root_folder_id
        else:
            config['root_folder_even'] = root_folder_id
        
        config['parent_folder_url'] = parent_folder_url
        config['last_manual_update'] = beijing_time
        config['last_updated'] = beijing_time
        config['update_reason'] = f'æ‰‹åŠ¨æ›´æ–°{"å•æ•°" if is_odd_day else "åŒæ•°"}æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹'
        
        # ä¿å­˜é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': f'é…ç½®å·²æ›´æ–° ({"å•æ•°" if is_odd_day else "åŒæ•°"}æ—¥æœŸçˆ¶æ–‡ä»¶å¤¹)',
            'config': config
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/gdrive-config/manual-trigger', methods=['POST'])
def gdrive_manual_trigger():
    """æ‰‹åŠ¨è§¦å‘æ•°æ®é‡‡é›†"""
    try:
        import subprocess
        import os
        
        # è¿è¡Œgdrive_final_detector.pyä¸€æ¬¡
        script_path = '/home/user/webapp/gdrive_final_detector.py'
        
        if not os.path.exists(script_path):
            return jsonify({
                'success': False,
                'error': f'è„šæœ¬ä¸å­˜åœ¨: {script_path}'
            }), 404
        
        # åœ¨åå°è¿è¡Œä¸€æ¬¡æ£€æµ‹
        process = subprocess.Popen(
            ['python3', script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            cwd='/home/user/webapp'
        )
        
        # ç­‰å¾…æœ€å¤š5ç§’
        try:
            stdout, stderr = process.communicate(timeout=5)
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨è§¦å‘æˆåŠŸ,æ•°æ®é‡‡é›†å·²å¼€å§‹',
                'output': stdout.decode('utf-8', errors='ignore')[:500]
            })
        except subprocess.TimeoutExpired:
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨è§¦å‘æˆåŠŸ,æ•°æ®é‡‡é›†æ­£åœ¨åå°è¿è¡Œ'
            })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/gdrive-config/latest-data')
def gdrive_latest_data():
    """è·å–æœ€æ–°æ•°æ®æ—¶é—´å’ŒçŠ¶æ€"""
    try:
        import sqlite3
        from datetime import datetime
        
        db_path = '/home/user/webapp/databases/crypto_data.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°æ•°æ®
        cursor.execute("""
            SELECT snapshot_time, rush_up, rush_down, count, status, created_at
            FROM crypto_snapshots
            ORDER BY created_at DESC
            LIMIT 1
        """)
        
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return jsonify({
                'success': True,
                'has_data': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        snapshot_time = result[0]
        created_at = result[5]
        
        # è®¡ç®—å»¶è¿Ÿ(åˆ†é’Ÿ)
        now = datetime.now(BEIJING_TZ)
        try:
            snapshot_dt = datetime.strptime(snapshot_time, '%Y-%m-%d %H:%M:%S')
            snapshot_dt = BEIJING_TZ.localize(snapshot_dt)
        except:
            snapshot_dt = datetime.strptime(snapshot_time, '%Y-%m-%d %H:%M:%S.%f')
            snapshot_dt = BEIJING_TZ.localize(snapshot_dt)
        
        delay_minutes = (now - snapshot_dt).total_seconds() / 60
        
        return jsonify({
            'success': True,
            'has_data': True,
            'data': {
                'snapshot_time': snapshot_time,
                'rush_up': result[1],
                'rush_down': result[2],
                'count': result[3],
                'status': result[4],
                'created_at': created_at,
                'delay_minutes': round(delay_minutes, 1)
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== SARæ–œç‡ç³»ç»Ÿ API ====================

@app.route('/sar-slope')
def sar_slope_page():
    """SARæ–œç‡ç³»ç»Ÿé¡µé¢"""
    response = make_response(render_template('sar_slope.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/sar-slope/latest')
def api_sar_slope_latest():
    """è·å–æ‰€æœ‰å¸ç§çš„æœ€æ–°SARæ–œç‡æ•°æ® - ä»JSONLè¯»å–"""
    try:
        import sys
        import glob
        sys.path.insert(0, '/home/user/webapp/source_code')
        
        # ä»sar_jsonlç›®å½•è¯»å–æ‰€æœ‰å¸ç§çš„æœ€æ–°æ•°æ®
        sar_jsonl_dir = '/home/user/webapp/data/sar_jsonl'
        
        if not os.path.exists(sar_jsonl_dir):
            return jsonify({
                'success': False,
                'error': 'SARæ•°æ®ç›®å½•ä¸å­˜åœ¨',
                'data': []
            })
        
        symbol_filter = request.args.get('symbol', '').upper()
        position_filter = request.args.get('position', '')  # bullish/bearish
        
        # è¯»å–æ‰€æœ‰å¸ç§æ–‡ä»¶çš„æœ€æ–°è®°å½•
        results = []
        jsonl_files = glob.glob(os.path.join(sar_jsonl_dir, '*.jsonl'))
        
        for jsonl_file in jsonl_files:
            symbol = os.path.basename(jsonl_file).replace('.jsonl', '')
            
            # åº”ç”¨symbolè¿‡æ»¤
            if symbol_filter and symbol_filter not in symbol:
                continue
            
            try:
                # è¯»å–æ–‡ä»¶æœ€åä¸€è¡Œ(æœ€æ–°è®°å½•)
                with open(jsonl_file, 'rb') as f:
                    # ä»æ–‡ä»¶æœ«å°¾è¯»å–
                    try:
                        f.seek(-2, os.SEEK_END)
                        while f.read(1) != b'\n':
                            f.seek(-2, os.SEEK_CUR)
                    except OSError:
                        f.seek(0)
                    last_line = f.readline().decode('utf-8')
                
                if last_line.strip():
                    record = json.loads(last_line)
                    
                    # åº”ç”¨positionè¿‡æ»¤
                    if position_filter and record.get('position') != position_filter:
                        continue
                    
                    results.append({
                        'symbol': symbol,
                        'position': record.get('position', 'unknown'),
                        'quadrant': record.get('quadrant', 'unknown'),
                        'duration_minutes': record.get('duration_minutes', 0),
                        'slope_value': record.get('slope_value', 0),
                        'slope_direction': record.get('slope_direction', 'unknown'),
                        'close': record.get('close', 0),
                        'sar': record.get('sar', 0),
                        'timestamp': record.get('timestamp', 0),
                        'beijing_time': record.get('beijing_time', '')
                    })
            except Exception as e:
                print(f"[é”™è¯¯] è¯»å–{symbol}æ•°æ®å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        bullish_count = sum(1 for r in results if r['position'] == 'bullish')
        bearish_count = sum(1 for r in results if r['position'] == 'bearish')
        
        durations = [r['duration_minutes'] for r in results if r['duration_minutes'] > 0]
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        stats = {
            'total_symbols': len(results),
            'bullish_count': bullish_count,
            'bearish_count': bearish_count,
            'avg_duration': round(avg_duration, 1)
        }
        
        return jsonify({
            'success': True,
            'data': results,
            'stats': stats,
            'data_source': 'JSONL'
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/latest-jsonl')
def sar_slope_latest_jsonl():
    """ä»JSONLç›´æ¥è¯»å–æœ€æ–°çš„SARæ–œç‡æ•°æ®"""
    try:
        jsonl_file = '/home/user/webapp/data/sar_slope_jsonl/latest_sar_slope.jsonl'
        
        if not os.path.exists(jsonl_file):
            return jsonify({
                'success': False,
                'error': 'SARæ–œç‡JSONLæ–‡ä»¶ä¸å­˜åœ¨',
                'data': []
            })
        
        # è¯»å–æ‰€æœ‰å¸ç§çš„æœ€æ–°æ•°æ®
        latest_data = {}
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    record = json.loads(line)
                    symbol = record.get('symbol')
                    if symbol:
                        # ä¿å­˜æœ€æ–°çš„è®°å½•(åé¢çš„ä¼šè¦†ç›–å‰é¢çš„)
                        latest_data[symbol] = record
                except json.JSONDecodeError:
                    continue
        
        # è½¬æ¢ä¸ºåˆ—è¡¨
        data_list = list(latest_data.values())
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        bullish_count = sum(1 for d in data_list if d.get('sar_position') == 'bullish')
        bearish_count = sum(1 for d in data_list if d.get('sar_position') == 'bearish')
        
        # è®¡ç®—å¹³å‡æŒç»­æ—¶é—´
        durations = [d.get('position_duration', 0) for d in data_list if d.get('position_duration')]
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        return jsonify({
            'success': True,
            'data': data_list,
            'data_source': 'JSONL',
            'stats': {
                'total_symbols': len(data_list),
                'bullish_count': bullish_count,
                'bearish_count': bearish_count,
                'avg_duration': round(avg_duration, 1)
            }
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-day-change/latest')
def api_okx_day_change_latest():
    """è·å–OKX 27å¸ç§æ¶¨è·Œæœ€æ–°æ•°æ® - ä½¿ç”¨ Coin Price Tracker æ•°æ®"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from coin_price_tracker_adapter import CoinPriceTrackerAdapter
        
        limit = int(request.args.get('limit', 60))  # é»˜è®¤æœ€è¿‘60åˆ†é’Ÿ
        
        # ä½¿ç”¨æ–°çš„é€‚é…å™¨æ›¿ä»£æ—§çš„ OKXTradingJSONLManager
        adapter = CoinPriceTrackerAdapter()
        records = adapter.get_latest_records(limit=limit)
        
        if not records:
            return jsonify({
                'success': True,
                'data': [],
                'message': 'æš‚æ— æ•°æ®'
            })
        
        return jsonify({
            'success': True,
            'data': records,
            'count': len(records),
            'data_source': 'CoinPriceTracker'  # æ ‡è®°æ•°æ®æ¥æº
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-day-change/history')
def api_okx_day_change_history():
    """è·å–OKX 27å¸ç§æ¶¨è·Œå†å²æ•°æ® - ä½¿ç”¨ Coin Price Tracker æ•°æ®"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from coin_price_tracker_adapter import CoinPriceTrackerAdapter
        from datetime import datetime, timedelta
        
        # è·å–æ—¶é—´èŒƒå›´å‚æ•°
        hours = int(request.args.get('hours', 24))  # é»˜è®¤24å°æ—¶
        
        end_time = int(datetime.now().timestamp())
        start_time = end_time - (hours * 3600)
        
        # ä½¿ç”¨æ–°çš„é€‚é…å™¨æ›¿ä»£æ—§çš„ OKXTradingJSONLManager
        adapter = CoinPriceTrackerAdapter()
        records = adapter.get_records_by_time_range(start_time, end_time)
        
        return jsonify({
            'success': True,
            'data': records,
            'count': len(records),
            'hours': hours,
            'data_source': 'CoinPriceTracker'  # æ ‡è®°æ•°æ®æ¥æº
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/coin-price-tracker/latest')
def api_coin_price_tracker_latest():
    """å¸ä»·è¿½è¸ªå™¨ - è·å–æœ€æ–°Næ¡æ•°æ®(30åˆ†é’Ÿé—´éš”)"""
    try:
        # è·å–å‚æ•°
        limit = request.args.get('limit', 48, type=int)  # é»˜è®¤48æ¡ = 24å°æ—¶
        
        # è¯»å–JSONLæ–‡ä»¶
        jsonl_file = '/home/user/webapp/data/coin_price_tracker/coin_prices_30min.jsonl'
        
        if not os.path.exists(jsonl_file):
            return jsonify({
                'success': False,
                'error': 'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'
            })
        
        # è¯»å–æœ€åNæ¡è®°å½•
        records = []
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines[-limit:]:
                if line.strip():
                    records.append(json.loads(line))
        
        return jsonify({
            'success': True,
            'count': len(records),
            'data': records
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/coin-price-tracker/history')
def api_coin_price_tracker_history():
    """å¸ä»·è¿½è¸ªå™¨ - æŸ¥è¯¢æŒ‡å®šæ—¶é—´èŒƒå›´çš„æ•°æ®(ä¸æŒ‡å®šæ—¶é—´åˆ™è¿”å›æœ€è¿‘7å¤©)"""
    try:
        from datetime import datetime, timedelta
        
        # è·å–å‚æ•°
        start_time = request.args.get('start_time', '')
        end_time = request.args.get('end_time', '')
        days = request.args.get('days', type=int, default=7)  # é»˜è®¤è¿”å›æœ€è¿‘7å¤©
        all_data = request.args.get('all', 'false').lower() == 'true'  # æ˜¯å¦è¿”å›å…¨éƒ¨æ•°æ®
        
        # è¯»å–JSONLæ–‡ä»¶
        jsonl_file = '/home/user/webapp/data/coin_price_tracker/coin_prices_30min.jsonl'
        
        if not os.path.exists(jsonl_file):
            return jsonify({
                'success': False,
                'error': 'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'
            })
        
        # å¦‚æœè¯·æ±‚å…¨éƒ¨æ•°æ®,ä¸åšæ—¶é—´è¿‡æ»¤
        if all_data:
            records = []
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        records.append(json.loads(line))
            
            return jsonify({
                'success': True,
                'count': len(records),
                'data': records
            })
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¶é—´èŒƒå›´,è®¡ç®—é»˜è®¤æ—¶é—´èŒƒå›´(æœ€è¿‘Nå¤©)
        if not start_time and not end_time:
            now = datetime.now()
            end_dt = now
            start_dt = now - timedelta(days=days)
            start_time = start_dt.strftime('%Y-%m-%d 00:00:00')
            end_time = end_dt.strftime('%Y-%m-%d 23:59:59')
        
        records = []
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    record = json.loads(line)
                    collect_time = record.get('collect_time', '')
                    
                    # è¿‡æ»¤æ—¶é—´èŒƒå›´
                    if start_time <= collect_time <= end_time:
                        records.append(record)
        
        response_data = {
            'success': True,
            'count': len(records),
            'data': records,
            'start_time': start_time,
            'end_time': end_time
        }
        
        return jsonify(response_data)
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/aligned-data/history')
def api_aligned_data_history():
    """è·å–å¯¹é½åçš„Coin Tracker + Escape Signalæ•°æ®"""
    try:
        # è·å–å‚æ•°
        start_time = request.args.get('start_time', '')
        end_time = request.args.get('end_time', '')
        limit = request.args.get('limit', type=int)
        
        # è¯»å–å¯¹é½æ•°æ®æ–‡ä»¶
        aligned_file = '/home/user/webapp/data/aligned_data_30min.jsonl'
        
        if not os.path.exists(aligned_file):
            return jsonify({
                'success': False,
                'error': 'å¯¹é½æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨,è¯·å…ˆè¿è¡Œ align_data_sources.py'
            })
        
        records = []
        with open(aligned_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    record = json.loads(line)
                    time_str = record.get('time', '')
                    
                    # æ—¶é—´è¿‡æ»¤
                    if start_time and end_time:
                        if start_time <= time_str <= end_time:
                            records.append(record)
                    else:
                        records.append(record)
        
        # æŒ‰æ—¶é—´æ’åº
        records.sort(key=lambda x: x['timestamp'])
        
        # é™åˆ¶æ•°é‡
        if limit and limit > 0:
            records = records[-limit:]
        
        response_data = {
            'success': True,
            'count': len(records),
            'data': records
        }
        
        if start_time and end_time:
            response_data['start_time'] = start_time
            response_data['end_time'] = end_time
        
        return jsonify(response_data)
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/history/<symbol>')
def api_sar_slope_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„SARæ–œç‡å†å²æ•°æ®(é»˜è®¤48å°æ—¶)"""
    try:
        days = int(request.args.get('days', 2))
        limit = int(request.args.get('limit', 600))
        
        # è®¡ç®—èµ·å§‹æ—¶é—´æˆ³
        start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                timestamp,
                datetime_beijing,
                sar_value,
                sar_position,
                sar_quadrant,
                position_duration,
                slope_value,
                slope_direction,
                price_open,
                price_close
            FROM sar_slope_data
            WHERE symbol = ? AND timestamp >= ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (symbol, start_time, limit))
        
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            results.append({
                'timestamp': row[0],
                'datetime': row[1],
                'sar_value': round(row[2], 6) if row[2] else None,
                'sar_position': row[3],
                'sar_quadrant': row[4],
                'position_duration': row[5],
                'slope_value': round(row[6], 4) if row[6] else None,
                'slope_direction': row[7],
                'price_open': round(row[8], 6) if row[8] else None,
                'price': round(row[9], 6) if row[9] else None
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'days': days,
            'data': results,
            'count': len(results)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/sar-slope/position-changes/<symbol>')
def api_sar_slope_position_changes(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„SARä½ç½®å˜åŒ–å†å²"""
    try:
        days = int(request.args.get('days', 7))
        start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾ä½ç½®å˜åŒ–ç‚¹
        cursor.execute("""
            WITH position_changes AS (
                SELECT 
                    timestamp,
                    datetime_beijing,
                    sar_value,
                    sar_position,
                    position_duration,
                    price_close,
                    LAG(sar_position) OVER (ORDER BY timestamp) as prev_position
                FROM sar_slope_data
                WHERE symbol = ? AND timestamp >= ?
            )
            SELECT 
                timestamp,
                datetime_beijing,
                sar_value,
                sar_position,
                position_duration,
                price_close
            FROM position_changes
            WHERE prev_position IS NULL OR sar_position != prev_position
            ORDER BY timestamp DESC
            LIMIT 100
        """, (symbol, start_time))
        
        rows = cursor.fetchall()
        
        results = []
        for row in rows:
            results.append({
                'timestamp': row[0],
                'datetime': row[1],
                'sar_value': round(row[2], 6) if row[2] else None,
                'position': row[3],
                'duration': row[4],
                'price': round(row[5], 6) if row[5] else None
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'days': days,
            'data': results,
            'count': len(results)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/sar-slope/collector-status')
def api_sar_slope_collector_status():
    """è·å–SARæ–œç‡é‡‡é›†å™¨çŠ¶æ€"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/crypto_data.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°æ•°æ®æ—¶é—´
        cursor.execute("""
            SELECT MAX(timestamp) FROM sar_slope_data
        """)
        
        latest_timestamp = cursor.fetchone()[0]
        
        if latest_timestamp:
            latest_dt = datetime.utcfromtimestamp(latest_timestamp / 1000)
            latest_dt_beijing = latest_dt.replace(tzinfo=pytz.UTC).astimezone(BEIJING_TZ)
            latest_time = latest_dt_beijing.strftime('%Y-%m-%d %H:%M:%S')
            
            # è®¡ç®—å»¶è¿Ÿ
            now = datetime.now(BEIJING_TZ)
            delay_minutes = (now - latest_dt_beijing).total_seconds() / 60
        else:
            latest_time = None
            delay_minutes = None
        
        # è·å–æ•°æ®ç»Ÿè®¡
        cursor.execute("""
            SELECT COUNT(*) FROM sar_slope_data
        """)
        total_records = cursor.fetchone()[0]
        
        # è·å–å„å¸ç§æ•°æ®é‡
        cursor.execute("""
            SELECT symbol, COUNT(*) as count
            FROM sar_slope_data
            GROUP BY symbol
            ORDER BY count DESC
        """)
        
        symbol_counts = [{'symbol': row[0], 'count': row[1]} for row in cursor.fetchall()]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'status': {
                'latest_time': latest_time,
                'delay_minutes': round(delay_minutes, 1) if delay_minutes else None,
                'is_delayed': delay_minutes > 10 if delay_minutes else True,
                'total_records': total_records,
                'symbol_counts': symbol_counts
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== Telegram é…ç½®ç®¡ç† API ====================

@app.route('/api/telegram/config', methods=['GET', 'POST'])
def telegram_config_api():
    """
    è·å–æˆ–æ›´æ–° Telegram é…ç½®
    GET: è¿”å›å½“å‰é…ç½®
    POST: æ›´æ–°é…ç½®
    """
    config_file = 'telegram_config.json'
    
    try:
        if request.method == 'GET':
            # è¯»å–å½“å‰é…ç½®
            if not os.path.exists(config_file):
                return jsonify({
                    'success': False,
                    'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                }), 404
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.json
            
            if not data:
                return jsonify({
                    'success': False,
                    'error': 'è¯·æä¾›é…ç½®æ•°æ®'
                }), 400
            
            # è¯»å–ç°æœ‰é…ç½®
            if not os.path.exists(config_file):
                return jsonify({
                    'success': False,
                    'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
                }), 404
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æ›´æ–°ä¿¡å·ç±»å‹çš„å¯ç”¨çŠ¶æ€
            if 'buy' in data:
                config['signal_types']['buy']['enabled'] = data['buy']
            if 'sell' in data:
                config['signal_types']['sell']['enabled'] = data['sell']
            if 'double_buy' in data:
                config['signal_types']['double_buy']['enabled'] = data['double_buy']
            if 'double_sell' in data:
                config['signal_types']['double_sell']['enabled'] = data['double_sell']
            
            # å¤‡ä»½åŸé…ç½®
            backup_file = f'telegram_config_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # ä¿å­˜æ–°é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'message': 'é…ç½®å·²æ›´æ–°',
                'config': config,
                'backup_file': backup_file
            })
            
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== èµ„é‡‘ç›‘æ§ç³»ç»Ÿ API ====================

@app.route('/api/fund-monitor/latest', methods=['GET'])
def fund_monitor_latest():
    """è·å–æœ€æ–°çš„èµ„é‡‘ç›‘æ§æ•°æ®(æ‰€æœ‰å¸ç§,æ‰€æœ‰æ—¶é—´å‘¨æœŸ)"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/fund_monitor.db')
        cursor = conn.cursor()
        
        # è·å–æ¯ä¸ªå¸ç§ã€æ¯ä¸ªæ—¶é—´å‘¨æœŸçš„æœ€æ–°æ•°æ®
        cursor.execute('''
            SELECT symbol, interval_type, timestamp, collect_time, volume, 
                   avg_3day, deviation_percent, is_abnormal
            FROM fund_monitor_aggregated
            WHERE (symbol, interval_type, timestamp) IN (
                SELECT symbol, interval_type, MAX(timestamp)
                FROM fund_monitor_aggregated
                GROUP BY symbol, interval_type
            )
            ORDER BY symbol, interval_type
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        # æŒ‰å¸ç§ç»„ç»‡æ•°æ®
        data_by_symbol = {}
        for row in rows:
            symbol = row[0]
            if symbol not in data_by_symbol:
                data_by_symbol[symbol] = {
                    '15min': None,
                    '30min': None,
                    '60min': None
                }
            
            interval_type = row[1]
            data_by_symbol[symbol][interval_type] = {
                'timestamp': row[2],
                'collect_time': row[3],
                'volume': round(row[4], 2),
                'avg_3day': round(row[5], 2) if row[5] is not None else None,
                'deviation_percent': round(row[6], 2) if row[6] is not None else None,
                'is_abnormal': bool(row[7])
            }
        
        return jsonify({
            'success': True,
            'data': data_by_symbol,
            'update_time': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/history/<symbol>', methods=['GET'])
def fund_monitor_history(symbol):
    """è·å–æŒ‡å®šå¸ç§çš„å†å²æ•°æ®"""
    try:
        interval_type = request.args.get('interval', '15min')  # é»˜è®¤15åˆ†é’Ÿ
        hours = int(request.args.get('hours', 24))  # é»˜è®¤24å°æ—¶
        
        conn = sqlite3.connect('/home/user/webapp/databases/fund_monitor.db')
        cursor = conn.cursor()
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_time = int(datetime.now(BEIJING_TZ).timestamp() * 1000)
        start_time = end_time - (hours * 60 * 60 * 1000)
        
        cursor.execute('''
            SELECT timestamp, collect_time, volume, avg_3day, 
                   deviation_percent, is_abnormal
            FROM fund_monitor_aggregated
            WHERE symbol = ?
            AND interval_type = ?
            AND timestamp >= ?
            ORDER BY timestamp ASC
        ''', (symbol.upper(), interval_type, start_time))
        
        rows = cursor.fetchall()
        conn.close()
        
        history = []
        for row in rows:
            history.append({
                'timestamp': row[0],
                'collect_time': row[1],
                'volume': round(row[2], 2),
                'avg_3day': round(row[3], 2) if row[3] is not None else None,
                'deviation_percent': round(row[4], 2) if row[4] is not None else None,
                'is_abnormal': bool(row[5])
            })
        
        return jsonify({
            'success': True,
            'symbol': symbol.upper(),
            'interval_type': interval_type,
            'hours': hours,
            'data': history
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal', methods=['GET'])
def fund_monitor_abnormal():
    """è·å–å½“å‰æ‰€æœ‰å¼‚å¸¸æ•°æ®"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/fund_monitor.db')
        cursor = conn.cursor()
        
        # è·å–æœ€æ–°å¼‚å¸¸æ•°æ®
        cursor.execute('''
            SELECT symbol, interval_type, timestamp, collect_time, 
                   volume, avg_3day, deviation_percent
            FROM fund_monitor_aggregated
            WHERE is_abnormal = 1
            AND (symbol, interval_type, timestamp) IN (
                SELECT symbol, interval_type, MAX(timestamp)
                FROM fund_monitor_aggregated
                WHERE is_abnormal = 1
                GROUP BY symbol, interval_type
            )
            ORDER BY ABS(deviation_percent) DESC
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        abnormal_list = []
        for row in rows:
            abnormal_list.append({
                'symbol': row[0],
                'interval_type': row[1],
                'timestamp': row[2],
                'collect_time': row[3],
                'volume': round(row[4], 2),
                'avg_3day': round(row[5], 2) if row[5] is not None else None,
                'deviation_percent': round(row[6], 2)
            })
        
        return jsonify({
            'success': True,
            'count': len(abnormal_list),
            'data': abnormal_list,
            'update_time': datetime.now(BEIJING_TZ).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/config', methods=['GET', 'POST'])
def fund_monitor_config():
    """è·å–æˆ–æ›´æ–°èµ„é‡‘ç›‘æ§é…ç½®"""
    config_file = 'fund_monitor_config.json'
    
    try:
        if request.method == 'GET':
            # è¯»å–é…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            else:
                config = {
                    'threshold_percentage': 20.0,
                    'lookback_days': 3,
                    'collection_interval': 300
                }
            
            return jsonify({
                'success': True,
                'config': config
            })
        
        elif request.method == 'POST':
            # æ›´æ–°é…ç½®
            data = request.json
            
            if not data:
                return jsonify({
                    'success': False,
                    'error': 'è¯·æä¾›é…ç½®æ•°æ®'
                }), 400
            
            # è¯»å–ç°æœ‰é…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            else:
                config = {
                    'threshold_percentage': 20.0,
                    'lookback_days': 3,
                    'collection_interval': 300
                }
            
            # æ›´æ–°é…ç½®
            if 'threshold_percentage' in data:
                config['threshold_percentage'] = float(data['threshold_percentage'])
            if 'lookback_days' in data:
                config['lookback_days'] = int(data['lookback_days'])
            if 'collection_interval' in data:
                config['collection_interval'] = int(data['collection_interval'])
            
            # ä¿å­˜é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            return jsonify({
                'success': True,
                'message': 'é…ç½®å·²æ›´æ–°',
                'config': config
            })
            
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal-history', methods=['GET'])
def fund_monitor_abnormal_history():
    """æŸ¥è¯¢å¼‚å¸¸æ•°æ®å†å²è®°å½•"""
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        date = request.args.get('date')  # æ ¼å¼:YYYY-MM-DD
        start_date = request.args.get('start_date')  # æ ¼å¼:YYYY-MM-DD
        end_date = request.args.get('end_date')  # æ ¼å¼:YYYY-MM-DD
        symbol = request.args.get('symbol')  # å¸ç§
        interval = request.args.get('interval')  # æ—¶é—´å‘¨æœŸ
        severity = request.args.get('severity')  # ä¸¥é‡ç¨‹åº¦
        deviation_type = request.args.get('type')  # surgeæˆ–drop
        limit = int(request.args.get('limit', 100))  # è¿”å›è®°å½•æ•°
        
        conn = sqlite3.connect('/home/user/webapp/databases/fund_monitor.db')
        cursor = conn.cursor()
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = []
        params = []
        
        if date:
            conditions.append('collect_date = ?')
            params.append(date)
        elif start_date and end_date:
            conditions.append('collect_date BETWEEN ? AND ?')
            params.extend([start_date, end_date])
        elif start_date:
            conditions.append('collect_date >= ?')
            params.append(start_date)
        elif end_date:
            conditions.append('collect_date <= ?')
            params.append(end_date)
        
        if symbol:
            conditions.append('symbol = ?')
            params.append(symbol.upper())
        
        if interval:
            conditions.append('interval_type = ?')
            params.append(interval)
        
        if severity:
            conditions.append('severity = ?')
            params.append(severity)
        
        if deviation_type:
            conditions.append('deviation_type = ?')
            params.append(deviation_type)
        
        where_clause = ' AND '.join(conditions) if conditions else '1=1'
        
        # æ‰§è¡ŒæŸ¥è¯¢
        query = f'''
            SELECT id, symbol, interval_type, timestamp, collect_time, collect_date,
                   volume, avg_3day, deviation_percent, deviation_type, severity
            FROM fund_monitor_abnormal_history
            WHERE {where_clause}
            ORDER BY timestamp DESC
            LIMIT ?
        '''
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        # æ ¼å¼åŒ–ç»“æœ
        history = []
        for row in rows:
            history.append({
                'id': row[0],
                'symbol': row[1],
                'interval_type': row[2],
                'timestamp': row[3],
                'collect_time': row[4],
                'collect_date': row[5],
                'volume': round(row[6], 2),
                'avg_3day': round(row[7], 2),
                'deviation_percent': round(row[8], 2),
                'deviation_type': row[9],
                'severity': row[10]
            })
        
        # ç»Ÿè®¡ä¿¡æ¯
        cursor.execute(f'''
            SELECT COUNT(*) FROM fund_monitor_abnormal_history
            WHERE {where_clause}
        ''', params[:-1])  # å»æ‰limitå‚æ•°
        total_count = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'total_count': total_count,
            'returned_count': len(history),
            'data': history
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal-dates', methods=['GET'])
def fund_monitor_abnormal_dates():
    """è·å–æœ‰å¼‚å¸¸æ•°æ®çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        conn = sqlite3.connect('/home/user/webapp/databases/fund_monitor.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æ‰€æœ‰æœ‰å¼‚å¸¸æ•°æ®çš„æ—¥æœŸåŠå…¶ç»Ÿè®¡
        cursor.execute('''
            SELECT collect_date, 
                   COUNT(*) as count,
                   COUNT(DISTINCT symbol) as affected_coins,
                   AVG(ABS(deviation_percent)) as avg_deviation
            FROM fund_monitor_abnormal_history
            GROUP BY collect_date
            ORDER BY collect_date DESC
        ''')
        
        rows = cursor.fetchall()
        
        dates = []
        for row in rows:
            dates.append({
                'date': row[0],
                'count': row[1],
                'affected_coins': row[2],
                'avg_deviation': round(row[3], 2)
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'dates': dates
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/fund-monitor/abnormal-timeline', methods=['GET'])
def fund_monitor_abnormal_timeline():
    """è·å–å¼‚å¸¸æ•°æ®æ—¶é—´è½´(æŒ‰å°æ—¶èšåˆ)"""
    try:
        date = request.args.get('date')  # YYYY-MM-DD
        
        if not date:
            return jsonify({
                'success': False,
                'error': 'è¯·æä¾›dateå‚æ•°'
            }), 400
        
        conn = sqlite3.connect('/home/user/webapp/databases/fund_monitor.db')
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰å¼‚å¸¸æ•°æ®
        cursor.execute('''
            SELECT symbol, interval_type, collect_time, volume, 
                   avg_3day, deviation_percent, deviation_type, severity
            FROM fund_monitor_abnormal_history
            WHERE collect_date = ?
            ORDER BY collect_time ASC
        ''', (date,))
        
        rows = cursor.fetchall()
        
        # æŒ‰å°æ—¶åˆ†ç»„
        timeline = {}
        for row in rows:
            collect_time = row[2]
            hour = collect_time[:13]  # YYYY-MM-DD HH
            
            if hour not in timeline:
                timeline[hour] = []
            
            timeline[hour].append({
                'symbol': row[0],
                'interval_type': row[1],
                'time': collect_time,
                'volume': round(row[3], 2),
                'avg_3day': round(row[4], 2),
                'deviation_percent': round(row[5], 2),
                'deviation_type': row[6],
                'severity': row[7]
            })
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        timeline_list = []
        for hour, events in sorted(timeline.items()):
            timeline_list.append({
                'hour': hour,
                'count': len(events),
                'events': events
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'date': date,
            'timeline': timeline_list
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/fund-monitor', methods=['GET'])
def fund_monitor_page():
    """èµ„é‡‘ç›‘æ§ç³»ç»Ÿå‰ç«¯é¡µé¢"""
    return render_template('fund_monitor.html')

@app.route('/fund-monitor-history', methods=['GET'])
def fund_monitor_history_page():
    """èµ„é‡‘ç›‘æ§å¼‚å¸¸å†å²æŸ¥è¯¢é¡µé¢"""
    return render_template('fund_monitor_history.html')

# ==================== SARæ–œç‡ç³»ç»Ÿè·¯ç”± ====================
# å·²åœ¨ä¸Šæ–¹å®šä¹‰,æ­¤å¤„åˆ é™¤é‡å¤è·¯ç”±

@app.route('/sar-slope/<symbol>')
def sar_slope_detail(symbol):
    """SARæ–œç‡å•å¸è¯¦ç»†è¿½è¸ªé¡µé¢"""
    response = make_response(render_template('sar_slope_detail.html', symbol=symbol.upper()))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/sar-slope/status')
def sar_slope_status():
    """è·å–æ‰€æœ‰å¸ç§çš„SARçŠ¶æ€ - ä»JSONLè¯»å–"""
    # æ£€æŸ¥æœåŠ¡å™¨ç«¯ç¼“å­˜
    cache_key = "sar_slope_status:all"
    cached_data = server_cache.get(cache_key, max_age=30)
    if cached_data:
        cached_data['_from_server_cache'] = True
        cached_data['_cache_age'] = int(time.time() - server_cache.timestamps.get(cache_key, 0))
        return jsonify(cached_data)
    
    try:
        import json
        from collections import defaultdict
        
        # è¯»å–æ–°SARé‡‡é›†å™¨å†™å…¥çš„ç›®å½•
        # æ–°é‡‡é›†å™¨sar_collector_fixed.pyå†™å…¥åˆ°/home/user/webapp/data/sar_jsonl/
        sar_jsonl_dir = '/home/user/webapp/data/sar_jsonl'
        
        if not os.path.exists(sar_jsonl_dir):
            return jsonify({
                'success': False,
                'error': 'SARæ•°æ®ç›®å½•ä¸å­˜åœ¨'
            })
        
        # è¯»å–æ¯ä¸ªå¸ç§çš„JSONLæ–‡ä»¶,è·å–æœ€æ–°è®°å½•
        status_dict = {}
        import glob
        
        # éå†æ‰€æœ‰å¸ç§çš„JSONLæ–‡ä»¶
        jsonl_files = glob.glob(os.path.join(sar_jsonl_dir, '*.jsonl'))
        
        for jsonl_file in jsonl_files:
            symbol = os.path.basename(jsonl_file).replace('.jsonl', '')
            
            try:
                # å…ˆè·å–æ–‡ä»¶æ€»è¡Œæ•°
                total_lines = 0
                with open(jsonl_file, 'r', encoding='utf-8') as f:
                    total_lines = sum(1 for line in f if line.strip())
                
                # è¯»å–æ–‡ä»¶æœ€åä¸€è¡Œ(æœ€æ–°è®°å½•)
                with open(jsonl_file, 'rb') as f:
                    # ä»æ–‡ä»¶æœ«å°¾è¯»å–
                    try:
                        f.seek(-2, os.SEEK_END)
                        while f.read(1) != b'\n':
                            f.seek(-2, os.SEEK_CUR)
                    except OSError:
                        f.seek(0)
                    last_line = f.readline().decode('utf-8')
                
                if last_line.strip():
                    record = json.loads(last_line)
                    
                    # ä»recordä¸­æå–éœ€è¦çš„å­—æ®µ(æ–°é‡‡é›†å™¨çš„å­—æ®µå)
                    status_dict[symbol] = {
                        'symbol': symbol,
                        'current_position': record.get('position', 'unknown'),  # bullish/bearish
                        'current_sequence': record.get('duration_minutes', 0),
                        'last_kline_time': record.get('beijing_time', ''),
                        'updated_at': record.get('beijing_time', ''),
                        'total_klines': total_lines,  # ä½¿ç”¨å®é™…æ–‡ä»¶è¡Œæ•°
                        'slope_direction': record.get('slope_direction', ''),
                        'slope_value': record.get('slope_value', 0)
                    }
            except Exception as e:
                # è·³è¿‡æœ‰é—®é¢˜çš„æ–‡ä»¶
                continue
        
        status_list = list(status_dict.values())
        
        result = {
            'success': True,
            'count': len(status_list),
            'data': status_list,
            '_from_server_cache': False
        }
        
        # ç¼“å­˜30ç§’
        server_cache.set(cache_key, result)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })
        
        status_list = []
        for jsonl_file in sorted(jsonl_files):
            # ä»æ–‡ä»¶åæå–å¸ç§ç¬¦å·
            symbol = jsonl_file.split('/')[-1].replace('.jsonl', '')
            
            try:
                manager = SARJSONLManager(symbol)
                latest_status = manager.get_latest_status()
                
                if latest_status:
                    # è·å–æ€»è®°å½•æ•°
                    all_records = manager.read_records(limit=None)
                    total_klines = len(all_records) if all_records else 0
                    
                    status_list.append({
                        'symbol': symbol,
                        'last_kline_time': latest_status.get('last_update_time', ''),
                        'total_klines': total_klines,
                        'current_position': latest_status.get('current_position', ''),
                        'current_sequence': latest_status.get('current_sequence', 0),
                        'updated_at': latest_status.get('last_update_time', '')
                    })
            except Exception as e:
                # è·³è¿‡æœ‰é—®é¢˜çš„æ–‡ä»¶
                continue
        
        result = {
            'success': True,
            'data': status_list,
            'count': len(status_list)
        }
        
        # ä¿å­˜åˆ°æœåŠ¡å™¨ç«¯ç¼“å­˜
        server_cache.set(cache_key, result)
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/symbol/<symbol>')
def sar_slope_symbol_data(symbol):
    """è·å–å•ä¸ªå¸ç§çš„è¯¦ç»†SARæ•°æ®"""
    try:
        limit = request.args.get('limit', 500, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        # è·å–åŸå§‹SARæ•°æ®
        cursor.execute('''
            SELECT timestamp, kline_time, open_price, high_price, low_price, 
                   close_price, sar_value, position, position_sequence, duration_minutes
            FROM sar_raw_data
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT ?
        ''', (symbol, limit))
        
        sar_data = []
        for row in cursor.fetchall():
            sar_data.append({
                'timestamp': row[0],
                'kline_time': row[1],
                'open': row[2],
                'high': row[3],
                'low': row[4],
                'close': row[5],
                'sar': row[6],
                'position': row[7],
                'sequence': row[8],
                'duration': row[9]
            })
        
        # è·å–å˜åŒ–ç‡æ•°æ®
        cursor.execute('''
            SELECT sequence_num, prev_sar, current_sar, change_value, 
                   change_percent, kline_time, position
            FROM sar_consecutive_changes
            WHERE symbol = ?
            ORDER BY id DESC
            LIMIT ?
        ''', (symbol, limit))
        
        changes = []
        for row in cursor.fetchall():
            changes.append({
                'sequence': row[0],
                'prev_sar': row[1],
                'current_sar': row[2],
                'change_value': row[3],
                'change_percent': row[4],
                'time': row[5],
                'position': row[6]
            })
        
        # è·å–å¹³å‡å€¼
        cursor.execute('''
            SELECT position, period_type, avg_change_percent, sample_count
            FROM sar_period_averages
            WHERE symbol = ?
        ''', (symbol,))
        
        averages = {}
        for row in cursor.fetchall():
            pos = row[0]
            if pos not in averages:
                averages[pos] = {}
            averages[pos][row[1]] = {
                'avg': row[2],
                'samples': row[3]
            }
        
        # è·å–æœ€è¿‘å¼‚å¸¸
        cursor.execute('''
            SELECT position, sequence_num, sar_value, change_percent,
                   deviation_percent, alert_level, is_extreme_point, kline_time
            FROM sar_anomaly_alerts
            WHERE symbol = ?
            ORDER BY created_at DESC
            LIMIT 100
        ''', (symbol,))
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'position': row[0],
                'sequence': row[1],
                'sar': row[2],
                'change_percent': row[3],
                'deviation': row[4],
                'level': row[5],
                'is_extreme': row[6],
                'time': row[7]
            })
        
        # è·å–è½¬æ¢ç‚¹
        cursor.execute('''
            SELECT timestamp, kline_time, from_position, to_position,
                   conversion_sar, conversion_price, previous_duration
            FROM sar_conversion_points
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT 50
        ''', (symbol,))
        
        conversions = []
        for row in cursor.fetchall():
            conversions.append({
                'timestamp': row[0],
                'time': row[1],
                'from_position': row[2],
                'to_position': row[3],
                'sar': row[4],
                'price': row[5],
                'prev_duration': row[6]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'sar_data': sar_data,
            'changes': changes,
            'averages': averages,
            'alerts': alerts,
            'conversions': conversions
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/alerts')
def sar_slope_alerts():
    """è·å–æ‰€æœ‰å¼‚å¸¸å‘Šè­¦"""
    try:
        limit = request.args.get('limit', 50, type=int)
        symbol = request.args.get('symbol', None)
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        if symbol:
            cursor.execute('''
                SELECT symbol, position, sequence_num, sar_value,
                       change_percent, deviation_percent, alert_level,
                       is_extreme_point, extreme_type, kline_time
                FROM sar_anomaly_alerts
                WHERE symbol = ?
                ORDER BY created_at DESC
                LIMIT ?
            ''', (symbol, limit))
        else:
            cursor.execute('''
                SELECT symbol, position, sequence_num, sar_value,
                       change_percent, deviation_percent, alert_level,
                       is_extreme_point, extreme_type, kline_time
                FROM sar_anomaly_alerts
                ORDER BY created_at DESC
                LIMIT ?
            ''', (limit,))
        
        alerts = []
        for row in cursor.fetchall():
            alerts.append({
                'symbol': row[0],
                'position': row[1],
                'sequence': row[2],
                'sar': row[3],
                'change_percent': row[4],
                'deviation': row[5],
                'level': row[6],
                'is_extreme': row[7],
                'extreme_type': row[8],
                'time': row[9]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': alerts,
            'count': len(alerts)
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/1min-data')
def sar_1min_data():
    """è·å–1åˆ†é’Ÿçº§åˆ«çš„SARæ•°æ®"""
    try:
        import json
        from pathlib import Path
        from datetime import datetime, timedelta
        import pytz
        
        symbol = request.args.get('symbol', 'BTC')
        hours = request.args.get('hours', 1, type=int)  # é»˜è®¤è¿”å›æœ€è¿‘1å°æ—¶çš„æ•°æ®
        
        beijing_tz = pytz.timezone('Asia/Shanghai')
        data_dir = Path('/home/user/webapp/data/sar_1min')
        
        # è®¡ç®—éœ€è¦è¯»å–çš„æ—¥æœŸèŒƒå›´
        now = datetime.now(beijing_tz)
        start_time = now - timedelta(hours=hours)
        
        # å¯èƒ½è·¨è¶Šä¸¤å¤©,éœ€è¦è¯»å–ä»Šå¤©å’Œæ˜¨å¤©çš„æ–‡ä»¶
        dates_to_check = []
        current_date = start_time.date()
        end_date = now.date()
        
        while current_date <= end_date:
            dates_to_check.append(current_date.strftime('%Y%m%d'))
            current_date += timedelta(days=1)
        
        # è¯»å–æ•°æ®
        all_records = []
        for date_str in dates_to_check:
            file_path = data_dir / f'sar_1min_{date_str}.jsonl'
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            record = json.loads(line)
                            if record['symbol'] == symbol:
                                all_records.append(record)
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        filtered_records = []
        for record in all_records:
            try:
                record_time = datetime.fromisoformat(record['collected_at'])
                if record_time >= start_time:
                    filtered_records.append(record)
            except:
                continue
        
        # æŒ‰æ—¶é—´æ’åº
        filtered_records.sort(key=lambda x: x['collected_at'])
        
        return jsonify({
            'success': True,
            'symbol': symbol,
            'hours': hours,
            'count': len(filtered_records),
            'data': filtered_records
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/sar-slope/chart')
def sar_slope_chart():
    """SARæ–œç‡æ›²çº¿å›¾é¡µé¢"""
    response = make_response(render_template('sar_slope_chart.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/sar-slope/bias-chart')
def sar_bias_chart():
    """SARåå‘ç»Ÿè®¡æ›²çº¿å›¾é¡µé¢"""
    response = make_response(render_template('sar_bias_chart.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/api/sar-slope/conversions')
def sar_slope_conversions():
    """è·å–å¤šç©ºè½¬æ¢ç‚¹"""
    try:
        limit = request.args.get('limit', 50, type=int)
        symbol = request.args.get('symbol', None)
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        if symbol:
            cursor.execute('''
                SELECT symbol, timestamp, kline_time, from_position, to_position,
                       conversion_sar, conversion_price, previous_duration
                FROM sar_conversion_points
                WHERE symbol = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (symbol, limit))
        else:
            cursor.execute('''
                SELECT symbol, timestamp, kline_time, from_position, to_position,
                       conversion_sar, conversion_price, previous_duration
                FROM sar_conversion_points
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (limit,))
        
        conversions = []
        for row in cursor.fetchall():
            conversions.append({
                'symbol': row[0],
                'timestamp': row[1],
                'time': row[2],
                'from_position': row[3],
                'to_position': row[4],
                'sar': row[5],
                'price': row[6],
                'prev_duration': row[7]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': conversions,
            'count': len(conversions)
        })
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/sar-slope/query/<symbol>')
def sar_slope_query_symbol(symbol):
    """
    å®Œæ•´çš„å•å¸æŸ¥è¯¢æ¥å£
    æŸ¥è¯¢å‚æ•°:
    - start_time: å¼€å§‹æ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)
    - end_time: ç»“æŸæ—¶é—´ (æ ¼å¼: YYYY-MM-DD HH:MM:SS)
    - limit: è¿”å›æ•°é‡é™åˆ¶ (é»˜è®¤: 1000)
    - position: ç­›é€‰å¤šç©ºçŠ¶æ€ (long/short)
    - include_changes: æ˜¯å¦åŒ…å«å˜åŒ–ç‡ (true/false, é»˜è®¤: true)
    - include_alerts: æ˜¯å¦åŒ…å«å¼‚å¸¸å‘Šè­¦ (true/false, é»˜è®¤: true)
    - include_conversions: æ˜¯å¦åŒ…å«å¤šç©ºè½¬æ¢ (true/false, é»˜è®¤: true)
    - include_averages: æ˜¯å¦åŒ…å«å‘¨æœŸå¹³å‡å€¼ (true/false, é»˜è®¤: true)
    """
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        start_time = request.args.get('start_time', None)
        end_time = request.args.get('end_time', None)
        limit = request.args.get('limit', 1000, type=int)
        position = request.args.get('position', None)  # long/short
        
        include_changes = request.args.get('include_changes', 'true').lower() == 'true'
        include_alerts = request.args.get('include_alerts', 'true').lower() == 'true'
        include_conversions = request.args.get('include_conversions', 'true').lower() == 'true'
        include_averages = request.args.get('include_averages', 'true').lower() == 'true'
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'query_params': {
                'start_time': start_time,
                'end_time': end_time,
                'limit': limit,
                'position': position
            }
        }
        
        # 1. è·å–ç³»ç»ŸçŠ¶æ€
        cursor.execute('''
            SELECT last_update_time, last_kline_time, total_klines,
                   current_position, current_sequence, status, updated_at
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status_row = cursor.fetchone()
        if status_row:
            result['system_status'] = {
                'last_update_time': status_row[0],
                'last_kline_time': status_row[1],
                'total_klines': status_row[2],
                'current_position': status_row[3],
                'current_sequence': status_row[4],
                'status': status_row[5],
                'updated_at': status_row[6]
            }
        else:
            return jsonify({
                'success': False,
                'error': f'Symbol {symbol.upper()} not found in system'
            })
        
        # 2. æ„å»ºåŸå§‹æ•°æ®æŸ¥è¯¢SQL
        sql_conditions = ["symbol = ?"]
        sql_params = [symbol.upper()]
        
        if start_time:
            # è½¬æ¢æ—¶é—´å­—ç¬¦ä¸²ä¸ºæ—¶é—´æˆ³
            from datetime import datetime
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            dt = beijing_tz.localize(datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S'))
            timestamp = int(dt.timestamp() * 1000)
            sql_conditions.append("timestamp >= ?")
            sql_params.append(timestamp)
        
        if end_time:
            from datetime import datetime
            import pytz
            beijing_tz = pytz.timezone('Asia/Shanghai')
            dt = beijing_tz.localize(datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S'))
            timestamp = int(dt.timestamp() * 1000)
            sql_conditions.append("timestamp <= ?")
            sql_params.append(timestamp)
        
        if position:
            sql_conditions.append("position = ?")
            sql_params.append(position)
        
        # è·å–åŸå§‹SARæ•°æ®
        cursor.execute(f'''
            SELECT timestamp, kline_time, open_price, high_price, low_price,
                   close_price, sar_value, position, position_sequence, duration_minutes
            FROM sar_raw_data
            WHERE {' AND '.join(sql_conditions)}
            ORDER BY timestamp DESC
            LIMIT ?
        ''', sql_params + [limit])
        
        sar_data = []
        for row in cursor.fetchall():
            sar_data.append({
                'timestamp': row[0],
                'kline_time': row[1],
                'open': row[2],
                'high': row[3],
                'low': row[4],
                'close': row[5],
                'sar': row[6],
                'position': row[7],
                'sequence': row[8],
                'duration': row[9]
            })
        
        result['sar_data'] = {
            'count': len(sar_data),
            'data': sar_data
        }
        
        # 3. è·å–å˜åŒ–ç‡æ•°æ®(å¦‚æœéœ€è¦)
        if include_changes:
            change_conditions = ["symbol = ?"]
            change_params = [symbol.upper()]
            
            if position:
                change_conditions.append("position = ?")
                change_params.append(position)
            
            cursor.execute(f'''
                SELECT sequence_num, prev_sar, current_sar, change_value,
                       change_percent, kline_time, position
                FROM sar_consecutive_changes
                WHERE {' AND '.join(change_conditions)}
                ORDER BY id DESC
                LIMIT ?
            ''', change_params + [limit])
            
            changes = []
            for row in cursor.fetchall():
                changes.append({
                    'sequence': row[0],
                    'prev_sar': row[1],
                    'current_sar': row[2],
                    'change_value': row[3],
                    'change_percent': row[4],
                    'time': row[5],
                    'position': row[6]
                })
            
            result['changes'] = {
                'count': len(changes),
                'data': changes
            }
        
        # 4. è·å–å‘¨æœŸå¹³å‡å€¼(å¦‚æœéœ€è¦)
        if include_averages:
            cursor.execute('''
                SELECT position, period_type, avg_change_percent, 
                       sample_count, calculated_at
                FROM sar_period_averages
                WHERE symbol = ?
                ORDER BY position, period_type
            ''', (symbol.upper(),))
            
            averages = {
                'long': {},
                'short': {}
            }
            
            for row in cursor.fetchall():
                pos = row[0]
                period = row[1]
                averages[pos][period] = {
                    'avg_change_percent': row[2],
                    'sample_count': row[3],
                    'calculated_at': row[4]
                }
            
            result['averages'] = averages
        
        # 5. è·å–å¼‚å¸¸å‘Šè­¦(å¦‚æœéœ€è¦)
        if include_alerts:
            alert_conditions = ["symbol = ?"]
            alert_params = [symbol.upper()]
            
            if position:
                alert_conditions.append("position = ?")
                alert_params.append(position)
            
            cursor.execute(f'''
                SELECT position, sequence_num, sar_value, change_percent,
                       period_avg, deviation_percent, alert_level,
                       is_extreme_point, extreme_type, kline_time, created_at
                FROM sar_anomaly_alerts
                WHERE {' AND '.join(alert_conditions)}
                ORDER BY created_at DESC
                LIMIT ?
            ''', alert_params + [min(limit, 200)])
            
            alerts = []
            for row in cursor.fetchall():
                alerts.append({
                    'position': row[0],
                    'sequence': row[1],
                    'sar': row[2],
                    'change_percent': row[3],
                    'period_avg': row[4],
                    'deviation': row[5],
                    'level': row[6],
                    'is_extreme': row[7],
                    'extreme_type': row[8],
                    'time': row[9],
                    'created_at': row[10]
                })
            
            result['alerts'] = {
                'count': len(alerts),
                'data': alerts
            }
        
        # 6. è·å–å¤šç©ºè½¬æ¢ç‚¹(å¦‚æœéœ€è¦)
        if include_conversions:
            cursor.execute('''
                SELECT timestamp, kline_time, from_position, to_position,
                       conversion_sar, conversion_price, previous_duration, created_at
                FROM sar_conversion_points
                WHERE symbol = ?
                ORDER BY timestamp DESC
                LIMIT ?
            ''', (symbol.upper(), min(limit, 100)))
            
            conversions = []
            for row in cursor.fetchall():
                conversions.append({
                    'timestamp': row[0],
                    'time': row[1],
                    'from_position': row[2],
                    'to_position': row[3],
                    'sar': row[4],
                    'price': row[5],
                    'prev_duration': row[6],
                    'created_at': row[7]
                })
            
            result['conversions'] = {
                'count': len(conversions),
                'data': conversions
            }
        
        # 7. ç»Ÿè®¡ä¿¡æ¯
        result['statistics'] = {
            'total_records': len(sar_data),
            'date_range': {
                'earliest': sar_data[-1]['kline_time'] if sar_data else None,
                'latest': sar_data[0]['kline_time'] if sar_data else None
            }
        }
        
        # è®¡ç®—å¤šç©ºåˆ†å¸ƒ
        if sar_data:
            long_count = sum(1 for d in sar_data if d['position'] == 'bullish')
            short_count = sum(1 for d in sar_data if d['position'] == 'bearish')
            result['statistics']['position_distribution'] = {
                'long': long_count,
                'short': short_count,
                'long_percent': round(long_count / len(sar_data) * 100, 2),
                'short_percent': round(short_count / len(sar_data) * 100, 2)
            }
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/sequence-compare/<symbol>')
def sar_slope_sequence_compare(symbol):
    """
    åºåˆ—å·å¯¹æ¯”æ¥å£ - ç”¨æˆ·éœ€æ±‚
    å¯¹æ¯”å½“å‰åºåˆ—å·çš„å˜åŒ–ç‡ä¸è¯¥åºåˆ—å·çš„å†å²å¹³å‡å€¼
    
    ä¾‹å¦‚:å½“å‰æ˜¯ç©ºå¤´02â†’ç©ºå¤´03,å˜åŒ–ç‡æ˜¯0.05%
    æŸ¥è¯¢æ‰€æœ‰å†å²ä¸Š"ç©ºå¤´02â†’ç©ºå¤´03"è¿™ä¸€æ­¥çš„å¹³å‡å˜åŒ–ç‡æ˜¯0.04%
    å¾—å‡ºç»“è®º:å½“å‰æ¯”å¹³å‡å€¼å¢åŠ äº†0.01%
    
    å‚æ•°:
    - position: long/short (å¯é€‰,ä¸å¡«åˆ™è¿”å›ä¸¤ä¸ªæ–¹å‘)
    - sequence: åºåˆ—å· (å¯é€‰,ä¸å¡«åˆ™è¿”å›æ‰€æœ‰åºåˆ—å·)
    """
    try:
        position_filter = request.args.get('position', None)
        sequence_filter = request.args.get('sequence', None, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'comparisons': []
        }
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        result['current_status'] = {
            'position': status[0],
            'sequence': status[1]
        }
        
        # è·å–å½“å‰æœ€æ–°çš„å˜åŒ–ç‡
        cursor.execute('''
            SELECT sequence_num, change_percent, kline_time, position
            FROM sar_consecutive_changes
            WHERE symbol = ?
            ORDER BY id DESC
            LIMIT 50
        ''', (symbol.upper(),))
        
        recent_changes = cursor.fetchall()
        
        # è·å–åºåˆ—å·å¹³å‡å€¼
        cursor.execute('''
            SELECT position, period_type, avg_change_percent, sample_count
            FROM sar_period_averages
            WHERE symbol = ? AND period_type LIKE 'seq_%'
            ORDER BY position, period_type
        ''', (symbol.upper(),))
        
        seq_averages = {}
        for row in cursor.fetchall():
            pos = row[0]
            period = row[1]  # æ ¼å¼: seq_01, seq_02, seq_03
            seq_num = int(period.split('_')[1])
            
            if pos not in seq_averages:
                seq_averages[pos] = {}
            
            seq_averages[pos][seq_num] = {
                'avg': row[2],
                'samples': row[3]
            }
        
        # å¯¹æ¯”åˆ†æ
        for change in recent_changes:
            seq_num = change[0]
            current_change = change[1]
            kline_time = change[2]
            pos = change[3]
            
            # è¿‡æ»¤æ¡ä»¶
            if position_filter and pos != position_filter:
                continue
            if sequence_filter and seq_num != sequence_filter:
                continue
            
            # è·å–è¯¥åºåˆ—å·çš„å†å²å¹³å‡å€¼
            if pos in seq_averages and seq_num in seq_averages[pos]:
                avg_data = seq_averages[pos][seq_num]
                avg_change = avg_data['avg']
                samples = avg_data['samples']
                
                # è®¡ç®—å·®å¼‚
                difference = current_change - avg_change
                difference_percent = (difference / avg_change * 100) if avg_change != 0 else 0
                
                # åˆ¤æ–­å¢åŠ è¿˜æ˜¯å‡å°
                trend = 'increase' if difference > 0 else 'decrease' if difference < 0 else 'equal'
                
                result['comparisons'].append({
                    'position': pos,
                    'sequence': seq_num,
                    'time': kline_time,
                    'current_change': round(current_change, 6),
                    'average_change': round(avg_change, 6),
                    'difference': round(difference, 6),
                    'difference_percent': round(difference_percent, 2),
                    'trend': trend,
                    'sample_count': samples,
                    'description': f'{"å¤šå¤´" if pos == "long" else "ç©ºå¤´"}{seq_num:02d}â†’{seq_num+1:02d}'
                })
        
        result['total_comparisons'] = len(result['comparisons'])
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/duration-signal/<symbol>')
def sar_slope_duration_signal(symbol):
    """
    æŒ‰æŒç»­æ—¶é—´æ®µåˆ†æä¿¡å· - ç”¨æˆ·æœ€æ–°éœ€æ±‚
    
    å¯¹æ¯”é€»è¾‘:
    - å¤šå¤´åŒºé—´:
      * 1å¤©å¹³å‡ < 3å¤©å¹³å‡(æ¯”å€¼å‡å°)â†’ å¼ºåŠ¿å¤šå¤´ä¿¡å·(åå¤š)
      * 1å¤©å¹³å‡ > 3å¤©å¹³å‡(æ¯”å€¼å¢å¤§)â†’ åŠ é€Ÿèµ¶é¡¶ä¿¡å·(åç©º)
    - ç©ºå¤´åŒºé—´:
      * 1å¤©å¹³å‡ < 3å¤©å¹³å‡(æ¯”å€¼å‡å°)â†’ å¼ºåŠ¿ç©ºå¤´ä¿¡å·(åç©º)
      * 1å¤©å¹³å‡ > 3å¤©å¹³å‡(æ¯”å€¼å¢å¤§)â†’ åŠ é€Ÿèµ¶åº•ä¿¡å·(åå¤š)
    
    å‚æ•°:
    - position: long/short (å¯é€‰,ä¸å¡«åˆ™è¿”å›ä¸¤ä¸ªæ–¹å‘)
    - duration: æŒç»­æ—¶é—´(åˆ†é’Ÿ,å¯é€‰)
    """
    try:
        position_filter = request.args.get('position', None)
        duration_filter = request.args.get('duration', None, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'signals': []
        }
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        result['current_status'] = {
            'position': status[0],
            'sequence': status[1]
        }
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = ["symbol = ?", "period_type LIKE 'dur_%'"]
        params = [symbol.upper()]
        
        if position_filter:
            conditions.append("position = ?")
            params.append(position_filter)
        
        # è·å–æ‰€æœ‰ duration çš„å¹³å‡å€¼æ•°æ®
        cursor.execute(f'''
            SELECT position, period_type, avg_change_percent, sample_count
            FROM sar_period_averages
            WHERE {' AND '.join(conditions)}
            ORDER BY position, period_type
        ''', params)
        
        # ç»„ç»‡æ•°æ®ç»“æ„: {position: {duration: {period: avg}}}
        duration_data = {}
        for row in cursor.fetchall():
            pos = row[0]
            period_type = row[1]  # æ ¼å¼: dur_15_1day
            avg_pct = row[2]
            sample_count = row[3]
            
            # è§£æ period_type
            parts = period_type.split('_')
            if len(parts) != 3:
                continue
            
            duration = int(parts[1])
            period = parts[2]  # 1day, 3day, 7day, 15day
            
            # è¿‡æ»¤ duration
            if duration_filter and duration != duration_filter:
                continue
            
            if pos not in duration_data:
                duration_data[pos] = {}
            if duration not in duration_data[pos]:
                duration_data[pos][duration] = {}
            
            duration_data[pos][duration][period] = {
                'avg': avg_pct,
                'samples': sample_count
            }
        
        # åˆ†ææ¯ä¸ª position å’Œ duration çš„ä¿¡å·
        for pos in duration_data:
            for duration in sorted(duration_data[pos].keys()):
                periods = duration_data[pos][duration]
                
                # å¿…é¡»æœ‰ 1day å’Œ 3day æ•°æ®æ‰èƒ½å¯¹æ¯”
                if '1day' not in periods or '3day' not in periods:
                    continue
                
                avg_1day = periods['1day']['avg']
                avg_3day = periods['3day']['avg']
                avg_7day = periods.get('7day', {}).get('avg', None)
                avg_15day = periods.get('15day', {}).get('avg', None)
                
                # è®¡ç®—æ¯”å€¼
                ratio = (avg_1day / avg_3day) if avg_3day != 0 else 1.0
                ratio_change = avg_1day - avg_3day
                ratio_change_percent = ((avg_1day - avg_3day) / avg_3day * 100) if avg_3day != 0 else 0
                
                # æ ¹æ®ç”¨æˆ·é€»è¾‘åˆ¤æ–­ä¿¡å·
                if pos == 'long':
                    if avg_1day < avg_3day:  # æ¯”å€¼å‡å°
                        signal_type = 'strong_long'
                        signal_desc = 'å¼ºåŠ¿å¤šå¤´'
                        bias = 'bullish'  # åå¤š
                        interpretation = 'å½“å¤©å¹³å‡ < 3å¤©å¹³å‡,å˜åŒ–ç‡å‡å°,è¶‹åŠ¿å¼ºåŠ²'
                    else:  # æ¯”å€¼å¢å¤§
                        signal_type = 'top_acceleration'
                        signal_desc = 'åŠ é€Ÿèµ¶é¡¶'
                        bias = 'bearish'  # åç©º
                        interpretation = 'å½“å¤©å¹³å‡ > 3å¤©å¹³å‡,å˜åŒ–ç‡å¢å¤§,å¯èƒ½è§é¡¶'
                else:  # short
                    if avg_1day < avg_3day:  # æ¯”å€¼å‡å°
                        signal_type = 'strong_short'
                        signal_desc = 'å¼ºåŠ¿ç©ºå¤´'
                        bias = 'bearish'  # åç©º
                        interpretation = 'å½“å¤©å¹³å‡ < 3å¤©å¹³å‡,å˜åŒ–ç‡å‡å°,è¶‹åŠ¿å¼ºåŠ²'
                    else:  # æ¯”å€¼å¢å¤§
                        signal_type = 'bottom_acceleration'
                        signal_desc = 'åŠ é€Ÿèµ¶åº•'
                        bias = 'bullish'  # åå¤š
                        interpretation = 'å½“å¤©å¹³å‡ > 3å¤©å¹³å‡,å˜åŒ–ç‡å¢å¤§,å¯èƒ½è§åº•'
                
                signal = {
                    'position': pos,
                    'duration_minutes': duration,
                    'averages': {
                        '1day': round(avg_1day, 6),
                        '3day': round(avg_3day, 6),
                        '7day': round(avg_7day, 6) if avg_7day else None,
                        '15day': round(avg_15day, 6) if avg_15day else None
                    },
                    'comparison': {
                        'ratio': round(ratio, 4),
                        'change': round(ratio_change, 6),
                        'change_percent': round(ratio_change_percent, 2)
                    },
                    'signal': {
                        'type': signal_type,
                        'description': signal_desc,
                        'bias': bias,
                        'interpretation': interpretation
                    },
                    'sample_counts': {
                        '1day': periods['1day']['samples'],
                        '3day': periods['3day']['samples'],
                        '7day': periods.get('7day', {}).get('samples', None),
                        '15day': periods.get('15day', {}).get('samples', None)
                    }
                }
                
                result['signals'].append(signal)
        
        result['total_signals'] = len(result['signals'])
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/transition-analysis/<symbol>')
def sar_slope_transition_analysis(symbol):
    """
    å¤šç©ºè½¬æ¢åˆ†ææ¥å£ - ç”¨æˆ·æœ€æ–°éœ€æ±‚
    
    æ ¸å¿ƒé€»è¾‘:
    1. è®°å½•æ¯ä¸ª5åˆ†é’Ÿçš„å¤šç©ºè½¬æ¢ç‚¹(ä¿ç•™16å¤©æ•°æ®)
    2. å¤šå¤´å…³æ³¨ sequence_num=2 (01â†’02,ç›¸å½“äº03â†’02çš„å˜åŒ–)
    3. ç©ºå¤´å…³æ³¨ sequence_num=2 (01â†’02,ç›¸å½“äº02â†’03çš„å˜åŒ–)
    4. è®¡ç®— å½“å¤©/3å¤©/7å¤©/15å¤© å¹³å‡å€¼
    5. å¯¹æ¯”å½“å‰å€¼ä¸å¹³å‡å€¼çš„å·®å€¼ç™¾åˆ†æ¯”
    6. åˆ¤æ–­åå¤š/åç©ºçŠ¶æ€
    
    å‚æ•°:
    - position: long/short (å¯é€‰)
    """
    try:
        position_filter = request.args.get('position', None)
        
        conn = sqlite3.connect('/home/user/webapp/databases/sar_slope_data.db', timeout=10.0)
        cursor = conn.cursor()
        
        result = {
            'success': True,
            'symbol': symbol.upper(),
            'analysis': {}
        }
        
        # è·å–å½“å‰çŠ¶æ€
        cursor.execute('''
            SELECT current_position, current_sequence, last_kline_time
            FROM system_status
            WHERE symbol = ?
        ''', (symbol.upper(),))
        
        status = cursor.fetchone()
        if not status:
            return jsonify({'success': False, 'error': 'Symbol not found'})
        
        # è·å–å½“å‰ä»·æ ¼å’ŒæŒç»­æ—¶é—´
        cursor.execute('''
            SELECT close_price, duration_minutes
            FROM sar_raw_data
            WHERE symbol = ?
            ORDER BY timestamp DESC
            LIMIT 1
        ''', (symbol.upper(),))
        
        price_data = cursor.fetchone()
        current_price = price_data[0] if price_data else None
        current_duration = price_data[1] if price_data else None
        
        result['current_status'] = {
            'position': status[0],
            'sequence': status[1],
            'last_update': status[2],
            'current_price': round(current_price, 2) if current_price else None,
            'duration_minutes': current_duration
        }
        
        # å¯¹æ¯ä¸ªæ–¹å‘è¿›è¡Œåˆ†æ
        positions = [position_filter] if position_filter else ['long', 'short']
        
        for pos in positions:
            # è·å–è¯¥æ–¹å‘ sequence_num=2 çš„æ‰€æœ‰å˜åŒ–ç‡æ•°æ®(æŒ‰æ—¶é—´é™åº)
            cursor.execute('''
                SELECT change_percent, kline_time, id
                FROM sar_consecutive_changes
                WHERE symbol = ? AND position = ? AND sequence_num = 2
                ORDER BY id DESC
            ''', (symbol.upper(), pos))
            
            changes = cursor.fetchall()
            
            if not changes:
                continue
            
            # å½“å‰æœ€æ–°å€¼
            current_value = changes[0][0]
            current_time = changes[0][1]
            
            # æå–æ‰€æœ‰å˜åŒ–ç‡(ä»æ—§åˆ°æ–°)
            all_changes = [c[0] for c in reversed(changes)]
            
            # è®¡ç®—å„å‘¨æœŸå¹³å‡å€¼
            periods = {
                '1day': 288,   # 24å°æ—¶ * 12ä¸ª5åˆ†é’Ÿ
                '3day': 864,   # 3 * 24 * 12
                '7day': 2016,  # 7 * 24 * 12
                '15day': 4320  # 15 * 24 * 12
            }
            
            period_averages = {}
            for period_name, period_count in periods.items():
                if len(all_changes) >= period_count:
                    period_changes = all_changes[-period_count:]
                else:
                    period_changes = all_changes
                
                if period_changes:
                    avg = sum(period_changes) / len(period_changes)
                    period_averages[period_name] = {
                        'average': avg,
                        'sample_count': len(period_changes)
                    }
            
            # å¯¹æ¯”å½“å‰å€¼ä¸å„å‘¨æœŸå¹³å‡å€¼
            comparisons = {}
            for period_name, period_data in period_averages.items():
                avg = period_data['average']
                diff = current_value - avg
                diff_percent = (diff / avg * 100) if avg != 0 else 0
                
                # åˆ¤æ–­è¶‹åŠ¿
                if diff > 0:
                    trend = 'increased'  # å¢åŠ 
                    trend_cn = 'å¢åŠ '
                elif diff < 0:
                    trend = 'decreased'  # å‡å°‘
                    trend_cn = 'å‡å°‘'
                else:
                    trend = 'unchanged'
                    trend_cn = 'æŒå¹³'
                
                comparisons[period_name] = {
                    'period_average': round(avg, 6),
                    'current_value': round(current_value, 6),
                    'difference': round(diff, 6),
                    'difference_percent': round(diff_percent, 2),
                    'trend': trend,
                    'trend_cn': trend_cn,
                    'sample_count': period_data['sample_count']
                }
            
            # ç»¼åˆåˆ¤æ–­åå¤š/åç©ºçŠ¶æ€
            # ä½¿ç”¨ 1å¤© å’Œ 3å¤© çš„å¯¹æ¯”ç»“æœ
            bias = None
            bias_reason = []
            
            if '1day' in comparisons and '3day' in comparisons:
                day1_diff = comparisons['1day']['difference_percent']
                day3_diff = comparisons['3day']['difference_percent']
                
                # å¦‚æœå½“å‰å€¼é«˜äºå¹³å‡å€¼,è¯´æ˜å˜åŒ–ç‡åœ¨å¢å¤§
                # å¦‚æœå½“å‰å€¼ä½äºå¹³å‡å€¼,è¯´æ˜å˜åŒ–ç‡åœ¨å‡å°
                
                if pos == 'long':
                    # å¤šå¤´åŒºé—´:å˜åŒ–ç‡å¢å¤§ â†’ åç©º(å¯èƒ½èµ¶é¡¶)
                    #          å˜åŒ–ç‡å‡å° â†’ åå¤š(è¶‹åŠ¿ç¨³å¥)
                    if day1_diff > 0 and day3_diff > 0:
                        bias = 'bearish'
                        bias_cn = 'åç©º'
                        bias_reason.append('å¤šå¤´å˜åŒ–ç‡å¢å¤§,å¯èƒ½åŠ é€Ÿèµ¶é¡¶')
                    elif day1_diff < 0 and day3_diff < 0:
                        bias = 'bullish'
                        bias_cn = 'åå¤š'
                        bias_reason.append('å¤šå¤´å˜åŒ–ç‡å‡å°,è¶‹åŠ¿ç¨³å¥')
                    else:
                        bias = 'neutral'
                        bias_cn = 'ä¸­æ€§'
                        bias_reason.append('å¤šå¤´ä¿¡å·ä¸æ˜ç¡®')
                else:  # short
                    # ç©ºå¤´åŒºé—´:å˜åŒ–ç‡å¢å¤§ â†’ åå¤š(å¯èƒ½èµ¶åº•)
                    #          å˜åŒ–ç‡å‡å° â†’ åç©º(è¶‹åŠ¿ç¨³å¥)
                    if day1_diff > 0 and day3_diff > 0:
                        bias = 'bullish'
                        bias_cn = 'åå¤š'
                        bias_reason.append('ç©ºå¤´å˜åŒ–ç‡å¢å¤§,å¯èƒ½åŠ é€Ÿèµ¶åº•')
                    elif day1_diff < 0 and day3_diff < 0:
                        bias = 'bearish'
                        bias_cn = 'åç©º'
                        bias_reason.append('ç©ºå¤´å˜åŒ–ç‡å‡å°,è¶‹åŠ¿ç¨³å¥')
                    else:
                        bias = 'neutral'
                        bias_cn = 'ä¸­æ€§'
                        bias_reason.append('ç©ºå¤´ä¿¡å·ä¸æ˜ç¡®')
            
            result['analysis'][pos] = {
                'position': pos,
                'position_cn': 'å¤šå¤´' if pos == 'bullish' else 'ç©ºå¤´',
                'sequence_info': '01â†’02 (åºåˆ—2)',
                'current_value': round(current_value, 6),
                'current_time': current_time,
                'total_samples': len(all_changes),
                'period_comparisons': comparisons,
                'bias': {
                    'type': bias,
                    'type_cn': bias_cn,
                    'reason': bias_reason
                }
            }
        
        conn.close()
        
        return jsonify(result)
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sar-slope/current-cycle/<symbol>')
def sar_slope_current_cycle_jsonl(symbol):
    """
    è·å–å½“å‰å®Œæ•´å‘¨æœŸçš„æ‰€æœ‰åºåˆ—æ•°æ® (JSONLç‰ˆæœ¬)
    
    ç”¨æˆ·éœ€æ±‚:
    - ç©ºå¤´01å¼€å§‹æ˜¾ç¤º,ä¸€ç›´åˆ°ç©ºå¤´è½¬å¤šå¤´
    - å¤šå¤´01å¼€å§‹æ˜¾ç¤º,ä¸€ç›´åˆ°å¤šå¤´è½¬ç©ºå¤´
    - ä¸æ˜¾ç¤ºæŒç»­æ—¶é—´å­—æ®µ
    
    è¿”å›å½“å‰å‘¨æœŸä»åºåˆ—01åˆ°å½“å‰åºåˆ—çš„å®Œæ•´æ•°æ®
    
    Queryå‚æ•°:
    - limit: æœ€å¤šè¿”å›å¤šå°‘æ¡è®°å½•,é»˜è®¤500(çº¦1.7å¤©)
    - include_history: æ˜¯å¦åŒ…å«å†å²æ•°æ®(true/false/1/0),é»˜è®¤false
    """
    try:
        # è·å–limitå‚æ•°
        limit = request.args.get('limit', 500, type=int)
        
        # è·å–include_historyå‚æ•°
        include_history_param = request.args.get('include_history', 'false').lower()
        include_history = include_history_param in ['true', '1', 'yes']
        
        # ç›´æ¥è°ƒç”¨JSONL API
        result = get_sar_current_cycle(symbol, limit=limit, include_history=include_history)
        
        if result['success']:
            # ç¼“å­˜ç»“æœ
            cache_key = f"sar_slope_current_cycle:{symbol.upper()}:limit{limit}:history{include_history}"
            server_cache.set(cache_key, result)
        
        # æ·»åŠ é˜²ç¼“å­˜å¤´
        response = jsonify(result)
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
        return response
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/sar-slope/bias-ratios')
def sar_slope_bias_ratios_batch():
    """
    æ‰¹é‡è·å–æ‰€æœ‰å¸ç§çš„åå¤š/åç©ºå æ¯”
    ä¼˜åŒ–:ä¸€æ¬¡æ€§è¿”å›29ä¸ªå¸ç§çš„æ•°æ®,é¿å…29æ¬¡APIè°ƒç”¨
    """
    try:
        from sar_api_jsonl import SYMBOLS, get_sar_current_cycle
        from datetime import datetime
        from pathlib import Path
        import json
        
        # æ£€æŸ¥ç¼“å­˜(30ç§’)
        cache_key = "sar_bias_ratios:all"
        cached_data = server_cache.get(cache_key, max_age=30)
        if cached_data:
            cached_data['_from_cache'] = True
            return jsonify(cached_data)
        
        results = {}
        data_dir = Path('/home/user/webapp/data/sar_jsonl')
        
        # æ‰¹é‡å¤„ç†æ‰€æœ‰å¸ç§
        for symbol in SYMBOLS:
            try:
                # æ–‡ä»¶åæ ¼å¼:BTC.jsonl (ä¸å¸¦ -USDT åç¼€)
                symbol_short = symbol.replace('-USDT', '')
                symbol_file = data_dir / f"{symbol_short}.jsonl"
                
                if not symbol_file.exists():
                    results[symbol_short] = {
                        'bullish_ratio': 0,
                        'bearish_ratio': 0,
                        'total_periods': 0,
                        'data_available': False,
                        'symbol_full': symbol
                    }
                    continue
                
                # è¯»å–æœ€è¿‘ N æ¡è®°å½•è¿›è¡Œç»Ÿè®¡(é»˜è®¤24æ¡,çº¦2å°æ—¶æ•°æ®)
                # æ ¹æ®é‡‡é›†é¢‘ç‡(2-6åˆ†é’Ÿ),24æ¡ = 48-144åˆ†é’Ÿ
                num_records = 24
                
                with open(symbol_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    recent_lines = lines[-num_records:] if len(lines) > num_records else lines
                
                records = []
                for line in recent_lines:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            records.append(data)
                        except json.JSONDecodeError:
                            continue
                
                if not records or len(records) < 2:
                    results[symbol_short] = {
                        'bullish_ratio': 0,
                        'bearish_ratio': 0,
                        'total_periods': 0,
                        'data_available': False,
                        'symbol_full': symbol
                    }
                    continue
                
                # ç»Ÿè®¡æœ€è¿‘Næ¡è®°å½•ä¸­çš„å¤šç©ºåˆ†å¸ƒ
                bullish_count = sum(1 for r in records if r.get('position') == 'bullish')
                bearish_count = sum(1 for r in records if r.get('position') == 'bearish')
                
                total = bullish_count + bearish_count
                
                if total > 0:
                    bullish_percent = (bullish_count / total) * 100
                    bearish_percent = (bearish_count / total) * 100
                else:
                    bullish_percent = 0
                    bearish_percent = 0
                
                # è·å–æœ€æ–°è®°å½•çš„positionå’Œæ—¶é—´
                latest_record = records[-1] if records else {}
                current_position = latest_record.get('position', 'unknown')
                
                # ä½¿ç”¨çŸ­æ ¼å¼ä½œä¸ºkey(å»æ‰-USDT),ä¸å‰ç«¯åŒ¹é…
                results[symbol_short] = {
                    'bullish_ratio': round(bullish_percent, 1),
                    'bearish_ratio': round(bearish_percent, 1),
                    'current_position': current_position,
                    'bullish_periods': bullish_count,
                    'bearish_periods': bearish_count,
                    'total_periods': total,
                    'data_available': True,
                    'last_update': latest_record.get('beijing_time', ''),
                    'sample_size': len(records),
                    'symbol_full': symbol  # ä¿ç•™å®Œæ•´ç¬¦å·ä¾›å‚è€ƒ
                }
                
            except Exception as e:
                # å•ä¸ªå¸ç§å¤±è´¥ä¸å½±å“å…¶ä»–å¸ç§
                results[symbol_short] = {
                    'bullish_ratio': 0,
                    'bearish_ratio': 0,
                    'total_periods': 0,
                    'data_available': False,
                    'error': str(e),
                    'symbol_full': symbol
                }
        
        response_data = {
            'success': True,
            'count': len(results),
            'data': results,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            '_from_cache': False
        }
        
        # ç¼“å­˜30ç§’
        server_cache.set(cache_key, response_data)
        
        return jsonify(response_data)
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


# ============================================
# SARåå‘è¶‹åŠ¿API
# ============================================
@app.route('/sar-bias-trend')
def sar_bias_trend_page():
    """SARåå‘è¶‹åŠ¿å›¾é¡µé¢"""
    response = make_response(render_template('sar_bias_trend.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/api/sar-slope/bias-trend')
def sar_slope_bias_trend():
    """è·å–SARåå‘è¶‹åŠ¿æ•°æ®(å®æ—¶ä»SAR JSONLæ–‡ä»¶è®¡ç®—,æŒ‰å¤©åˆ†é¡µ)"""
    try:
        from datetime import datetime, timedelta
        import json
        import os
        import glob
        import pytz
        from pathlib import Path
        from collections import defaultdict
        
        # è·å–å‚æ•°
        page = request.args.get('page', 1, type=int)
        target_date = request.args.get('date', None)  # æ ¼å¼: YYYY-MM-DD
        
        # åŒ—äº¬æ—¶åŒº
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # ç¡®å®šè¦æ˜¾ç¤ºçš„æ—¥æœŸ
        if target_date:
            # ç”¨æˆ·æŒ‡å®šæ—¥æœŸ
            display_date = datetime.strptime(target_date, '%Y-%m-%d')
            display_date = beijing_tz.localize(display_date)
        else:
            # æ ¹æ®pageè®¡ç®—æ—¥æœŸ:page=1æ˜¯ä»Šå¤©,page=2æ˜¯æ˜¨å¤©,ä¾æ­¤ç±»æ¨
            display_date = now - timedelta(days=page - 1)
        
        # è®¡ç®—å½“å¤©çš„æ—¶é—´èŒƒå›´(00:00:00 åˆ° 23:59:59)
        start_time = display_date.replace(hour=0, minute=0, second=0, microsecond=0)
        end_time = display_date.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        # SARæ•°æ®ç›®å½•
        sar_data_dir = Path('/home/user/webapp/data/sar_jsonl')
        
        # å®šä¹‰å¸ç§åˆ—è¡¨ (29ä¸ªå¸ç§,å·²ç§»é™¤MATIC,æ·»åŠ OKB)
        SYMBOLS = ['BTC', 'ETH', 'BNB', 'XRP', 'ADA', 'DOGE', 'SOL', 'DOT', 'LTC', 
                   'LINK', 'HBAR', 'TAO', 'CFX', 'TRX', 'TON', 'NEAR', 'LDO', 'CRO', 'ETC', 
                   'XLM', 'BCH', 'UNI', 'SUI', 'FIL', 'STX', 'CRV', 'AAVE', 'APT', 'OKB']
        
        # æŒ‰æ—¶é—´ç‚¹èšåˆæ•°æ®:{beijing_time: {symbol: position}}
        time_positions = defaultdict(dict)
        
        # è¯»å–æ¯ä¸ªå¸ç§çš„æ•°æ®
        for symbol in SYMBOLS:
            jsonl_file = sar_data_dir / f'{symbol}.jsonl'
            if not jsonl_file.exists():
                continue
            
            try:
                with open(jsonl_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        
                        try:
                            record = json.loads(line)
                            beijing_time_str = record.get('beijing_time', '')
                            if not beijing_time_str:
                                continue
                            
                            # è§£ææ—¶é—´
                            record_time = datetime.strptime(beijing_time_str, '%Y-%m-%d %H:%M:%S')
                            record_time = beijing_tz.localize(record_time)
                            
                            # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡æ—¥æœŸèŒƒå›´å†…
                            if start_time <= record_time <= end_time:
                                position = record.get('position', 'unknown')
                                time_positions[beijing_time_str][symbol] = position
                        except Exception as e:
                            continue
            except Exception as e:
                print(f"[SAR Bias Trend] è¯»å– {symbol} å¤±è´¥: {e}")
                continue
        
        # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„ç»Ÿè®¡æ•°æ®
        all_data = []
        # è‡³å°‘éœ€è¦26ä¸ªå¸ç§æ‰ç®—æœ‰æ•ˆæ•°æ®ç‚¹(æ€»å…±29ä¸ªå¸ç§,å…è®¸æœ€å¤š3ä¸ªç¼ºå¤±)
        min_symbols_required = 26
        
        for beijing_time_str in sorted(time_positions.keys()):
            positions = time_positions[beijing_time_str]
            
            bullish_count = sum(1 for pos in positions.values() if pos == 'bullish')
            bearish_count = sum(1 for pos in positions.values() if pos == 'bearish')
            total_count = len(positions)
            
            # è¿‡æ»¤:åªä¿ç•™æœ‰è¶³å¤Ÿå¤šå¸ç§æ•°æ®çš„æ—¶é—´ç‚¹(é¿å…ä¸å®Œæ•´çš„é‡‡é›†æ•°æ®)
            if total_count >= min_symbols_required:
                avg_bullish_ratio = bullish_count / total_count
                avg_bearish_ratio = bearish_count / total_count
                
                bullish_symbols = [sym for sym, pos in positions.items() if pos == 'bullish']
                bearish_symbols = [sym for sym, pos in positions.items() if pos == 'bearish']
                
                all_data.append({
                    'timestamp': beijing_time_str,
                    'bullish_count': bullish_count,
                    'bearish_count': bearish_count,
                    'total_symbols': total_count,
                    'avg_bullish_ratio': round(avg_bullish_ratio, 4),
                    'avg_bearish_ratio': round(avg_bearish_ratio, 4),
                    'bullish_symbols': bullish_symbols,
                    'bearish_symbols': bearish_symbols
                })
        
        # è®¡ç®—æ€»é¡µæ•°(æœ‰æ•°æ®çš„å¤©æ•°)
        # è·å–æœ€æ—©çš„SARæ•°æ®æ—¶é—´
        earliest_time = None
        for symbol in ['BTC', 'ETH', 'BNB']:  # æ£€æŸ¥å‡ ä¸ªä¸»è¦å¸ç§
            jsonl_file = sar_data_dir / f'{symbol}.jsonl'
            if jsonl_file.exists():
                try:
                    with open(jsonl_file, 'r', encoding='utf-8') as f:
                        first_line = f.readline().strip()
                        if first_line:
                            first_record = json.loads(first_line)
                            beijing_time_str = first_record.get('beijing_time', '')
                            if beijing_time_str:
                                first_time = datetime.strptime(beijing_time_str, '%Y-%m-%d %H:%M:%S')
                                first_time = beijing_tz.localize(first_time)
                                if earliest_time is None or first_time < earliest_time:
                                    earliest_time = first_time
                except:
                    continue
        
        total_pages = 1
        if earliest_time:
            days_diff = (now.date() - earliest_time.date()).days
            total_pages = max(1, days_diff + 1)
        
        # è·å–å½“å‰é¡µçš„æ—¶é—´èŒƒå›´(ç”¨äºæ˜¾ç¤º)
        time_range = {
            'start': start_time.strftime('%Y-%m-%d %H:%M:%S'),
            'end': end_time.strftime('%Y-%m-%d %H:%M:%S'),
            'date': display_date.strftime('%Y-%m-%d')
        }
        
        return jsonify({
            'success': True,
            'data': all_data,
            'total': len(all_data),
            'page': page,
            'total_pages': total_pages,
            'time_range': time_range,
            'has_prev': page > 1,
            'has_next': page < total_pages
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/sar-slope/bias-stats/latest')
def api_sar_bias_stats_latest():
    """è·å–æœ€æ–°çš„SARå¤šç©ºå æ¯”ç»Ÿè®¡ - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from panic_jsonl_manager import PanicJSONLManager
        
        manager = PanicJSONLManager()
        latest = manager.get_latest('sar_bias_stats')
        
        if latest:
            return jsonify({
                'success': True,
                'data': {
                    'record_time': latest.get('record_time'),
                    'bullish_over_80_count': latest.get('bullish_over_80_count', 0),
                    'bearish_over_80_count': latest.get('bearish_over_80_count', 0),
                    'bullish_over_80_symbols': latest.get('bullish_over_80_symbols', '').split(',') if latest.get('bullish_over_80_symbols') else [],
                    'bearish_over_80_symbols': latest.get('bearish_over_80_symbols', '').split(',') if latest.get('bearish_over_80_symbols') else [],
                    'total_symbols': latest.get('total_symbols', 0)
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': 'æš‚æ— æ•°æ®'
            })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/sar-slope/bias-trend-by-date')
def sar_slope_bias_trend_by_date():
    """æŒ‰æ—¥æœŸè·å–SARåå‘è¶‹åŠ¿æ•°æ®(ä»JSONLè¯»å–,æ˜¾ç¤ºå…¨å¤©çš„æ¯åˆ†é’Ÿæ•°æ®)"""
    try:
        from datetime import datetime, timedelta
        import json
        import os
        import pytz
        
        # è·å–æ—¥æœŸå‚æ•°,é»˜è®¤ä»Šå¤©
        date_str = request.args.get('date', '')
        
        # åŒ—äº¬æ—¶åŒº
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        if not date_str:
            # é»˜è®¤ä»Šå¤©
            target_date = now.strftime('%Y%m%d')
            display_date = now.strftime('%Y-%m-%d')
        else:
            # è§£æç”¨æˆ·ä¼ å…¥çš„æ—¥æœŸ
            try:
                # æ”¯æŒ YYYY-MM-DD æ ¼å¼
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                target_date = date_obj.strftime('%Y%m%d')
                display_date = date_str
            except:
                return jsonify({
                    'success': False,
                    'error': 'æ—¥æœŸæ ¼å¼é”™è¯¯,è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼'
                })
        
        # è¯»å–JSONLæ•°æ®
        data_dir = '/home/user/webapp/data/sar_bias_stats'
        jsonl_file = os.path.join(data_dir, f'bias_stats_{target_date}.jsonl')
        
        all_data = []
        
        if os.path.exists(jsonl_file):
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            record = json.loads(line)
                            all_data.append({
                                'timestamp': record.get('timestamp', ''),
                                'bullish_count': record.get('bullish_count', 0),
                                'bearish_count': record.get('bearish_count', 0),
                                'total_symbols': record.get('total_symbols', 27),
                                'success_count': record.get('success_count', 27),
                                'fail_count': record.get('fail_count', 0),
                                'avg_bullish_ratio': record.get('avg_bullish_ratio', 0),
                                'avg_bearish_ratio': record.get('avg_bearish_ratio', 0),
                                'bullish_symbols': record.get('bullish_symbols', []),
                                'bearish_symbols': record.get('bearish_symbols', [])
                            })
                        except Exception as e:
                            continue
        
        # æŒ‰æ—¶é—´æ’åº(å‡åº)
        all_data.sort(key=lambda x: x['timestamp'])
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        time_range = {}
        if all_data:
            time_range = {
                'start': all_data[0]['timestamp'],
                'end': all_data[-1]['timestamp']
            }
        
        return jsonify({
            'success': True,
            'data': all_data,
            'total': len(all_data),
            'date': display_date,
            'time_range': time_range
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/sar-slope/bias-stats/history')
def api_sar_bias_stats_history():
    """è·å–SARå¤šç©ºå æ¯”ç»Ÿè®¡å†å²æ•°æ® - ä»JSONLè¯»å–"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from panic_jsonl_manager import PanicJSONLManager
        
        manager = PanicJSONLManager()
        limit = request.args.get('limit', 100, type=int)
        
        records = manager.read_records('sar_bias_stats', limit=limit, reverse=True)
        
        # æ ¼å¼åŒ–æ•°æ®
        history_data = []
        for record in records:
            history_data.append({
                'record_time': record.get('record_time'),
                'bullish_over_80_count': record.get('bullish_over_80_count', 0),
                'bearish_over_80_count': record.get('bearish_over_80_count', 0),
                'total_symbols': record.get('total_symbols', 0)
            })
        
        return jsonify({
            'success': True,
            'data': history_data,
            'count': len(history_data)
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


# ============================================
# ç¼“å­˜ç®¡ç†API
# ============================================
@app.route('/api/cache/stats')
def cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    stats = server_cache.get_stats()
    return jsonify({
        'success': True,
        'cache_stats': stats,
        'message': 'æœåŠ¡å™¨ç«¯ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯'
    })

@app.route('/api/cache/clear', methods=['POST'])
def cache_clear():
    """æ¸…é™¤æœåŠ¡å™¨ç«¯ç¼“å­˜"""
    try:
        key = request.json.get('key') if request.json else None
        server_cache.clear(key)
        return jsonify({
            'success': True,
            'message': f'ç¼“å­˜å·²æ¸…é™¤{"(é”®: " + key + ")" if key else "(å…¨éƒ¨)"}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ========== é”šç‚¹ç³»ç»Ÿ(OKExæŒä»“ç›‘æ§) ==========

@app.route('/warning-test')
def warning_test():
    """é¢„è­¦æ¨¡å—æµ‹è¯•é¡µé¢"""
    return render_template('warning_test.html')

@app.route('/anchor-system')
def anchor_system():
    """é”šç‚¹ç³»ç»Ÿä¸»é¡µ - é‡å®šå‘åˆ°å®ç›˜"""
    return redirect('/anchor-system-real')

@app.route('/anchor-test')
def anchor_test():
    """Anchor System è¯Šæ–­é¡µé¢"""
    from flask import send_file
    return send_file('/home/user/webapp/anchor_test.html')

@app.route('/test-anchor-chart')
def test_anchor_chart():
    """é”šç‚¹å›¾è¡¨æµ‹è¯•é¡µé¢"""
    response = make_response(render_template('test_anchor_chart.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    return response

@app.route('/test-anchor-markpoint')
def test_anchor_markpoint():
    """é”šç‚¹å›¾è¡¨æ ‡è®°ç‚¹æµ‹è¯•é¡µé¢"""
    response = make_response(render_template('test_anchor_markpoint.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    return response

@app.route('/anchor-system-real')
def anchor_system_real():
    """å®ç›˜é”šç‚¹ç³»ç»Ÿ"""
    import time
    version = int(time.time())  # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºç‰ˆæœ¬å·å¼ºåˆ¶åˆ·æ–°
    response = make_response(render_template('anchor_system_real.html', cache_bust=version))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    response.headers['ETag'] = f'"{version}"'  # æ·»åŠ ETag
    response.headers['Last-Modified'] = time.strftime('%a, %d %b %Y %H:%M:%S GMT', time.gmtime())
    return response

@app.route('/okx-trading')
def okx_trading():
    """OKXå®ç›˜äº¤æ˜“ç³»ç»Ÿ"""
    response = make_response(render_template('okx_trading.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/okx-trading-fangfang12')
def okx_trading_fangfang12():
    """OKXå®ç›˜äº¤æ˜“ç³»ç»Ÿ - Fangfang12è´¦æˆ·"""
    response = make_response(render_template('okx_trading_fangfang12.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/okx-trading-marks')
def okx_trading_marks():
    """OKXäº¤æ˜“æ ‡è®°ç³»ç»Ÿ - åœ¨27å¸æ¶¨è·Œå¹…è¶‹åŠ¿å›¾ä¸Šæ ‡è®°å¼€ä»“/å¹³ä»“ç‚¹"""
    import time
    timestamp = int(time.time() * 1000)
    response = make_response(render_template('okx_trading_marks.html', cache_bust=timestamp))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/angle-test')
def angle_test():
    """è§’åº¦æ•°æ®æµ‹è¯•é¡µé¢ - 2æœˆ2-6æ—¥"""
    response = make_response(render_template('angle_test.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/coin-price-tracker')
def coin_price_tracker():
    """27å¸æ¶¨è·Œå¹…æ€»å’Œè¿½è¸ªå™¨ - å®æ—¶æ•°æ®"""
    import time
    timestamp = int(time.time())
    response = make_response(render_template('coin_sum_tracker.html', cache_bust=timestamp))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/coin-tracker-v2')
def coin_price_tracker_v2():
    """27å¸æ¶¨è·Œå¹…æ€»å’Œè¿½è¸ªå™¨ - æ–°ç‰ˆæœ¬(ç»•è¿‡ç¼“å­˜)"""
    import time
    timestamp = int(time.time())
    response = make_response(render_template('coin_sum_tracker.html', cache_bust=timestamp))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/coin-tracker-simple')
def coin_tracker_simple():
    """27å¸æ¶¨è·Œå¹…è¿½è¸ªå™¨ - ç®€åŒ–ç‰ˆ(å®Œå…¨é‡å†™)"""
    response = make_response(render_template('coin_tracker_simple.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/diagnostic')
def diagnostic():
    """ç³»ç»Ÿè¯Šæ–­é¡µé¢"""
    response = make_response(render_template('diagnostic.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/coin-price-history')
def coin_price_history():
    """27å¸ç§å†å²æ•°æ®æŸ¥è¯¢ - å®æ—¶æ•°æ®"""
    response = make_response(render_template('coin_price_history.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/system-status')
def system_status():
    """ç³»ç»Ÿè¿è¡ŒçŠ¶æ€ç›‘æ§"""
    response = make_response(render_template('system_status.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/aligned-data-view')
def aligned_data_view():
    """å¯¹é½æ•°æ®å¯è§†åŒ– - Coin Tracker + Escape Signal"""
    response = make_response(render_template('aligned_data_view.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response


@app.route('/anchor-system-paper')
def anchor_system_paper():
    """æ¨¡æ‹Ÿç›˜é”šç‚¹ç³»ç»Ÿ"""
    response = make_response(render_template('anchor_system_paper.html'))
    # ç¦ç”¨æ‰€æœ‰ç¼“å­˜
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response


@app.route('/anchor-system-v2')
def anchor_system_v2():
    """é”šç‚¹ç³»ç»Ÿä¸»é¡µ v2 (æ–°URLé¿å…ç¼“å­˜)"""
    response = make_response(render_template('anchor_system.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/api/anchor-system/monitors')
def get_anchor_monitors():
    """è·å–æŒä»“ç›‘æ§è®°å½•"""
    try:
        limit = request.args.get('limit', 100, type=int)
        db_path = '/home/user/webapp/databases/anchor_system.db'
        
        conn = sqlite3.connect(db_path, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT * FROM anchor_monitors 
        ORDER BY timestamp DESC 
        LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        monitors = []
        for row in rows:
            monitors.append({
                'id': row['id'],
                'timestamp': row['timestamp'],
                'inst_id': row['inst_id'],
                'pos_side': row['pos_side'],
                'pos_size': row['pos_size'],
                'avg_price': row['avg_price'],
                'mark_price': row['mark_price'],
                'upl': row['upl'],
                'upl_ratio': row['upl_ratio'],
                'margin': row['margin'],
                'leverage': row['leverage'],
                'profit_rate': row['profit_rate'],
                'alert_type': row['alert_type'],
                'alert_sent': row['alert_sent']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': monitors,
            'total': len(monitors)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/alerts')
def get_anchor_alerts():
    """è·å–å‘Šè­¦å†å²"""
    try:
        limit = request.args.get('limit', 50, type=int)
        db_path = '/home/user/webapp/databases/anchor_system.db'
        
        conn = sqlite3.connect(db_path, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT * FROM anchor_alerts 
        ORDER BY timestamp DESC 
        LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        alerts = []
        for row in rows:
            alerts.append({
                'id': row['id'],
                'timestamp': row['timestamp'],
                'inst_id': row['inst_id'],
                'pos_side': row['pos_side'],
                'profit_rate': row['profit_rate'],
                'alert_type': row['alert_type'],
                'message': row['message'],
                'sent_status': row['sent_status']
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': alerts,
            'total': len(alerts)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/sub-account/config')
def get_sub_account_config():
    """è·å–å­è´¦æˆ·é…ç½®"""
    try:
        import json
        import os
        
        config_path = '/home/user/webapp/sub_account_config.json'
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨,è¿”å›é»˜è®¤é…ç½®
        if not os.path.exists(config_path):
            default_config = {
                'follow_short_loss_enabled': False,
                'follow_long_loss_enabled': False,
                'super_maintain_long_enabled': False,
                'super_maintain_short_enabled': False
            }
            return jsonify({
                'success': True,
                'config': default_config
            })
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/sub-account/config', methods=['POST'])
def update_sub_account_config():
    """æ›´æ–°å­è´¦æˆ·é…ç½®"""
    try:
        import json
        
        config_path = '/home/user/webapp/sub_account_config.json'
        data = request.get_json()
        
        # ä¿å­˜é…ç½®
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': 'å­è´¦æˆ·é…ç½®å·²æ›´æ–°'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/okx-trading/account-balance', methods=['POST'])
def get_okx_account_balance():
    """è·å–OKXè´¦æˆ·ä½™é¢"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        request_path = '/api/v5/account/balance'
        method = 'GET'
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.get(base_url + request_path, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') == '0' and result.get('data'):
            # è·å–USDTä½™é¢
            balances = result['data']
            usdt_balance = 0.0
            
            for account in balances:
                details = account.get('details', [])
                for detail in details:
                    if detail.get('ccy') == 'USDT':
                        # åªä½¿ç”¨å¯ç”¨ä½™é¢(ä¸åŒ…å«å†»ç»“çš„ä¿è¯é‡‘)
                        available = float(detail.get('availBal', 0))
                        usdt_balance += available
            
            return jsonify({
                'success': True,
                'balance': round(usdt_balance, 2),
                'availableBalance': round(usdt_balance, 2),  # æ·»åŠ æ˜ç¡®çš„å¯ç”¨ä½™é¢å­—æ®µ
                'currency': 'USDT',
                'raw_data': result['data']
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('msg', 'è·å–ä½™é¢å¤±è´¥'),
                'code': result.get('code', 'unknown')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/account-info', methods=['POST'])
def get_okx_account_info():
    """è·å–OKXè´¦æˆ·è¯¦ç»†ä¿¡æ¯(æƒç›Šã€ä¿è¯é‡‘ã€ç›ˆäºç­‰)"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        request_path = '/api/v5/account/balance'
        method = 'GET'
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.get(base_url + request_path, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') == '0' and result.get('data'):
            # è§£æè´¦æˆ·ä¿¡æ¯
            account_data = result['data'][0]
            details = account_data.get('details', [])
            
            # æ±‡æ€»ä¿¡æ¯
            total_equity = float(account_data.get('totalEq', 0))  # æ€»æƒç›Š(ç¾å…ƒ)
            available_balance = 0.0  # å¯ç”¨ä½™é¢
            frozen_balance = 0.0  # å†»ç»“ä½™é¢
            margin_used = 0.0  # å·²ç”¨ä¿è¯é‡‘
            unrealized_pnl = 0.0  # æœªå®ç°ç›ˆäº
            
            # ç»Ÿè®¡å„å¸ç§
            for detail in details:
                if detail.get('ccy') == 'USDT':
                    # å¤„ç†å¯èƒ½çš„ç©ºå­—ç¬¦ä¸²
                    availBal = detail.get('availBal', '0')
                    frozenBal = detail.get('frozenBal', '0')
                    upl = detail.get('upl', '0')
                    
                    available_balance = float(availBal if availBal and availBal != '' else '0')
                    frozen_balance = float(frozenBal if frozenBal and frozenBal != '' else '0')
                    unrealized_pnl = float(upl if upl and upl != '' else '0')
            
            # è®¡ç®—å·²ç”¨ä¿è¯é‡‘(ä»è´¦æˆ·ä½™é¢APIæ— æ³•ç›´æ¥è·å–,éœ€è¦ä»æŒä»“APIè·å–)
            # è¿™é‡Œå…ˆè¿”å›åŸºç¡€ä¿¡æ¯
            
            return jsonify({
                'success': True,
                'data': {
                    'totalEquity': total_equity,  # æ€»æƒç›Š(USD)
                    'availableBalance': available_balance,  # å¯ç”¨ä½™é¢(USDT)
                    'frozenBalance': frozen_balance,  # å†»ç»“ä½™é¢(USDT)
                    'usedMargin': margin_used,  # å·²ç”¨ä¿è¯é‡‘
                    'unrealizedPnl': unrealized_pnl,  # æœªå®ç°ç›ˆäº
                    'currency': 'USDT'
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('msg', 'è·å–è´¦æˆ·ä¿¡æ¯å¤±è´¥'),
                'code': result.get('code', 'unknown')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/positions', methods=['POST'])
def get_okx_positions():
    """è·å–OKXæŒä»“åˆ—è¡¨"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        
        print(f"[get_okx_positions] æ”¶åˆ°è¯·æ±‚")
        print(f"[get_okx_positions] API Key: {api_key[:8]}..." if api_key else "[get_okx_positions] API Key: ç©º")
        print(f"[get_okx_positions] Secret: {'å·²æä¾›' if secret_key else 'æœªæä¾›'}")
        print(f"[get_okx_positions] Passphrase: {'å·²æä¾›' if passphrase else 'æœªæä¾›'}")
        
        if not api_key or not secret_key or not passphrase:
            print(f"[get_okx_positions] é”™è¯¯: APIå‡­è¯ä¸å®Œæ•´")
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        request_path = '/api/v5/account/positions'
        method = 'GET'
        
        print(f"[get_okx_positions] å‡†å¤‡è°ƒç”¨OKX API: {base_url}{request_path}")
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        print(f"[get_okx_positions] ç­¾åç”ŸæˆæˆåŠŸ, timestamp: {timestamp}")
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        print(f"[get_okx_positions] å‘é€è¯·æ±‚åˆ°OKX...")
        response = requests.get(base_url + request_path, headers=headers, timeout=10)
        print(f"[get_okx_positions] OKXå“åº”çŠ¶æ€ç : {response.status_code}")
        
        result = response.json()
        print(f"[get_okx_positions] OKXå“åº”ä»£ç : {result.get('code')}")
        print(f"[get_okx_positions] OKXå“åº”æ¶ˆæ¯: {result.get('msg')}")
        
        if result.get('code') == '0':
            positions_data = result.get('data', [])
            print(f"[get_okx_positions] åŸå§‹æŒä»“æ•°æ®æ•°é‡: {len(positions_data)}")
            
            # è¿‡æ»¤å’Œæ ¼å¼åŒ–æŒä»“æ•°æ®
            positions = []
            total_margin = 0.0
            total_unrealized_pnl = 0.0
            
            for pos in positions_data:
                pos_size = float(pos.get('pos', 0))
                if pos_size != 0:  # åªè¿”å›æœ‰æŒä»“çš„
                    inst_id = pos.get('instId', '')
                    pos_side = pos.get('posSide', '')
                    
                    # ğŸ”§ ä¿®å¤:å•å‘æŒä»“æ¨¡å¼ä¸‹,posSideä¸ºç©ºå­—ç¬¦ä¸²
                    # æ ¹æ®poså­—æ®µçš„æ­£è´Ÿåˆ¤æ–­æ–¹å‘:æ­£æ•°=å¤šå•(long),è´Ÿæ•°=ç©ºå•(short)
                    if not pos_side:
                        pos_side = 'long' if pos_size > 0 else 'short'
                        print(f"[æŒä»“æŸ¥è¯¢] å•å‘æŒä»“æ¨¡å¼ - {inst_id}: pos={pos_size}, åˆ¤æ–­ä¸º {pos_side}")
                    
                    leverage = float(pos.get('lever', 0))
                    avg_price = float(pos.get('avgPx', 0))
                    mark_price = float(pos.get('markPx', 0))
                    upl = float(pos.get('upl', 0))
                    upl_ratio = float(pos.get('uplRatio', 0))
                    margin = float(pos.get('margin', 0))
                    
                    total_margin += margin
                    total_unrealized_pnl += upl
                    
                    positions.append({
                        'instId': inst_id,
                        'posSide': pos_side,
                        'posSize': abs(pos_size),
                        'leverage': leverage,
                        'avgPrice': avg_price,
                        'markPrice': mark_price,
                        'unrealizedPnl': upl,
                        'unrealizedPnlRatio': upl_ratio * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                        'margin': margin
                    })
            
            print(f"[get_okx_positions] è¿‡æ»¤åæŒä»“æ•°é‡: {len(positions)}")
            print(f"[get_okx_positions] æ€»ä¿è¯é‡‘: {total_margin:.2f} USDT")
            print(f"[get_okx_positions] æ€»æœªå®ç°ç›ˆäº: {total_unrealized_pnl:.2f} USDT")
            
            return jsonify({
                'success': True,
                'data': positions,
                'summary': {
                    'totalPositions': len(positions),
                    'totalMargin': total_margin,
                    'totalUnrealizedPnl': total_unrealized_pnl
                }
            })
        else:
            error_msg = result.get('msg', 'è·å–æŒä»“å¤±è´¥')
            error_code = result.get('code', 'unknown')
            print(f"[get_okx_positions] OKX APIé”™è¯¯: code={error_code}, msg={error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg,
                'code': error_code
            })
            
    except requests.exceptions.Timeout:
        print(f"[get_okx_positions] é”™è¯¯: APIè¯·æ±‚è¶…æ—¶")
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        print(f"[get_okx_positions] é”™è¯¯: ç½‘ç»œè¯·æ±‚å¤±è´¥ - {str(e)}")
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        print(f"[get_okx_positions] é”™è¯¯: {str(e)}")
        print(f"[get_okx_positions] å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/logs', methods=['GET'])
def get_okx_trading_logs():
    """è·å–OKXäº¤æ˜“æ—¥å¿—"""
    try:
        date_str = request.args.get('date', None)  # YYYYMMDDæ ¼å¼
        limit = int(request.args.get('limit', 100))
        
        logs = okx_trading_logger.get_logs(date_str=date_str, limit=limit)
        
        return jsonify({
            'success': True,
            'count': len(logs),
            'logs': logs
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/okx-trading/favorite-symbols', methods=['GET'])
def get_favorite_symbols():
    """è·å–å¸¸ç”¨å¸åˆ—è¡¨(å…¨å±€å…±äº«)"""
    try:
        import json
        import os
        
        file_path = 'data/favorite_symbols.jsonl'
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨,åˆ›å»ºé»˜è®¤é…ç½®ï¼ˆç”¨æˆ·é…ç½®çš„15ä¸ªå¸ï¼‰
        if not os.path.exists(file_path):
            default_symbols = [
                "SOL-USDT-SWAP", "XRP-USDT-SWAP", "TAO-USDT-SWAP",
                "LDO-USDT-SWAP", "CFX-USDT-SWAP", "CRV-USDT-SWAP",
                "UNI-USDT-SWAP", "CRO-USDT-SWAP", "FIL-USDT-SWAP",
                "APT-USDT-SWAP", "SUI-USDT-SWAP", "NEAR-USDT-SWAP",
                "DOT-USDT-SWAP", "LINK-USDT-SWAP", "STX-USDT-SWAP"
            ]
            with open(file_path, 'w') as f:
                from datetime import datetime
                json.dump({
                    'symbols': default_symbols,
                    'updated_at': datetime.utcnow().isoformat() + 'Z'
                }, f)
        
        # è¯»å–æœ€åä¸€è¡Œ
        with open(file_path, 'r') as f:
            lines = f.readlines()
            if lines:
                data = json.loads(lines[-1].strip())
                return jsonify({
                    'success': True,
                    'symbols': data.get('symbols', []),
                    'updated_at': data.get('updated_at', '')
                })
        
        return jsonify({
            'success': True,
            'symbols': [],
            'updated_at': ''
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/okx-trading/favorite-symbols', methods=['POST'])
def update_favorite_symbols():
    """æ›´æ–°å¸¸ç”¨å¸åˆ—è¡¨(å…¨å±€å…±äº«)"""
    try:
        import json
        from datetime import datetime
        
        data = request.get_json()
        symbols = data.get('symbols', [])
        
        file_path = 'data/favorite_symbols.jsonl'
        
        # è¿½åŠ æ–°çš„é…ç½®åˆ°æ–‡ä»¶
        with open(file_path, 'a') as f:
            json.dump({
                'symbols': symbols,
                'updated_at': datetime.utcnow().isoformat() + 'Z'
            }, f)
            f.write('\n')
        
        return jsonify({
            'success': True,
            'symbols': symbols
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })


def load_okx_api_config():
    """åŠ è½½OKX APIé…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), '..', 'configs', 'okx_api_config.json')
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config = json.load(f)
                return {
                    'api_key': config.get('api_key', ''),
                    'secret_key': config.get('secret_key', ''),
                    'passphrase': config.get('passphrase', ''),
                    'base_url': config.get('base_url', 'https://www.okx.com')
                }
    except Exception as e:
        print(f"åŠ è½½OKX APIé…ç½®å¤±è´¥: {e}")
    return None


@app.route('/api/okx-trading/place-order', methods=['POST'])
def place_okx_order():
    """OKXä¸‹å•æ¥å£"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        
        # ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ é€’çš„APIå¯†é’¥,å¦‚æœæ²¡æœ‰åˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        
        # å¦‚æœå‰ç«¯æ²¡æœ‰ä¼ é€’,å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
        if not api_key or not secret_key or not passphrase:
            config = load_okx_api_config()
            if config:
                api_key = api_key or config['api_key']
                secret_key = secret_key or config['secret_key']
                passphrase = passphrase or config['passphrase']

        passphrase = data.get('passphrase', '')
        
        # è®¢å•å‚æ•°
        inst_id = data.get('instId', '')  # äº¤æ˜“å¯¹,å¦‚ BTC-USDT-SWAP
        side = data.get('side', '')  # buy/sell
        pos_side = data.get('posSide', '')  # long/short
        order_type = data.get('ordType', 'market')  # market/limit
        size = data.get('sz', '')  # USDTé‡‘é¢
        price = data.get('px', '')  # é™ä»·å•ä»·æ ¼
        leverage = data.get('lever', '10')  # æ æ†å€æ•°,é»˜è®¤10
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        if not inst_id or not side or not size:
            return jsonify({
                'success': False,
                'error': 'è®¢å•å‚æ•°ä¸å®Œæ•´'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        
        # ğŸ”¥ æ­¥éª¤0: è·å–è´¦æˆ·æŒä»“æ¨¡å¼
        position_mode = 'long_short_mode'  # é»˜è®¤åŒå‘æŒä»“(æ›´å®‰å…¨)
        try:
            config_path = '/api/v5/account/config'
            config_timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
            config_message = config_timestamp + 'GET' + config_path
            config_mac = hmac.new(
                bytes(secret_key, encoding='utf8'),
                bytes(config_message, encoding='utf-8'),
                digestmod='sha256'
            )
            config_signature = base64.b64encode(config_mac.digest()).decode()
            
            config_response = requests.get(base_url + config_path, headers={
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': config_signature,
                'OK-ACCESS-TIMESTAMP': config_timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
            }, timeout=5)
            config_result = config_response.json()
            if config_result.get('code') == '0' and config_result.get('data'):
                # posMode: "long_short_mode" æˆ– "net_mode"
                position_mode = config_result['data'][0].get('posMode', 'long_short_mode')
                print(f"[è´¦æˆ·é…ç½®] æŒä»“æ¨¡å¼: {position_mode}")
            else:
                print(f"[è´¦æˆ·é…ç½®] æŸ¥è¯¢å¤±è´¥: {config_result}")
        except Exception as e:
            print(f"[è´¦æˆ·é…ç½®] è·å–å¤±è´¥,é»˜è®¤åŒå‘æŒä»“: {str(e)}")
        
        # æ­¥éª¤1: è®¾ç½®æ æ†å€æ•°(é‡è¦ï¼)
        try:
            set_leverage_path = '/api/v5/account/set-leverage'
            leverage_body_dict = {
                'instId': inst_id,
                'lever': str(leverage),
                'mgnMode': 'isolated',  # é€ä»“æ¨¡å¼
            }
            
            # åªæœ‰åœ¨åŒå‘æŒä»“æ¨¡å¼ä¸‹æ‰éœ€è¦æŒ‡å®šposSide
            if position_mode == 'long_short_mode' and pos_side:
                leverage_body_dict['posSide'] = pos_side
            
            leverage_body = json.dumps(leverage_body_dict)
            
            leverage_timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
            leverage_message = leverage_timestamp + 'POST' + set_leverage_path + leverage_body
            leverage_mac = hmac.new(
                bytes(secret_key, encoding='utf8'),
                bytes(leverage_message, encoding='utf-8'),
                digestmod='sha256'
            )
            leverage_signature = base64.b64encode(leverage_mac.digest()).decode()
            
            leverage_headers = {
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': leverage_signature,
                'OK-ACCESS-TIMESTAMP': leverage_timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
                'Content-Type': 'application/json'
            }
            
            leverage_response = requests.post(base_url + set_leverage_path, headers=leverage_headers, data=leverage_body, timeout=10)
            leverage_result = leverage_response.json()
            
            # æ æ†è®¾ç½®å¤±è´¥ä¸ä¸€å®šæ˜¯è‡´å‘½é”™è¯¯(å¯èƒ½å·²ç»è®¾ç½®è¿‡)
            if leverage_result.get('code') != '0':
                print(f"è®¾ç½®æ æ†å¤±è´¥(å¯èƒ½å·²è®¾ç½®): {leverage_result.get('msg')}")
        except Exception as e:
            print(f"è®¾ç½®æ æ†å¼‚å¸¸(ç»§ç»­ä¸‹å•): {str(e)}")
        
        # æ­¥éª¤2: ä¸‹å•
        request_path = '/api/v5/trade/order'
        method = 'POST'
        
        # å°†USDTé‡‘é¢è½¬æ¢ä¸ºåˆçº¦å¼ æ•°(æ°¸ç»­åˆçº¦,é¢å€¼ä¸º1USD)
        # szå•ä½:åˆçº¦æ°¸ç»­æ˜¯å¸çš„æ•°é‡(å¦‚BTCæ•°é‡)
        # å¯¹äºUSDTè®¡ä»·åˆçº¦,sz = USDTé‡‘é¢ / å½“å‰ä»·æ ¼
        current_price = float(price) if price else None
        
        # å¦‚æœæ²¡æœ‰ä»·æ ¼,éœ€è¦å…ˆè·å–å½“å‰å¸‚ä»·
        if not current_price:
            try:
                ticker_path = f'/api/v5/market/ticker?instId={inst_id}'
                ticker_response = requests.get(base_url + ticker_path, timeout=5)
                ticker_data = ticker_response.json()
                if ticker_data.get('code') == '0' and ticker_data.get('data'):
                    current_price = float(ticker_data['data'][0].get('last', 0))
            except:
                pass
        
        if not current_price or current_price == 0:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•è·å–å½“å‰ä»·æ ¼,è¯·ä½¿ç”¨é™ä»·å•å¹¶æŒ‡å®šä»·æ ¼'
            })
        
        # ç”¨æˆ·è¾“å…¥çš„æ˜¯åˆçº¦ä»·å€¼(USDT),ä¸æ˜¯ä¿è¯é‡‘ï¼
        # é‡è¦:ç”¨æˆ·è¾“å…¥7.5 USDT,å°±æ˜¯æƒ³å¼€7.5 USDTçš„ä»“ä½
        # ä¿è¯é‡‘ = åˆçº¦ä»·å€¼ / æ æ†å€æ•°
        
        user_usdt = float(size)  # ç”¨æˆ·è¾“å…¥çš„USDTé‡‘é¢(åˆçº¦ä»·å€¼)
        leverage_value = float(leverage)  # æ æ†å€æ•°
        
        # åˆçº¦ä»·å€¼å°±æ˜¯ç”¨æˆ·è¾“å…¥çš„é‡‘é¢
        contract_value_usdt = user_usdt
        
        # ğŸ”¥ åŠ¨æ€è·å–åˆçº¦é¢å€¼(ctVal)- æ¯å¼ åˆçº¦ä»£è¡¨å¤šå°‘å¸
        # ä¸åŒå¸ç§çš„åˆçº¦é¢å€¼ä¸åŒ,å¿…é¡»ä» API è·å–,ä¸èƒ½ç¡¬ç¼–ç ï¼
        coin_per_contract = None
        try:
            instruments_path = f'/api/v5/public/instruments?instType=SWAP&instId={inst_id}'
            instruments_response = requests.get(base_url + instruments_path, timeout=5)
            instruments_data = instruments_response.json()
            
            if instruments_data.get('code') == '0' and instruments_data.get('data'):
                ct_val = instruments_data['data'][0].get('ctVal', '')
                if ct_val:
                    coin_per_contract = float(ct_val)
                    print(f"[åˆçº¦è§„æ ¼] {inst_id} æ¯å¼ åˆçº¦é¢å€¼: {coin_per_contract} å¸")
        except Exception as e:
            print(f"[åˆçº¦è§„æ ¼] è·å–å¤±è´¥,ä½¿ç”¨å›é€€é€»è¾‘: {str(e)}")
        
        # å¦‚æœ API è·å–å¤±è´¥,ä½¿ç”¨å›é€€é€»è¾‘(ä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºå¤‡ä»½)
        if coin_per_contract is None:
            if 'BTC' in inst_id:
                coin_per_contract = 0.01
            elif 'ETH' in inst_id:
                coin_per_contract = 0.1
            elif 'SOL' in inst_id or 'DOGE' in inst_id or 'XRP' in inst_id or 'ADA' in inst_id or 'TRX' in inst_id:
                coin_per_contract = 1.0
            else:
                coin_per_contract = 0.1
            print(f"[åˆçº¦è§„æ ¼] ä½¿ç”¨å›é€€å€¼: {coin_per_contract} å¸")
        
        # æ¯å¼ åˆçº¦çš„USDTä»·å€¼ = æ¯å¼ åˆçº¦çš„å¸æ•°é‡ * å½“å‰å¸ä»·
        usdt_per_contract = coin_per_contract * current_price
        
        # éœ€è¦çš„åˆçº¦å¼ æ•° = åˆçº¦ä»·å€¼ / æ¯å¼ åˆçº¦ä»·å€¼
        contracts_count = contract_value_usdt / usdt_per_contract
        
        # OKXè¦æ±‚szå¿…é¡»æ˜¯æ•´æ•°å¼ æ•°,å››èˆäº”å…¥
        contracts_count = max(1, round(contracts_count))
        contracts_str = str(int(contracts_count))
        
        # è®¡ç®—å®é™…ä½¿ç”¨çš„USDTé‡‘é¢
        actual_contract_value = contracts_count * usdt_per_contract
        actual_margin_used = actual_contract_value / leverage_value
        
        print(f"[ä¸‹å•è®¡ç®—] ç”¨æˆ·è¾“å…¥åˆçº¦ä»·å€¼: {user_usdt} USDT")
        print(f"[ä¸‹å•è®¡ç®—] æ æ†å€æ•°: {leverage_value}x")
        print(f"[ä¸‹å•è®¡ç®—] æ¯å¼ åˆçº¦: {coin_per_contract} å¸ = {usdt_per_contract:.4f} USDT")
        print(f"[ä¸‹å•è®¡ç®—] æ‰€éœ€å¼ æ•°: {contracts_count} å¼ ")
        print(f"[ä¸‹å•è®¡ç®—] å®é™…åˆçº¦ä»·å€¼: {actual_contract_value:.4f} USDT")
        print(f"[ä¸‹å•è®¡ç®—] å®é™…å ç”¨ä¿è¯é‡‘: {actual_margin_used:.4f} USDT")
        
        # æ„å»ºè¯·æ±‚ä½“
        order_params = {
            'instId': inst_id,
            'tdMode': 'isolated',  # é€ä»“æ¨¡å¼(åªä½¿ç”¨æŒ‡å®šçš„ä¿è¯é‡‘,ä¸ä¼šå ç”¨å…¨éƒ¨ä½™é¢)
            'side': side,
            'ordType': order_type,
            'sz': contracts_str  # åˆçº¦å¼ æ•°(å¸çš„æ•°é‡)
        }
        
        # åªæœ‰åœ¨åŒå‘æŒä»“æ¨¡å¼ä¸‹æ‰éœ€è¦æŒ‡å®šæŒä»“æ–¹å‘
        if position_mode == 'long_short_mode' and pos_side:
            order_params['posSide'] = pos_side
        else:
            # å•å‘æŒä»“æ¨¡å¼ä¸‹,OKXä¼šæ ¹æ®sideè‡ªåŠ¨åˆ¤æ–­æ–¹å‘
            # buy = å¼€å¤š/å¹³ç©º, sell = å¼€ç©º/å¹³å¤š
            print(f"[æŒä»“æ¨¡å¼] å•å‘æŒä»“,ä¸è®¾ç½®posSide,ç”±OKXæ ¹æ®side={side}è‡ªåŠ¨åˆ¤æ–­")
        
        # é™ä»·å•éœ€è¦ä»·æ ¼
        if order_type == 'limit' and price:
            order_params['px'] = str(price)
        
        body = json.dumps(order_params)
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path + body
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(base_url + request_path, headers=headers, data=body, timeout=10)
        result = response.json()
        
        # è®°å½•è¯¦ç»†æ—¥å¿—
        print(f"[OKXä¸‹å•] è¯·æ±‚å‚æ•°: {order_params}")
        print(f"[OKXä¸‹å•] å“åº”ç»“æœ: {result}")
        
        if result.get('code') == '0':
            order_data = result.get('data', [])
            if order_data:
                order = order_data[0]
                
                # è®°å½•æˆåŠŸæ—¥å¿—
                okx_trading_logger.log(
                    action='open_position',
                    account_id='user_account',  # å¯ä»¥ä»å‰ç«¯ä¼ å…¥
                    details={
                        'instId': inst_id,
                        'side': side,
                        'posSide': pos_side,
                        'ordType': order_type,
                        'contracts': contracts_str,
                        'inputUsdt': user_usdt,
                        'leverage': leverage_value,
                        'price': current_price
                    },
                    result={
                        'status': 'success',
                        'ordId': order.get('ordId', ''),
                        'actualUsdt': round(actual_margin_used, 2),
                        'contractValue': round(actual_contract_value, 2)
                    }
                )
                
                # å¦‚æœæœ‰æ­¢ç›ˆæ­¢æŸè®¾ç½®,åˆ™åœ¨ä¸‹å•æˆåŠŸåè®¾ç½®
                take_profit_percent = data.get('takeProfitPercent', None)
                stop_loss_percent = data.get('stopLossPercent', None)
                tpsl_result = None
                
                if take_profit_percent or stop_loss_percent:
                    try:
                        print(f"[OKXä¸‹å•] å¼€å§‹è®¾ç½®æ­¢ç›ˆæ­¢æŸ: TP={take_profit_percent}%, SL={stop_loss_percent}%")
                        
                        # ç­‰å¾…ä¸€ä¼šå„¿,ç¡®ä¿æŒä»“å·²ç»å»ºç«‹
                        import time
                        time.sleep(1)
                        
                        # è®¡ç®—æ­¢ç›ˆæ­¢æŸä»·æ ¼
                        tp_px = None
                        sl_px = None
                        
                        if take_profit_percent:
                            tp_percent = float(take_profit_percent) / 100
                            if pos_side == 'long':
                                tp_px = current_price * (1 + tp_percent)
                            else:
                                tp_px = current_price * (1 - tp_percent)
                            print(f"[OKXä¸‹å•] æ­¢ç›ˆä»·: {tp_px}")
                        
                        if stop_loss_percent:
                            sl_percent = float(stop_loss_percent) / 100
                            if pos_side == 'long':
                                sl_px = current_price * (1 - sl_percent)
                            else:
                                sl_px = current_price * (1 + sl_percent)
                            print(f"[OKXä¸‹å•] æ­¢æŸä»·: {sl_px}")
                        
                        # è°ƒç”¨OKXæ­¢ç›ˆæ­¢æŸAPI
                        algo_path = '/api/v5/trade/order-algo'
                        algo_params = {
                            'instId': inst_id,
                            'tdMode': 'isolated',
                            'side': 'sell' if pos_side == 'long' else 'buy',
                            'posSide': pos_side,
                            'ordType': 'conditional',
                            'sz': contracts_str,
                            'reduceOnly': 'true'
                        }
                        
                        if tp_px:
                            algo_params['tpTriggerPx'] = str(round(tp_px, 2))
                            algo_params['tpOrdPx'] = '-1'  # å¸‚ä»·
                        
                        if sl_px:
                            algo_params['slTriggerPx'] = str(round(sl_px, 2))
                            algo_params['slOrdPx'] = '-1'  # å¸‚ä»·
                        
                        algo_body = json.dumps(algo_params)
                        
                        # ç”Ÿæˆç­¾å
                        algo_timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
                        algo_message = algo_timestamp + 'POST' + algo_path + algo_body
                        algo_mac = hmac.new(
                            bytes(secret_key, encoding='utf8'),
                            bytes(algo_message, encoding='utf-8'),
                            digestmod='sha256'
                        )
                        algo_signature = base64.b64encode(algo_mac.digest()).decode()
                        
                        algo_headers = {
                            'OK-ACCESS-KEY': api_key,
                            'OK-ACCESS-SIGN': algo_signature,
                            'OK-ACCESS-TIMESTAMP': algo_timestamp,
                            'OK-ACCESS-PASSPHRASE': passphrase,
                            'Content-Type': 'application/json'
                        }
                        
                        algo_response = requests.post(base_url + algo_path, headers=algo_headers, data=algo_body, timeout=10)
                        algo_result = algo_response.json()
                        
                        print(f"[OKXä¸‹å•] æ­¢ç›ˆæ­¢æŸç»“æœ: {algo_result}")
                        
                        if algo_result.get('code') == '0':
                            tpsl_result = {
                                'success': True,
                                'tpPrice': tp_px,
                                'slPrice': sl_px
                            }
                            print(f"[OKXä¸‹å•] æ­¢ç›ˆæ­¢æŸè®¾ç½®æˆåŠŸ")
                        else:
                            tpsl_result = {
                                'success': False,
                                'error': algo_result.get('msg', 'è®¾ç½®å¤±è´¥')
                            }
                            print(f"[OKXä¸‹å•] æ­¢ç›ˆæ­¢æŸè®¾ç½®å¤±è´¥: {algo_result.get('msg')}")
                            
                    except Exception as e:
                        tpsl_result = {
                            'success': False,
                            'error': str(e)
                        }
                        print(f"[OKXä¸‹å•] æ­¢ç›ˆæ­¢æŸè®¾ç½®å¼‚å¸¸: {str(e)}")
                
                response_data = {
                    'success': True,
                    'data': {
                        'ordId': order.get('ordId', ''),
                        'clOrdId': order.get('clOrdId', ''),
                        'sCode': order.get('sCode', '0'),
                        'sMsg': order.get('sMsg', 'è®¢å•æäº¤æˆåŠŸ'),
                        'contracts': contracts_str,
                        'inputUsdt': user_usdt,  # ç”¨æˆ·è¾“å…¥çš„å¼€ä»“é‡‘é¢
                        'actualUsdt': round(actual_margin_used, 2),  # å®é™…å ç”¨çš„ä¿è¯é‡‘
                        'contractValue': round(actual_contract_value, 2),  # å®é™…åˆçº¦ä»·å€¼
                        'leverage': leverage_value,  # æ æ†å€æ•°
                        'price': current_price
                    },
                    'message': f'ä¸‹å•æˆåŠŸï¼å¼€ä»“ {round(actual_contract_value, 2)} USDT,å ç”¨ä¿è¯é‡‘ {round(actual_margin_used, 2)} USDT({leverage_value}xæ æ†)'
                }
                
                # æ·»åŠ æ­¢ç›ˆæ­¢æŸç»“æœ
                if tpsl_result:
                    response_data['tpslResult'] = tpsl_result
                    if tpsl_result.get('success'):
                        response_data['message'] += f"\nâœ… æ­¢ç›ˆæ­¢æŸå·²è®¾ç½®"
                    else:
                        response_data['message'] += f"\nâš ï¸ æ­¢ç›ˆæ­¢æŸè®¾ç½®å¤±è´¥: {tpsl_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                
                return jsonify(response_data)
            else:
                return jsonify({
                    'success': False,
                    'error': 'è®¢å•å“åº”æ•°æ®ä¸ºç©º'
                })
        else:
            # è®°å½•å¤±è´¥æ—¥å¿—
            error_msg = result.get('msg', 'ä¸‹å•å¤±è´¥')
            error_code = result.get('code', 'unknown')
            
            okx_trading_logger.log(
                action='open_position',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'side': side,
                    'posSide': pos_side,
                    'ordType': order_type,
                    'contracts': contracts_str,
                    'inputUsdt': user_usdt,
                    'leverage': leverage_value
                },
                result={
                    'status': 'failed',
                    'error': error_msg,
                    'code': error_code
                }
            )
            
            # è¿”å›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_msg = result.get('msg', 'ä¸‹å•å¤±è´¥')
            error_code = result.get('code', 'unknown')
            
            # å¸¸è§é”™è¯¯ä»£ç è§£é‡Š
            error_hints = {
                '1': 'æ“ä½œå¤±è´¥,è¯·æ£€æŸ¥APIæƒé™ã€è´¦æˆ·çŠ¶æ€å’Œè®¢å•å‚æ•°',
                '50004': 'API Keyæ— æ•ˆ',
                '50005': 'APIç­¾åé”™è¯¯',
                '50006': 'API Passphraseé”™è¯¯',
                '50007': 'APIæƒé™ä¸è¶³',
                '50011': 'ä½™é¢ä¸è¶³',
                '51000': 'å‚æ•°é”™è¯¯',
                '51001': 'äº¤æ˜“å¯¹ä¸å­˜åœ¨æˆ–å·²ä¸‹æ¶',
                '51008': 'è®¢å•æ•°é‡å¤ªå°',
                '51009': 'è®¢å•æ•°é‡å¤ªå¤§',
                '51010': 'è®¢å•é‡‘é¢å¤ªå°',
                '51020': 'è´¦æˆ·çŠ¶æ€å¼‚å¸¸',
            }
            
            hint = error_hints.get(error_code, '')
            full_error = f"{error_msg} (ä»£ç :{error_code})"
            if hint:
                full_error += f"\næç¤º: {hint}"
            
            return jsonify({
                'success': False,
                'error': full_error,
                'code': error_code,
                'details': {
                    'instId': inst_id,
                    'contracts': contracts_str,
                    'usdtAmount': size,
                    'price': current_price
                }
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-accounts/list-with-credentials', methods=['GET'])
def get_okx_accounts_list():
    """è·å–OKXè´¦æˆ·åˆ—è¡¨(å¸¦å‡­è¯)"""
    try:
        import json
        import os
        
        config_path = os.path.join(os.path.dirname(__file__), 'okx_accounts.json')
        
        # å¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨,ä»æ–‡ä»¶è¯»å–
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                accounts = config.get('accounts', [])
                default_account = config.get('default_account', accounts[0]['id'] if accounts else None)
        else:
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨,è¿”å›é»˜è®¤è´¦æˆ·
            accounts = [
                {
                    "id": "account_poit_main",
                    "name": "POIT (å­è´¦æˆ·)",
                    "apiKey": "8650e46c-059b-431d-93cf-55f8c79babdb",
                    "apiSecret": "4C2BD2AC6A08615EA7F36A6251857FCE",
                    "passphrase": "Wu666666."
                }
            ]
            default_account = "account_poit_main"
        
        return jsonify({
            'success': True,
            'accounts': accounts,
            'default_account': default_account
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/tpsl-settings/<account_id>', methods=['GET'])
def get_okx_tpsl_settings(account_id):
    """è·å–æŒ‡å®šè´¦æˆ·çš„æ­¢ç›ˆæ­¢æŸè®¾ç½®"""
    try:
        import json
        import os
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‘ä¸Šä¸¤çº§ï¼‰
        current_dir = os.path.dirname(os.path.abspath(__file__))  # /home/user/webapp/code/python
        project_root = os.path.dirname(os.path.dirname(current_dir))  # /home/user/webapp
        settings_dir = os.path.join(project_root, 'data', 'okx_tpsl_settings')
        os.makedirs(settings_dir, exist_ok=True)
        
        settings_file = os.path.join(settings_dir, f'{account_id}.json')
        
        # å¦‚æœè®¾ç½®æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶è¿”å›
        if os.path.exists(settings_file):
            with open(settings_file, 'r', encoding='utf-8') as f:
                settings = json.load(f)
                return jsonify({
                    'success': True,
                    'settings': settings
                })
        else:
            # è¿”å›é»˜è®¤è®¾ç½®
            default_settings = {
                'takeProfitThreshold': 50,
                'stopLossThreshold': -30,
                'takeProfitEnabled': False,
                'stopLossEnabled': False
            }
            return jsonify({
                'success': True,
                'settings': default_settings
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/tpsl-settings/<account_id>', methods=['POST'])
def save_okx_tpsl_settings(account_id):
    """ä¿å­˜æŒ‡å®šè´¦æˆ·çš„æ­¢ç›ˆæ­¢æŸè®¾ç½®"""
    try:
        import json
        import os
        from datetime import datetime
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‘ä¸Šä¸¤çº§ï¼‰
        current_dir = os.path.dirname(os.path.abspath(__file__))  # /home/user/webapp/code/python
        project_root = os.path.dirname(os.path.dirname(current_dir))  # /home/user/webapp
        settings_dir = os.path.join(project_root, 'data', 'okx_tpsl_settings')
        os.makedirs(settings_dir, exist_ok=True)
        
        settings_file = os.path.join(settings_dir, f'{account_id}.json')
        
        # è·å–å‰ç«¯ä¼ æ¥çš„è®¾ç½®
        data = request.get_json()
        
        # æ·»åŠ æ—¶é—´æˆ³
        settings = {
            'takeProfitThreshold': float(data.get('takeProfitThreshold', 50)),
            'stopLossThreshold': float(data.get('stopLossThreshold', -30)),
            'takeProfitEnabled': bool(data.get('takeProfitEnabled', False)),
            'stopLossEnabled': bool(data.get('stopLossEnabled', False)),
            'lastUpdated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(settings_file, 'w', encoding='utf-8') as f:
            json.dump(settings, f, ensure_ascii=False, indent=2)
        
        # åŒæ—¶ä¿å­˜åˆ°JSONLå†å²è®°å½•
        jsonl_file = os.path.join(settings_dir, f'{account_id}_history.jsonl')
        with open(jsonl_file, 'a', encoding='utf-8') as f:
            history_entry = settings.copy()
            history_entry['timestamp'] = datetime.now().isoformat()
            f.write(json.dumps(history_entry, ensure_ascii=False) + '\n')
        
        return jsonify({
            'success': True,
            'message': 'æ­¢ç›ˆæ­¢æŸè®¾ç½®å·²ä¿å­˜',
            'settings': settings
        })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/auto-strategy/<account_id>', methods=['GET'])
def get_okx_auto_strategy(account_id):
    """è·å–æŒ‡å®šè´¦æˆ·çš„è‡ªåŠ¨äº¤æ˜“ç­–ç•¥è®¾ç½®"""
    try:
        import json
        import os
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))
        settings_dir = os.path.join(project_root, 'data', 'okx_auto_strategy')
        os.makedirs(settings_dir, exist_ok=True)
        
        settings_file = os.path.join(settings_dir, f'{account_id}.json')
        
        # å¦‚æœè®¾ç½®æ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶è¿”å›
        if os.path.exists(settings_file):
            with open(settings_file, 'r', encoding='utf-8') as f:
                settings = json.load(f)
                return jsonify({
                    'success': True,
                    'settings': settings
                })
        else:
            # è¿”å›é»˜è®¤è®¾ç½®
            default_settings = {
                'enabled': False,
                'triggerPrice': 65000,
                'lastExecutedTime': None,
                'executedCount': 0
            }
            return jsonify({
                'success': True,
                'settings': default_settings
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/auto-strategy/<account_id>', methods=['POST'])
def save_okx_auto_strategy(account_id):
    """ä¿å­˜æŒ‡å®šè´¦æˆ·çš„è‡ªåŠ¨äº¤æ˜“ç­–ç•¥è®¾ç½®"""
    try:
        import json
        import os
        from datetime import datetime
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(current_dir))
        settings_dir = os.path.join(project_root, 'data', 'okx_auto_strategy')
        os.makedirs(settings_dir, exist_ok=True)
        
        settings_file = os.path.join(settings_dir, f'{account_id}.json')
        
        # è·å–å‰ç«¯ä¼ æ¥çš„è®¾ç½®
        data = request.get_json()
        
        # æ„å»ºè®¾ç½®å¯¹è±¡
        settings = {
            'enabled': bool(data.get('enabled', False)),
            'triggerPrice': float(data.get('triggerPrice', 65000)),
            'lastExecutedTime': data.get('lastExecutedTime'),
            'executedCount': int(data.get('executedCount', 0)),
            'lastUpdated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(settings_file, 'w', encoding='utf-8') as f:
            json.dump(settings, f, ensure_ascii=False, indent=2)
        
        # åŒæ—¶ä¿å­˜åˆ°JSONLå†å²è®°å½•
        jsonl_file = os.path.join(settings_dir, f'{account_id}_history.jsonl')
        with open(jsonl_file, 'a', encoding='utf-8') as f:
            history_entry = settings.copy()
            history_entry['timestamp'] = datetime.now().isoformat()
            f.write(json.dumps(history_entry, ensure_ascii=False) + '\n')
        
        return jsonify({
            'success': True,
            'message': 'è‡ªåŠ¨äº¤æ˜“ç­–ç•¥è®¾ç½®å·²ä¿å­˜',
            'settings': settings
        })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/market-tickers', methods=['GET'])
def get_okx_market_tickers():
    """è·å–OKXå¸‚åœºè¡Œæƒ…æ•°æ®"""
    try:
        import requests
        
        # è·å–æ‰€æœ‰SWAPåˆçº¦çš„è¡Œæƒ…
        base_url = 'https://www.okx.com'
        ticker_path = '/api/v5/market/tickers?instType=SWAP'
        
        response = requests.get(base_url + ticker_path, timeout=10)
        result = response.json()
        
        if result.get('code') == '0':
            tickers_data = result.get('data', [])
            
            # æŒ‡å®šè¦æ˜¾ç¤ºçš„27ä¸ªå¸ç§
            allowed_symbols = [
                'BTC', 'ETH', 'XRP', 'BNB', 'SOL', 'LTC', 'DOGE', 'SUI', 'TRX',
                'TON', 'ETC', 'BCH', 'HBAR', 'XLM', 'FIL', 'LINK', 'CRO', 'DOT',
                'AAVE', 'UNI', 'NEAR', 'APT', 'CFX', 'CRV', 'STX', 'LDO', 'TAO'
            ]
            
            # åªè¿”å›æŒ‡å®šçš„USDT-SWAPäº¤æ˜“å¯¹
            usdt_tickers = []
            for ticker in tickers_data:
                inst_id = ticker.get('instId', '')
                if 'USDT-SWAP' in inst_id:
                    # æå–å¸ç§åç§°
                    symbol = inst_id.replace('-USDT-SWAP', '')
                    
                    # åªå¤„ç†å…è®¸çš„å¸ç§
                    if symbol not in allowed_symbols:
                        continue
                    
                    # è®¡ç®—UTC+8 0ç‚¹å¼€å§‹çš„æ¶¨è·Œå¹…
                    current_price = float(ticker.get('last', 0))
                    open_price_utc8 = float(ticker.get('sodUtc8', 0))  # UTC+8 0ç‚¹(åŒ—äº¬æ—¶é—´0ç‚¹)çš„å¼€ç›˜ä»·
                    
                    # è®¡ç®—æ¶¨è·Œå¹…ç™¾åˆ†æ¯”
                    if open_price_utc8 > 0:
                        change_percent = ((current_price - open_price_utc8) / open_price_utc8) * 100
                    else:
                        change_percent = 0
                    
                    usdt_tickers.append({
                        'symbol': inst_id,
                        'name': symbol,
                        'price': current_price,
                        'change24h': round(change_percent, 2),  # 24hæ¶¨è·Œå¹…(UTC+8 0ç‚¹å¼€å§‹)
                        'high24h': float(ticker.get('high24h', 0)),
                        'low24h': float(ticker.get('low24h', 0)),
                        'vol24h': float(ticker.get('vol24h', 0)),
                        'volCcy24h': float(ticker.get('volCcy24h', 0)),
                        'timestamp': ticker.get('ts', '')
                    })
            
            # æŒ‰ç…§æŒ‡å®šé¡ºåºæ’åº
            sorted_tickers = []
            for symbol in allowed_symbols:
                ticker = next((t for t in usdt_tickers if t['name'] == symbol), None)
                if ticker:
                    sorted_tickers.append(ticker)
            
            return jsonify({
                'success': True,
                'data': sorted_tickers,
                'count': len(sorted_tickers)
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('msg', 'è·å–è¡Œæƒ…å¤±è´¥')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/okx-trading/pending-orders', methods=['POST'])
def get_okx_pending_orders():
    """è·å–å½“å‰å§”æ‰˜(æœªæˆäº¤è®¢å•)"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        request_path = '/api/v5/trade/orders-pending?instType=SWAP'
        method = 'GET'
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.get(base_url + request_path, headers=headers, timeout=10)
        result = response.json()
        
        if result.get('code') == '0':
            orders_data = result.get('data', [])
            
            # æ ¼å¼åŒ–è®¢å•æ•°æ®
            orders = []
            for order in orders_data:
                orders.append({
                    'ordId': order.get('ordId'),
                    'instId': order.get('instId'),
                    'side': order.get('side'),  # buy/sell
                    'posSide': order.get('posSide'),  # long/short
                    'ordType': order.get('ordType'),  # market/limit
                    'px': order.get('px', ''),  # å§”æ‰˜ä»·æ ¼
                    'sz': order.get('sz'),  # å§”æ‰˜æ•°é‡
                    'fillSz': order.get('fillSz', '0'),  # å·²æˆäº¤æ•°é‡
                    'avgPx': order.get('avgPx', '0'),  # æˆäº¤å‡ä»·
                    'state': order.get('state'),  # live/partially_filled
                    'cTime': order.get('cTime'),  # åˆ›å»ºæ—¶é—´
                    'uTime': order.get('uTime')  # æ›´æ–°æ—¶é—´
                })
            
            return jsonify({
                'success': True,
                'data': orders,
                'count': len(orders)
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('msg', 'è·å–å§”æ‰˜å¤±è´¥'),
                'code': result.get('code', '')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/cancel-order', methods=['POST'])
def cancel_okx_order():
    """æ’¤é”€è®¢å•"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        order_id = data.get('ordId', '')
        inst_id = data.get('instId', '')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        if not order_id or not inst_id:
            return jsonify({
                'success': False,
                'error': 'è®¢å•IDæˆ–äº¤æ˜“å¯¹ä¸èƒ½ä¸ºç©º'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        request_path = '/api/v5/trade/cancel-order'
        method = 'POST'
        
        # æ„å»ºè¯·æ±‚ä½“
        order_params = {
            'instId': inst_id,
            'ordId': order_id
        }
        
        body = json.dumps(order_params)
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path + body
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(base_url + request_path, headers=headers, data=body, timeout=10)
        result = response.json()
        
        print(f"[OKXæ’¤å•] è¯·æ±‚å‚æ•°: {order_params}")
        print(f"[OKXæ’¤å•] å“åº”ç»“æœ: {result}")
        
        if result.get('code') == '0':
            # è®°å½•æ’¤å•æˆåŠŸæ—¥å¿—
            okx_trading_logger.log(
                action='cancel_order',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'ordId': ord_id
                },
                result={
                    'status': 'success'
                }
            )
            
            return jsonify({
                'success': True,
                'message': 'æ’¤å•æˆåŠŸ'
            })
        else:
            # è®°å½•æ’¤å•å¤±è´¥æ—¥å¿—
            okx_trading_logger.log(
                action='cancel_order',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'ordId': ord_id
                },
                result={
                    'status': 'failed',
                    'error': result.get('msg', 'æ’¤å•å¤±è´¥'),
                    'code': result.get('code', '')
                }
            )
            
            return jsonify({
                'success': False,
                'error': result.get('msg', 'æ’¤å•å¤±è´¥'),
                'code': result.get('code', '')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/order-detail', methods=['POST'])
def get_okx_order_detail():
    """æŸ¥è¯¢OKXè®¢å•è¯¦æƒ…"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        order_id = data.get('ordId', '')
        inst_id = data.get('instId', '')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        if not order_id or not inst_id:
            return jsonify({
                'success': False,
                'error': 'è®¢å•IDæˆ–äº¤æ˜“å¯¹ä¸èƒ½ä¸ºç©º'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        request_path = f'/api/v5/trade/order?instId={inst_id}&ordId={order_id}'
        method = 'GET'
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.get(base_url + request_path, headers=headers, timeout=10)
        result = response.json()
        
        print(f"[OKXè®¢å•æŸ¥è¯¢] è®¢å•ID: {order_id}, å“åº”: {result}")
        
        if result.get('code') == '0':
            order_data = result.get('data', [])
            if order_data:
                order = order_data[0]
                
                # è®¢å•çŠ¶æ€æ˜ å°„
                state_map = {
                    'live': 'ç­‰å¾…æˆäº¤',
                    'partially_filled': 'éƒ¨åˆ†æˆäº¤',
                    'filled': 'å®Œå…¨æˆäº¤',
                    'canceled': 'å·²æ’¤é”€',
                    'mmp_canceled': 'åšå¸‚å•†ä¿æŠ¤æ’¤å•',
                    'partially_canceled': 'éƒ¨åˆ†æˆäº¤å·²æ’¤é”€'
                }
                
                state = order.get('state', '')
                state_text = state_map.get(state, state)
                
                return jsonify({
                    'success': True,
                    'data': {
                        'ordId': order.get('ordId'),
                        'instId': order.get('instId'),
                        'state': state,
                        'stateText': state_text,
                        'px': order.get('px', ''),  # å§”æ‰˜ä»·æ ¼
                        'sz': order.get('sz', ''),  # å§”æ‰˜æ•°é‡
                        'fillSz': order.get('fillSz', '0'),  # æˆäº¤æ•°é‡
                        'avgPx': order.get('avgPx', '0'),  # æˆäº¤å‡ä»·
                        'side': order.get('side', ''),  # buy/sell
                        'posSide': order.get('posSide', ''),  # long/short
                        'ordType': order.get('ordType', ''),  # market/limit
                        'fee': order.get('fee', '0'),  # æ‰‹ç»­è´¹
                        'rebate': order.get('rebate', '0'),  # è¿”ä½£
                        'pnl': order.get('pnl', '0'),  # æ”¶ç›Š
                        'uTime': order.get('uTime', ''),  # æ›´æ–°æ—¶é—´
                        'cTime': order.get('cTime', ''),  # åˆ›å»ºæ—¶é—´
                        'cancelSource': order.get('cancelSource', ''),  # æ’¤å•æ¥æº
                        'code': order.get('code', ''),  # é”™è¯¯ç 
                        'msg': order.get('msg', '')  # é”™è¯¯ä¿¡æ¯
                    }
                })
            else:
                return jsonify({
                    'success': False,
                    'error': 'è®¢å•ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ'
                })
        else:
            return jsonify({
                'success': False,
                'error': result.get('msg', 'æŸ¥è¯¢å¤±è´¥'),
                'code': result.get('code', '')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/trade-history', methods=['POST'])
def get_okx_trade_history():
    """è·å–OKXäº¤æ˜“å†å²(ä»JSONLæ–‡ä»¶è¯»å–)"""
    try:
        import json
        from pathlib import Path
        from datetime import datetime
        
        data = request.get_json()
        start_date = data.get('startDate', '')  # æ ¼å¼: YYYYMMDD
        end_date = data.get('endDate', '')      # æ ¼å¼: YYYYMMDD
        
        # æ•°æ®ç›®å½•
        data_dir = Path(__file__).parent / 'data' / 'okx_trading_history'
        
        if not data_dir.exists():
            return jsonify({
                'success': False,
                'message': 'äº¤æ˜“å†å²æ•°æ®ç›®å½•ä¸å­˜åœ¨'
            })
        
        # è§£ææ—¥æœŸèŒƒå›´
        if start_date:
            start_dt = datetime.strptime(start_date, '%Y%m%d')
        else:
            start_dt = datetime.now() - timedelta(days=7)
        
        if end_date:
            end_dt = datetime.strptime(end_date, '%Y%m%d')
        else:
            end_dt = datetime.now()
        
        # æ”¶é›†æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ‰€æœ‰äº¤æ˜“
        all_trades = []
        current_date = start_dt
        
        while current_date <= end_dt:
            date_str = current_date.strftime('%Y%m%d')
            file_path = data_dir / f'okx_trades_{date_str}.jsonl'
            
            if file_path.exists():
                with open(file_path, 'r') as f:
                    for line in f:
                        if line.strip():
                            try:
                                trade = json.loads(line)
                                all_trades.append(trade)
                            except json.JSONDecodeError:
                                continue
            
            current_date += timedelta(days=1)
        
        # æŒ‰æ—¶é—´å€’åºæ’åºï¼ˆå°†fillTimeè½¬æ¢ä¸ºæ•´æ•°ï¼‰
        def get_fill_time(trade):
            try:
                fill_time = trade.get('fillTime', '0')
                return int(fill_time) if fill_time else 0
            except (ValueError, TypeError):
                return 0
        
        all_trades.sort(key=get_fill_time, reverse=True)
        
        return jsonify({
            'success': True,
            'data': all_trades,
            'count': len(all_trades)
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/okx-trading/angles', methods=['GET'])
def get_okx_angles():
    """è·å–OKXè¶‹åŠ¿è§’åº¦åˆ†ææ•°æ®"""
    try:
        import json
        from pathlib import Path
        from datetime import datetime, timedelta
        
        # è·å–æ—¥æœŸå‚æ•°(æ”¯æŒå¤šä¸ªæ—¥æœŸ)
        date_str = request.args.get('date', '')  # å•ä¸ªæ—¥æœŸ YYYYMMDD
        start_date = request.args.get('startDate', '')  # èµ·å§‹æ—¥æœŸ
        end_date = request.args.get('endDate', '')  # ç»“æŸæ—¥æœŸ
        
        # æ•°æ®ç›®å½•
        data_dir = Path(__file__).parent / 'data' / 'okx_angle_analysis'
        
        if not data_dir.exists():
            return jsonify({
                'success': False,
                'message': 'è§’åº¦åˆ†ææ•°æ®ç›®å½•ä¸å­˜åœ¨'
            })
        
        all_angles = []
        
        # ç¡®å®šæ—¥æœŸèŒƒå›´
        if date_str:
            # å•ä¸ªæ—¥æœŸ
            dates = [date_str]
        elif start_date and end_date:
            # æ—¥æœŸèŒƒå›´
            start_dt = datetime.strptime(start_date, '%Y%m%d')
            end_dt = datetime.strptime(end_date, '%Y%m%d')
            dates = []
            current = start_dt
            while current <= end_dt:
                dates.append(current.strftime('%Y%m%d'))
                current += timedelta(days=1)
        else:
            # é»˜è®¤æœ€è¿‘3å¤©
            today = datetime.now()
            dates = [(today - timedelta(days=i)).strftime('%Y%m%d') for i in range(3)]
        
        # è¯»å–å„æ—¥æœŸçš„è§’åº¦æ•°æ®
        for date in dates:
            file_path = data_dir / f'okx_angles_{date}.jsonl'
            
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            try:
                                angle_data = json.loads(line)
                                all_angles.append(angle_data)
                            except json.JSONDecodeError:
                                continue
        
        return jsonify({
            'success': True,
            'data': all_angles,
            'count': len(all_angles)
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/okx-trading/angles/manual', methods=['POST', 'DELETE'])
def manage_manual_angles():
    """ç®¡ç†æ‰‹åŠ¨è§’åº¦æ ‡è®°"""
    try:
        import json
        from pathlib import Path
        from datetime import datetime
        
        # æ•°æ®ç›®å½•
        data_dir = Path(__file__).parent / 'data' / 'okx_angle_analysis'
        if not data_dir.exists():
            data_dir.mkdir(parents=True, exist_ok=True)
        
        if request.method == 'POST':
            # ä¿å­˜æ‰‹åŠ¨è§’åº¦
            data = request.get_json()
            angle = data.get('angle')
            date_str = data.get('date')
            
            if not angle or not date_str:
                return jsonify({
                    'success': False,
                    'message': 'ç¼ºå°‘å¿…è¦å‚æ•°:angleæˆ–date'
                })
            
            # æ ‡è®°ä¸ºæ‰‹åŠ¨æ·»åŠ 
            angle['manual'] = True
            angle['created_at'] = datetime.now().isoformat()
            
            # è¯»å–ç°æœ‰æ•°æ®
            file_path = data_dir / f'okx_angles_{date_str}.jsonl'
            existing_angles = []
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            try:
                                existing_angles.append(json.loads(line))
                            except json.JSONDecodeError:
                                continue
            
            # æ·»åŠ æ–°è§’åº¦
            existing_angles.append(angle)
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                for a in existing_angles:
                    f.write(json.dumps(a, ensure_ascii=False) + '\n')
            
            return jsonify({
                'success': True,
                'message': 'æ‰‹åŠ¨è§’åº¦å·²ä¿å­˜',
                'angle': angle
            })
        
        elif request.method == 'DELETE':
            # åˆ é™¤è§’åº¦(æ”¯æŒæ‰‹åŠ¨å’Œç³»ç»Ÿè§’åº¦,ç”¨äºçº é”™)
            data = request.get_json()
            date_str = data.get('date')
            peak_time = data.get('peak_time')
            angle_value = data.get('angle')
            
            if not date_str or not peak_time:
                return jsonify({
                    'success': False,
                    'message': 'ç¼ºå°‘å¿…è¦å‚æ•°:dateæˆ–peak_time'
                })
            
            # è¯»å–ç°æœ‰æ•°æ®
            file_path = data_dir / f'okx_angles_{date_str}.jsonl'
            if not file_path.exists():
                return jsonify({
                    'success': False,
                    'message': 'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨'
                })
            
            existing_angles = []
            deleted = False
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            angle_data = json.loads(line)
                            # åˆ é™¤åŒ¹é…çš„è§’åº¦(æ”¯æŒæ‰‹åŠ¨å’Œç³»ç»Ÿè§’åº¦)
                            if (angle_data.get('peak_time') == peak_time and
                                angle_data.get('angle') == angle_value):
                                deleted = True
                                # è®°å½•åˆ é™¤çš„è§’åº¦ç±»å‹
                                angle_type = 'æ‰‹åŠ¨' if angle_data.get('manual') else 'ç³»ç»Ÿ'
                                print(f"ğŸ—‘ï¸ åˆ é™¤{angle_type}è§’åº¦: {peak_time} {angle_value}Â°")
                                continue
                            existing_angles.append(angle_data)
                        except json.JSONDecodeError:
                            continue
            
            if not deleted:
                return jsonify({
                    'success': False,
                    'message': 'æœªæ‰¾åˆ°åŒ¹é…çš„è§’åº¦'
                })
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                for a in existing_angles:
                    f.write(json.dumps(a, ensure_ascii=False) + '\n')
            
            return jsonify({
                'success': True,
                'message': 'è§’åº¦å·²åˆ é™¤'
            })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/okx-trading/trade-ratings', methods=['GET', 'POST', 'DELETE'])
def manage_trade_ratings():
    """ç®¡ç†äº¤æ˜“è¯„ä»·å’Œå¤‡æ³¨
    
    GET: è·å–æŒ‡å®šæ—¥æœŸçš„äº¤æ˜“è¯„ä»·
    POST: ä¿å­˜æˆ–æ›´æ–°äº¤æ˜“è¯„ä»·
    DELETE: åˆ é™¤äº¤æ˜“è¯„ä»·
    """
    try:
        import json
        from pathlib import Path
        from datetime import datetime
        
        # æ•°æ®ç›®å½•
        data_dir = Path(__file__).parent / 'data' / 'trade_ratings'
        if not data_dir.exists():
            data_dir.mkdir(parents=True, exist_ok=True)
        
        if request.method == 'GET':
            # è·å–äº¤æ˜“è¯„ä»·
            date_str = request.args.get('date')
            
            if not date_str:
                return jsonify({
                    'success': False,
                    'message': 'ç¼ºå°‘æ—¥æœŸå‚æ•°'
                })
            
            # è¯»å–è¯¥æ—¥æœŸçš„è¯„ä»·æ–‡ä»¶
            file_path = data_dir / f'ratings_{date_str}.jsonl'
            ratings = []
            
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            try:
                                ratings.append(json.loads(line))
                            except json.JSONDecodeError:
                                continue
            
            return jsonify({
                'success': True,
                'ratings': ratings,
                'count': len(ratings)
            })
        
        elif request.method == 'POST':
            # ä¿å­˜æˆ–æ›´æ–°äº¤æ˜“è¯„ä»·
            data = request.get_json()
            trade_id = data.get('tradeId')
            date_str = data.get('date')
            rating = data.get('rating')  # 'correct' or 'incorrect'
            note = data.get('note', '').strip()[:50]  # é™åˆ¶50å­—
            
            if not trade_id or not date_str or not rating:
                return jsonify({
                    'success': False,
                    'message': 'ç¼ºå°‘å¿…è¦å‚æ•°:tradeId, date, rating'
                })
            
            if rating not in ['correct', 'incorrect']:
                return jsonify({
                    'success': False,
                    'message': 'rating å¿…é¡»æ˜¯ correct æˆ– incorrect'
                })
            
            # åˆ›å»ºè¯„ä»·å¯¹è±¡
            new_rating = {
                'tradeId': trade_id,
                'date': date_str,
                'rating': rating,
                'note': note,
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            # è¯»å–ç°æœ‰è¯„ä»·
            file_path = data_dir / f'ratings_{date_str}.jsonl'
            existing_ratings = []
            updated = False
            
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            try:
                                rating_data = json.loads(line)
                                if rating_data.get('tradeId') == trade_id:
                                    # æ›´æ–°ç°æœ‰è¯„ä»·
                                    rating_data.update({
                                        'rating': rating,
                                        'note': note,
                                        'updated_at': datetime.now().isoformat()
                                    })
                                    existing_ratings.append(rating_data)
                                    updated = True
                                else:
                                    existing_ratings.append(rating_data)
                            except json.JSONDecodeError:
                                continue
            
            # å¦‚æœæ˜¯æ–°è¯„ä»·,æ·»åŠ åˆ°åˆ—è¡¨
            if not updated:
                existing_ratings.append(new_rating)
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                for r in existing_ratings:
                    f.write(json.dumps(r, ensure_ascii=False) + '\n')
            
            return jsonify({
                'success': True,
                'message': 'è¯„ä»·ä¿å­˜æˆåŠŸ',
                'rating': new_rating
            })
        
        elif request.method == 'DELETE':
            # åˆ é™¤äº¤æ˜“è¯„ä»·
            data = request.get_json()
            trade_id = data.get('tradeId')
            date_str = data.get('date')
            
            if not trade_id or not date_str:
                return jsonify({
                    'success': False,
                    'message': 'ç¼ºå°‘å¿…è¦å‚æ•°:tradeId, date'
                })
            
            file_path = data_dir / f'ratings_{date_str}.jsonl'
            if not file_path.exists():
                return jsonify({
                    'success': False,
                    'message': 'è¯„ä»·æ–‡ä»¶ä¸å­˜åœ¨'
                })
            
            # è¯»å–å¹¶è¿‡æ»¤
            existing_ratings = []
            deleted = False
            
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        try:
                            rating_data = json.loads(line)
                            if rating_data.get('tradeId') == trade_id:
                                deleted = True
                                continue
                            existing_ratings.append(rating_data)
                        except json.JSONDecodeError:
                            continue
            
            if not deleted:
                return jsonify({
                    'success': False,
                    'message': 'æœªæ‰¾åˆ°è¯¥äº¤æ˜“çš„è¯„ä»·'
                })
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                for r in existing_ratings:
                    f.write(json.dumps(r, ensure_ascii=False) + '\n')
            
            return jsonify({
                'success': True,
                'message': 'è¯„ä»·å·²åˆ é™¤'
            })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })

@app.route('/api/okx-trading/close-position', methods=['POST'])
def close_okx_position():
    """å¹³ä»“æ¥å£ - æ”¯æŒå…¨éƒ¨å¹³ä»“æˆ–éƒ¨åˆ†å¹³ä»“"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        inst_id = data.get('instId', '')
        pos_side = data.get('posSide', '')  # long/short
        close_size = data.get('closeSize', None)  # å¹³ä»“æ•°é‡(å¼ æ•°),None=å…¨éƒ¨å¹³ä»“
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        if not inst_id or not pos_side:
            return jsonify({
                'success': False,
                'error': 'äº¤æ˜“å¯¹å’ŒæŒä»“æ–¹å‘ä¸èƒ½ä¸ºç©º'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        method = 'POST'
        
        # ğŸ”¥ å…ˆæŸ¥è¯¢è´¦æˆ·æŒä»“æ¨¡å¼
        position_mode = 'long_short_mode'  # é»˜è®¤åŒå‘æŒä»“
        try:
            config_path = '/api/v5/account/config'
            config_timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
            config_message = config_timestamp + 'GET' + config_path
            config_mac = hmac.new(
                bytes(secret_key, encoding='utf8'),
                bytes(config_message, encoding='utf-8'),
                digestmod='sha256'
            )
            config_signature = base64.b64encode(config_mac.digest()).decode()
            
            config_response = requests.get(base_url + config_path, headers={
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': config_signature,
                'OK-ACCESS-TIMESTAMP': config_timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
            }, timeout=5)
            config_result = config_response.json()
            if config_result.get('code') == '0' and config_result.get('data'):
                position_mode = config_result['data'][0].get('posMode', 'long_short_mode')
                print(f"[å¹³ä»“-è´¦æˆ·é…ç½®] æŒä»“æ¨¡å¼: {position_mode}")
            else:
                print(f"[å¹³ä»“-è´¦æˆ·é…ç½®] æŸ¥è¯¢å¤±è´¥: {config_result}")
        except Exception as e:
            print(f"[å¹³ä»“-è´¦æˆ·é…ç½®] è·å–å¤±è´¥,é»˜è®¤åŒå‘æŒä»“: {str(e)}")
        
        # åˆ¤æ–­æ˜¯å…¨éƒ¨å¹³ä»“è¿˜æ˜¯éƒ¨åˆ†å¹³ä»“
        if close_size is None or close_size == 0:
            # å…¨éƒ¨å¹³ä»“:ä½¿ç”¨ close-position æ¥å£
            request_path = '/api/v5/trade/close-position'
            order_params = {
                'instId': inst_id,
                'mgnMode': 'isolated'  # é€ä»“æ¨¡å¼
            }
            
            # åªæœ‰åœ¨åŒå‘æŒä»“æ¨¡å¼ä¸‹æ‰éœ€è¦æŒ‡å®šposSide
            if position_mode == 'long_short_mode':
                order_params['posSide'] = pos_side
                print(f"[OKXå¹³ä»“] å…¨éƒ¨å¹³ä»“(åŒå‘æŒä»“): {inst_id} {pos_side}")
            else:
                # å•å‘æŒä»“æ¨¡å¼ä¸‹,OKXä¼šè‡ªåŠ¨åˆ¤æ–­æ–¹å‘
                print(f"[OKXå¹³ä»“] å…¨éƒ¨å¹³ä»“(å•å‘æŒä»“): {inst_id}")
        else:
            # éƒ¨åˆ†å¹³ä»“:ä½¿ç”¨ä¸‹å•æ¥å£,é€šè¿‡åå‘å¼€ä»“æ¥å¹³ä»“
            request_path = '/api/v5/trade/order'
            
            # å¹³å¤šå• -> sell,å¹³ç©ºå• -> buy
            side = 'sell' if pos_side == 'long' else 'buy'
            
            order_params = {
                'instId': inst_id,
                'tdMode': 'isolated',
                'side': side,
                'ordType': 'market',  # å¸‚ä»·å•
                'sz': str(int(close_size)),  # å¹³ä»“æ•°é‡(å¼ æ•°)
                'reduceOnly': 'true'  # åªå‡ä»“,ä¸å¼€æ–°ä»“
            }
            
            # åªæœ‰åœ¨åŒå‘æŒä»“æ¨¡å¼ä¸‹æ‰éœ€è¦æŒ‡å®šposSide
            if position_mode == 'long_short_mode':
                order_params['posSide'] = pos_side
                print(f"[OKXå¹³ä»“] éƒ¨åˆ†å¹³ä»“(åŒå‘æŒä»“): {inst_id} {pos_side} {close_size}å¼ ")
            else:
                # å•å‘æŒä»“æ¨¡å¼ä¸‹,OKXä¼šæ ¹æ®sideè‡ªåŠ¨åˆ¤æ–­æ–¹å‘
                print(f"[OKXå¹³ä»“] éƒ¨åˆ†å¹³ä»“(å•å‘æŒä»“): {inst_id} {close_size}å¼ ")
        
        body = json.dumps(order_params)
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path + body
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(base_url + request_path, headers=headers, data=body, timeout=10)
        result = response.json()
        
        print(f"[OKXå¹³ä»“] è¯·æ±‚å‚æ•°: {order_params}")
        print(f"[OKXå¹³ä»“] å“åº”ç»“æœ: {result}")
        
        if result.get('code') == '0':
            # è®°å½•å¹³ä»“æˆåŠŸæ—¥å¿—
            okx_trading_logger.log(
                action='close_position',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'posSide': pos_side,
                    'closeSize': close_size,
                    'closeType': 'full' if close_size is None else 'partial'
                },
                result={
                    'status': 'success'
                }
            )
            
            return jsonify({
                'success': True,
                'message': 'å¹³ä»“æˆåŠŸ'
            })
        else:
            # è®°å½•å¹³ä»“å¤±è´¥æ—¥å¿—
            okx_trading_logger.log(
                action='close_position',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'posSide': pos_side,
                    'closeSize': close_size
                },
                result={
                    'status': 'failed',
                    'error': result.get('msg', 'å¹³ä»“å¤±è´¥'),
                    'code': result.get('code', '')
                }
            )
            
            return jsonify({
                'success': False,
                'error': result.get('msg', 'å¹³ä»“å¤±è´¥'),
                'code': result.get('code', '')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/set-tpsl', methods=['POST'])
def set_okx_tpsl():
    """è®¾ç½®æ­¢ç›ˆæ­¢æŸæ¥å£ - åŸºäºç™¾åˆ†æ¯”è®¾ç½®"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone
        import requests
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        inst_id = data.get('instId', '')
        pos_side = data.get('posSide', '')  # long/short
        take_profit_percent = data.get('takeProfitPercent', None)  # æ­¢ç›ˆç™¾åˆ†æ¯”
        stop_loss_percent = data.get('stopLossPercent', None)  # æ­¢æŸç™¾åˆ†æ¯”
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        if not inst_id or not pos_side:
            return jsonify({
                'success': False,
                'error': 'äº¤æ˜“å¯¹å’ŒæŒä»“æ–¹å‘ä¸èƒ½ä¸ºç©º'
            })
        
        if not take_profit_percent and not stop_loss_percent:
            return jsonify({
                'success': False,
                'error': 'è‡³å°‘éœ€è¦è®¾ç½®æ­¢ç›ˆæˆ–æ­¢æŸ'
            })
        
        # é¦–å…ˆè·å–æŒä»“ä¿¡æ¯ä»¥è·å–å¼€ä»“å‡ä»·
        base_url = 'https://www.okx.com'
        positions_path = '/api/v5/account/positions'
        
        # è·å–æŒä»“ä¿¡æ¯
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + 'GET' + positions_path
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        response = requests.get(base_url + positions_path, headers=headers, timeout=10)
        positions_result = response.json()
        
        if positions_result.get('code') != '0':
            return jsonify({
                'success': False,
                'error': f'è·å–æŒä»“å¤±è´¥: {positions_result.get("msg", "æœªçŸ¥é”™è¯¯")}'
            })
        
        # æ‰¾åˆ°ç›®æ ‡æŒä»“
        target_position = None
        for pos in positions_result.get('data', []):
            if pos.get('instId') == inst_id and pos.get('posSide') == pos_side:
                target_position = pos
                break
        
        if not target_position:
            return jsonify({
                'success': False,
                'error': f'æœªæ‰¾åˆ°æŒä»“: {inst_id} {pos_side}'
            })
        
        # è·å–å¼€ä»“å‡ä»·
        avg_px = float(target_position.get('avgPx', 0))
        if avg_px <= 0:
            return jsonify({
                'success': False,
                'error': 'æ— æ³•è·å–å¼€ä»“å‡ä»·'
            })
        
        print(f"[OKXè®¾ç½®æ­¢ç›ˆæ­¢æŸ] {inst_id} {pos_side}, å¼€ä»“å‡ä»·: {avg_px}")
        
        # è®¡ç®—æ­¢ç›ˆæ­¢æŸä»·æ ¼
        tp_px = None
        sl_px = None
        
        if take_profit_percent:
            tp_percent = float(take_profit_percent) / 100
            if pos_side == 'long':
                # å¤šå•:æ­¢ç›ˆä»· = å¼€ä»“ä»· * (1 + æ­¢ç›ˆ%)
                tp_px = avg_px * (1 + tp_percent)
            else:
                # ç©ºå•:æ­¢ç›ˆä»· = å¼€ä»“ä»· * (1 - æ­¢ç›ˆ%)
                tp_px = avg_px * (1 - tp_percent)
            print(f"[OKXè®¾ç½®æ­¢ç›ˆæ­¢æŸ] æ­¢ç›ˆä»·: {tp_px}")
        
        if stop_loss_percent:
            sl_percent = float(stop_loss_percent) / 100
            if pos_side == 'long':
                # å¤šå•:æ­¢æŸä»· = å¼€ä»“ä»· * (1 - æ­¢æŸ%)
                sl_px = avg_px * (1 - sl_percent)
            else:
                # ç©ºå•:æ­¢æŸä»· = å¼€ä»“ä»· * (1 + æ­¢æŸ%)
                sl_px = avg_px * (1 + sl_percent)
            print(f"[OKXè®¾ç½®æ­¢ç›ˆæ­¢æŸ] æ­¢æŸä»·: {sl_px}")
        
        # è°ƒç”¨OKXæ­¢ç›ˆæ­¢æŸAPI
        method = 'POST'
        request_path = '/api/v5/trade/order-algo'
        
        algo_params = {
            'instId': inst_id,
            'tdMode': 'isolated',
            'side': 'sell' if pos_side == 'long' else 'buy',
            'posSide': pos_side,
            'ordType': 'conditional',  # æ¡ä»¶å•
            'sz': target_position.get('pos', '0'),  # æŒä»“æ•°é‡
            'reduceOnly': 'true'
        }
        
        # æ·»åŠ æ­¢ç›ˆæ­¢æŸä»·æ ¼
        if tp_px:
            algo_params['tpTriggerPx'] = str(round(tp_px, 2))
            algo_params['tpOrdPx'] = '-1'  # å¸‚ä»·
        
        if sl_px:
            algo_params['slTriggerPx'] = str(round(sl_px, 2))
            algo_params['slOrdPx'] = '-1'  # å¸‚ä»·
        
        body = json.dumps(algo_params)
        
        # ç”Ÿæˆç­¾å
        timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        message = timestamp + method + request_path + body
        mac = hmac.new(
            bytes(secret_key, encoding='utf8'),
            bytes(message, encoding='utf-8'),
            digestmod='sha256'
        )
        signature = base64.b64encode(mac.digest()).decode()
        
        # è¯·æ±‚å¤´
        headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': signature,
            'OK-ACCESS-TIMESTAMP': timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        # å‘é€è¯·æ±‚
        response = requests.post(base_url + request_path, headers=headers, data=body, timeout=10)
        result = response.json()
        
        print(f"[OKXè®¾ç½®æ­¢ç›ˆæ­¢æŸ] è¯·æ±‚å‚æ•°: {algo_params}")
        print(f"[OKXè®¾ç½®æ­¢ç›ˆæ­¢æŸ] å“åº”ç»“æœ: {result}")
        
        if result.get('code') == '0':
            # è®°å½•æˆåŠŸæ—¥å¿—
            okx_trading_logger.log(
                action='set_tpsl',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'posSide': pos_side,
                    'avgPx': avg_px,
                    'takeProfitPercent': take_profit_percent,
                    'stopLossPercent': stop_loss_percent,
                    'tpPrice': tp_px,
                    'slPrice': sl_px
                },
                result={
                    'status': 'success',
                    'algoId': result.get('data', [{}])[0].get('algoId', '')
                }
            )
            
            return jsonify({
                'success': True,
                'message': 'æ­¢ç›ˆæ­¢æŸè®¾ç½®æˆåŠŸ',
                'data': {
                    'avgPx': avg_px,
                    'tpPrice': tp_px,
                    'slPrice': sl_px
                }
            })
        else:
            # è®°å½•å¤±è´¥æ—¥å¿—
            okx_trading_logger.log(
                action='set_tpsl',
                account_id='user_account',
                details={
                    'instId': inst_id,
                    'posSide': pos_side,
                    'takeProfitPercent': take_profit_percent,
                    'stopLossPercent': stop_loss_percent
                },
                result={
                    'status': 'failed',
                    'error': result.get('msg', 'è®¾ç½®å¤±è´¥'),
                    'code': result.get('code', '')
                }
            )
            
            return jsonify({
                'success': False,
                'error': result.get('msg', 'è®¾ç½®å¤±è´¥'),
                'code': result.get('code', '')
            })
            
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'APIè¯·æ±‚è¶…æ—¶'
        })
    except requests.exceptions.RequestException as e:
        return jsonify({
            'success': False,
            'error': f'ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/auto-maintenance-config')
def get_auto_maintenance_config():
    """è·å–è‡ªåŠ¨ç»´æŠ¤é…ç½®"""
    try:
        import json
        import os
        
        config_path = '/home/user/webapp/auto_maintenance_config.json'
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨,è¿”å›é»˜è®¤é…ç½®
        if not os.path.exists(config_path):
            default_config = {
                'auto_maintain_long_enabled': False,
                'auto_maintain_short_enabled': False,
                'super_maintain_long_enabled': False,
                'super_maintain_short_enabled': False
            }
            return jsonify({
                'success': True,
                'config': default_config
            })
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        return jsonify({
            'success': True,
            'config': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/anchor-system/auto-maintenance-config', methods=['POST'])
def update_auto_maintenance_config():
    """æ›´æ–°è‡ªåŠ¨ç»´æŠ¤é…ç½®"""
    try:
        import json
        
        config_path = '/home/user/webapp/auto_maintenance_config.json'
        data = request.get_json()
        
        # ä¿å­˜é…ç½®
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': 'è‡ªåŠ¨ç»´æŠ¤é…ç½®å·²æ›´æ–°'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/anchor-system/status')
def get_anchor_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        import json
        
        # è¯»å–é…ç½®
        config_path = '/home/user/webapp/anchor_config.json'
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # è·å–æœ€æ–°ç›‘æ§è®°å½•
        db_path = '/home/user/webapp/databases/anchor_system.db'
        conn = sqlite3.connect(db_path, timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM anchor_monitors')
        total_monitors = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM anchor_alerts')
        total_alerts = cursor.fetchone()[0]
        
        cursor.execute('''
        SELECT * FROM anchor_monitors 
        ORDER BY timestamp DESC 
        LIMIT 1
        ''')
        latest = cursor.fetchone()
        
        conn.close()
        
        # ä½¿ç”¨é»˜è®¤é…ç½®å€¼(å› ä¸º anchor_config.json æ²¡æœ‰ monitor é”®)
        return jsonify({
            'success': True,
            'status': {
                'total_monitors': total_monitors,
                'total_alerts': total_alerts,
                'latest_check': latest[1] if latest else None,
                'config': {
                    'profit_target': 40.0,  # é»˜è®¤ç›ˆåˆ©ç›®æ ‡ 40%
                    'loss_limit': -10.0,     # é»˜è®¤æ­¢æŸé™åˆ¶ -10%
                    'check_interval': 30,    # é»˜è®¤æ£€æŸ¥é—´éš” 30ç§’
                    'only_short': False      # é»˜è®¤æ”¯æŒå¤šç©º
                }
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/profit-records')
def get_anchor_profit_records():
    """è·å–å†å²æå€¼è®°å½• - ä½¿ç”¨JSONLå­˜å‚¨,å®ç›˜å’Œæ¨¡æ‹Ÿç›˜ä½¿ç”¨ä¸åŒçš„æ–‡ä»¶"""
    try:
        inst_id = request.args.get('inst_id')
        pos_side = request.args.get('pos_side')
        trade_mode = request.args.get('trade_mode', 'real')  # é»˜è®¤å®ç›˜
        
        # åˆ›å»ºJSONLç®¡ç†å™¨
        manager = ExtremeJSONLManager(trade_mode=trade_mode)
        
        if inst_id or pos_side:
            # æŸ¥è¯¢ç‰¹å®šå¸ç§/æ–¹å‘çš„è®°å½•
            all_records = manager.get_all_records()
            filtered_records = []
            for r in all_records:
                # æ ¹æ®æä¾›çš„å‚æ•°è¿›è¡Œè¿‡æ»¤
                if inst_id and r.get('inst_id') != inst_id:
                    continue
                if pos_side and r.get('pos_side') != pos_side:
                    continue
                filtered_records.append(r)
            
            # æŒ‰ inst_id, pos_side, record_type æ’åº
            filtered_records.sort(key=lambda x: (
                x.get('inst_id', ''),
                x.get('pos_side', ''),
                x.get('record_type', '')
            ))
            
            records = []
            for r in filtered_records:
                records.append({
                    'inst_id': r.get('inst_id'),
                    'pos_side': r.get('pos_side'),
                    'record_type': r.get('record_type'),
                    'profit_rate': r.get('profit_rate'),
                    'timestamp': r.get('timestamp'),
                    'pos_size': r.get('pos_size'),
                    'avg_price': r.get('avg_price'),
                    'mark_price': r.get('mark_price'),
                    'upl': r.get('upl'),
                    'margin': r.get('margin'),
                    'leverage': r.get('leverage')
                })
        else:
            # æŸ¥è¯¢æ‰€æœ‰è®°å½•
            all_records = manager.get_all_records()
            
            # åªä¿ç•™æ¯ä¸ª(inst_id, pos_side, record_type)ç»„åˆçš„æœ€æ–°è®°å½•
            latest_records = {}
            for r in all_records:
                key = (r.get('inst_id'), r.get('pos_side'), r.get('record_type'))
                # æ¯”è¾ƒupdated_atæˆ–created_at,ä¿ç•™æœ€æ–°çš„
                existing = latest_records.get(key)
                if existing is None:
                    latest_records[key] = r
                else:
                    # æ¯”è¾ƒæ—¶é—´æˆ³,ä¿ç•™æ›´æ–°çš„
                    existing_time = existing.get('updated_at') or existing.get('created_at') or ''
                    new_time = r.get('updated_at') or r.get('created_at') or ''
                    if new_time > existing_time:
                        latest_records[key] = r
            
            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
            unique_records = list(latest_records.values())
            unique_records.sort(key=lambda x: (
                x.get('inst_id', ''),
                x.get('pos_side', ''),
                x.get('record_type', '')
            ))
            
            records = []
            for r in unique_records:
                records.append({
                    'inst_id': r.get('inst_id'),
                    'pos_side': r.get('pos_side'),
                    'record_type': r.get('record_type'),
                    'profit_rate': r.get('profit_rate'),
                    'timestamp': r.get('updated_at') or r.get('created_at'),
                    'pos_size': r.get('pos_size'),
                    'avg_price': r.get('avg_price'),
                    'mark_price': r.get('mark_price')
                })
        
        return jsonify({
            'success': True,
            'records': records,
            'total': len(records),
            'trade_mode': trade_mode,
            'data_source': 'JSONL'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/profit-records-with-coins')
def get_profit_records_with_coins():
    """è·å–å†å²æå€¼è®°å½• + 27ä¸ªå¸çš„å®æ—¶æ¶¨è·Œå¹…å’Œä»·æ ¼(æ”¯æŒæŒ‰æ—¥æœŸæŸ¥è¯¢)"""
    try:
        from datetime import datetime as dt_module
        from extreme_daily_jsonl_manager import ExtremeDailyJSONLManager
        
        trade_mode = request.args.get('trade_mode', 'real')
        date = request.args.get('date', None)  # æ–°å¢:æ—¥æœŸå‚æ•° (YYYY-MM-DDæ ¼å¼)
        limit = request.args.get('limit', None, type=int)
        
        # 1. è·å–æå€¼è®°å½•(ä½¿ç”¨æŒ‰æ—¥æœŸåˆ†åŒºçš„ç®¡ç†å™¨)
        manager = ExtremeDailyJSONLManager(trade_mode=trade_mode)
        
        if date:
            # å¦‚æœæŒ‡å®šäº†æ—¥æœŸ,åªåŠ è½½è¯¥æ—¥æœŸçš„æ•°æ®
            date_str = date.replace('-', '')  # è½¬æ¢ä¸º YYYYMMDD æ ¼å¼
            all_records = manager.get_records_by_date(date_str)
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸ,åŠ è½½ä»Šå¤©çš„æ•°æ®
            all_records = manager.get_today_deduplicated_records()
        
        # å¦‚æœè®¾ç½®äº†limit,åªè¿”å›æœ€æ–°çš„limitæ¡
        if limit and limit > 0:
            # æŒ‰æ—¶é—´æˆ³é™åºæ’åº,å–æœ€æ–°çš„Næ¡
            all_records.sort(key=lambda x: x.get('updated_at', x.get('created_at', '')), reverse=True)
            all_records = all_records[:limit]
        
        # è½¬æ¢ä¸ºAPIæ ¼å¼
        records = []
        for r in all_records:
            records.append({
                'inst_id': r.get('inst_id'),
                'pos_side': r.get('pos_side'),
                'record_type': r.get('record_type'),
                'profit_rate': r.get('profit_rate'),
                'max_profit': r.get('max_profit'),  # æ–°å¢:æœ€å¤§ç›ˆåˆ©
                'max_loss': r.get('max_loss'),      # æ–°å¢:æœ€å¤§äºæŸ
                'timestamp': r.get('updated_at') or r.get('created_at'),
                'pos_size': r.get('pos_size'),
                'avg_price': r.get('avg_price'),
                'mark_price': r.get('mark_price')
            })
        
        # 2. è·å–27ä¸ªå¸çš„å®æ—¶æ¶¨è·Œå¹…å’Œä»·æ ¼
        coins_data = None
        try:
            # è¯»å–æœ€æ–°çš„27å¸æ•°æ®
            import os
            import json as json_module
            
            coin_prices_file = 'data/coin_price_tracker/coin_prices_30min.jsonl'
            if os.path.exists(coin_prices_file):
                with open(coin_prices_file, 'r', encoding='utf-8') as f:
                    # è¯»å–æœ€åä¸€è¡Œ(æœ€æ–°æ•°æ®)
                    lines = f.readlines()
                    if lines:
                        last_line = lines[-1].strip()
                        if last_line:
                            latest_data = json_module.loads(last_line)
                            
                            # æå–27ä¸ªå¸çš„æ•°æ®
                            coins_list = []
                            day_changes = latest_data.get('day_changes', {})
                            
                            for symbol, data in day_changes.items():
                                if isinstance(data, dict):
                                    coins_list.append({
                                        'symbol': symbol,
                                        'name': symbol,  # ç®€åŒ–å¤„ç†
                                        'current_price': data.get('current_price', 0),
                                        'base_price': data.get('base_price', 0),
                                        'day_change_percent': data.get('change_pct', 0),  # ä½¿ç”¨ change_pct å­—æ®µ
                                    })
                            
                            if coins_list:
                                coins_data = {
                                    'timestamp': latest_data.get('timestamp'),
                                    'datetime': latest_data.get('collect_time', latest_data.get('datetime')),  # ä½¿ç”¨ collect_time
                                    'total_change': latest_data.get('total_change', 0),  # ä½¿ç”¨ total_change
                                    'coins': coins_list
                                }
        except Exception as e:
            print(f"âŒ è·å–27å¸æ•°æ®å¤±è´¥: {e}")
        
        response_data = {
            'success': True,
            'records': records,
            'total': len(records),
            'trade_mode': trade_mode,
            'data_source': 'JSONL (filtered by date)' if date else 'JSONL',
            'coins_data': coins_data  # æ–°å¢:27ä¸ªå¸çš„å®æ—¶æ•°æ®
        }
        
        # å¦‚æœæŒ‰æ—¥æœŸæŸ¥è¯¢,æ·»åŠ æ—¥æœŸä¿¡æ¯
        if date:
            response_data['date'] = date
            response_data['query_type'] = 'by_date_filter'
        
        return jsonify(response_data)
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/cleanup-extremes', methods=['POST'])
def cleanup_extreme_records():
    """æ¸…ç†é”™è¯¯çš„æå€¼è®°å½•(åˆ é™¤æ‰€æœ‰äºæŸè®°å½•)"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from extreme_correction_system import (
            init_correction_system, backup_current_data,
            detect_error_records, delete_error_records, get_statistics
        )
        
        # åˆå§‹åŒ–
        from anchor_system import init_database
        init_database()
        init_correction_system()
        
        # å¤‡ä»½
        backup_count = backup_current_data()
        
        # æ£€æµ‹é”™è¯¯è®°å½•
        error_records = detect_error_records()
        
        if not error_records:
            return jsonify({
                'success': True,
                'message': 'æ²¡æœ‰å‘ç°é”™è¯¯è®°å½•',
                'backup_count': backup_count,
                'deleted_count': 0
            })
        
        # åˆ é™¤é”™è¯¯è®°å½•
        deleted_count = delete_error_records(error_records, "Webç«¯æ‰‹åŠ¨æ¸…ç†")
        
        # è·å–ç»Ÿè®¡
        stats = get_statistics()
        
        return jsonify({
            'success': True,
            'message': f'å·²æ¸…ç† {deleted_count} æ¡é”™è¯¯è®°å½•',
            'backup_count': backup_count,
            'deleted_count': deleted_count,
            'statistics': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/anchor-system/extreme-stats')
def get_extreme_stats():
    """è·å–æå€¼è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp')
        from extreme_correction_system import get_statistics, detect_error_records
        
        # è·å–ç»Ÿè®¡
        stats = get_statistics()
        
        # æ£€æµ‹é”™è¯¯è®°å½•
        error_records = detect_error_records()
        
        return jsonify({
            'success': True,
            'statistics': stats,
            'error_count': len(error_records),
            'has_errors': len(error_records) > 0
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/anchor-system/correction-log')
def get_correction_log():
    """è·å–çº é”™æ—¥å¿—"""
    try:
        limit = int(request.args.get('limit', 20))
        
        db_path = '/home/user/webapp/databases/anchor_system.db'
        conn = sqlite3.connect(db_path, timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT id, correction_type, inst_id, pos_side, record_type,
               old_profit_rate, new_profit_rate, reason, created_at
        FROM extreme_corrections_log
        ORDER BY created_at DESC
        LIMIT ?
        ''', (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        logs = []
        for row in rows:
            logs.append({
                'id': row[0],
                'correction_type': row[1],
                'inst_id': row[2],
                'pos_side': row[3],
                'record_type': row[4],
                'old_profit_rate': row[5],
                'new_profit_rate': row[6],
                'reason': row[7],
                'created_at': row[8]
            })
        
        return jsonify({
            'success': True,
            'logs': logs,
            'total': len(logs)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/anchor-system/current-positions')
def get_current_positions():
    """è·å–å½“å‰æŒä»“æƒ…å†µ - æ¨¡æ‹Ÿç›˜ç›´æ¥è¯»å–æ•°æ®åº“,å®ç›˜ä» OKEx API å®æ—¶è·å–"""
    try:
        import sys
        import sqlite3
        from datetime import datetime
        sys.path.append('/home/user/webapp')
        from anchor_system import get_positions, calculate_profit_rate
        
        # è·å–äº¤æ˜“æ¨¡å¼(é»˜è®¤ä¸º paper æ¨¡æ‹Ÿç›˜)
        trade_mode = request.args.get('trade_mode', 'paper')
        
        # è¿æ¥æ•°æ®åº“,è·å–ç»´æŠ¤åçš„å¼€ä»“ä»·æ ¼
        DB_PATH = '/home/user/webapp/databases/trading_decision.db'
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ä»æ•°æ®åº“è¯»å–æ¨¡æ‹Ÿç›˜æ•°æ® - è”åˆæŸ¥è¯¢ç»´æŠ¤ä»·æ ¼è¡¨
        cursor.execute('''
            SELECT 
                p.inst_id, 
                p.pos_side, 
                COALESCE(amp.maintenance_price, p.open_price) as open_price,
                p.open_size, 
                p.updated_time, 
                p.mark_price, 
                p.profit_rate, 
                p.upl, 
                p.lever, 
                p.margin,
                amp.original_open_price,
                amp.maintenance_count,
                p.is_anchor
            FROM position_opens p
            LEFT JOIN anchor_maintenance_prices amp 
                ON p.inst_id = amp.inst_id 
                AND p.pos_side = amp.pos_side 
                AND p.trade_mode = amp.trade_mode
            WHERE p.trade_mode = ?
        ''', (trade_mode,))
        
        db_positions = cursor.fetchall()
        conn.close()
        
        # å¦‚æœæ˜¯æ¨¡æ‹Ÿç›˜,ç›´æ¥ä½¿ç”¨æ•°æ®åº“æ•°æ®
        if trade_mode == 'paper':
            position_list = []
            for row in db_positions:
                profit_rate = row['profit_rate'] if row['profit_rate'] is not None else 0.0
                
                # åˆ¤æ–­çŠ¶æ€
                status = 'ç›‘æ§ä¸­'
                status_class = 'normal'
                if profit_rate >= 40:
                    status = 'æ¥è¿‘ç›ˆåˆ©ç›®æ ‡'
                    status_class = 'profit'
                elif profit_rate <= -10:
                    status = 'æ¥è¿‘æ­¢æŸ'
                    status_class = 'loss'
                
                position_list.append({
                    'inst_id': row['inst_id'],
                    'pos_side': row['pos_side'],
                    'pos_size': abs(float(row['open_size'])),
                    'avg_price': float(row['open_price']),  # ç°åœ¨ä½¿ç”¨ç»´æŠ¤ä»·æ ¼
                    'mark_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'lever': int(row['lever']) if row['lever'] else 10,
                    'upl': float(row['upl']) if row['upl'] else 0.0,
                    'margin': float(row['margin']) if row['margin'] else 0.0,
                    'profit_rate': profit_rate,
                    'status': status,
                    'status_class': status_class,
                    'is_anchor': int(row['is_anchor']) if row['is_anchor'] else 0
                })
            
            # åŠ è½½æå€¼æ•°æ®å¹¶é™„åŠ åˆ°æŒä»“è®°å½•(æ¨¡æ‹Ÿç›˜)
            try:
                sys.path.append('/home/user/webapp')
                from anchor_extreme_tracker import AnchorExtremeTracker
                
                tracker = AnchorExtremeTracker()
                extreme_map = tracker.get_extreme_value_map(trade_mode=trade_mode)
                
                # é™„åŠ æå€¼æ•°æ®åˆ°æ¯ä¸ªæŒä»“
                for pos in position_list:
                    key = f"{pos['inst_id']}_{pos['pos_side']}"
                    if key in extreme_map:
                        extreme_data = extreme_map[key]
                        pos['max_profit_rate'] = extreme_data['max_profit_rate']
                        pos['max_loss_rate'] = extreme_data['max_loss_rate']
                        pos['max_profit_time'] = extreme_data['max_profit_time']
                        pos['max_loss_time'] = extreme_data['max_loss_time']
                    else:
                        pos['max_profit_rate'] = 0
                        pos['max_loss_rate'] = 0
                        pos['max_profit_time'] = None
                        pos['max_loss_time'] = None
                
                # æ‰¹é‡æ›´æ–°æå€¼(å¦‚æœå½“å‰ç›ˆäºç‡åˆ›æ–°é«˜/æ–°ä½)
                update_result = tracker.batch_update_from_positions(position_list, trade_mode)
                
            except Exception as e:
                print(f"âš ï¸ æå€¼æ•°æ®åŠ è½½å¤±è´¥(æ¨¡æ‹Ÿç›˜): {e}")
            
            return jsonify({
                'success': True,
                'positions': position_list,
                'total': len(position_list),
                'trade_mode': trade_mode
            })
        
        # å¦‚æœæ˜¯å®ç›˜,ä» OKEx API è·å–å®æ—¶æŒä»“
        okex_positions = get_positions()
        
        if not okex_positions or len(okex_positions) == 0:
            return jsonify({
                'success': True,
                'positions': [],
                'total': 0,
                'trade_mode': trade_mode,
                'message': 'ä»OKEx APIè·å–åˆ°0ä¸ªä»“ä½'
            })
        
        # å°†æ•°æ®åº“è®°å½•è½¬æ¢ä¸ºå­—å…¸(åªç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºé”šç‚¹å•)
        db_positions_dict = {(row['inst_id'], row['pos_side']): row for row in db_positions}
        
        position_list = []
        for pos in okex_positions:
            inst_id = pos.get('instId')
            pos_side = pos.get('posSide')
            pos_value = float(pos.get('pos', 0))
            
            # è·³è¿‡æŒä»“é‡ä¸º0çš„
            if pos_value == 0:
                continue
            
            # æŸ¥æ‰¾æ•°æ®åº“è®°å½•(åªç”¨äºæ ‡è®°æ˜¯å¦ä¸ºé”šç‚¹å•)
            db_record = db_positions_dict.get((inst_id, pos_side))
            
            # âœ… å®ç›˜æ¨¡å¼:å®Œå…¨ä½¿ç”¨ OKEx API çš„å®æ—¶æ•°æ®
            avg_price = float(pos.get('avgPx', 0) or 0)
            mark_price = float(pos.get('markPx', 0) or 0)
            lever = int(pos.get('lever', 10) or 10)
            upl = float(pos.get('upl', 0) or 0)
            margin = float(pos.get('margin', 0) or 0)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºé”šç‚¹å•(ä»æ•°æ®åº“æ ‡è®°)
            is_anchor = 0
            if db_record and db_record['is_anchor']:
                is_anchor = int(db_record['is_anchor'])
            
            # è®¡ç®—æ”¶ç›Šç‡:ä½¿ç”¨ margin è®¡ç®—(æ›´å‡†ç¡®)
            if margin > 0:
                profit_rate = (upl / margin) * 100
            else:
                # å¤‡ç”¨è®¡ç®—:ä»·æ ¼å˜åŠ¨ç‡ * æ æ†
                if avg_price > 0:
                    if pos_side == 'short':
                        profit_rate = ((avg_price - mark_price) / avg_price) * lever * 100
                    else:  # long
                        profit_rate = ((mark_price - avg_price) / avg_price) * lever * 100
                else:
                    profit_rate = 0.0
            
            # åˆ¤æ–­çŠ¶æ€
            status = 'ç›‘æ§ä¸­'
            status_class = 'normal'
            if profit_rate >= 40:
                status = 'æ¥è¿‘ç›ˆåˆ©ç›®æ ‡'
                status_class = 'profit'
            elif profit_rate <= -10:
                status = 'æ¥è¿‘æ­¢æŸ'
                status_class = 'loss'
            
            position_list.append({
                'inst_id': inst_id,
                'pos_side': pos_side,
                'pos_size': abs(pos_value),
                'avg_price': avg_price,
                'mark_price': mark_price,
                'lever': lever,
                'upl': upl,
                'margin': margin,
                'profit_rate': profit_rate,
                'status': status,
                'status_class': status_class,
                'is_anchor': is_anchor
            })
        
        # åŠ è½½æå€¼æ•°æ®å¹¶é™„åŠ åˆ°æŒä»“è®°å½•
        try:
            sys.path.append('/home/user/webapp')
            from anchor_extreme_tracker import AnchorExtremeTracker
            
            tracker = AnchorExtremeTracker()
            extreme_map = tracker.get_extreme_value_map(trade_mode=trade_mode)
            
            # é™„åŠ æå€¼æ•°æ®åˆ°æ¯ä¸ªæŒä»“
            for pos in position_list:
                key = f"{pos['inst_id']}_{pos['pos_side']}"
                if key in extreme_map:
                    extreme_data = extreme_map[key]
                    pos['max_profit_rate'] = extreme_data['max_profit_rate']
                    pos['max_loss_rate'] = extreme_data['max_loss_rate']
                    pos['max_profit_time'] = extreme_data['max_profit_time']
                    pos['max_loss_time'] = extreme_data['max_loss_time']
                else:
                    pos['max_profit_rate'] = 0
                    pos['max_loss_rate'] = 0
                    pos['max_profit_time'] = None
                    pos['max_loss_time'] = None
            
            # æ‰¹é‡æ›´æ–°æå€¼(å¦‚æœå½“å‰ç›ˆäºç‡åˆ›æ–°é«˜/æ–°ä½)
            update_result = tracker.batch_update_from_positions(position_list, trade_mode)
            
        except Exception as e:
            print(f"âš ï¸ æå€¼æ•°æ®åŠ è½½å¤±è´¥: {e}")
            # å³ä½¿æå€¼åŠ è½½å¤±è´¥,ä¹Ÿä¸å½±å“ä¸»è¦åŠŸèƒ½,ç»§ç»­è¿”å›æŒä»“æ•°æ®
        
        return jsonify({
            'success': True,
            'positions': position_list,
            'total': len(position_list),
            'trade_mode': trade_mode
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/extreme-values')
def get_anchor_extreme_values():
    """è·å–é”šç‚¹å•æå€¼è®°å½•"""
    try:
        import sys
        sys.path.append('/home/user/webapp')
        from anchor_extreme_tracker import AnchorExtremeTracker
        
        trade_mode = request.args.get('trade_mode', 'real')
        inst_id = request.args.get('inst_id', None)
        pos_side = request.args.get('pos_side', None)
        
        tracker = AnchorExtremeTracker()
        extremes = tracker.get_extreme_values(inst_id=inst_id, pos_side=pos_side, trade_mode=trade_mode)
        
        return jsonify({
            'success': True,
            'data': extremes,
            'total': len(extremes),
            'trade_mode': trade_mode
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ====================äº¤æ˜“å†³ç­–ç³»ç»Ÿè·¯ç”± ====================

@app.route('/trading-decision')
def trading_decision_page():
    """äº¤æ˜“å†³ç­–ç³»ç»Ÿç®¡ç†é¡µé¢ - é‡å®šå‘åˆ°ç»Ÿä¸€ç®¡ç†é¡µé¢"""
    return redirect('/trading-manager')

@app.route('/api/trading/anchor-maintenance/logs')
def anchor_maintenance_logs_api():
    """è·å–é”šç‚¹å•ç»´æŠ¤æ—¥å¿—"""
    try:
        limit = request.args.get('limit', 10, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT id, inst_id, pos_side, original_size, original_price, 
               original_margin, current_price, profit_rate, step, action,
               trade_size, trade_price, remaining_size, remaining_margin,
               trigger_reason, decision_log, status, executed_at, created_at
        FROM anchor_maintenance_logs
        ORDER BY created_at DESC
        LIMIT ?
        ''', (limit,))
        
        logs = []
        for row in cursor.fetchall():
            logs.append({
                'id': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'original_size': float(row[3]),
                'original_price': float(row[4]),
                'original_margin': float(row[5]),
                'current_price': float(row[6]),
                'profit_rate': float(row[7]),
                'step': row[8],
                'action': row[9],
                'trade_size': float(row[10]),
                'trade_price': float(row[11]),
                'remaining_size': float(row[12]),
                'remaining_margin': float(row[13]),
                'trigger_reason': row[14],
                'decision_log': row[15],
                'status': row[16],
                'executed_at': row[17],
                'created_at': row[18]
            })
        
        conn.close()
        
        return jsonify({
            'success': True,
            'count': len(logs),
            'logs': logs
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/api/trading/config', methods=['GET', 'POST'])
def trading_config_api():
    """äº¤æ˜“é…ç½®API"""
    config_file = '/home/user/webapp/trading_config.json'
    
    if request.method == 'GET':
        try:
            with open(config_file, 'r') as f:
                config = json.load(f)
            return jsonify({'success': True, 'config': config})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500
    
    elif request.method == 'POST':
        try:
            new_config = request.json
            
            # æ›´æ–°æ•°æ®åº“ä¸­çš„é…ç½®
            conn = sqlite3.connect('/home/user/webapp/databases/trading_decision.db', timeout=10.0)
            cursor = conn.cursor()
            cursor.execute('''
            UPDATE market_config SET
                market_mode = ?,
                market_trend = ?,
                total_capital = ?,
                position_limit_percent = ?,
                anchor_capital_limit = ?,
                allow_long = ?,
                enabled = ?,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = 1
            ''', (
                new_config.get('market_mode'),
                new_config.get('market_trend'),
                new_config.get('total_capital'),
                new_config.get('position_limit_percent'),
                new_config.get('anchor_capital_limit'),
                1 if new_config.get('allow_long') else 0,
                1 if new_config.get('enabled') else 0
            ))
            conn.commit()
            conn.close()
            
            # æ›´æ–°JSONæ–‡ä»¶
            with open(config_file, 'w') as f:
                json.dump(new_config, f, indent=2)
            
            return jsonify({'success': True, 'message': 'é…ç½®æ›´æ–°æˆåŠŸ'})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/decisions')
def trading_decisions_api():
    """è·å–äº¤æ˜“å†³ç­–è®°å½•"""
    try:
        limit = request.args.get('limit', 50, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        cursor.execute(f'''
        SELECT id, inst_id, pos_side, action, decision_type, current_size,
               target_size, close_size, close_percent, profit_rate,
               current_price, reason, executed, timestamp
        FROM trading_decisions
        ORDER BY id DESC
        LIMIT {limit}
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        decisions = []
        for row in rows:
            decisions.append({
                'id': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'action': row[3],
                'decision_type': row[4],
                'current_size': row[5],
                'target_size': row[6],
                'close_size': row[7],
                'close_percent': row[8],
                'profit_rate': row[9],
                'current_price': row[10],
                'reason': row[11],
                'executed': bool(row[12]),
                'timestamp': row[13]
            })
        
        return jsonify({'success': True, 'decisions': decisions, 'total': len(decisions)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/signals')
def trading_signals_api():
    """è·å–äº¤æ˜“ä¿¡å·(ä¾›å…¶ä»–è´¦å·ä½¿ç”¨)"""
    try:
        limit = request.args.get('limit', 50, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        cursor.execute(f'''
        SELECT id, inst_id, signal_type, action, price, size,
               profit_rate, reason, timestamp
        FROM trading_signals
        ORDER BY id DESC
        LIMIT {limit}
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        signals = []
        for row in rows:
            signals.append({
                'id': row[0],
                'inst_id': row[1],
                'signal_type': row[2],
                'action': row[3],
                'price': row[4],
                'size': row[5],
                'profit_rate': row[6],
                'reason': row[7],
                'timestamp': row[8]
            })
        
        return jsonify({'success': True, 'signals': signals, 'total': len(signals)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/trading/maintenance')
def trading_maintenance_api():
    """è·å–é”šç‚¹å•ç»´æŠ¤è®°å½•"""
    try:
        limit = request.args.get('limit', 50, type=int)
        
        conn = sqlite3.connect('/home/user/webapp/databases/trading_decision.db', timeout=10.0)
        cursor = conn.cursor()
        cursor.execute(f'''
        SELECT id, inst_id, pos_side, original_size, original_price,
               maintenance_price, maintenance_size, profit_rate,
               action, status, timestamp
        FROM anchor_maintenance
        ORDER BY id DESC
        LIMIT {limit}
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        records = []
        for row in rows:
            records.append({
                'id': row[0],
                'inst_id': row[1],
                'pos_side': row[2],
                'original_size': row[3],
                'original_price': row[4],
                'maintenance_price': row[5],
                'maintenance_size': row[6],
                'profit_rate': row[7],
                'action': row[8],
                'status': row[9],
                'timestamp': row[10]
            })
        
        return jsonify({'success': True, 'records': records, 'total': len(records)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# å·²ç§»é™¤ trading-manager åŠŸèƒ½(ç”¨æˆ·éœ€æ±‚ 2026-01-14)
# @app.route('/dashboard')
# def dashboard():
#     """å®æ—¶ç›‘æ§ä»ªè¡¨æ¿ - é‡å®šå‘åˆ°ç»Ÿä¸€ç®¡ç†é¡µé¢"""
#     return redirect('/trading-manager')
# 
# @app.route('/trading-manager')
# def trading_manager():
#     """äº¤æ˜“ç®¡ç†ç•Œé¢ - æ¨¡æ‹Ÿäº¤æ˜“ç³»ç»Ÿ"""
#     try:
#         with open('/home/user/webapp/templates/trading_manager.html', 'r', encoding='utf-8') as f:
#             content = f.read()
#         
#         # æ·»åŠ ç¼“å­˜æ§åˆ¶å¤´,å¼ºåˆ¶æµè§ˆå™¨åˆ·æ–°
#         response = make_response(content)
#         response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
#         response.headers['Pragma'] = 'no-cache'
#         response.headers['Expires'] = '0'
#         return response
#     except FileNotFoundError:
#         return "Trading manager template not found", 404
#     except Exception as e:
#         return f"Error loading trading manager: {str(e)}", 500
# 
# @app.route('/simulated-trades')
# def simulated_trades():
#     """æ¨¡æ‹Ÿäº¤æ˜“è¯¦æƒ…ç•Œé¢"""
#     try:
#         with open('/home/user/webapp/templates/simulated_trades.html', 'r', encoding='utf-8') as f:
#             return f.read()
#     except FileNotFoundError:
#         return "Simulated trades template not found", 404
#     except Exception as e:
#         return f"Error loading simulated trades: {str(e)}", 500

@app.route('/api/anchor-system/warnings')
def get_anchor_warnings():
    """è·å–å½“å‰æ´»è·ƒçš„é”šç‚¹é¢„è­¦"""
    try:
        import sqlite3
        
        # è·å–äº¤æ˜“æ¨¡å¼
        trade_mode = request.args.get('trade_mode', 'paper')
        
        DB_PATH = '/home/user/webapp/databases/trading_decision.db'
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æ´»è·ƒé¢„è­¦
        cursor.execute('''
            SELECT inst_id, pos_side, open_price, current_price, profit_rate, 
                   open_size, warning_level, alert_message, status, created_at, trade_mode
            FROM anchor_warning_monitor
            WHERE status = 'active' AND trade_mode = ?
            ORDER BY profit_rate ASC
        ''', (trade_mode,))
        
        warnings = cursor.fetchall()
        conn.close()
        
        warning_list = []
        for row in warnings:
            warning_list.append({
                'inst_id': row['inst_id'],
                'pos_side': row['pos_side'],
                'open_price': float(row['open_price']),
                'current_price': float(row['current_price']) if row['current_price'] else 0.0,
                'profit_rate': float(row['profit_rate']),
                'open_size': float(row['open_size']),
                'warning_level': row['warning_level'],
                'alert_message': row['alert_message'],
                'status': row['status'],
                'created_at': row['created_at'],
                'trade_mode': row['trade_mode']
            })
        
        return jsonify({
            'success': True,
            'warnings': warning_list,
            'total': len(warning_list),
            'trade_mode': trade_mode
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/sub-account-positions')
def get_sub_account_positions():
    """è·å–å­è´¦æˆ·æŒä»“æƒ…å†µ"""
    try:
        import sys
        import hmac
        import base64
        import hashlib
        import requests
        from datetime import datetime
        
        sys.path.append('/home/user/webapp/source_code')
        from okex_api_config_subaccount import (
            OKEX_API_KEY, 
            OKEX_SECRET_KEY, 
            OKEX_PASSPHRASE,
            OKEX_REST_URL
        )
        
        # è·å–äº¤æ˜“æ¨¡å¼
        trade_mode = request.args.get('trade_mode', 'paper')
        
        # å¦‚æœæ˜¯æ¨¡æ‹Ÿç›˜,è¿”å›ç©ºæ•°æ®
        if trade_mode == 'paper':
            return jsonify({
                'success': True,
                'positions': [],
                'total': 0,
                'trade_mode': trade_mode,
                'account_name': 'å­è´¦æˆ·(æ¨¡æ‹Ÿç›˜)'
            })
        
        # ç”Ÿæˆç­¾å
        def get_signature(secret_key, timestamp, method, request_path, body=''):
            message = timestamp + method + request_path + body
            mac = hmac.new(
                bytes(secret_key, encoding='utf8'),
                bytes(message, encoding='utf8'),
                digestmod=hashlib.sha256
            )
            return base64.b64encode(mac.digest()).decode()
        
        # è·å–è¯·æ±‚å¤´
        def get_headers(method, request_path, body=''):
            timestamp = datetime.utcnow().isoformat(timespec='milliseconds') + 'Z'
            signature = get_signature(OKEX_SECRET_KEY, timestamp, method, request_path, body)
            
            return {
                'OK-ACCESS-KEY': OKEX_API_KEY,
                'OK-ACCESS-SIGN': signature,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': OKEX_PASSPHRASE,
                'Content-Type': 'application/json'
            }
        
        # è·å–å­è´¦æˆ·æŒä»“
        method = 'GET'
        request_path = '/api/v5/account/positions'
        headers = get_headers(method, request_path)
        
        response = requests.get(OKEX_REST_URL + request_path, headers=headers, timeout=10)
        data = response.json()
        
        if data.get('code') != '0':
            return jsonify({
                'success': False,
                'error': f"OKEx APIé”™è¯¯: {data.get('msg')}",
                'positions': [],
                'total': 0
            })
        
        positions = data.get('data', [])
        
        # è¿‡æ»¤å¹¶æ ¼å¼åŒ–æŒä»“æ•°æ®
        position_list = []
        for pos in positions:
            try:
                pos_size = float(pos.get('pos', 0))
                if pos_size == 0:
                    continue
                
                inst_id = pos.get('instId', '')
                pos_side = pos.get('posSide', '').lower()
                
                # å®‰å…¨åœ°è½¬æ¢æ•°å€¼,å¤„ç†ç©ºå­—ç¬¦ä¸²
                def safe_float(value, default=0.0):
                    if value == '' or value is None:
                        return default
                    try:
                        return float(value)
                    except (ValueError, TypeError):
                        return default
                
                avg_price = safe_float(pos.get('avgPx', 0))
                mark_price = safe_float(pos.get('markPx', 0))
                lever = int(safe_float(pos.get('lever', 10)))
                upl = safe_float(pos.get('upl', 0))
                margin = safe_float(pos.get('margin', 0))
                
                # è®¡ç®—æ”¶ç›Šç‡
                profit_rate = 0.0
                upl_ratio = pos.get('uplRatio')
                if upl_ratio and upl_ratio != '':
                    profit_rate = safe_float(upl_ratio) * 100
                elif margin > 0:
                    profit_rate = (upl / margin) * 100
                
                position_list.append({
                    'account_name': 'å­è´¦æˆ·',
                    'inst_id': inst_id,
                    'pos_side': pos_side,
                    'pos_size': abs(pos_size),
                    'avg_price': avg_price,
                    'mark_price': mark_price,
                    'leverage': lever,
                    'upl': upl,
                    'margin': margin,
                    'profit_rate': profit_rate
                })
            except Exception as e:
                print(f"å¤„ç†æŒä»“æ•°æ®é”™è¯¯: {e}, pos: {pos}")
                continue
        
        return jsonify({
            'success': True,
            'positions': position_list,
            'total': len(position_list),
            'trade_mode': trade_mode,
            'account_name': 'å­è´¦æˆ·'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc(),
            'positions': [],
            'total': 0
        })

@app.route('/api/trading/positions/opens')
def get_trading_positions_opens():
    """è·å–å¼€ä»“æŒä»“ - Trading Managerä¸“ç”¨,æ”¯æŒç»´æŠ¤ä»·æ ¼è¡¨"""
    try:
        import sqlite3
        
        # è·å–å‚æ•°
        is_anchor = request.args.get('is_anchor', type=int)
        limit = request.args.get('limit', 50, type=int)
        trade_mode = request.args.get('trade_mode', 'paper')
        
        DB_PATH = '/home/user/webapp/databases/trading_decision.db'
        conn = sqlite3.connect(DB_PATH, timeout=10.0)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # å¦‚æœæ˜¯é”šç‚¹å•,ä½¿ç”¨ç»´æŠ¤ä»·æ ¼è¡¨
        if is_anchor == 1:
            # è”åˆæŸ¥è¯¢:position_opens å’Œ anchor_maintenance_prices
            cursor.execute('''
                SELECT 
                    p.id,
                    p.inst_id,
                    p.pos_side,
                    p.open_size,
                    p.mark_price,
                    p.profit_rate,
                    p.lever,
                    p.upl,
                    p.margin,
                    p.created_at,
                    p.updated_time,
                    p.trade_mode,
                    p.is_anchor,
                    p.granularity,
                    p.open_percent,
                    p.total_adds,
                    p.total_positions,
                    COALESCE(amp.maintenance_price, p.open_price) as open_price,
                    amp.original_open_price,
                    amp.maintenance_count,
                    amp.last_maintenance_time,
                    p.mark_price as current_price
                FROM position_opens p
                LEFT JOIN anchor_maintenance_prices amp 
                    ON p.inst_id = amp.inst_id 
                    AND p.pos_side = amp.pos_side 
                    AND p.trade_mode = amp.trade_mode
                WHERE p.is_anchor = 1 AND p.trade_mode = ?
                ORDER BY p.id DESC
                LIMIT ?
            ''', (trade_mode, limit))
            
            rows = cursor.fetchall()
            
            # è·å–æœ€æ–°ä»·æ ¼æ›´æ–°æ—¶é—´
            cursor.execute('''
                SELECT MAX(updated_time) FROM position_opens WHERE is_anchor = 1 AND trade_mode = ?
            ''', (trade_mode,))
            
            price_update_time = cursor.fetchone()[0] or ''
            
            records = []
            for row in rows:
                records.append({
                    'id': row['id'],
                    'inst_id': row['inst_id'],
                    'pos_side': row['pos_side'],
                    'open_price': float(row['open_price']),  # ä½¿ç”¨ç»´æŠ¤ä»·æ ¼
                    'original_open_price': float(row['original_open_price']) if row['original_open_price'] else None,
                    'open_size': float(row['open_size']),
                    'current_price': float(row['current_price']) if row['current_price'] else 0.0,
                    'mark_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'profit_rate': float(row['profit_rate']) if row['profit_rate'] else 0.0,
                    'lever': int(row['lever']) if row['lever'] else 10,
                    'upl': float(row['upl']) if row['upl'] else 0.0,
                    'margin': float(row['margin']) if row['margin'] else 0.0,
                    'is_anchor': bool(row['is_anchor']),
                    'granularity': float(row['granularity']) if row['granularity'] else 0.0,
                    'open_percent': float(row['open_percent']) if row['open_percent'] else 0.0,
                    'total_adds': int(row['total_adds']) if row['total_adds'] else 0,
                    'total_positions': int(row['total_positions']) if row['total_positions'] else 0,
                    'maintenance_count': int(row['maintenance_count']) if row['maintenance_count'] else 0,
                    'last_maintenance_time': row['last_maintenance_time'] or '',
                    'created_at': row['created_at'],
                    'price_update_time': row['updated_time'] or '',
                    'trade_mode': row['trade_mode']
                })
            
            conn.close()
            
            return jsonify({
                'success': True,
                'records': records,
                'total': len(records),
                'price_update_time': price_update_time,
                'trade_mode': trade_mode
            })
        
        # éé”šç‚¹å•,ç›´æ¥æŸ¥è¯¢
        else:
            cursor.execute('''
                SELECT 
                    id, inst_id, pos_side, open_price, open_size, mark_price, 
                    profit_rate, lever, upl, margin, created_at, updated_time,
                    trade_mode, is_anchor, granularity, open_percent, 
                    total_adds, total_positions
                FROM position_opens
                WHERE (? IS NULL OR is_anchor = ?) AND trade_mode = ?
                ORDER BY id DESC
                LIMIT ?
            ''', (is_anchor, is_anchor, trade_mode, limit))
            
            rows = cursor.fetchall()
            conn.close()
            
            records = []
            for row in rows:
                records.append({
                    'id': row['id'],
                    'inst_id': row['inst_id'],
                    'pos_side': row['pos_side'],
                    'open_price': float(row['open_price']),
                    'open_size': float(row['open_size']),
                    'current_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'mark_price': float(row['mark_price']) if row['mark_price'] else 0.0,
                    'profit_rate': float(row['profit_rate']) if row['profit_rate'] else 0.0,
                    'lever': int(row['lever']) if row['lever'] else 10,
                    'upl': float(row['upl']) if row['upl'] else 0.0,
                    'margin': float(row['margin']) if row['margin'] else 0.0,
                    'is_anchor': bool(row['is_anchor']),
                    'granularity': float(row['granularity']) if row['granularity'] else 0.0,
                    'open_percent': float(row['open_percent']) if row['open_percent'] else 0.0,
                    'total_adds': int(row['total_adds']) if row['total_adds'] else 0,
                    'total_positions': int(row['total_positions']) if row['total_positions'] else 0,
                    'created_at': row['created_at'],
                    'price_update_time': row['updated_time'] or '',
                    'trade_mode': row['trade_mode']
                })
            
            return jsonify({
                'success': True,
                'records': records,
                'total': len(records),
                'trade_mode': trade_mode
            })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# æµ‹è¯•é¡µé¢è·¯ç”±
@app.route('/test-positions')
def test_positions_page():
    """æŒä»“æ•°æ®æµ‹è¯•é¡µé¢"""
    return render_template('test_positions.html')

# ==================== äº¤æ˜“å¯¹ä¿æŠ¤ç³»ç»Ÿ API ====================

# å¯¼å…¥ä¿æŠ¤ç³»ç»Ÿæ¨¡å—
import sys
sys.path.append('/home/user/webapp/source_code')

from gdrive_jsonl_manager import GDriveJSONLManager

from trading_pair_protector import (
    start_protection, 
    stop_protection, 
    get_protection_status,
    check_and_protect,
    get_protected_pairs
)

@app.route('/api/pair-protection/start', methods=['POST'])
def start_pair_protection():
    """å¯åŠ¨äº¤æ˜“å¯¹ä¿æŠ¤"""
    try:
        success = start_protection()
        status = get_protection_status()
        
        return jsonify({
            'success': success,
            'protected_count': status.get('protected_count', 0),
            'current_count': status.get('current_count', 0),
            'message': 'ä¿æŠ¤ç³»ç»Ÿå·²å¯åŠ¨' if success else 'å¯åŠ¨å¤±è´¥'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/pair-protection/stop', methods=['POST'])
def stop_pair_protection():
    """åœæ­¢äº¤æ˜“å¯¹ä¿æŠ¤"""
    try:
        stop_protection()
        
        return jsonify({
            'success': True,
            'message': 'ä¿æŠ¤ç³»ç»Ÿå·²åœæ­¢'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/pair-protection/status')
def get_pair_protection_status():
    """è·å–ä¿æŠ¤çŠ¶æ€"""
    try:
        status = get_protection_status()
        protected = get_protected_pairs()
        
        return jsonify({
            'success': True,
            'is_running': status.get('is_running', False),
            'protected_count': status.get('protected_count', 0),
            'current_count': status.get('current_count', 0),
            'last_check': status.get('last_check'),
            'fill_count': status.get('fill_count', 0),
            'missing_pairs': status.get('missing_pairs', []),
            'protected_pairs': list(protected)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/pair-protection/check', methods=['POST'])
def manual_check_protection():
    """æ‰‹åŠ¨æ£€æŸ¥ä¸€æ¬¡"""
    try:
        check_and_protect()
        status = get_protection_status()
        
        return jsonify({
            'success': True,
            'status': status,
            'message': 'æ£€æŸ¥å®Œæˆ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ==================== é”šå®šç³»ç»Ÿç›ˆåˆ©æŒ‡æ ‡ç›‘æ§ API ====================

@app.route('/api/anchor-profit/latest')
def get_anchor_profit_latest():
    """è·å–æœ€è¿‘çš„ç›ˆåˆ©æŒ‡æ ‡æ•°æ®"""
    try:
        import sys
        from pathlib import Path
        sys.path.insert(0, '/home/user/webapp/source_code')
        from anchor_profit_monitor import get_recent_data
        
        # è·å–æ—¶é—´èŒƒå›´å‚æ•°(åˆ†é’Ÿ)
        minutes = request.args.get('minutes', 60, type=int)
        
        # è·å–æœ€è¿‘æ•°æ®
        data = get_recent_data(minutes)
        
        return jsonify({
            'success': True,
            'data': data,
            'count': len(data),
            'minutes': minutes
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/anchor-profit/collect', methods=['POST'])
def trigger_anchor_profit_collect():
    """æ‰‹åŠ¨è§¦å‘ä¸€æ¬¡æ•°æ®æ”¶é›†"""
    try:
        import sys
        from pathlib import Path
        sys.path.insert(0, '/home/user/webapp/source_code')
        from anchor_profit_monitor import collect_and_save
        
        # æ”¶é›†å¹¶ä¿å­˜æ•°æ®
        data = collect_and_save()
        
        return jsonify({
            'success': True,
            'data': data,
            'message': 'æ•°æ®æ”¶é›†å®Œæˆ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/anchor-profit/history')
def get_anchor_profit_history():
    """è·å–å†å²æ•°æ®(ä¼˜åŒ–ç‰ˆ:æ”¯æŒå‹ç¼©)"""
    try:
        import sys
        from pathlib import Path
        sys.path.insert(0, '/home/user/webapp/source_code')
        from anchor_profit_monitor import get_recent_data
        
        # è·å–limitå‚æ•°(é»˜è®¤60æ¡,å³æœ€è¿‘1å°æ—¶)
        limit = request.args.get('limit', 60, type=int)
        
        # é™åˆ¶æœ€å¤§è¯·æ±‚é‡,é¿å…æ€§èƒ½é—®é¢˜
        max_limit = 4320  # æœ€å¤š3å¤©çš„æ•°æ®
        if limit > max_limit:
            limit = max_limit
        
        # è·å–æœ€è¿‘æ•°æ®
        data = get_recent_data(limit)
        
        response_data = {
            'success': True,
            'data': data,
            'count': len(data)
        }
        
        # åˆ›å»ºå“åº”
        response = jsonify(response_data)
        
        # æ·»åŠ ç¼“å­˜å¤´(ç¼“å­˜60ç§’)
        response.headers['Cache-Control'] = 'public, max-age=60'
        
        return response
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/anchor-profit/dates')
def get_anchor_profit_dates():
    """è·å–å¯ç”¨çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/source_code')
        from anchor_daily_reader import AnchorDailyReader
        
        reader = AnchorDailyReader()
        dates = reader.get_available_dates()
        
        return jsonify({
            'success': True,
            'dates': dates,
            'count': len(dates)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/anchor-profit/by-date')
def get_anchor_profit_by_date():
    """æŒ‰æ—¥æœŸè·å–é”šç‚¹ç›ˆåˆ©æ•°æ®"""
    try:
        from datetime import datetime
        
        # è·å–æ—¥æœŸå‚æ•°(é»˜è®¤ä»Šå¤©)
        date = request.args.get('date', datetime.now().strftime("%Y-%m-%d"))
        data_type = request.args.get('type', 'profit_stats')  # é»˜è®¤åªè¿”å›ç›ˆåˆ©ç»Ÿè®¡
        
        # ä½¿ç”¨å…¨å±€reader(å¸¦ç¼“å­˜)
        reader = get_anchor_reader()
        data = reader.get_date_data(date, data_type)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = reader.get_date_statistics(date)
        
        return jsonify({
            'success': True,
            'date': date,
            'data': data,
            'count': len(data),
            'statistics': stats
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-profit/summary')
def get_anchor_profit_summary():
    """è·å–ç›ˆåˆ©ç»Ÿè®¡æ‘˜è¦"""
    try:
        from datetime import datetime
        
        # è·å–æ—¥æœŸå‚æ•°(é»˜è®¤ä»Šå¤©)
        date = request.args.get('date', datetime.now().strftime("%Y-%m-%d"))
        
        # ä½¿ç”¨å…¨å±€reader(å¸¦ç¼“å­˜)
        reader = get_anchor_reader()
        summary = reader.get_profit_stats_summary(date)
        
        return jsonify({
            'success': True,
            'summary': summary
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/backfill-monitor')
def backfill_monitor():
    """æ•°æ®å›å¡«ç›‘æ§é¡µé¢"""
    response = make_response(render_template('backfill_monitor.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/api/backfill-monitor/logs')
def backfill_monitor_logs():
    """è·å–å›å¡«æ—¥å¿—"""
    try:
        log_file = '/home/user/webapp/logs/coin_price_backfill.log'
        if os.path.exists(log_file):
            # è¯»å–æœ€å500è¡Œ
            with open(log_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                recent_lines = lines[-500:] if len(lines) > 500 else lines
                logs = ''.join(recent_lines)
        else:
            logs = 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨'
        
        return jsonify({
            'success': True,
            'logs': logs
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/backfill-monitor/stop', methods=['POST'])
def backfill_monitor_stop():
    """åœæ­¢å›å¡«è¿›ç¨‹"""
    try:
        import subprocess
        # æŸ¥æ‰¾å›å¡«è¿›ç¨‹å¹¶ç»ˆæ­¢
        result = subprocess.run(['pkill', '-f', 'coin_price_backfill_history.py'], capture_output=True)
        return jsonify({
            'success': True,
            'message': 'å·²å‘é€åœæ­¢ä¿¡å·'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/extreme-market-alerts/latest')
def api_extreme_market_alerts_latest():
    """è·å–æœ€æ–°çš„æç«¯å¸‚åœºé¢„è­¦è®°å½•"""
    try:
        db_path = '/home/user/webapp/databases/crypto_data.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        limit = request.args.get('limit', 50, type=int)
        
        cursor.execute("""
            SELECT alert_time, alert_type, total_change, coin_count, details, created_at
            FROM extreme_market_alerts
            ORDER BY alert_time DESC
            LIMIT ?
        """, (limit,))
        
        rows = cursor.fetchall()
        conn.close()
        
        alerts = []
        for row in rows:
            alert_time, alert_type, total_change, coin_count, details, created_at = row
            alerts.append({
                'alert_time': alert_time,
                'alert_type': alert_type,
                'alert_type_name': 'æç«¯ä¸Šæ¶¨' if alert_type == 'extreme_high' else 'æç«¯æš´è·Œ',
                'total_change': total_change,
                'coin_count': coin_count,
                'details': json.loads(details) if details else [],
                'created_at': created_at
            })
        
        return jsonify({
            'success': True,
            'count': len(alerts),
            'data': alerts
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/extreme-market-alerts/stats')
def api_extreme_market_alerts_stats():
    """è·å–æç«¯å¸‚åœºé¢„è­¦ç»Ÿè®¡"""
    try:
        db_path = '/home/user/webapp/databases/crypto_data.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ç»Ÿè®¡æ€»æ•°
        cursor.execute("SELECT COUNT(*) FROM extreme_market_alerts")
        total_count = cursor.fetchone()[0]
        
        # ç»Ÿè®¡æç«¯ä¸Šæ¶¨æ¬¡æ•°
        cursor.execute("SELECT COUNT(*) FROM extreme_market_alerts WHERE alert_type = 'extreme_high'")
        high_count = cursor.fetchone()[0]
        
        # ç»Ÿè®¡æç«¯æš´è·Œæ¬¡æ•°
        cursor.execute("SELECT COUNT(*) FROM extreme_market_alerts WHERE alert_type = 'extreme_low'")
        low_count = cursor.fetchone()[0]
        
        # è·å–æœ€æ–°é¢„è­¦
        cursor.execute("""
            SELECT alert_time, alert_type, total_change
            FROM extreme_market_alerts
            ORDER BY alert_time DESC
            LIMIT 1
        """)
        latest = cursor.fetchone()
        
        conn.close()
        
        stats = {
            'total_count': total_count,
            'extreme_high_count': high_count,
            'extreme_low_count': low_count,
            'latest_alert': {
                'alert_time': latest[0],
                'alert_type': latest[1],
                'alert_type_name': 'æç«¯ä¸Šæ¶¨' if latest[1] == 'extreme_high' else 'æç«¯æš´è·Œ',
                'total_change': latest[2]
            } if latest else None
        }
        
        return jsonify({
            'success': True,
            'stats': stats
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })


# ==================== æå€¼è¿½è¸ªç³»ç»Ÿ API ====================

@app.route('/api/extreme-tracking/snapshots')
def api_extreme_tracking_snapshots():
    """è·å–æå€¼è¿½è¸ªå¿«ç…§åˆ—è¡¨"""
    try:
        import json
        from pathlib import Path
        
        snapshots_file = Path('/home/user/webapp/data/extreme_tracking/extreme_snapshots.jsonl')
        
        if not snapshots_file.exists():
            return jsonify({
                'success': True,
                'data': [],
                'message': 'æš‚æ— å¿«ç…§æ•°æ®'
            })
        
        # è¯»å–æ‰€æœ‰å¿«ç…§
        snapshots = []
        with open(snapshots_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    snapshots.append(json.loads(line))
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        snapshots.sort(key=lambda x: x.get('trigger_time', 0), reverse=True)
        
        # è·å–æŸ¥è¯¢å‚æ•°
        limit = request.args.get('limit', type=int, default=None)
        status = request.args.get('status', type=str, default=None)  # active/completed
        
        # è¿‡æ»¤çŠ¶æ€
        if status:
            snapshots = [s for s in snapshots if s.get('status') == status]
        
        # é™åˆ¶æ•°é‡
        if limit:
            snapshots = snapshots[:limit]
        
        return jsonify({
            'success': True,
            'data': snapshots,
            'count': len(snapshots)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/extreme-tracking/snapshot/<snapshot_id>')
def api_extreme_tracking_snapshot_detail(snapshot_id):
    """è·å–å•ä¸ªå¿«ç…§çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        import json
        from pathlib import Path
        
        snapshots_file = Path('/home/user/webapp/data/extreme_tracking/extreme_snapshots.jsonl')
        
        if not snapshots_file.exists():
            return jsonify({
                'success': False,
                'message': 'å¿«ç…§æ–‡ä»¶ä¸å­˜åœ¨'
            })
        
        # æŸ¥æ‰¾æŒ‡å®šå¿«ç…§
        with open(snapshots_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    snapshot = json.loads(line)
                    if snapshot.get('snapshot_id') == snapshot_id:
                        return jsonify({
                            'success': True,
                            'data': snapshot
                        })
        
        return jsonify({
            'success': False,
            'message': f'æœªæ‰¾åˆ°å¿«ç…§: {snapshot_id}'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/extreme-tracking/stats')
def api_extreme_tracking_stats():
    """è·å–æå€¼è¿½è¸ªç»Ÿè®¡ä¿¡æ¯"""
    try:
        import json
        from pathlib import Path
        from collections import Counter
        
        snapshots_file = Path('/home/user/webapp/data/extreme_tracking/extreme_snapshots.jsonl')
        
        if not snapshots_file.exists():
            return jsonify({
                'success': True,
                'stats': {
                    'total_snapshots': 0,
                    'active_snapshots': 0,
                    'completed_snapshots': 0,
                    'trigger_types': {}
                }
            })
        
        # è¯»å–æ‰€æœ‰å¿«ç…§
        snapshots = []
        with open(snapshots_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    snapshots.append(json.loads(line))
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_count = len(snapshots)
        active_count = len([s for s in snapshots if s.get('status') == 'active'])
        completed_count = len([s for s in snapshots if s.get('status') == 'completed'])
        
        # ç»Ÿè®¡è§¦å‘ç±»å‹
        trigger_types = Counter()
        for snapshot in snapshots:
            for trigger in snapshot.get('triggers', []):
                trigger_types[trigger.get('type', 'unknown')] += 1
        
        # è®¡ç®—å¹³å‡ä»·æ ¼å˜åŒ–(å·²å®Œæˆçš„å¿«ç…§)
        completed_snapshots = [s for s in snapshots if s.get('status') == 'completed']
        avg_changes = {
            '1h': 0, '3h': 0, '6h': 0, '12h': 0, '24h': 0
        }
        
        if completed_snapshots:
            for period in avg_changes.keys():
                changes = [
                    s['tracking'][period]['total_change']
                    for s in completed_snapshots
                    if s.get('tracking', {}).get(period)
                ]
                if changes:
                    avg_changes[period] = sum(changes) / len(changes)
        
        stats = {
            'total_snapshots': total_count,
            'active_snapshots': active_count,
            'completed_snapshots': completed_count,
            'trigger_types': dict(trigger_types),
            'average_price_changes': avg_changes
        }
        
        return jsonify({
            'success': True,
            'stats': stats
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


# ==================== å®ç›˜äº¤æ˜“ç³»ç»Ÿè·¯ç”± ====================

@app.route('/live-trading')
def live_trading():
    """å®ç›˜äº¤æ˜“ç³»ç»Ÿä¸»é¡µ"""
    try:
        with open('/home/user/webapp/live-trading-system/public/live-trading-v2.html', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "å®ç›˜äº¤æ˜“ç³»ç»Ÿæ–‡ä»¶æœªæ‰¾åˆ°", 404
    except Exception as e:
        return f"åŠ è½½å®ç›˜äº¤æ˜“ç³»ç»Ÿå¤±è´¥: {str(e)}", 500

@app.route('/live-trading/<path:filename>')
def live_trading_static(filename):
    """å®ç›˜äº¤æ˜“ç³»ç»Ÿé™æ€æ–‡ä»¶æœåŠ¡"""
    try:
        # å°è¯•ä»publicç›®å½•åŠ è½½
        file_path = f'/home/user/webapp/live-trading-system/public/{filename}'
        if os.path.exists(file_path):
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åè®¾ç½®mimetype
            if filename.endswith('.js'):
                return send_file(file_path, mimetype='application/javascript')
            elif filename.endswith('.css'):
                return send_file(file_path, mimetype='text/css')
            elif filename.endswith('.html'):
                return send_file(file_path, mimetype='text/html')
            else:
                return send_file(file_path)
        
        # å°è¯•ä»æ ¹ç›®å½•åŠ è½½
        file_path = f'/home/user/webapp/live-trading-system/{filename}'
        if os.path.exists(file_path):
            if filename.endswith('.js'):
                return send_file(file_path, mimetype='application/javascript')
            elif filename.endswith('.css'):
                return send_file(file_path, mimetype='text/css')
            else:
                return send_file(file_path)
        
        return f"æ–‡ä»¶æœªæ‰¾åˆ°: {filename}", 404
    except Exception as e:
        import traceback
        print(f"é™æ€æ–‡ä»¶åŠ è½½é”™è¯¯: {str(e)}")
        print(traceback.format_exc())
        return f"åŠ è½½æ–‡ä»¶å¤±è´¥: {str(e)}", 500

# å®ç›˜äº¤æ˜“APIç«¯ç‚¹
@app.route('/api/live-trading/<path:endpoint>', methods=['GET', 'POST', 'PUT', 'DELETE'])
def live_trading_api(endpoint):
    """å®ç›˜äº¤æ˜“APIä»£ç†"""
    try:
        import json
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„äº¤æ˜“API
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
        return jsonify({
            'success': True,
            'message': f'API endpoint: {endpoint}',
            'method': request.method,
            'data': request.get_json() if request.is_json else None
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

# ==================== æœåŠ¡å¥åº·ç›‘æ§ API ====================
@app.route('/api/service-health')
def service_health():
    """è·å–æ‰€æœ‰æ•°æ®é‡‡é›†æœåŠ¡çš„å¥åº·çŠ¶æ€"""
    try:
        from service_health_monitor import get_health_status
        result = get_health_status()
        return jsonify({
            'success': True,
            **result
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

# ==================== é‡å¤§äº‹ä»¶ç³»ç»Ÿ API ====================
@app.route('/major-events-test')
def major_events_test():
    """é‡å¤§äº‹ä»¶æŒ‰é’®æµ‹è¯•é¡µé¢"""
    try:
        html_file = '/home/user/webapp/test_buttons.html'
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # æ·»åŠ no-cacheå¤´
        response = make_response(html_content)
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '-1'
        return response
    except FileNotFoundError:
        return "æµ‹è¯•é¡µé¢æœªæ‰¾åˆ°", 404
    except Exception as e:
        return f"åŠ è½½æµ‹è¯•é¡µé¢å¤±è´¥: {str(e)}", 500

@app.route('/major-events')
def major_events_page():
    """é‡å¤§äº‹ä»¶ç³»ç»Ÿä¸»é¡µ"""
    try:
        html_file = '/home/user/webapp/major-events-system/major_events.html'
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # æ·»åŠ no-cacheå¤´
        response = make_response(html_content)
        response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '-1'
        return response
    except FileNotFoundError:
        return 'é‡å¤§äº‹ä»¶ç³»ç»Ÿé¡µé¢æœªæ‰¾åˆ°', 404
    except Exception as e:
        return f'åŠ è½½é‡å¤§äº‹ä»¶ç³»ç»Ÿå¤±è´¥: {str(e)}', 500

@app.route('/major-events/<path:filename>')
def major_events_static(filename):
    """é‡å¤§äº‹ä»¶ç³»ç»Ÿé™æ€æ–‡ä»¶"""
    try:
        file_path = f'/home/user/webapp/major-events-system/{filename}'
        if os.path.exists(file_path):
            if filename.endswith('.js'):
                return send_file(file_path, mimetype='application/javascript')
            elif filename.endswith('.css'):
                return send_file(file_path, mimetype='text/css')
            else:
                return send_file(file_path)
        return f"æ–‡ä»¶æœªæ‰¾åˆ°: {filename}", 404
    except Exception as e:
        return f"åŠ è½½æ–‡ä»¶å¤±è´¥: {str(e)}", 500

@app.route('/api/major-events/current-status', methods=['GET'])
def get_major_events_status():
    """è·å–å½“å‰äº‹ä»¶ç›‘æ§çŠ¶æ€ - ä»å®æ—¶APIè·å–æ•°æ®"""
    try:
        import requests
        
        # 1. è·å–2hè§é¡¶ä¿¡å·æ•°é‡ - ä»escape signal API
        top_signal_count = 0
        try:
            escape_response = requests.get('http://localhost:5000/api/escape-signal-stats?limit=1', timeout=2)
            if escape_response.ok:
                escape_data = escape_response.json()
                if escape_data.get('success'):
                    recent_data = escape_data.get('recent_data', [])
                    if recent_data:
                        top_signal_count = recent_data[0].get('signal_2h_count', 0)
        except Exception as e:
            logger.warning(f"è·å–escape signalå¤±è´¥: {e}")
        
        # 2. è·å–27å¸æ¶¨è·Œå¹…å’Œ - ä»coin price API  
        coins_change_sum = 0
        try:
            # è¯»å–æœ€æ–°çš„30åˆ†é’Ÿå¸ä»·æ•°æ®
            import json
            coin_price_file = '/home/user/webapp/data/coin_price_tracker/coin_prices_30min.jsonl'
            with open(coin_price_file, 'r') as f:
                lines = f.readlines()
                if lines:
                    latest = json.loads(lines[-1])
                    coins_change_sum = latest.get('total_change', 0)
        except Exception as e:
            logger.warning(f"è·å–å¸ä»·å˜åŒ–å¤±è´¥: {e}")
        
        # 3. è·å–1å°æ—¶çˆ†ä»“é‡‘é¢ - ä»panic API
        liquidation_amount = 0
        try:
            panic_response = requests.get('http://localhost:5000/api/panic/latest', timeout=2)
            if panic_response.ok:
                panic_data = panic_response.json()
                if panic_data.get('success'):
                    data = panic_data.get('data', {})
                    liquidation_amount = data.get('hour_1_amount', 0)
        except Exception as e:
            logger.warning(f"è·å–çˆ†ä»“æ•°æ®å¤±è´¥: {e}")
        
        # 4. è·å–äº‹ä»¶7å’Œäº‹ä»¶8çš„çŠ¶æ€
        event_states = {}
        try:
            import sys
            sys.path.insert(0, '/home/user/webapp/major-events-system')
            from major_events_monitor import MajorEventsMonitor
            
            monitor = MajorEventsMonitor()
            event_states = monitor.get_current_event_states()
        except Exception as e:
            logger.warning(f"è·å–äº‹ä»¶çŠ¶æ€å¤±è´¥: {e}")
        
        return jsonify({
            'success': True,
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).isoformat(),
            'data': {
                'top_signal_count': top_signal_count,
                'coins_change_sum': coins_change_sum,
                'liquidation_amount': liquidation_amount
            },
            'current_data': {
                'top_signal_2h': top_signal_count,
                'coins_change_sum': coins_change_sum,
                'liquidation_1h': liquidation_amount
            },
            'event_states': event_states
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/major-events/recent', methods=['GET'])
def get_recent_major_events():
    """è·å–æœ€è¿‘çš„é‡å¤§äº‹ä»¶"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/major-events-system')
        from major_events_monitor import MajorEventsMonitor
        
        monitor = MajorEventsMonitor()
        
        # è·å–æ—¶é—´å‚æ•°
        hours = int(request.args.get('hours', 24))
        
        events = monitor.get_recent_events(hours=hours)
        
        return jsonify({
            'success': True,
            'hours': hours,
            'events': list(reversed(events)),  # å€’åºæ’åˆ—,æœ€æ–°çš„åœ¨å‰
            'total': len(events)
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/major-events/trigger-check', methods=['POST'])
def trigger_event_check():
    """æ‰‹åŠ¨è§¦å‘äº‹ä»¶æ£€æŸ¥"""
    try:
        import sys
        sys.path.insert(0, '/home/user/webapp/major-events-system')
        from major_events_monitor import MajorEventsMonitor
        
        monitor = MajorEventsMonitor()
        triggered_events = monitor.monitor_cycle()
        
        return jsonify({
            'success': True,
            'triggered_events': triggered_events,
            'count': len(triggered_events)
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/anchor-system/profit-history', methods=['GET'])
def get_anchor_system_profit_history():
    """è·å–é”šå®šç³»ç»Ÿç›ˆåˆ©å†å²æ•°æ®(æŒ‰æ—¥æœŸæŸ¥è¯¢,æ”¯æŒåˆ†é¡µåŠ è½½)"""
    try:
        import json
        from pathlib import Path
        
        # è·å–å‚æ•°
        trade_mode = request.args.get('trade_mode', 'real')  # real or paper
        date_str = request.args.get('date')  # YYYY-MM-DD æ ¼å¼
        
        # æ•°æ®ç›®å½•
        data_dir = Path('/home/user/webapp/data/anchor_profit_stats')
        
        # å¦‚æœæŒ‡å®šäº†æ—¥æœŸ,å°è¯•ä»æŒ‰æ—¥æœŸæ–‡ä»¶è¯»å–
        if date_str:
            # å°è¯•æŒ‰æ—¥æœŸæ–‡ä»¶(æ–°æ ¼å¼)
            date_file = data_dir / f'anchor_profit_{date_str}.jsonl'
            
            if date_file.exists():
                # ä»æŒ‰æ—¥æœŸæ–‡ä»¶è¯»å–
                history_data = []
                with open(date_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            data = json.loads(line.strip())
                            # å…¼å®¹æ—§æ•°æ®:å¦‚æœæ²¡æœ‰ trade_mode å­—æ®µ,é»˜è®¤è®¤ä¸ºæ˜¯ real
                            data_trade_mode = data.get('trade_mode', 'real')
                            if data_trade_mode == trade_mode:
                                history_data.append(data)
                        except:
                            continue
                
                return jsonify({
                    'success': True,
                    'trade_mode': trade_mode,
                    'date': date_str,
                    'history': history_data,
                    'count': len(history_data),
                    'source': 'date_file'
                })
            else:
                # æŒ‰æ—¥æœŸæ–‡ä»¶ä¸å­˜åœ¨,å°è¯•ä»ä¸»æ–‡ä»¶è¯»å–(å…¼å®¹æ—§æ•°æ®)
                main_file = data_dir / 'anchor_profit_stats.jsonl'
                if not main_file.exists():
                    return jsonify({
                        'success': False,
                        'error': f'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨:{date_str}'
                    })
                
                # è§£ææ—¥æœŸèŒƒå›´
                from datetime import datetime as dt
                target_date = dt.strptime(date_str, '%Y-%m-%d')
                start_timestamp = int(target_date.replace(hour=0, minute=0, second=0).timestamp())
                end_timestamp = int(target_date.replace(hour=23, minute=59, second=59).timestamp())
                
                # ä»ä¸»æ–‡ä»¶è¯»å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®
                history_data = []
                with open(main_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            data = json.loads(line.strip())
                            timestamp = data.get('timestamp', 0)
                            if start_timestamp <= timestamp <= end_timestamp:
                                # å…¼å®¹æ—§æ•°æ®:å¦‚æœæ²¡æœ‰ trade_mode å­—æ®µ,é»˜è®¤è®¤ä¸ºæ˜¯ real
                                data_trade_mode = data.get('trade_mode', 'real')
                                if data_trade_mode == trade_mode:
                                    history_data.append(data)
                        except:
                            continue
                
                return jsonify({
                    'success': True,
                    'trade_mode': trade_mode,
                    'date': date_str,
                    'history': history_data,
                    'count': len(history_data),
                    'source': 'main_file_filtered'
                })
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸ,è¿”å›ä»Šå¤©çš„æ•°æ®(é»˜è®¤è¡Œä¸º)
        else:
            today_str = datetime.now(BEIJING_TZ).strftime('%Y-%m-%d')
            return get_anchor_system_profit_history_by_date(trade_mode, today_str, data_dir)
            
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

def get_anchor_system_profit_history_by_date(trade_mode, date_str, data_dir):
    """è¾…åŠ©å‡½æ•°: æŒ‰æ—¥æœŸæŸ¥è¯¢æ•°æ®"""
    import json
    from pathlib import Path
    from datetime import datetime as dt
    
    # å°è¯•æŒ‰æ—¥æœŸæ–‡ä»¶
    date_file = data_dir / f'anchor_profit_{date_str}.jsonl'
    
    if date_file.exists():
        history_data = []
        with open(date_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    # å…¼å®¹æ—§æ•°æ®:å¦‚æœæ²¡æœ‰ trade_mode å­—æ®µ,é»˜è®¤è®¤ä¸ºæ˜¯ real
                    data_trade_mode = data.get('trade_mode', 'real')
                    if data_trade_mode == trade_mode:
                        history_data.append(data)
                except:
                    continue
        
        return jsonify({
            'success': True,
            'trade_mode': trade_mode,
            'date': date_str,
            'history': history_data,
            'count': len(history_data),
            'source': 'date_file'
        })
    else:
        # ä»ä¸»æ–‡ä»¶è¯»å–
        main_file = data_dir / 'anchor_profit_stats.jsonl'
        if not main_file.exists():
            return jsonify({
                'success': False,
                'error': f'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨:{date_str}'
            })
        
        target_date = dt.strptime(date_str, '%Y-%m-%d')
        start_timestamp = int(target_date.replace(hour=0, minute=0, second=0).timestamp())
        end_timestamp = int(target_date.replace(hour=23, minute=59, second=59).timestamp())
        
        history_data = []
        with open(main_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    timestamp = data.get('timestamp', 0)
                    if start_timestamp <= timestamp <= end_timestamp:
                        # å…¼å®¹æ—§æ•°æ®:å¦‚æœæ²¡æœ‰ trade_mode å­—æ®µ,é»˜è®¤è®¤ä¸ºæ˜¯ real
                        data_trade_mode = data.get('trade_mode', 'real')
                        if data_trade_mode == trade_mode:
                            history_data.append(data)
                except:
                    continue
        
        return jsonify({
            'success': True,
            'trade_mode': trade_mode,
            'date': date_str,
            'history': history_data,
            'count': len(history_data),
            'source': 'main_file_filtered'
        })

@app.route('/api/major-events/data/sar-slope', methods=['GET'])
def get_sar_slope_data():
    """è·å–SARæ–œç‡æ•°æ®(ä»JSONLè¯»å–)"""
    try:
        import json
        from pathlib import Path
        
        hours = int(request.args.get('hours', 1))  # é»˜è®¤1å°æ—¶
        jsonl_file = Path('/home/user/webapp/major-events-system/data/sar_slope_data.jsonl')
        
        if not jsonl_file.exists():
            return jsonify({'success': False, 'error': 'JSONLæ–‡ä»¶ä¸å­˜åœ¨'})
        
        data_list = []
        cutoff_time = int(time.time()) - (hours * 3600)
        
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    if data.get('timestamp', 0) >= cutoff_time:
                        data_list.append(data)
                except:
                    continue
        
        return jsonify({
            'success': True,
            'hours': hours,
            'data': data_list,
            'count': len(data_list)
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/major-events/data/liquidation', methods=['GET'])
def get_liquidation_data():
    """è·å–çˆ†ä»“æ•°æ®(ä»JSONLè¯»å–)"""
    try:
        import json
        from pathlib import Path
        
        hours = int(request.args.get('hours', 1))  # é»˜è®¤1å°æ—¶
        jsonl_file = Path('/home/user/webapp/major-events-system/data/liquidation_data.jsonl')
        
        if not jsonl_file.exists():
            return jsonify({'success': False, 'error': 'JSONLæ–‡ä»¶ä¸å­˜åœ¨'})
        
        data_list = []
        cutoff_time = int(time.time()) - (hours * 3600)
        
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    data = json.loads(line.strip())
                    if data.get('timestamp', 0) >= cutoff_time:
                        data_list.append(data)
                except:
                    continue
        
        return jsonify({
            'success': True,
            'hours': hours,
            'data': data_list,
            'count': len(data_list)
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })

@app.route('/api/okx-trading/batch-order', methods=['POST'])
def batch_order_from_event():
    """ä»é‡å¤§äº‹ä»¶é¡µé¢è§¦å‘çš„æ‰¹é‡å¼€ä»“"""
    try:
        import requests
        import hmac
        import base64
        from datetime import datetime, timezone
        
        data = request.get_json()
        direction = data.get('direction', 'short')  # long/short
        percent_per_coin = float(data.get('percentPerCoin', 5))
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        # 1. è·å–è´¦æˆ·ä½™é¢
        base_url = 'https://www.okx.com'
        balance_path = '/api/v5/account/balance'
        balance_timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
        balance_message = balance_timestamp + 'GET' + balance_path
        balance_mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(balance_message, encoding='utf-8'), digestmod='sha256')
        balance_signature = base64.b64encode(balance_mac.digest()).decode()
        
        balance_headers = {
            'OK-ACCESS-KEY': api_key,
            'OK-ACCESS-SIGN': balance_signature,
            'OK-ACCESS-TIMESTAMP': balance_timestamp,
            'OK-ACCESS-PASSPHRASE': passphrase,
            'Content-Type': 'application/json'
        }
        
        balance_response = requests.get(base_url + balance_path, headers=balance_headers, timeout=10)
        balance_result = balance_response.json()
        
        if balance_result.get('code') != '0':
            return jsonify({
                'success': False,
                'error': f"è·å–ä½™é¢å¤±è´¥: {balance_result.get('msg')}"
            })
        
        # æå–USDTå¯ç”¨ä½™é¢
        balance = 0
        for detail in balance_result.get('data', [{}])[0].get('details', []):
            if detail.get('ccy') == 'USDT':
                balance = float(detail.get('availBal', 0))
                break
        
        if balance <= 0:
            return jsonify({
                'success': False,
                'error': f"USDTä½™é¢ä¸è¶³: {balance}"
            })
        
        # 2. è·å–å¸¸ç”¨å¸åˆ—è¡¨
        favorite_file = 'data/favorite_symbols.jsonl'
        favorite_symbols = []
        try:
            with open(favorite_file, 'r') as f:
                lines = f.readlines()
                if lines:
                    favorite_data = json.loads(lines[-1].strip())
                    favorite_symbols = favorite_data.get('symbols', [])
        except:
            favorite_symbols = ["BTC-USDT-SWAP", "ETH-USDT-SWAP", "SOL-USDT-SWAP", 
                              "BNB-USDT-SWAP", "XRP-USDT-SWAP", "DOGE-USDT-SWAP"]
        
        if len(favorite_symbols) < 6:
            return jsonify({
                'success': False,
                'error': f"å¸¸ç”¨å¸ä¸è¶³6ä¸ª,å½“å‰: {len(favorite_symbols)}ä¸ª"
            })
        
        # 3. è·å–å¸‚åœºè¡Œæƒ…,é€‰æ‹©æ¶¨å¹…å‰6
        ticker_path = '/api/v5/market/tickers?instType=SWAP'
        ticker_response = requests.get(base_url + ticker_path, timeout=10)
        ticker_result = ticker_response.json()
        
        if ticker_result.get('code') != '0':
            return jsonify({
                'success': False,
                'error': f"è·å–è¡Œæƒ…å¤±è´¥: {ticker_result.get('msg')}"
            })
        
        # ç­›é€‰å¸¸ç”¨å¸å¹¶æŒ‰æ¶¨è·Œå¹…æ’åº
        symbols_data = []
        for ticker in ticker_result.get('data', []):
            inst_id = ticker.get('instId', '')
            if inst_id in favorite_symbols:
                change_24h = float(ticker.get('changeRate24h', 0)) * 100
                price = float(ticker.get('last', 0))
                symbols_data.append({
                    'instId': inst_id,
                    'price': price,
                    'change': change_24h
                })
        
        # æŒ‰æ¶¨è·Œå¹…æ’åº,å–å‰6
        symbols_data.sort(key=lambda x: x['change'], reverse=True)
        top6_symbols = symbols_data[:6]
        
        if len(top6_symbols) < 6:
            return jsonify({
                'success': False,
                'error': f"å¯ç”¨å¸ç§ä¸è¶³6ä¸ª,å½“å‰: {len(top6_symbols)}ä¸ª"
            })
        
        # 4. è®¡ç®—æ¯ä¸ªå¸çš„å¼€ä»“å‚æ•°
        margin_per_coin = balance * percent_per_coin / 100  # ä¿è¯é‡‘
        contract_value_per_coin = margin_per_coin * 10  # åˆçº¦ä»·å€¼(10xæ æ†)
        
        # 5. æ‰¹é‡ä¸‹å•
        success_count = 0
        fail_count = 0
        results = []
        
        for symbol_data in top6_symbols:
            inst_id = symbol_data['instId']
            price = symbol_data['price']
            
            try:
                # è®¾ç½®æ æ†
                leverage = '10'
                pos_side = direction  # long/short
                
                set_leverage_path = '/api/v5/account/set-leverage'
                leverage_body = json.dumps({
                    'instId': inst_id,
                    'lever': leverage,
                    'mgnMode': 'isolated',
                    'posSide': pos_side
                })
                
                leverage_timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
                leverage_message = leverage_timestamp + 'POST' + set_leverage_path + leverage_body
                leverage_mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(leverage_message, encoding='utf-8'), digestmod='sha256')
                leverage_signature = base64.b64encode(leverage_mac.digest()).decode()
                
                leverage_headers = {
                    'OK-ACCESS-KEY': api_key,
                    'OK-ACCESS-SIGN': leverage_signature,
                    'OK-ACCESS-TIMESTAMP': leverage_timestamp,
                    'OK-ACCESS-PASSPHRASE': passphrase,
                    'Content-Type': 'application/json'
                }
                
                requests.post(base_url + set_leverage_path, headers=leverage_headers, data=leverage_body, timeout=10)
                
                # è·å–åˆçº¦è§„æ ¼
                instruments_path = f'/api/v5/public/instruments?instType=SWAP&instId={inst_id}'
                instruments_response = requests.get(base_url + instruments_path, timeout=5)
                instruments_data = instruments_response.json()
                
                ct_val = 0.1  # é»˜è®¤å€¼
                if instruments_data.get('code') == '0' and instruments_data.get('data'):
                    ct_val = float(instruments_data['data'][0].get('ctVal', 0.1))
                
                # è®¡ç®—åˆçº¦å¼ æ•°
                usdt_per_contract = ct_val * price
                contracts_count = max(1, round(contract_value_per_coin / usdt_per_contract))
                
                # ä¸‹å•
                request_path = '/api/v5/trade/order'
                side = 'buy' if direction == 'long' else 'sell'
                
                order_params = {
                    'instId': inst_id,
                    'tdMode': 'isolated',
                    'side': side,
                    'posSide': pos_side,
                    'ordType': 'market',
                    'sz': str(int(contracts_count))
                }
                
                body = json.dumps(order_params)
                timestamp = datetime.now(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z')
                message = timestamp + 'POST' + request_path + body
                mac = hmac.new(bytes(secret_key, encoding='utf8'), bytes(message, encoding='utf-8'), digestmod='sha256')
                signature = base64.b64encode(mac.digest()).decode()
                
                headers = {
                    'OK-ACCESS-KEY': api_key,
                    'OK-ACCESS-SIGN': signature,
                    'OK-ACCESS-TIMESTAMP': timestamp,
                    'OK-ACCESS-PASSPHRASE': passphrase,
                    'Content-Type': 'application/json'
                }
                
                response = requests.post(base_url + request_path, headers=headers, data=body, timeout=10)
                result = response.json()
                
                print(f"[æ‰¹é‡å¼€ä»“] {inst_id} ä¸‹å•å“åº”: {result}")
                
                if result.get('code') == '0':
                    success_count += 1
                    results.append(f"âœ… {inst_id}: æˆåŠŸ ({contracts_count}å¼ )")
                else:
                    fail_count += 1
                    error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
                    error_code = result.get('code', 'æœªçŸ¥ä»£ç ')
                    results.append(f"âŒ {inst_id}: [{error_code}] {error_msg}")
                    print(f"[æ‰¹é‡å¼€ä»“] {inst_id} å¤±è´¥: code={error_code}, msg={error_msg}")
                    
            except Exception as e:
                fail_count += 1
                results.append(f"âŒ {inst_id}: {str(e)}")
                print(f"[æ‰¹é‡å¼€ä»“] {inst_id} å¼‚å¸¸: {str(e)}")
        
        return jsonify({
            'success': success_count > 0,
            'successCount': success_count,
            'failCount': fail_count,
            'results': results
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/okx-trading/hedge-order', methods=['POST'])
def hedge_order_from_event():
    """ä»é‡å¤§äº‹ä»¶é¡µé¢è§¦å‘çš„å¯¹å†²å¼€ä»“"""
    try:
        data = request.get_json()
        hedge_direction = data.get('hedgeDirection', 'short')  # short=ç©ºå•é…å¤šå•, long=å¤šå•é…ç©ºå•
        
        # TODO: è¿™é‡Œéœ€è¦è·å–è´¦æˆ·é…ç½®å’ŒæŒä»“ä¿¡æ¯
        # ä¸´æ—¶æ–¹æ¡ˆ:è¿”å›æç¤ºä¿¡æ¯,è¦æ±‚ç”¨æˆ·åœ¨äº¤æ˜“é¡µé¢é…ç½®è´¦æˆ·åå†ä½¿ç”¨
        
        return jsonify({
            'success': False,
            'error': 'æ­¤åŠŸèƒ½éœ€è¦å…ˆåœ¨äº¤æ˜“é¡µé¢é…ç½®APIå¯†é’¥ã€‚\n\nè¯·å‰å¾€"OKXäº¤æ˜“ç³»ç»Ÿ"é¡µé¢é…ç½®è´¦æˆ·åä½¿ç”¨ã€‚',
            'redirect': '/okx-trading'
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/okx-trading/profit-analysis', methods=['POST'])
def okx_profit_analysis():
    """æ¯æ—¥åˆ©æ¶¦åˆ†æ - åŸºäºèµ„é‡‘è´¦å•"""
    try:
        import hmac
        import base64
        from datetime import datetime, timezone, timedelta
        import requests
        from collections import defaultdict
        
        data = request.get_json()
        api_key = data.get('apiKey', '')
        secret_key = data.get('apiSecret', '')
        passphrase = data.get('passphrase', '')
        date_range = data.get('dateRange', '30')  # 7, 30, 90, all
        start_date = data.get('startDate')
        end_date = data.get('endDate')
        
        if not api_key or not secret_key or not passphrase:
            return jsonify({
                'success': False,
                'error': 'APIå‡­è¯ä¸å®Œæ•´'
            })
        
        # OKX APIé…ç½®
        base_url = 'https://www.okx.com'
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        # ç¡®ä¿ç»“æŸæ—¶é—´æ˜¯å½“å‰æ—¶é—´,åŒ…å«ä»Šå¤©æœ€æ–°çš„æ•°æ®
        end_time = int(datetime.now().timestamp() * 1000)
        
        if start_date and end_date:
            # ä½¿ç”¨è‡ªå®šä¹‰æ—¥æœŸ
            start_time = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp() * 1000)
            # ç»“æŸæ—¶é—´è®¾ç½®ä¸ºç¬¬äºŒå¤©çš„å¼€å§‹,ç¡®ä¿åŒ…å«end_dateçš„å…¨å¤©æ•°æ®
            end_time = int((datetime.strptime(end_date, '%Y-%m-%d') + timedelta(days=1)).timestamp() * 1000)
            # å¦‚æœend_dateæ˜¯ä»Šå¤©,ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºç»“æŸæ—¶é—´
            if end_date == datetime.now().strftime('%Y-%m-%d'):
                end_time = int(datetime.now().timestamp() * 1000)
        elif date_range == 'all':
            # æœ€å¤šæŸ¥è¯¢90å¤©
            start_time = int((datetime.now() - timedelta(days=90)).timestamp() * 1000)
        else:
            days = int(date_range)
            start_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        
        # æ„å»ºè¯·æ±‚
        timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        method = 'GET'
        request_path = '/api/v5/asset/bills'
        
        # åˆ†é¡µè·å–æ‰€æœ‰æ•°æ®
        all_bills = []
        after = None  # ç”¨äºåˆ†é¡µ
        
        while True:
            # è·å–èµ„é‡‘è´¦å•(è·å–æ‰€æœ‰ç±»å‹)
            params_dict = {
                'begin': start_time,
                'end': end_time,
                'limit': 100  # æ¯æ¬¡è·å–100æ¡
            }
            if after:
                params_dict['after'] = after
            
            params = '&'.join([f'{k}={v}' for k, v in params_dict.items()])
            
            prehash = timestamp + method + request_path + '?' + params
            signature = base64.b64encode(
                hmac.new(secret_key.encode('utf-8'), prehash.encode('utf-8'), digestmod='sha256').digest()
            ).decode()
            
            headers = {
                'OK-ACCESS-KEY': api_key,
                'OK-ACCESS-SIGN': signature,
                'OK-ACCESS-TIMESTAMP': timestamp,
                'OK-ACCESS-PASSPHRASE': passphrase,
                'Content-Type': 'application/json'
            }
            
            # è°ƒç”¨API
            url = f'{base_url}{request_path}?{params}'
            response = requests.get(url, headers=headers, timeout=10)
            result = response.json()
            
            if result.get('code') != '0':
                return jsonify({
                    'success': False,
                    'error': f"OKX APIé”™è¯¯: {result.get('msg', 'Unknown error')}"
                })
            
            bills = result.get('data', [])
            if not bills:
                break
            
            all_bills.extend(bills)
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
            if len(bills) < 100:
                break
            
            # è·å–æœ€åä¸€æ¡çš„billIdä½œä¸ºä¸‹ä¸€é¡µçš„afterå‚æ•°
            after = bills[-1].get('billId')
            if not after:
                break
            
            # æ›´æ–°timestampç”¨äºä¸‹ä¸€æ¬¡è¯·æ±‚
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'
        
        # ä½¿ç”¨è·å–åˆ°çš„æ‰€æœ‰è´¦å•
        bills = all_bills
        
        # æ·»åŠ æ—¥å¿—
        print(f"[Profit Analysis] æŸ¥è¯¢æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(start_time/1000)} åˆ° {datetime.fromtimestamp(end_time/1000)}")
        print(f"[Profit Analysis] è·å–åˆ° {len(bills)} æ¡è´¦å•è®°å½•")
        if bills:
            print(f"[Profit Analysis] æœ€æ–°è®°å½•æ—¶é—´: {datetime.fromtimestamp(int(bills[0].get('ts', 0))/1000)}")
            print(f"[Profit Analysis] æœ€æ—©è®°å½•æ—¶é—´: {datetime.fromtimestamp(int(bills[-1].get('ts', 0))/1000)}")
        
        # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡ - æ–°ç­–ç•¥:åªçœ‹ä»äº¤æ˜“è´¦æˆ·è½¬å›çš„é‡‘é¢
        daily_stats = defaultdict(lambda: {
            'profit_from_trading': 0,  # ä»äº¤æ˜“è´¦æˆ·è½¬å› (ç±»å‹130,æ­£æ•°) = åˆ©æ¶¦æå–
            'loss_supplement': 0,      # è½¬å…¥èµ„é‡‘è´¦æˆ·çš„è¡¥å…… (ç±»å‹23,æ­£æ•°) = äºæŸè¡¥å……  
            'count': 0
        })
        
        for bill in bills:
            # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ—¥æœŸ
            ts = int(bill.get('ts', 0))
            date = datetime.fromtimestamp(ts / 1000).strftime('%Y-%m-%d')
            
            amount = float(bill.get('balChg', 0))
            bill_type = str(bill.get('type', ''))
            
            # ç±»å‹130: ä»äº¤æ˜“è´¦æˆ·è½¬å…¥èµ„é‡‘è´¦æˆ· (æ­£æ•°) = è¿™æ˜¯æå–åˆ©æ¶¦
            # ç±»å‹23: è½¬å…¥èµ„é‡‘è´¦æˆ· (æ­£æ•°) = è¿™å¯èƒ½æ˜¯äºæŸè¡¥å……æˆ–å……å€¼
            # ç±»å‹22: ä»èµ„é‡‘è´¦æˆ·è½¬å‡ºåˆ°äº¤æ˜“è´¦æˆ· (è´Ÿæ•°) = æ—¥å¸¸è½¬è´¦,å¿½ç•¥
            # ç±»å‹131: ä»èµ„é‡‘è´¦æˆ·è½¬å‡º (è´Ÿæ•°) = å¯èƒ½æ˜¯æç°,å¿½ç•¥
            
            if bill_type == '130' and amount > 0:
                # ä»äº¤æ˜“è´¦æˆ·è½¬å› = åˆ©æ¶¦
                daily_stats[date]['profit_from_trading'] += amount
            elif bill_type == '23' and amount > 0:
                # è½¬å…¥èµ„é‡‘è´¦æˆ· = å¯èƒ½æ˜¯äºæŸè¡¥å……
                daily_stats[date]['loss_supplement'] += amount
            
            daily_stats[date]['count'] += 1
        
        # ç”Ÿæˆæ¯æ—¥æ•°æ®
        daily_data = []
        cumulative_profit = 0
        base_capital = 300  # æœ¬é‡‘300 USDT
        
        sorted_dates = sorted(daily_stats.keys())
        
        # è·³è¿‡ç¬¬ä¸€å¤©çš„æœ¬é‡‘è½¬å…¥
        for idx, date in enumerate(sorted_dates):
            stats = daily_stats[date]
            
            # ç¬¬ä¸€å¤©:å¿½ç•¥æœ¬é‡‘è½¬å…¥å’Œè½¬å‡º,åˆ©æ¶¦ä¸º0
            if idx == 0:
                # ç¬¬ä¸€å¤©æ˜¯åˆå§‹æœ¬é‡‘çš„è¿›å‡º,ä¸ç®—åˆ©æ¶¦
                profit_amount = 0
                profit_rate = 0
            else:
                # åç»­å¤©æ•°:åªçœ‹ä»äº¤æ˜“è´¦æˆ·è½¬å›çš„é‡‘é¢ä½œä¸ºåˆ©æ¶¦
                # profit_from_trading (ç±»å‹130) = åˆ©æ¶¦
                # loss_supplement (ç±»å‹23) = äºæŸè¡¥å……,è§†ä¸ºè´Ÿåˆ©æ¶¦
                
                profit_from_trading = stats['profit_from_trading']  # åˆ©æ¶¦
                loss_supplement = stats['loss_supplement']          # äºæŸè¡¥å……
                
                # å‡€åˆ©æ¶¦ = ä»äº¤æ˜“è´¦æˆ·è·å¾—çš„ - è¡¥å……çš„äºæŸ
                profit_amount = profit_from_trading - loss_supplement
                profit_rate = (profit_amount / base_capital) * 100 if base_capital > 0 else 0
            
            cumulative_profit += profit_amount
            
            daily_data.append({
                'date': date,
                'withdraw': -stats['profit_from_trading'],  # æ˜¾ç¤ºä¸ºè´Ÿæ•°(è½¬å‡º)
                'deposit': stats['loss_supplement'],         # æ˜¾ç¤ºä¸ºæ­£æ•°(è½¬å…¥/äºæŸ)
                'profit': profit_amount,
                'profitRate': round(profit_rate, 2),
                'cumulativeProfit': cumulative_profit,
                'transactionCount': stats['count']
            })
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if daily_data:
            profits = [d['profit'] for d in daily_data]
            profit_rates = [d['profitRate'] for d in daily_data]
            
            total_profit = sum(profits)
            avg_daily_profit = total_profit / len(daily_data)
            avg_profit_rate = sum(profit_rates) / len(profit_rates)
            
            max_profit = max(profits)
            max_index = profits.index(max_profit)
            max_date = daily_data[max_index]['date']
            max_profit_rate = profit_rates[max_index]
            
            min_profit = min(profits)
            min_index = profits.index(min_profit)
            min_date = daily_data[min_index]['date']
            min_profit_rate = profit_rates[min_index]
            
            total_withdraw = sum(d['withdraw'] for d in daily_data)
            total_deposit = sum(d['deposit'] for d in daily_data)
        else:
            total_profit = 0
            avg_daily_profit = 0
            avg_profit_rate = 0
            max_profit = 0
            max_profit_rate = 0
            max_date = ''
            min_profit = 0
            min_profit_rate = 0
            min_date = ''
            total_withdraw = 0
            total_deposit = 0
        
        return jsonify({
            'success': True,
            'data': {
                'dailyData': daily_data,
                'stats': {
                    'totalProfit': total_profit,
                    'avgDailyProfit': avg_daily_profit,
                    'avgProfitRate': round(avg_profit_rate, 2),
                    'maxDailyProfit': max_profit,
                    'maxProfitRate': round(max_profit_rate, 2),
                    'maxDailyDate': max_date,
                    'minDailyProfit': min_profit,
                    'minProfitRate': round(min_profit_rate, 2),
                    'minDailyDate': min_date,
                    'totalWithdraw': total_withdraw,
                    'totalDeposit': total_deposit,
                    'tradingDays': len(daily_data),
                    'baseCapital': 300
                }
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/okx-profit-analysis')
def okx_profit_analysis_page():
    """æ¯æ—¥åˆ©æ¶¦åˆ†æé¡µé¢"""
    from flask import make_response
    response = make_response(render_template('okx_profit_analysis.html'))
    # å¼ºåˆ¶ç¦ç”¨ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response
    
@app.route('/okx-profit-analysis-v2')
def okx_profit_analysis_v2_page():
    """æ¯æ—¥åˆ©æ¶¦åˆ†æé¡µé¢ V2 - ç®€åŒ–ç‰ˆæœ¬"""
    from flask import make_response
    response = make_response(render_template('okx_profit_analysis_v2.html'))
    # å¼ºåˆ¶ç¦ç”¨ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/okx-profit-analysis-v4')
def okx_profit_analysis_v4_page():
    """æ¯æ—¥åˆ©æ¶¦åˆ†æé¡µé¢ V4 - æµ‹è¯•ç‰ˆæœ¬(ä¿®å¤è½¬å…¥/è½¬å‡ºæ˜¾ç¤º)"""
    from flask import make_response
    response = make_response(render_template('okx_profit_analysis_v4.html'))
    # å¼ºåˆ¶ç¦ç”¨ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

@app.route('/okx-profit-analysis-v5')
def okx_profit_analysis_v5_page():
    """æ¯æ—¥åˆ©æ¶¦åˆ†æé¡µé¢ V5 - æœ€ç»ˆç‰ˆæœ¬(ä¿®å¤æ‰€æœ‰é—®é¢˜)"""
    from flask import make_response
    response = make_response(render_template('okx_profit_analysis_v5.html'))
    # å¼ºåˆ¶ç¦ç”¨ç¼“å­˜
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response


@app.route('/api/okx-trading/profit-notes', methods=['GET', 'POST', 'DELETE'])
def manage_profit_notes():
    """ç®¡ç†æ¯æ—¥åˆ©æ¶¦å¤‡æ³¨
    
    GET: è·å–æŒ‡å®šè´¦æˆ·å’Œæ—¥æœŸèŒƒå›´çš„å¤‡æ³¨
    POST: ä¿å­˜æˆ–æ›´æ–°å¤‡æ³¨
    DELETE: åˆ é™¤å¤‡æ³¨
    """
    import os
    import json
    from datetime import datetime
    
    # å¤‡æ³¨å­˜å‚¨ç›®å½•
    notes_dir = '/home/user/webapp/data/profit_notes'
    os.makedirs(notes_dir, exist_ok=True)
    
    try:
        if request.method == 'GET':
            # è·å–å¤‡æ³¨
            account_id = request.args.get('account_id')
            start_date = request.args.get('start_date')
            end_date = request.args.get('end_date')
            
            if not account_id:
                return jsonify({'success': False, 'error': 'ç¼ºå°‘è´¦æˆ·ID'})
            
            # è¯»å–è¯¥è´¦æˆ·çš„å¤‡æ³¨æ–‡ä»¶
            notes_file = os.path.join(notes_dir, f'{account_id}_notes.jsonl')
            notes = []
            
            if os.path.exists(notes_file):
                with open(notes_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            note = json.loads(line.strip())
                            # å¦‚æœæŒ‡å®šäº†æ—¥æœŸèŒƒå›´,è¿›è¡Œè¿‡æ»¤
                            if start_date and end_date:
                                if start_date <= note['date'] <= end_date:
                                    notes.append(note)
                            else:
                                notes.append(note)
            
            return jsonify({'success': True, 'notes': notes})
        
        elif request.method == 'POST':
            # ä¿å­˜æˆ–æ›´æ–°å¤‡æ³¨
            data = request.get_json()
            account_id = data.get('account_id')
            date = data.get('date')
            note_text = data.get('note', '').strip()
            
            if not account_id or not date:
                return jsonify({'success': False, 'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'})
            
            notes_file = os.path.join(notes_dir, f'{account_id}_notes.jsonl')
            
            # åˆ›å»ºæ–°å¤‡æ³¨å¯¹è±¡
            new_note = {
                'account_id': account_id,
                'date': date,
                'note': note_text,
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            # è¯»å–ç°æœ‰å¤‡æ³¨
            existing_notes = []
            updated = False
            
            if os.path.exists(notes_file):
                with open(notes_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            note = json.loads(line.strip())
                            if note['account_id'] == account_id and note['date'] == date:
                                # æ›´æ–°ç°æœ‰å¤‡æ³¨
                                note['note'] = note_text
                                note['updated_at'] = datetime.now().isoformat()
                                existing_notes.append(note)
                                updated = True
                            else:
                                existing_notes.append(note)
            
            # å¦‚æœæ˜¯æ–°å¤‡æ³¨,æ·»åŠ åˆ°åˆ—è¡¨
            if not updated:
                existing_notes.append(new_note)
            
            # å†™å›æ–‡ä»¶
            with open(notes_file, 'w', encoding='utf-8') as f:
                for note in existing_notes:
                    f.write(json.dumps(note, ensure_ascii=False) + '\n')
            
            return jsonify({'success': True, 'message': 'å¤‡æ³¨ä¿å­˜æˆåŠŸ', 'note': new_note})
        
        elif request.method == 'DELETE':
            # åˆ é™¤å¤‡æ³¨
            data = request.get_json()
            account_id = data.get('account_id')
            date = data.get('date')
            
            if not account_id or not date:
                return jsonify({'success': False, 'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'})
            
            notes_file = os.path.join(notes_dir, f'{account_id}_notes.jsonl')
            
            if not os.path.exists(notes_file):
                return jsonify({'success': True, 'message': 'å¤‡æ³¨ä¸å­˜åœ¨'})
            
            # è¯»å–å¹¶è¿‡æ»¤æ‰è¦åˆ é™¤çš„å¤‡æ³¨
            remaining_notes = []
            with open(notes_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        note = json.loads(line.strip())
                        if not (note['account_id'] == account_id and note['date'] == date):
                            remaining_notes.append(note)
            
            # å†™å›æ–‡ä»¶
            with open(notes_file, 'w', encoding='utf-8') as f:
                for note in remaining_notes:
                    f.write(json.dumps(note, ensure_ascii=False) + '\n')
            
            return jsonify({'success': True, 'message': 'å¤‡æ³¨åˆ é™¤æˆåŠŸ'})
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/okx-trading/account-limit', methods=['GET'])
def get_account_limit():
    """è·å–è´¦æˆ·ä»“ä½é™é¢ä¿¡æ¯
    
    è§„åˆ™:
    - åˆå§‹é™é¢: 300 USDT
    - æ¯æ»¡30å¤©å¢åŠ : 300 USDT
    - è´¦æˆ·ä»é…ç½®çš„å¼€å§‹æ—¥æœŸè®¡ç®—
    """
    try:
        from datetime import datetime, timedelta
        import json
        import os
        
        account_name = request.args.get('account_name', 'ä¸»è´¦æˆ·')
        
        # è´¦æˆ·é…ç½®æ–‡ä»¶è·¯å¾„
        config_file = '/home/user/webapp/okx_account_limits.json'
        
        # è¯»å–æˆ–åˆå§‹åŒ–è´¦æˆ·é…ç½®
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                accounts_config = json.load(f)
        else:
            # é»˜è®¤é…ç½®
            accounts_config = {
                'ä¸»è´¦æˆ·': {
                    'start_date': '2025-01-01',  # é»˜è®¤å¼€å§‹æ—¥æœŸ
                    'base_limit': 300,
                    'increment_days': 30,
                    'increment_amount': 300
                },
                'POIT (å­è´¦æˆ·)': {
                    'start_date': '2025-01-01',
                    'base_limit': 300,
                    'increment_days': 30,
                    'increment_amount': 300
                }
            }
            # ä¿å­˜é»˜è®¤é…ç½®
            os.makedirs(os.path.dirname(config_file), exist_ok=True)
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(accounts_config, f, ensure_ascii=False, indent=2)
        
        # è·å–è´¦æˆ·é…ç½®
        if account_name not in accounts_config:
            # å¦‚æœè´¦æˆ·ä¸å­˜åœ¨,ä½¿ç”¨é»˜è®¤é…ç½®
            accounts_config[account_name] = {
                'start_date': datetime.now().strftime('%Y-%m-%d'),
                'base_limit': 300,
                'increment_days': 30,
                'increment_amount': 300
            }
            # ä¿å­˜æ–°è´¦æˆ·é…ç½®
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(accounts_config, f, ensure_ascii=False, indent=2)
        
        config = accounts_config[account_name]
        
        # è®¡ç®—é™é¢
        start_date = datetime.strptime(config['start_date'], '%Y-%m-%d')
        today = datetime.now()
        days_passed = (today - start_date).days
        
        # è®¡ç®—å·²å®Œæˆçš„å‘¨æœŸæ•°(æ¯30å¤©ä¸€ä¸ªå‘¨æœŸ)
        completed_periods = days_passed // config['increment_days']
        
        # å½“å‰æœ€å¤§é™é¢ = åŸºç¡€é™é¢ + (å®Œæˆå‘¨æœŸæ•° Ã— å¢é‡)
        current_max_limit = config['base_limit'] + (completed_periods * config['increment_amount'])
        
        # è®¡ç®—ä¸‹æ¬¡å¢åŠ æ—¥æœŸ
        next_increase_date = start_date + timedelta(days=(completed_periods + 1) * config['increment_days'])
        days_until_next_increase = (next_increase_date - today).days
        
        return jsonify({
            'success': True,
            'data': {
                'account_name': account_name,
                'start_date': config['start_date'],
                'days_passed': days_passed,
                'current_max_limit': current_max_limit,
                'next_increase_date': next_increase_date.strftime('%Y-%m-%d'),
                'days_until_next_increase': days_until_next_increase,
                'base_limit': config['base_limit'],
                'increment_days': config['increment_days'],
                'increment_amount': config['increment_amount'],
                'completed_periods': completed_periods
            }
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


# ==================== 27å¸æ¶¨è·Œå¹…è¿½è¸ªç³»ç»Ÿ API ====================

@app.route('/api/coin-change-tracker/latest', methods=['GET'])
def get_coin_change_latest():
    """è·å–æœ€æ–°çš„27å¸æ¶¨è·Œå¹…æ•°æ®"""
    try:
        from datetime import datetime, timezone, timedelta
        from pathlib import Path
        
        data_dir = Path('/home/user/webapp/data/coin_change_tracker')
        if not data_dir.exists():
            return jsonify({
                'success': False,
                'error': 'æ•°æ®ç›®å½•ä¸å­˜åœ¨'
            })
        
        # è·å–å½“å‰æ—¥æœŸ
        beijing_time = datetime.now(timezone(timedelta(hours=8)))
        date_str = beijing_time.strftime('%Y%m%d')
        
        # è¯»å–ä»Šå¤©çš„æ•°æ®æ–‡ä»¶
        data_file = data_dir / f'coin_change_{date_str}.jsonl'
        
        if not data_file.exists():
            return jsonify({
                'success': False,
                'error': f'ä»Šå¤©çš„æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {date_str}'
            })
        
        # è¯»å–æœ€åä¸€æ¡è®°å½•
        with open(data_file, 'r') as f:
            lines = f.readlines()
            if lines:
                latest = json.loads(lines[-1].strip())
                return jsonify({
                    'success': True,
                    'data': latest
                })
            else:
                return jsonify({
                    'success': False,
                    'error': 'æ•°æ®æ–‡ä»¶ä¸ºç©º'
                })
                
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/coin-change-tracker/history', methods=['GET'])
def get_coin_change_history():
    """è·å–27å¸æ¶¨è·Œå¹…å†å²æ•°æ®"""
    try:
        from datetime import datetime, timezone, timedelta
        from pathlib import Path
        
        # è·å–å‚æ•°
        date_str = request.args.get('date')  # YYYY-MM-DD æˆ– YYYYMMDD
        limit = int(request.args.get('limit', 1440))  # é»˜è®¤1å¤©çš„æ•°æ®(1440åˆ†é’Ÿ)
        
        data_dir = Path('/home/user/webapp/data/coin_change_tracker')
        if not data_dir.exists():
            return jsonify({
                'success': False,
                'error': 'æ•°æ®ç›®å½•ä¸å­˜åœ¨'
            })
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸ,ä½¿ç”¨ä»Šå¤©
        if not date_str:
            beijing_time = datetime.now(timezone(timedelta(hours=8)))
            file_date_str = beijing_time.strftime('%Y%m%d')
        else:
            # æ”¯æŒä¸¤ç§æ ¼å¼:YYYY-MM-DD æˆ– YYYYMMDD
            if '-' in date_str:
                # è½¬æ¢ YYYY-MM-DD ä¸º YYYYMMDD
                file_date_str = date_str.replace('-', '')
            else:
                file_date_str = date_str
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        data_file = data_dir / f'coin_change_{file_date_str}.jsonl'
        
        if not data_file.exists():
            return jsonify({
                'success': False,
                'error': f'æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_date_str}'
            })
        
        # è¯»å–æ•°æ®
        records = []
        with open(data_file, 'r') as f:
            lines = f.readlines()
            # å–æœ€ålimitæ¡
            for line in lines[-limit:]:
                if line.strip():
                    records.append(json.loads(line.strip()))
        
        return jsonify({
            'success': True,
            'date': file_date_str,
            'count': len(records),
            'data': records
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/coin-change-tracker/baseline', methods=['GET'])
def get_coin_change_baseline():
    """è·å–å½“å¤©çš„åŸºå‡†ä»·"""
    try:
        from datetime import datetime, timezone, timedelta
        from pathlib import Path
        
        # è·å–å‚æ•°
        date_str = request.args.get('date')
        
        data_dir = Path('/home/user/webapp/data/coin_change_tracker')
        if not data_dir.exists():
            return jsonify({
                'success': False,
                'error': 'æ•°æ®ç›®å½•ä¸å­˜åœ¨'
            })
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸ,ä½¿ç”¨ä»Šå¤©
        if not date_str:
            beijing_time = datetime.now(timezone(timedelta(hours=8)))
            date_str = beijing_time.strftime('%Y%m%d')
        
        # è¯»å–åŸºå‡†ä»·æ–‡ä»¶
        baseline_file = data_dir / f'baseline_{date_str}.json'
        
        if not baseline_file.exists():
            return jsonify({
                'success': False,
                'error': f'åŸºå‡†ä»·æ–‡ä»¶ä¸å­˜åœ¨: {date_str}'
            })
        
        with open(baseline_file, 'r') as f:
            baseline_data = json.load(f)
        
        return jsonify({
            'success': True,
            'data': baseline_data
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/coin-change-tracker/reset-baseline', methods=['POST'])
def reset_coin_change_baseline():
    """æ‰‹åŠ¨é‡ç½®åŸºå‡†ä»·(ä½¿ç”¨å½“å‰ä»·æ ¼)"""
    try:
        from datetime import datetime, timezone, timedelta
        from pathlib import Path
        import requests
        
        # è·å–å½“å‰æ—¶é—´
        beijing_time = datetime.now(timezone(timedelta(hours=8)))
        date_str = beijing_time.strftime('%Y%m%d')
        
        # è·å–å½“å‰å¸ä»·
        symbols = [
            'BTC-USDT-SWAP', 'ETH-USDT-SWAP', 'XRP-USDT-SWAP',
            'BNB-USDT-SWAP', 'SOL-USDT-SWAP', 'LTC-USDT-SWAP',
            'DOGE-USDT-SWAP', 'SUI-USDT-SWAP', 'TRX-USDT-SWAP',
            'TON-USDT-SWAP', 'ETC-USDT-SWAP', 'BCH-USDT-SWAP',
            'HBAR-USDT-SWAP', 'XLM-USDT-SWAP', 'FIL-USDT-SWAP',
            'LINK-USDT-SWAP', 'CRO-USDT-SWAP', 'DOT-USDT-SWAP',
            'AAVE-USDT-SWAP', 'UNI-USDT-SWAP', 'NEAR-USDT-SWAP',
            'APT-USDT-SWAP', 'CFX-USDT-SWAP', 'CRV-USDT-SWAP',
            'STX-USDT-SWAP', 'LDO-USDT-SWAP', 'TAO-USDT-SWAP'
        ]
        
        # ä»OKXè·å–å½“å‰ä»·æ ¼
        url = 'https://www.okx.com/api/v5/market/tickers?instType=SWAP'
        response = requests.get(url, timeout=10)
        data = response.json()
        
        if data.get('code') != '0':
            return jsonify({
                'success': False,
                'error': f"è·å–è¡Œæƒ…å¤±è´¥: {data.get('msg')}"
            })
        
        prices = {}
        for ticker in data.get('data', []):
            inst_id = ticker.get('instId')
            if inst_id in symbols:
                prices[inst_id] = float(ticker.get('last', 0))
        
        if len(prices) < 27:
            return jsonify({
                'success': False,
                'error': f"è·å–å¸ä»·ä¸å®Œæ•´,åªè·å–åˆ°{len(prices)}ä¸ª"
            })
        
        # ä¿å­˜åŸºå‡†ä»·
        data_dir = Path('/home/user/webapp/data/coin_change_tracker')
        data_dir.mkdir(parents=True, exist_ok=True)
        baseline_file = data_dir / f'baseline_{date_str}.json'
        
        baseline_data = {
            'date': date_str,
            'timestamp': beijing_time.isoformat(),
            'prices': prices,
            'note': 'æ‰‹åŠ¨é‡ç½®'
        }
        
        with open(baseline_file, 'w') as f:
            json.dump(baseline_data, f, indent=2)
        
        return jsonify({
            'success': True,
            'message': 'åŸºå‡†ä»·å·²é‡ç½®',
            'date': date_str,
            'timestamp': beijing_time.isoformat(),
            'count': len(prices)
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


# ==================== æ•°æ®é‡‡é›†å¥åº·ç›‘æ§ ====================
@app.route('/data-health-monitor')
def data_health_monitor_page():
    """æ•°æ®é‡‡é›†å¥åº·ç›‘æ§é¡µé¢"""
    response = make_response(render_template('data_health_monitor.html'))
    response.headers['Cache-Control'] = 'no-store, no-cache, must-revalidate, post-check=0, pre-check=0, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    return response

@app.route('/api/data-health-monitor/status')
def data_health_monitor_status():
    """è·å–æ‰€æœ‰ç›‘æ§å™¨çš„çŠ¶æ€"""
    try:
        import json
        from pathlib import Path
        
        state_file = Path('/home/user/webapp/data/data_health_monitor_state.json')
        
        if not state_file.exists():
            return jsonify({
                'stats': {
                    'total': 0,
                    'healthy': 0,
                    'unhealthy': 0,
                    'today_restarts': 0
                },
                'monitors': []
            })
        
        with open(state_file, 'r', encoding='utf-8') as f:
            state_data = json.load(f)
        
        # ç»Ÿè®¡
        total = len(state_data)
        healthy = sum(1 for s in state_data.values() if s.get('status') == 'healthy')
        unhealthy = total - healthy
        
        # è®¡ç®—ä»Šæ—¥é‡å¯æ¬¡æ•°
        today = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d')
        today_restarts = 0
        for monitor_state in state_data.values():
            last_restart = monitor_state.get('last_restart_time', '')
            if last_restart.startswith(today):
                today_restarts += 1
        
        # æ„å»ºç›‘æ§å™¨åˆ—è¡¨
        monitors = []
        monitor_configs = {
            '27å¸æ¶¨è·Œå¹…è¿½è¸ª': 'coin-change-tracker',
            '1å°æ—¶çˆ†ä»“é‡‘é¢': 'liquidation-1h-collector',
            'ææ…Œæ¸…æ´—æŒ‡æ•°': 'panic-collector',
            'é”šç‚¹ç›ˆåˆ©ç»Ÿè®¡': 'anchor-profit-monitor',
            'é€ƒé¡¶ä¿¡å·ç»Ÿè®¡': 'escape-signal-calculator',
            'æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ': 'support-resistance-collector',
            'SARæ–œç‡ç³»ç»Ÿ': 'sar-jsonl-collector',
            'Google Driveç›‘æ§': 'gdrive-detector',
            'SARåå‘ç»Ÿè®¡': 'sar-bias-stats-collector',
            'é€æ˜æ ‡ç­¾å¿«ç…§': 'gdrive-detector',
            'é‡å¤§äº‹ä»¶ç›‘æ§ç³»ç»Ÿ': 'major-events-monitor'
        }
        
        for name, pm2_name in monitor_configs.items():
            monitor_state = state_data.get(name, {})
            monitors.append({
                'name': name,
                'pm2_name': pm2_name,
                'status': monitor_state.get('status', 'unknown'),
                'delay_minutes': monitor_state.get('delay_minutes'),
                'pm2_status': monitor_state.get('pm2_status'),
                'consecutive_failures': monitor_state.get('consecutive_failures', 0),
                'last_check_time': monitor_state.get('last_check_time', ''),
                'last_restart_time': monitor_state.get('last_restart_time', '')
            })
        
        return jsonify({
            'stats': {
                'total': total,
                'healthy': healthy,
                'unhealthy': unhealthy,
                'today_restarts': today_restarts
            },
            'monitors': monitors
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/data-health-monitor/logs')
def data_health_monitor_logs():
    """è·å–æœ€è¿‘çš„ç›‘æ§æ—¥å¿—"""
    try:
        from pathlib import Path
        
        log_file = Path('/home/user/webapp/logs/data_health_monitor.log')
        limit = request.args.get('limit', 50, type=int)
        
        if not log_file.exists():
            return jsonify({'logs': []})
        
        # è¯»å–æœ€åNè¡Œ
        with open(log_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # è§£ææ—¥å¿—
        logs = []
        for line in lines[-limit:]:
            line = line.strip()
            if not line:
                continue
            
            # å°è¯•è§£ææ—¥å¿—æ ¼å¼: 2026-02-01 01:36:53,566 [INFO] message
            import re
            match = re.match(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) \[(\w+)\] (.+)', line)
            if match:
                timestamp, level, message = match.groups()
                logs.append({
                    'timestamp': timestamp,
                    'level': level.lower(),
                    'message': message
                })
            else:
                logs.append({
                    'timestamp': '',
                    'level': 'info',
                    'message': line
                })
        
        return jsonify({'logs': logs})
    
    except Exception as e:
        import traceback
        return jsonify({
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/data-health-monitor/restart', methods=['POST'])
def data_health_monitor_restart():
    """æ‰‹åŠ¨é‡å¯æœåŠ¡"""
    try:
        data = request.get_json()
        pm2_name = data.get('pm2_name')
        
        if not pm2_name:
            return jsonify({'success': False, 'error': 'ç¼ºå°‘pm2_nameå‚æ•°'}), 400
        
        import subprocess
        result = subprocess.run(
            ['pm2', 'restart', pm2_name],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode == 0:
            return jsonify({'success': True, 'message': f'æœåŠ¡ {pm2_name} å·²é‡å¯'})
        else:
            return jsonify({'success': False, 'error': result.stderr}), 500
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/data-health-monitor/service-logs')
def data_health_monitor_service_logs():
    """æŸ¥çœ‹ç‰¹å®šæœåŠ¡çš„æ—¥å¿—"""
    try:
        pm2_name = request.args.get('pm2_name')
        if not pm2_name:
            return "ç¼ºå°‘pm2_nameå‚æ•°", 400
        
        import subprocess
        result = subprocess.run(
            ['pm2', 'logs', pm2_name, '--nostream', '--lines', '100'],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        return f"<pre>{result.stdout}\n{result.stderr}</pre>"
    
    except Exception as e:
        return f"<pre>è·å–æ—¥å¿—å¤±è´¥: {str(e)}</pre>", 500

# ==================== ä¸»å‰¯ç³»ç»Ÿç®¡ç† API ====================

@app.route('/api/system-role/config', methods=['GET'])
def api_system_role_config_get():
    """è·å–ç³»ç»Ÿè§’è‰²é…ç½®"""
    try:
        config_file = '/home/user/webapp/configs/system_role_config.json'
        
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        else:
            # è¿”å›é»˜è®¤é…ç½®
            config = {
                "current_role": "primary",
                "telegram_enabled": True,
                "primary_system": {
                    "url": "",
                    "name": "ä¸»ç³»ç»Ÿ",
                    "enabled": True,
                    "last_check": None,
                    "last_success": None,
                    "consecutive_failures": 0,
                    "status": "unknown"
                },
                "secondary_systems": [
                    {
                        "url": "",
                        "name": f"å‰¯ç³»ç»Ÿ{i}",
                        "enabled": False,
                        "last_check": None,
                        "last_success": None,
                        "consecutive_failures": 0,
                        "status": "unknown"
                    } for i in range(1, 4)
                ],
                "health_check": {
                    "interval_seconds": 180,
                    "timeout_seconds": 30,
                    "failure_threshold": 2,
                    "notify_on_failure": True
                },
                "last_update": None,
                "last_notification": None
            }
        
        return jsonify({
            'success': True,
            'data': config
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/system-role/config', methods=['POST'])
def api_system_role_config_post():
    """æ›´æ–°ç³»ç»Ÿè§’è‰²é…ç½®"""
    try:
        config_file = '/home/user/webapp/configs/system_role_config.json'
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘é…ç½®æ•°æ®'
            }), 400
        
        # æ·»åŠ æ›´æ–°æ—¶é—´
        data['last_update'] = datetime.now(BEIJING_TZ).isoformat()
        
        # ä¿å­˜é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': 'é…ç½®å·²æ›´æ–°',
            'data': data
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/system-role/toggle', methods=['POST'])
def api_system_role_toggle():
    """åˆ‡æ¢ç³»ç»Ÿè§’è‰²(ä¸»ç³»ç»Ÿ/å‰¯ç³»ç»Ÿ)"""
    try:
        config_file = '/home/user/webapp/configs/system_role_config.json'
        data = request.get_json()
        
        new_role = data.get('role')  # 'primary' or 'secondary'
        
        if new_role not in ['primary', 'secondary']:
            return jsonify({
                'success': False,
                'error': 'æ— æ•ˆçš„è§’è‰²ç±»å‹,å¿…é¡»æ˜¯ primary æˆ– secondary'
            }), 400
        
        # è¯»å–é…ç½®
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        else:
            return jsonify({
                'success': False,
                'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        # æ›´æ–°è§’è‰²
        old_role = config.get('current_role', 'primary')
        config['current_role'] = new_role
        
        # æ ¹æ®è§’è‰²è®¾ç½®TGæ¶ˆæ¯å¼€å…³
        config['telegram_enabled'] = (new_role == 'primary')
        
        config['last_update'] = datetime.now(BEIJING_TZ).isoformat()
        
        # ä¿å­˜é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        return jsonify({
            'success': True,
            'message': f'ç³»ç»Ÿè§’è‰²å·²ä» {old_role} åˆ‡æ¢åˆ° {new_role}',
            'data': {
                'old_role': old_role,
                'new_role': new_role,
                'telegram_enabled': config['telegram_enabled']
            }
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/system-role/health-status', methods=['GET'])
def api_system_role_health_status():
    """è·å–æ‰€æœ‰ç³»ç»Ÿçš„å¥åº·çŠ¶æ€"""
    try:
        config_file = '/home/user/webapp/configs/system_role_config.json'
        
        if not os.path.exists(config_file):
            return jsonify({
                'success': False,
                'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'
            }), 404
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # æå–å¥åº·çŠ¶æ€ä¿¡æ¯
        primary = config.get('primary_system', {})
        secondaries = config.get('secondary_systems', [])
        
        health_data = {
            'current_role': config.get('current_role', 'unknown'),
            'telegram_enabled': config.get('telegram_enabled', False),
            'primary_system': {
                'name': primary.get('name', 'ä¸»ç³»ç»Ÿ'),
                'url': primary.get('url', ''),
                'enabled': primary.get('enabled', False),
                'status': primary.get('status', 'unknown'),
                'last_check': primary.get('last_check'),
                'last_success': primary.get('last_success'),
                'consecutive_failures': primary.get('consecutive_failures', 0)
            },
            'secondary_systems': [
                {
                    'name': s.get('name', f'å‰¯ç³»ç»Ÿ{i+1}'),
                    'url': s.get('url', ''),
                    'enabled': s.get('enabled', False),
                    'status': s.get('status', 'unknown'),
                    'last_check': s.get('last_check'),
                    'last_success': s.get('last_success'),
                    'consecutive_failures': s.get('consecutive_failures', 0)
                }
                for i, s in enumerate(secondaries)
            ],
            'last_notification': config.get('last_notification')
        }
        
        return jsonify({
            'success': True,
            'data': health_data
        })
    
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

# ==================== Telegramé€šçŸ¥é…ç½®ç®¡ç† ====================

@app.route('/telegram-notification-settings')
def telegram_notification_settings_page():
    """Telegramé€šçŸ¥è®¾ç½®é¡µé¢"""
    return render_template('telegram_notification_settings.html')

@app.route('/api/telegram/notification-config', methods=['GET'])
def get_telegram_notification_config():
    """è·å–Telegramé€šçŸ¥é…ç½®"""
    try:
        config_file = os.path.join(os.path.dirname(__file__), 'telegram_notification_config.json')
        
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
        else:
            # é»˜è®¤é…ç½®
            config = {
                "major_events": {},
                "extreme_tracking": {"enabled": True, "name": "æå€¼è¿½è¸ªç³»ç»Ÿ"},
                "support_resistance": {"enabled": True, "name": "æ”¯æ’‘å‹åŠ›çº¿ç³»ç»Ÿ"},
                "alert_system": {"enabled": True, "name": "è®¡æ¬¡é¢„è­¦ç³»ç»Ÿ"},
                "trading_signals": {"enabled": True, "name": "äº¤æ˜“ä¿¡å·ç³»ç»Ÿ"}
            }
        
        return jsonify({
            'success': True,
            'data': config
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/telegram/notification-config', methods=['POST'])
def update_telegram_notification_config():
    """æ›´æ–°Telegramé€šçŸ¥é…ç½®"""
    try:
        config = request.json
        config_file = os.path.join(os.path.dirname(__file__), 'telegram_notification_config.json')
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'message': 'é…ç½®å·²æ›´æ–°'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/telegram/send-alert', methods=['POST'])
def send_telegram_alert():
    """å‘é€Telegramé¢„è­¦é€šçŸ¥"""
    try:
        data = request.json
        message = data.get('message', '')
        alert_type = data.get('type', 'general')
        
        if not message:
            return jsonify({
                'success': False,
                'error': 'æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º'
            }), 400
        
        # è¯»å–Telegramé…ç½®
        config_file = os.path.join(os.path.dirname(__file__), 'telegram_notification_config.json')
        
        if not os.path.exists(config_file):
            return jsonify({
                'success': False,
                'error': 'Telegramé…ç½®æ–‡ä»¶ä¸å­˜åœ¨,è¯·å…ˆé…ç½®Telegram Bot'
            }), 404
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        bot_token = config.get('bot_token')
        chat_id = config.get('chat_id')
        
        if not bot_token or not chat_id:
            return jsonify({
                'success': False,
                'error': 'Telegramé…ç½®ä¸å®Œæ•´'
            }), 400
        
        # å‘é€æ¶ˆæ¯åˆ°Telegram
        import requests as req
        telegram_api_url = f'https://api.telegram.org/bot{bot_token}/sendMessage'
        
        payload = {
            'chat_id': chat_id,
            'text': message,
            'parse_mode': 'HTML'
        }
        
        response = req.post(telegram_api_url, json=payload, timeout=10)
        
        if response.status_code == 200:
            return jsonify({
                'success': True,
                'message': 'é€šçŸ¥å·²å‘é€',
                'type': alert_type
            })
        else:
            return jsonify({
                'success': False,
                'error': f'Telegram APIé”™è¯¯: {response.text}'
            }), 500
            
    except Exception as e:
        print(f"å‘é€Telegramé€šçŸ¥å¤±è´¥: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/coin-tracker/alert-settings', methods=['GET', 'POST'])
def coin_tracker_alert_settings():
    """è·å–æˆ–ä¿å­˜å¸ç§è¿½è¸ªé¢„è­¦è®¾ç½®"""
    settings_file = os.path.join(os.path.dirname(__file__), 'data', 'coin_alert_settings', 'settings.jsonl')
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(settings_file), exist_ok=True)
    
    if request.method == 'GET':
        # è¯»å–æœ€æ–°çš„è®¾ç½®
        try:
            if os.path.exists(settings_file):
                with open(settings_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        # è¿”å›æœ€åä¸€è¡Œ(æœ€æ–°çš„è®¾ç½®)
                        latest = json.loads(lines[-1])
                        return jsonify({
                            'success': True,
                            'settings': latest
                        })
            
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©º,è¿”å›é»˜è®¤è®¾ç½®
            return jsonify({
                'success': True,
                'settings': {
                    'upperThreshold': 5,
                    'lowerThreshold': -5,
                    'upperEnabled': False,
                    'lowerEnabled': False,
                    'tgEnabled': False,
                    'timestamp': datetime.now().isoformat()
                }
            })
        except Exception as e:
            return jsonify({
                'success': False,
                'error': str(e)
            }), 500
    
    elif request.method == 'POST':
        # ä¿å­˜æ–°çš„è®¾ç½®
        try:
            settings = request.json
            
            # æ·»åŠ æ—¶é—´æˆ³
            settings['timestamp'] = datetime.now().isoformat()
            
            # è¿½åŠ åˆ°JSONLæ–‡ä»¶
            with open(settings_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(settings, ensure_ascii=False) + '\n')
            
            print(f"âœ… é¢„è­¦è®¾ç½®å·²ä¿å­˜: {settings}")
            
            return jsonify({
                'success': True,
                'message': 'è®¾ç½®å·²ä¿å­˜',
                'settings': settings
            })
        except Exception as e:
            print(f"âŒ ä¿å­˜é¢„è­¦è®¾ç½®å¤±è´¥: {e}")
            return jsonify({
                'success': False,
                'error': str(e)
            }), 500

@app.route('/system-config')
def system_config_page():
    """ç³»ç»Ÿé…ç½®é¡µé¢"""
    return render_template('system_config.html')

@app.route('/alert-test')
def alert_test_page():
    """é¢„è­¦è®¾ç½®æµ‹è¯•é¡µé¢"""
    return render_template('alert_test.html')


# ==================== Flask App å¯åŠ¨å…¥å£ ====================
# ==========================================
# æ”¯æ’‘å‹åŠ›ç³»ç»Ÿ v2.0 APIè·¯ç”±
# ==========================================
try:
    from core.api_routes import register_sr_v2_routes
    register_sr_v2_routes(app)
    print("âœ… æ”¯æ’‘å‹åŠ›ç³»ç»Ÿ v2.0 APIå·²åŠ è½½")
except Exception as e:
    print(f"âš ï¸  æ”¯æ’‘å‹åŠ›ç³»ç»Ÿ v2.0 APIåŠ è½½å¤±è´¥: {e}")

# ==========================================
# ä»·æ ¼ä½ç½®é¢„è­¦ç³»ç»Ÿ v2.0 APIè·¯ç”±
# ==========================================
# ä»·æ ¼ä½ç½®é¢„è­¦ç³»ç»Ÿ v2.0 APIè·¯ç”±(å†…è”ç‰ˆæœ¬)
# ==========================================
@app.route('/api/price-position/list')
def api_price_position_list():
    """è·å–æ‰€æœ‰å¸ç§çš„ä»·æ ¼ä½ç½®åˆ—è¡¨"""
    try:
        import sqlite3
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT p1.inst_id, p1.snapshot_time, p1.current_price,
                   p1.high_48h, p1.low_48h, p1.position_48h,
                   p1.high_7d, p1.low_7d, p1.position_7d,
                   p1.alert_48h_low, p1.alert_48h_high,
                   p1.alert_7d_low, p1.alert_7d_high
            FROM price_positions p1
            INNER JOIN (
                SELECT inst_id, MAX(snapshot_time) as max_time
                FROM price_positions
                GROUP BY inst_id
            ) p2 ON p1.inst_id = p2.inst_id AND p1.snapshot_time = p2.max_time
            ORDER BY p1.inst_id
        """)
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            symbol_name = row[0].replace('-USDT-SWAP', '')
            data.append({
                'inst_id': row[0],
                'symbol': symbol_name,
                'snapshot_time': row[1],
                'current_price': row[2],
                'high_48h': row[3],
                'low_48h': row[4],
                'position_48h': round(row[5], 1),
                'high_7d': row[6],
                'low_7d': row[7],
                'position_7d': round(row[8], 1),
                'alert_48h_low': bool(row[9]),
                'alert_48h_high': bool(row[10]),
                'alert_7d_low': bool(row[11]),
                'alert_7d_high': bool(row[12]),
            })
        
        return jsonify({'success': True, 'count': len(data), 'data': data})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/signal-timeline/data')
def api_signal_timeline_data():
    """è·å–ä¿¡å·æ—¶é—´çº¿æ•°æ®(æŸä¸€å¤©çš„480æ¡è®°å½•)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        # è·å–æ—¥æœŸå‚æ•°(é»˜è®¤ä»Šå¤©)
        date_str = request.args.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æŸ¥è¯¢è¯¥å¤©çš„æ‰€æœ‰è®°å½•
        cursor.execute("""
            SELECT snapshot_time,
                   support_line_48h, support_line_7d,
                   pressure_line_48h, pressure_line_7d,
                   signal_type, signal_triggered, trigger_reason
            FROM signal_timeline
            WHERE DATE(snapshot_time) = ?
            ORDER BY snapshot_time ASC
        """, (date_str,))
        
        rows = cursor.fetchall()
        conn.close()
        
        timeline = []
        for row in rows:
            timeline.append({
                'time': row[0],
                'support_48h': row[1],
                'support_7d': row[2],
                'pressure_48h': row[3],
                'pressure_7d': row[4],
                'signal_type': row[5],
                'signal_triggered': row[6],
                'trigger_reason': row[7] or '',
            })
        
        return jsonify({
            'success': True,
            'date': date_str,
            'count': len(timeline),
            'data': timeline
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/signal-timeline/stats')
def api_signal_timeline_stats():
    """è·å–ä¿¡å·ç»Ÿè®¡(24hå’Œ2h)"""
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        now = datetime.now()
        time_24h_ago = (now - timedelta(hours=24)).strftime('%Y-%m-%d %H:%M:%S')
        time_2h_ago = (now - timedelta(hours=2)).strftime('%Y-%m-%d %H:%M:%S')
        
        # 24å°æ—¶ç»Ÿè®¡
        cursor.execute("""
            SELECT 
                SUM(CASE WHEN signal_triggered = 1 THEN 1 ELSE 0 END) as buy_24h,
                SUM(CASE WHEN signal_triggered = 2 THEN 1 ELSE 0 END) as sell_24h
            FROM signal_timeline
            WHERE snapshot_time >= ?
        """, (time_24h_ago,))
        row_24h = cursor.fetchone()
        
        # 2å°æ—¶ç»Ÿè®¡
        cursor.execute("""
            SELECT 
                SUM(CASE WHEN signal_triggered = 1 THEN 1 ELSE 0 END) as buy_2h,
                SUM(CASE WHEN signal_triggered = 2 THEN 1 ELSE 0 END) as sell_2h
            FROM signal_timeline
            WHERE snapshot_time >= ?
        """, (time_2h_ago,))
        row_2h = cursor.fetchone()
        
        # æœ€æ–°ä¸€æ¡è®°å½•
        cursor.execute("""
            SELECT snapshot_time, support_line_48h, support_line_7d,
                   pressure_line_48h, pressure_line_7d, signal_type
            FROM signal_timeline
            ORDER BY snapshot_time DESC
            LIMIT 1
        """)
        latest = cursor.fetchone()
        
        conn.close()
        
        return jsonify({
            'success': True,
            'stats_24h': {
                'buy_signals': row_24h[0] or 0,
                'sell_signals': row_24h[1] or 0,
            },
            'stats_2h': {
                'buy_signals': row_2h[0] or 0,
                'sell_signals': row_2h[1] or 0,
            },
            'latest': {
                'time': latest[0] if latest else None,
                'support_48h': latest[1] if latest else 0,
                'support_7d': latest[2] if latest else 0,
                'pressure_48h': latest[3] if latest else 0,
                'pressure_7d': latest[4] if latest else 0,
                'signal_type': latest[5] if latest else 'none',
            } if latest else None
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/escape-stats/data')
def api_escape_stats_data():
    """è·å–é€ƒé¡¶ç»Ÿè®¡æ—¶é—´çº¿æ•°æ®(æŸä¸€å¤©)"""
    try:
        import sqlite3
        from datetime import datetime
        
        date_str = request.args.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT snapshot_time, escape_24h_count, escape_24h_symbols,
                   escape_2h_count, escape_2h_symbols
            FROM escape_stats_timeline
            WHERE DATE(snapshot_time) = ?
            ORDER BY snapshot_time ASC
        """, (date_str,))
        
        rows = cursor.fetchall()
        conn.close()
        
        timeline = []
        for row in rows:
            import json
            timeline.append({
                'time': row[0],
                'escape_24h_count': row[1],
                'escape_24h_symbols': json.loads(row[2]) if row[2] else [],
                'escape_2h_count': row[3],
                'escape_2h_symbols': json.loads(row[4]) if row[4] else [],
            })
        
        return jsonify({
            'success': True,
            'date': date_str,
            'count': len(timeline),
            'data': timeline
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/signal-timeline/jsonl')
def api_signal_timeline_jsonl():
    """è·å–JSONLæ€»æ—¶é—´è½´æ•°æ®(ä»æ•°æ®åº“è¯»å–ï¼Œæ— è®ºæ˜¯å¦è§¦å‘éƒ½æ˜¾ç¤º)"""
    try:
        from datetime import datetime
        import sqlite3
        
        date_str = request.args.get('date', datetime.now().strftime('%Y-%m-%d'))
        
        # ä»æ•°æ®åº“è¯»å–
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„ä¿¡å·æ—¶é—´è½´æ•°æ®
        cursor.execute("""
            SELECT snapshot_time, support_line_48h, support_line_7d,
                   pressure_line_48h, pressure_line_7d, signal_type,
                   signal_triggered, trigger_reason
            FROM signal_timeline
            WHERE DATE(snapshot_time) = ?
            ORDER BY snapshot_time ASC
        """, (date_str,))
        
        rows = cursor.fetchall()
        conn.close()
        
        timeline = []
        for row in rows:
            timeline.append({
                'time': row[0],
                'support_48h': round(row[1], 2) if row[1] else 0,
                'support_7d': round(row[2], 2) if row[2] else 0,
                'pressure_48h': round(row[3], 2) if row[3] else 0,
                'pressure_7d': round(row[4], 2) if row[4] else 0,
                'signal_type': row[5],
                'signal_triggered': row[6],
                'trigger_reason': row[7],
                'detail_data': {}  # å…¼å®¹å‰ç«¯ï¼Œæš‚æ—¶è¿”å›ç©ºå¯¹è±¡
            })
        
        return jsonify({
            'success': True,
            'date': date_str,
            'count': len(timeline),
            'data': timeline
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/price-position/list-detailed')
def api_price_position_list_detailed():
    """è·å–27ä¸ªå¸ç§çš„è¯¦ç»†ä½ç½®æ•°æ®(ç”¨äºè¡¨æ ¼å±•ç¤º)"""
    try:
        import sqlite3
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT p1.inst_id, p1.snapshot_time, p1.current_price,
                   p1.high_48h, p1.low_48h, p1.position_48h,
                   p1.high_7d, p1.low_7d, p1.position_7d,
                   p1.alert_48h_low, p1.alert_48h_high,
                   p1.alert_7d_low, p1.alert_7d_high
            FROM price_positions p1
            INNER JOIN (
                SELECT inst_id, MAX(snapshot_time) as max_time
                FROM price_positions
                GROUP BY inst_id
            ) p2 ON p1.inst_id = p2.inst_id AND p1.snapshot_time = p2.max_time
            ORDER BY p1.inst_id
        """)
        
        rows = cursor.fetchall()
        conn.close()
        
        data = []
        for row in rows:
            symbol_name = row[0].replace('-USDT-SWAP', '')
            
            # è®¡ç®—ä»·æ ¼å˜åŒ–è¶‹åŠ¿(ç®€åŒ–ç‰ˆ)
            price_trend_48h = "up" if row[5] > 50 else "down"
            price_trend_7d = "up" if row[8] > 50 else "down"
            
            data.append({
                'inst_id': row[0],
                'symbol': symbol_name,
                'snapshot_time': row[1],
                'current_price': row[2],
                'high_48h': row[3],
                'low_48h': row[4],
                'position_48h': round(row[5], 1),
                'price_trend_48h': price_trend_48h,
                'high_7d': row[6],
                'low_7d': row[7],
                'position_7d': round(row[8], 1),
                'price_trend_7d': price_trend_7d,
                'alert_48h_low': bool(row[9]),
                'alert_48h_high': bool(row[10]),
                'alert_7d_low': bool(row[11]),
                'alert_7d_high': bool(row[12]),
            })
        
        return jsonify({'success': True, 'count': len(data), 'data': data})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

print("âœ… ä»·æ ¼ä½ç½®é¢„è­¦ç³»ç»Ÿ v2.0 APIå·²åŠ è½½(å†…è”ç‰ˆæœ¬)")

# ==========================================
# é€ƒé¡¶ä¿¡å·ç³»ç»Ÿ v2.0 APIè·¯ç”±
# ==========================================
try:
    from core.escape_api_routes import register_escape_v2_routes
    register_escape_v2_routes(app)
    print("âœ… é€ƒé¡¶ä¿¡å·ç³»ç»Ÿ v2.0 APIå·²åŠ è½½")
except Exception as e:
    print(f"âš ï¸  é€ƒé¡¶ä¿¡å·ç³»ç»Ÿ v2.0 APIåŠ è½½å¤±è´¥: {e}")

@app.route('/api/signal-timeline/available-dates')
def api_available_dates():
    """è·å–æ‰€æœ‰æœ‰æ•°æ®çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        import sqlite3
        db_path = '/home/user/webapp/price_position_v2/config/data/db/price_position.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ä»signal_timelineè¡¨è·å–æ‰€æœ‰æœ‰æ•°æ®çš„æ—¥æœŸ
        cursor.execute("""
            SELECT DISTINCT DATE(snapshot_time) as date, COUNT(*) as count
            FROM signal_timeline
            GROUP BY DATE(snapshot_time)
            ORDER BY date DESC
        """)
        
        rows = cursor.fetchall()
        conn.close()
        
        dates = []
        for row in rows:
            dates.append({
                'date': row[0],
                'count': row[1]
            })
        
        return jsonify({
            'success': True,
            'dates': dates,
            'total': len(dates)
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

# é‡‘èæŒ‡æ•°è·¯ç”±
# ============================================================================

# Financial index routes removed - 2026-02-12
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


# ============================================================================
# é‡‘èæŒ‡æ•°è·¯ç”±


# ============================================================================
# SAR åå¤šåç©ºè¶‹åŠ¿æ•°æ® API
# ============================================================================

@app.route('/api/sar-slope/bias-stats')
def api_sar_bias_stats():
    """è·å–SARåå¤šåç©ºè¶‹åŠ¿ç»Ÿè®¡æ•°æ®ï¼ˆä»é‡‡é›†çš„JSONLæ–‡ä»¶è¯»å–ï¼‰"""
    try:
        page = int(request.args.get('page', 1))
        date_str = request.args.get('date', '')
        
        # åŒ—äº¬æ—¶åŒº
        beijing_tz = pytz.timezone('Asia/Shanghai')
        now = datetime.now(beijing_tz)
        
        # ç¡®å®šè¦æŸ¥è¯¢çš„æ—¥æœŸ
        if date_str:
            try:
                display_date = datetime.strptime(date_str, '%Y-%m-%d').date()
            except:
                return jsonify({'success': False, 'error': 'æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD'}), 400
        else:
            # æ ¹æ® page è®¡ç®—æ—¥æœŸï¼ˆpage 1 = ä»Šå¤©ï¼Œpage 2 = æ˜¨å¤©ï¼Œ...ï¼‰
            display_date = (now - timedelta(days=page - 1)).date()
        
        # æ•°æ®ç›®å½•
        data_dir = Path('/home/user/webapp/data/sar_bias_stats')
        
        # JSONL æ–‡ä»¶è·¯å¾„
        jsonl_file = data_dir / f"bias_stats_{display_date.strftime('%Y%m%d')}.jsonl"
        
        if not jsonl_file.exists():
            return jsonify({
                'success': True,
                'data': [],
                'total': 0,
                'page': page,
                'date': display_date.strftime('%Y-%m-%d'),
                'message': f'æš‚æ—  {display_date} çš„æ•°æ®'
            })
        
        # è¯»å–JSONLæ–‡ä»¶
        all_data = []
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        record = json.loads(line)
                        all_data.append({
                            'timestamp': record['beijing_time'],
                            'bullish_count': record['bullish_count'],
                            'bearish_count': record['bearish_count'],
                            'total_symbols': record['total_monitored'],
                            'bullish_symbols': record.get('bullish_symbols', []),
                            'bearish_symbols': record.get('bearish_symbols', [])
                        })
                    except json.JSONDecodeError:
                        continue
        
        # è®¡ç®—æœ€æ—©å’Œæœ€æ™šæ•°æ®æ—¥æœŸï¼ˆç”¨äºåˆ†é¡µï¼‰
        earliest_file = None
        for file in sorted(data_dir.glob('bias_stats_*.jsonl')):
            earliest_file = file
            break
        
        if earliest_file:
            earliest_date_str = earliest_file.stem.replace('bias_stats_', '')
            earliest_date = datetime.strptime(earliest_date_str, '%Y%m%d').date()
            days_diff = (now.date() - earliest_date).days
            total_pages = max(1, days_diff + 1)
        else:
            total_pages = 1
        
        # æ„å»ºæ—¶é—´èŒƒå›´ä¿¡æ¯
        time_range = {
            'start': None,
            'end': None,
            'date': display_date.strftime('%Y-%m-%d')
        }
        
        if all_data:
            time_range['start'] = all_data[0]['timestamp']
            time_range['end'] = all_data[-1]['timestamp']
        
        return jsonify({
            'success': True,
            'data': all_data,
            'total': len(all_data),
            'page': page,
            'total_pages': total_pages,
            'date': display_date.strftime('%Y-%m-%d'),
            'time_range': time_range,
            'has_prev': page < total_pages,  # ä¿®å¤ï¼šæœ‰æ›´æ—©çš„æ•°æ®ï¼ˆå¯ä»¥ç‚¹"å‰ä¸€å¤©"ï¼‰
            'has_next': page > 1              # ä¿®å¤ï¼šæœ‰æ›´æ–°çš„æ•°æ®ï¼ˆå¯ä»¥ç‚¹"åä¸€å¤©"ï¼‰
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500


# ============================================================================
# Panic ç‹¬ç«‹ç³»ç»Ÿè·¯ç”±
# ============================================================================

@app.route('/panic-standalone')
def panic_standalone():
    """Panic ç‹¬ç«‹ç³»ç»Ÿ - æ‰€æœ‰é€»è¾‘åœ¨å‰ç«¯"""
    return render_template('panic_standalone.html')


@app.route('/panic-paged')
def panic_paged():
    """Panic æŒ‰æ—¥ç¿»é¡µç³»ç»Ÿ - ä¸¤ä¸ªå›¾è¡¨ç‹¬ç«‹ç¿»é¡µ"""
    return render_template('panic_paged.html')


@app.route('/panic-test')
def panic_test():
    """Panic ç¿»é¡µåŠŸèƒ½æµ‹è¯•é¡µé¢ - å…¨æ–°ç‹¬ç«‹ç‰ˆæœ¬"""
    return render_template('panic_test.html')


@app.route('/panic-demo-new')
def panic_demo_new():
    """Panic ç¿»é¡µæ¼”ç¤º - æ–°ç‰ˆæœ¬æµ‹è¯•"""
    return render_template('panic_test.html')


@app.route('/panic-date-picker')
def panic_date_picker():
    """Panic æ—¥æœŸé€‰æ‹©å™¨ç‰ˆæœ¬ - å°æŒ‰é’®+æ—¥æœŸé€‰æ‹©å™¨"""
    return render_template('panic_date_picker.html')


@app.route('/panic-final')
def panic_final():
    """Panic æœ€ç»ˆç‰ˆæœ¬ - å¸¦ç»Ÿè®¡å¡ç‰‡å’Œå®Œæ•´ç³»ç»Ÿè¯´æ˜"""
    return render_template('panic_final.html')

@app.route('/panic-real-api')
def panic_real_api():
    """Panic çœŸå®APIç‰ˆæœ¬ - ç›´æ¥è°ƒç”¨/api/panic-v3/latest"""
    response = make_response(render_template('panic_real_api.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '0'
    return response

# ============================================================================
# Panic V3 è·¯ç”±
# ============================================================================

PANIC_V3_DATA_DIR = Path('/home/user/webapp/panic_v3/data')

def load_panic_daily_data(date_str):
    """
    åŠ è½½æŒ‡å®šæ—¥æœŸçš„Panic V3æ•°æ®
    
    å‚æ•°:
        date_str: YYYYMMDDæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
    
    è¿”å›:
        list: æ•°æ®åˆ—è¡¨
    """
    file_path = PANIC_V3_DATA_DIR / f'panic_{date_str}.jsonl'
    
    if not file_path.exists():
        return []
    
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                try:
                    data.append(json.loads(line))
                except:
                    continue
    
    return data


def load_panic_recent_data(days=7):
    """
    åŠ è½½æœ€è¿‘Nå¤©çš„Panic V3æ•°æ®
    
    å‚æ•°:
        days: å¤©æ•°
    
    è¿”å›:
        list: æ•°æ®åˆ—è¡¨(æŒ‰æ—¶é—´æ’åº)
    """
    all_data = []
    now = datetime.now(pytz.timezone('Asia/Shanghai'))
    
    for i in range(days):
        date = now - timedelta(days=i)
        date_str = date.strftime('%Y%m%d')
        daily_data = load_panic_daily_data(date_str)
        all_data.extend(daily_data)
    
    # æŒ‰æ—¶é—´æˆ³æ’åº
    all_data.sort(key=lambda x: x.get('timestamp', 0))
    
    return all_data


@app.route('/panic-v3')
def panic_v3():
    """Panic V3ä¸»é¡µ"""
    return render_template('panic_v3.html')


@app.route('/api/panic-v3/latest')
def api_panic_v3_latest():
    """è·å–æœ€æ–°ä¸€æ¡Panic V3æ•°æ®"""
    try:
        # åŠ è½½ä»Šå¤©çš„æ•°æ®
        today = datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d')
        data = load_panic_daily_data(today)
        
        if not data:
            # å¦‚æœä»Šå¤©æ²¡æœ‰,å°è¯•æ˜¨å¤©
            yesterday = (datetime.now(pytz.timezone('Asia/Shanghai')) - timedelta(days=1)).strftime('%Y%m%d')
            data = load_panic_daily_data(yesterday)
        
        if not data:
            return jsonify({
                'success': False,
                'message': 'æš‚æ— æ•°æ®'
            })
        
        # è¿”å›æœ€åä¸€æ¡
        latest = data[-1]
        
        return jsonify({
            'success': True,
            'data': latest
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })


@app.route('/api/panic-v3/history/24h')
def api_panic_v3_history_24h():
    """è·å–æœ€è¿‘24å°æ—¶çš„Panic V3æ•°æ®"""
    try:
        # åŠ è½½æœ€è¿‘2å¤©çš„æ•°æ®(ç¡®ä¿è¦†ç›–24å°æ—¶)
        data = load_panic_recent_data(days=2)
        
        if not data:
            return jsonify({
                'success': True,
                'count': 0,
                'data': []
            })
        
        # è¿‡æ»¤æœ€è¿‘24å°æ—¶
        now_ts = int(datetime.now(pytz.timezone('Asia/Shanghai')).timestamp() * 1000)
        cutoff_ts = now_ts - (24 * 60 * 60 * 1000)  # 24å°æ—¶å‰
        
        filtered_data = [d for d in data if d.get('timestamp', 0) >= cutoff_ts]
        
        return jsonify({
            'success': True,
            'count': len(filtered_data),
            'data': filtered_data
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })


@app.route('/api/panic-v3/history/daily')
def api_panic_v3_history_daily():
    """è·å–æŒ‡å®šæ—¥æœŸçš„Panic V3æ•°æ®"""
    try:
        date_str = request.args.get('date', datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y%m%d'))
        data = load_panic_daily_data(date_str)
        
        return jsonify({
            'success': True,
            'date': date_str,
            'count': len(data),
            'data': data
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })


@app.route('/api/panic-v3/history/recent')
def api_panic_v3_history_recent():
    """è·å–æœ€è¿‘Nå¤©çš„Panic V3æ•°æ®"""
    try:
        days = int(request.args.get('days', 7))
        data = load_panic_recent_data(days=days)
        
        return jsonify({
            'success': True,
            'days': days,
            'count': len(data),
            'data': data
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': str(e)
        })


# ============================================================================
# Panic V3 è·¯ç”±ç»“æŸ


# ============================================================================
# Panic Paged V2 è·¯ç”±é›†æˆ
# ============================================================================
sys.path.insert(0, '/home/user/webapp/panic_paged_v2')
from api_routes import register_panic_paged_routes

# æ³¨å†ŒPanic Paged V2è·¯ç”±
register_panic_paged_routes(app)
print("[Panic Paged V2] APIè·¯ç”±å·²æ³¨å†Œ")


@app.route('/api/sar-slope/current-sequence', methods=['GET'])
def get_sar_current_sequence():
    """è·å–æ‰€æœ‰å¸ç§çš„å½“å‰SARåºå·"""
    try:
        import json
        import os
        from datetime import datetime
        import pytz
        
        # SARæ•°æ®ç›®å½•
        data_dir = '/home/user/webapp/data/sar_jsonl'
        
        # 29ä¸ªå¸ç§
        SYMBOLS = [
            'BTC', 'ETH', 'BNB', 'XRP', 'ADA', 'DOGE', 'SOL', 'DOT', 'LTC', 'LINK',
            'HBAR', 'TAO', 'CFX', 'TRX', 'TON', 'NEAR', 'LDO', 'CRO', 'ETC', 'XLM',
            'BCH', 'UNI', 'SUI', 'FIL', 'STX', 'CRV', 'AAVE', 'APT', 'OKB'
        ]
        
        result = {}
        
        for symbol in SYMBOLS:
            jsonl_file = os.path.join(data_dir, f'{symbol}.jsonl')
            
            if not os.path.exists(jsonl_file):
                continue
            
            # è¯»å–æœ€å100è¡Œ(è¶³å¤Ÿæ‰¾åˆ°è½¬æ¢ç‚¹)
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                records = []
                for line in lines[-100:]:
                    if line.strip():
                        try:
                            data = json.loads(line)
                            records.append(data)
                        except:
                            continue
            
            if not records:
                continue
            
            # è·å–æœ€æ–°è®°å½•
            latest = records[-1]
            current_pos = latest['position']
            current_time = latest['beijing_time']
            current_price = latest.get('close', 0)
            current_sar = latest.get('sar', 0)
            
            # è®¡ç®—åºå·:å¾€å‰æ‰¾è½¬æ¢ç‚¹
            sequence = 1
            for i in range(len(records)-2, -1, -1):
                if records[i]['position'] == current_pos:
                    sequence += 1
                else:
                    break
            
            # è®¡ç®—æŒç»­æ—¶é—´(åˆ†é’Ÿ)
            duration_minutes = latest.get('duration_minutes', 0)
            
            result[symbol] = {
                'position': current_pos,  # 'bullish' æˆ– 'bearish'
                'position_cn': 'å¤šå¤´' if current_pos == 'bullish' else 'ç©ºå¤´',
                'sequence': sequence,
                'sequence_label': f"{'å¤šå¤´' if current_pos == 'bullish' else 'ç©ºå¤´'}{sequence:02d}",
                'time': current_time,
                'price': current_price,
                'sar': current_sar,
                'duration_minutes': duration_minutes,
                'sar_position': 'SARåœ¨ä¸‹æ–¹' if current_pos == 'bullish' else 'SARåœ¨ä¸Šæ–¹'
            }
        
        return jsonify({
            'success': True,
            'data': result,
            'count': len(result),
            'timestamp': datetime.now(pytz.timezone('Asia/Shanghai')).strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/sar-slope/sequence-statistics', methods=['GET'])
def get_sar_sequence_stats():
    """
    è·å–æ‰€æœ‰å¸ç§çš„SARåºå·ç»Ÿè®¡æ•°æ®
    
    è®¡ç®—é€»è¾‘:
    - ç»Ÿè®¡æœ€è¿‘24å°æ—¶å†…,æ¯ä¸ªåºå·çš„å¹³å‡SARå·®å€¼
    - å¤šå¤´åºå·:å·®å€¼è¶Šå¤§â†’åç©ºï¼›å·®å€¼è¶Šå°â†’åå¤š
    - ç©ºå¤´åºå·:å·®å€¼è¶Šå¤§â†’åå¤šï¼›å·®å€¼è¶Šå°â†’åç©º
    
    è¿”å›æ ¼å¼:
    {
        "success": true,
        "data": {
            "BTC": {
                "å¤šå¤´": {
                    1: {"avg_diff": -0.001234, "count": 5, "bias": "åå¤š"},
                    2: {"avg_diff": 0.002345, "count": 3, "bias": "åç©º"}
                },
                "ç©ºå¤´": {
                    1: {"avg_diff": 0.001234, "count": 4, "bias": "åå¤š"}
                }
            }
        }
    }
    """
    try:
        from sar_api_jsonl import get_sar_sequence_statistics
        
        # è·å–hourså‚æ•°(é»˜è®¤24å°æ—¶)
        hours = request.args.get('hours', 24, type=int)
        
        # è°ƒç”¨ç»Ÿè®¡å‡½æ•°
        result = get_sar_sequence_statistics(hours=hours)
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


@app.route('/api/sar-slope/bias-ratio-2h', methods=['GET'])
def get_sar_bias_ratio_2h_api():
    """
    è·å–æœ€è¿‘2å°æ—¶çš„å¤šç©ºå æ¯”(åŸºäº1å¤©åºå·ç»Ÿè®¡)
    
    è®¡ç®—é€»è¾‘:
    1. å…ˆè·å–1å¤©çš„åºå·ç»Ÿè®¡(æ¯ä¸ªåºå·çš„åå‘)ä½œä¸ºåŸºå‡†
    2. è¯»å–æœ€è¿‘2å°æ—¶çš„æ‰€æœ‰æ•°æ®ç‚¹
    3. å¯¹æ¯ä¸ªæ•°æ®ç‚¹,è¯†åˆ«å…¶åºå·
    4. æŸ¥æ‰¾è¯¥åºå·åœ¨1å¤©ç»Ÿè®¡ä¸­çš„åå‘
    5. ç»Ÿè®¡åå¤šå’Œåç©ºçš„æ•°é‡å¹¶è®¡ç®—æ¯”ä¾‹
    
    è¿”å›æ ¼å¼:
    {
        "success": true,
        "data": {
            "DOT": {
                "bullish_bias_count": 18,
                "bearish_bias_count": 6,
                "total_points": 24,
                "bullish_ratio": 75.0,
                "bearish_ratio": 25.0,
                "dominant_bias": "åå¤š"
            }
        }
    }
    """
    try:
        from sar_api_jsonl import get_sar_bias_ratio_2h
        
        # è°ƒç”¨è®¡ç®—å‡½æ•°
        result = get_sar_bias_ratio_2h()
        
        return jsonify(result)
        
    except Exception as e:
        import traceback
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        })


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
