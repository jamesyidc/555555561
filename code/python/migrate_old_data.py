#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šä»è€ç³»ç»Ÿå¯¼å…¥åŸºç¡€æ—¶é—´è½´æ•°æ®åˆ°æ–°ç³»ç»Ÿ

åªå¯¼å…¥åŸºç¡€æ•°æ®ï¼ˆ4æ¡çº¿çš„å¸ç§æ•°é‡ï¼‰ï¼Œå…¶ä»–ç»Ÿè®¡ç”±æ–°ç³»ç»Ÿè‡ªåŠ¨è®¡ç®—
"""

import json
import sqlite3
import sys
from datetime import datetime
from pathlib import Path

class DataMigration:
    def __init__(self):
        # è€ç³»ç»Ÿæ•°æ®è·¯å¾„
        self.old_data_path = Path('/home/user/webapp/data/support_resistance_daily')
        
        # æ–°ç³»ç»Ÿæ•°æ®åº“è·¯å¾„
        self.new_db_path = Path('/home/user/webapp/price_position_v2/config/data/db/price_position.db')
        
        # å­—æ®µæ˜ å°„
        self.field_mapping = {
            'scenario_1_count': 'support_48h',
            'scenario_2_count': 'support_7d',
            'scenario_3_count': 'pressure_48h',
            'scenario_4_count': 'pressure_7d'
        }
    
    def load_old_data(self, date_str):
        """
        ä»è€ç³»ç»ŸJSONLåŠ è½½æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        date_str: YYYY-MM-DDæ ¼å¼
        """
        # è½¬æ¢ä¸ºæ–‡ä»¶åæ ¼å¼ï¼šYYYYMMDD
        file_date = date_str.replace('-', '')
        file_path = self.old_data_path / f'support_resistance_{file_date}.jsonl'
        
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return []
        
        records = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    data = json.loads(line)
                    
                    # åªå¤„ç†snapshotç±»å‹çš„è®°å½•
                    if data.get('type') != 'snapshot':
                        continue
                    
                    snapshot_data = data['data']
                    
                    # ä½¿ç”¨åŒ—äº¬æ—¶é—´
                    snapshot_time = snapshot_data.get('snapshot_time_beijing') or snapshot_data.get('snapshot_time')
                    
                    # è·³è¿‡æ²¡æœ‰æ—¶é—´æˆ³çš„è®°å½•
                    if not snapshot_time:
                        continue
                    
                    # è½¬æ¢å­—æ®µå
                    record = {
                        'snapshot_time': snapshot_time,
                        'support_48h': snapshot_data.get('scenario_1_count', 0),
                        'support_7d': snapshot_data.get('scenario_2_count', 0),
                        'pressure_48h': snapshot_data.get('scenario_3_count', 0),
                        'pressure_7d': snapshot_data.get('scenario_4_count', 0)
                    }
                    
                    records.append(record)
                    
                except Exception as e:
                    print(f"âš ï¸ ç¬¬{line_num}è¡Œè§£æé”™è¯¯: {e}")
                    continue
        
        print(f"âœ… ä» {file_path.name} è¯»å– {len(records)} æ¡è®°å½•")
        return records
    
    def import_to_signal_timeline(self, records):
        """å¯¼å…¥æ•°æ®åˆ° signal_timeline è¡¨"""
        if not records:
            print("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦å¯¼å…¥")
            return 0
        
        conn = sqlite3.connect(self.new_db_path)
        cursor = conn.cursor()
        
        imported_count = 0
        skipped_count = 0
        
        for record in records:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("""
                    SELECT COUNT(*) FROM signal_timeline 
                    WHERE snapshot_time = ?
                """, (record['snapshot_time'],))
                
                if cursor.fetchone()[0] > 0:
                    skipped_count += 1
                    continue
                
                # æ’å…¥åŸºç¡€æ•°æ®
                # æ³¨æ„ï¼šsignal_type å’Œ signal_triggered ç”±åç«¯é‡‡é›†å™¨è®¡ç®—
                # è¿™é‡Œåªå¯¼å…¥åŸºç¡€çš„4æ¡çº¿æ•°æ®ï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼
                cursor.execute("""
                    INSERT INTO signal_timeline (
                        snapshot_time,
                        support_line_48h,
                        support_line_7d,
                        pressure_line_48h,
                        pressure_line_7d,
                        signal_type,
                        signal_triggered
                    ) VALUES (?, ?, ?, ?, ?, 'none', 0)
                """, (
                    record['snapshot_time'],
                    record['support_48h'],
                    record['support_7d'],
                    record['pressure_48h'],
                    record['pressure_7d']
                ))
                
                imported_count += 1
                
            except Exception as e:
                print(f"âŒ æ’å…¥é”™è¯¯: {record['snapshot_time']} - {e}")
                continue
        
        conn.commit()
        conn.close()
        
        print(f"âœ… å¯¼å…¥å®Œæˆ: {imported_count} æ¡æ–°è®°å½•, {skipped_count} æ¡å·²å­˜åœ¨ï¼ˆè·³è¿‡ï¼‰")
        return imported_count
    
    def migrate_date(self, date_str):
        """è¿ç§»æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹è¿ç§»æ—¥æœŸ: {date_str}")
        print(f"{'='*60}")
        
        # 1. ä»è€ç³»ç»ŸåŠ è½½æ•°æ®
        records = self.load_old_data(date_str)
        
        if not records:
            print(f"âš ï¸ {date_str} æ²¡æœ‰å¯ç”¨æ•°æ®")
            return False
        
        # æ˜¾ç¤ºæ•°æ®èŒƒå›´
        times = [r['snapshot_time'] for r in records]
        print(f"ğŸ“Š æ—¶é—´èŒƒå›´: {times[0]} ~ {times[-1]}")
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   - æ€»è®°å½•æ•°: {len(records)}")
        
        # 2. å¯¼å…¥åˆ°æ–°ç³»ç»Ÿ
        imported = self.import_to_signal_timeline(records)
        
        return imported > 0
    
    def verify_import(self, date_str):
        """éªŒè¯å¯¼å…¥çš„æ•°æ®"""
        print(f"\n{'='*60}")
        print(f"éªŒè¯å¯¼å…¥æ•°æ®: {date_str}")
        print(f"{'='*60}")
        
        conn = sqlite3.connect(self.new_db_path)
        cursor = conn.cursor()
        
        # ç»Ÿè®¡å¯¼å…¥çš„æ•°æ®
        cursor.execute("""
            SELECT 
                COUNT(*) as total,
                MIN(snapshot_time) as first_time,
                MAX(snapshot_time) as last_time
            FROM signal_timeline
            WHERE DATE(snapshot_time) = ?
        """, (date_str,))
        
        result = cursor.fetchone()
        
        print(f"âœ… æ•°æ®åº“ä¸­çš„è®°å½•:")
        print(f"   - æ€»æ•°: {result[0]}")
        print(f"   - ç¬¬ä¸€æ¡: {result[1]}")
        print(f"   - æœ€åä¸€æ¡: {result[2]}")
        
        # æŸ¥çœ‹å‰5æ¡å’Œå5æ¡
        cursor.execute("""
            SELECT snapshot_time, support_line_48h, support_line_7d, pressure_line_48h, pressure_line_7d
            FROM signal_timeline
            WHERE DATE(snapshot_time) = ?
            ORDER BY snapshot_time
            LIMIT 5
        """, (date_str,))
        
        print(f"\nå‰5æ¡æ•°æ®:")
        for row in cursor.fetchall():
            print(f"   {row[0]}: æ”¯æ’‘48h={row[1]}, æ”¯æ’‘7d={row[2]}, å‹åŠ›48h={row[3]}, å‹åŠ›7d={row[4]}")
        
        cursor.execute("""
            SELECT snapshot_time, support_line_48h, support_line_7d, pressure_line_48h, pressure_line_7d
            FROM signal_timeline
            WHERE DATE(snapshot_time) = ?
            ORDER BY snapshot_time DESC
            LIMIT 5
        """, (date_str,))
        
        print(f"\nå5æ¡æ•°æ®:")
        for row in cursor.fetchall():
            print(f"   {row[0]}: æ”¯æ’‘48h={row[1]}, æ”¯æ’‘7d={row[2]}, å‹åŠ›48h={row[3]}, å‹åŠ›7d={row[4]}")
        
        conn.close()

def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("æ•°æ®è¿ç§»è„šæœ¬ï¼šè€ç³»ç»Ÿ â†’ æ–°ç³»ç»Ÿ")
    print("åªå¯¼å…¥åŸºç¡€æ—¶é—´è½´æ•°æ®ï¼ˆ4æ¡çº¿çš„å¸ç§æ•°é‡ï¼‰")
    print("="*60)
    
    # è¦è¿ç§»çš„æ—¥æœŸ - å¯¼å…¥æœ‰ä¸°å¯Œæ•°æ®çš„æ—¥æœŸ
    test_dates = [
        '2026-01-28',  # 2330æ¡éé›¶è®°å½•
        '2026-01-29',  # 1306æ¡éé›¶è®°å½•
        '2026-01-31',  # 1210æ¡éé›¶è®°å½•
        '2026-02-01',  # 101æ¡éé›¶è®°å½•
        '2026-02-02',  # 384æ¡éé›¶è®°å½•
    ]
    
    migrator = DataMigration()
    
    success_count = 0
    for date_str in test_dates:
        try:
            if migrator.migrate_date(date_str):
                success_count += 1
                migrator.verify_import(date_str)
        except Exception as e:
            print(f"âŒ è¿ç§» {date_str} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*60}")
    print(f"è¿ç§»å®Œæˆ: {success_count}/{len(test_dates)} ä¸ªæ—¥æœŸæˆåŠŸ")
    print(f"{'='*60}")
    
    return success_count == len(test_dates)

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
